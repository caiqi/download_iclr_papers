<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" class="no-js"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>EDDI: Efficient Dynamic Discovery of High-Value Information with Partial VAE | OpenReview</title>
  <meta name="description" content="" />

      <meta name="citation_title" content="EDDI: Efficient Dynamic Discovery of High-Value Information with Partial VAE" />
        <meta name="citation_author" content="Anonymous" />
      <meta name="citation_publication_date" content="2018/09/27" />
      <meta name="citation_online_date" content="2018/09/27" />
      <meta name="citation_pdf_url" content="https://openreview.net/pdf?id=HJl0jiRqtX" />
      <meta name="twitter:card" content="summary" />
      <meta name="twitter:site" content="@openreviewnet" />
      <meta name="og:title" content="EDDI: Efficient Dynamic Discovery of High-Value Information with..." />
      <meta name="og:description" content="Making decisions requires information relevant to the task at hand. Many real-life decision-making situations allow acquiring further relevant information at a specific cost. For example, in..." />
      <meta name="og:image" content="https://openreview.net/static/images/openreview_logo_512.png" />

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans:400,400i,700,700i" />

  <link rel="stylesheet" href="/static/css/bootstrap.min.css" />
  <link rel="stylesheet" href="/static/css/jquery-ui.min.css" />
  <link rel="stylesheet" href="/static/css/main.min.css" />
</head>

<body class="forum">
  <nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
  
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand home push-link" href="/"><strong>OpenReview</strong>.net</a>
      </div>
  
      <div id="navbar" class="navbar-collapse collapse">
        <form class="navbar-form navbar-left profile-search" role="search">
          <div class="form-group has-feedback">
            <input id="search_input" type="text" class="form-control ui-autocomplete-input" placeholder="Search ICLR 2019 Conference" autocomplete="off" />
            <span class="glyphicon glyphicon-search form-control-feedback" aria-hidden="true"></span>
          </div>
  
          <input id="search_group" type="hidden" value="ICLR.cc/2019/Conference" />
          <input id="search_content" type="hidden" value="all" />
        <ul id="ui-id-1" tabindex="0" class="ui-menu ui-widget ui-widget-content ui-autocomplete ui-front" style="display: none;"></ul></form>
  
        <ul class="nav navbar-nav navbar-right">
        
            <li id="user-menu"><a href="/login">Login</a></li>
        </ul>
      </div>
  
    </div>
  </nav>

  <div id="or-banner" class="banner" style="">
  <div class="container">
    <div class="row">
      <div class="col-xs-12"><a href="/group?id=ICLR.cc/2019/Conference" title="Venue Homepage"><img class="icon" src="/static/images/arrow_left.svg" /> Go to <strong>ICLR 2019 Conference</strong> homepage</a></div>
    </div>
  </div>
</div>
<div id="flash-message-container" class="alert alert-danger" role="alert" style="display: none;">
  <div class="container">
    <div class="row">
      <div class="col-xs-12">
        <div class="alert-content">
          <button type="button" class="close" aria-label="Close"><span aria-hidden="true">×</span></button>
        </div>
      </div>
    </div>
  </div>
</div>

<div class="container">
  <div class="row">
    <div class="col-xs-12">
      <main id="content" class="clearfix openbanner-visible legacy-styles"><div id="note_HJl0jiRqtX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>EDDI: Efficient Dynamic Discovery of High-Value Information with Partial VAE</a> <a class="note_content_pdf" href="/pdf?id=HJl0jiRqtX" title="Download PDF" target="_blank"><img src="/static/images/pdf_icon_blue.svg" /></a> </h2></div><div class="meta_row"><span class="signatures">Anonymous</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">28 Sep 2018 (modified: 19 Nov 2018)</span><span class="item">ICLR 2019 Conference Blind Submission</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span><span class="item"><a class="action-bibtex-modal" data-bibtex="@inproceedings{    &#10;anonymous2019eddi:,    &#10;title={EDDI: Efficient Dynamic Discovery of High-Value Information with Partial VAE},    &#10;author={Anonymous},    &#10;booktitle={Submitted to International Conference on Learning Representations},    &#10;year={2019},    &#10;url={https://openreview.net/forum?id=HJl0jiRqtX},    &#10;note={under review}    &#10;}">Show Bibtex</a></span><a class="note_content_pdf item" href="/revisions?id=HJl0jiRqtX" target="_blank">Show Revisions</a></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Abstract: </span><span class="note_content_value">Making decisions requires information relevant to the task at hand. Many real-life decision-making situations allow acquiring further relevant information at a specific cost. For example, in assessing the health status of a patient we may decide to take additional measurements such as diagnostic tests or imaging scans before making a final assessment. More information that is relevant allows for better decisions but it may be costly to acquire all of this information.  How can we trade off the desire to make good decisions with the option to acquire further information at a cost? To this end, we propose a principled framework, named EDDI (Efficient Dynamic Discovery of high-value Information), based on the theory of Bayesian experimental design. In EDDI we propose a novel partial variational autoencoder (Partial VAE), to efficiently handle missing data over varying subsets of known information. EDDI combines this Partial VAE with an acquisition function that maximizes expected information gain on a set of target variables. EDDI is efficient and demonstrates that dynamic discovery of high-value information is possible; we show cost reduction at the same decision quality and improved decision quality at the same cost in benchmarks and in two health-care applications.. We believe there is great potential for realizing these gains in real-world decision support systems.</span></div><div class="note_contents"><span class="note_content_field">Keywords: </span><span class="note_content_value">active variable selection, missing data, amortized inference</span></div><div class="reply_row clearfix"><div class="item" id="reply_count">8 Replies</div></div></div><hr class="small" /><div id="note_children"><div class="note_with_children"><div id="note_S1xhkTNxAX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Summary of the new revision</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HJl0jiRqtX&amp;noteId=S1xhkTNxAX"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper666 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">19 Nov 2018</span><span class="item">ICLR 2019 Conference Paper666 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Dear all, 

We have revised our paper utilizing all the feedback. We thus summarize main the changes in our revised paper below for your references. 
 
* Based on the comment of Reviewer 3, we have moved the introduction and discussion of recurrent PNs to the Appendix B.5. We have also revised the presentation of the Partial VAE include Figure 1. We have also updated all the experimental results with non-recurrent PN in the main paper.
* We have added statistical tests for model comparison in Appendix B. 2. (Reviewer 3), all the improvement is statistically significant. 
* We have added RMSE plots in Appendix B.2.5, as requested by Reviewer 1 and show that using RMSE, the conclusion is consistent as using predictive likelihood.
* We have discussed a new baseline that utilizing lasso in Appendix B.2.5, as suggested by Reviewer 2;
* We have added a discussion on the active feature acquisition (AFA) in Section 2.2 and clarified the different of AFA and our problem setting. 
* We have added the introduction of VAEs and amortized inference in Section 3.2, as required by Reviewer 1;
* We have added brief descriptions of image inpainting task in Section 4.1 (Reviewer 1).
</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_HJxgYLy-pX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Interesting but difficult to read</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HJl0jiRqtX&amp;noteId=HJxgYLy-pX"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper666 AnonReviewer1</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">08 Nov 2018</span><span class="item">ICLR 2019 Conference Paper666 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">The paper presents an algorithm EDDI that uses a a partial VAE and does active feature selection. The authors show quite a bit of experiments that seem to indicate the approach gives positive results.  However, since this is not my main area of expertise I do not know if these tasks are standard evaluation for this task.

For instance in Section 4.3, 4.4 why don't the authors plot accuracy as a function of steps/number of variables observed. That would seem much more useful than log likelihood.

In general, I found the methodology in the paper to be difficult to understand and not enough background was given.
I think the paper would be clearer if it was more self contained.

-For instance, I found much of Section 3 to not have enough background. The authors use lots of terminology around VAEs but don't give enough rigorous background so the paper doesn't feel self contained. 

-The same is true regarding "amortized inference" which I also feel isn't rigorously defined anywhere but often discussed. 

-The task for Section 4.1 (image inpainting) is not quite defined.</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">5: Marginally below acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_H1lvv_feA7" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Revision uploaded</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HJl0jiRqtX&amp;noteId=H1lvv_feA7"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper666 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">19 Nov 2018</span><span class="item">ICLR 2019 Conference Paper666 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Thank reviewer 1 for appreciating and application and the positive results. We have replied the concerns to clarify possible misunderstandings and updated the paper accordingly. The original review is indented using &gt;. 

&gt; Review: The paper presents an algorithm EDDI that uses a a partial VAE and does active &gt; feature selection. The authors show quite a bit of experiments that seem to indicate the 
&gt; approach gives positive results.  However, since this is not my main area of expertise I do &gt; not know if these tasks are standard evaluation for this task.

&gt; For instance in Section 4.3, 4.4 why don't the authors plot accuracy as a function of            &gt; steps/number of variables observed. That would seem much more useful than log 
&gt; likelihood.

Apart from existing results, we have reported test RMSE as suggested in the Appendix.B.2.5 for all UCI experiments in the revised version of the paper. Accuracy in terms of RMSE is consistent with the reported result using predictive log likelihood. Additionally, we would like to clarify that, log likelihood is the common standard when evaluating the performance related to generative models [1,2]. Compared with accuracy metric such as RMSE, log likelihood also account for model uncertainties (of the posterior on latent variable, z), which is very crucial in the practical application of active variable learning.

Reference:
[1] Kingma, Diederik P., and Max Welling. "Auto-encoding variational Bayes." arXiv preprint arXiv:1312.6114 (2013).
[2] Gregor, Karol, et al. "Draw: A recurrent neural network for image generation." arXiv preprint arXiv:1502.04623 (2015).
[3] Kingma, Diederik P., and Prafulla Dhariwal. "Glow: Generative flow with invertible 1x1 convolutions." arXiv preprint arXiv:1807.03039 (2018).

&gt; In general, I found the methodology in the paper to be difficult to understand and not enough background was given.
&gt; I think the paper would be clearer if it was more self-contained.

&gt; For instance, I found much of Section 3 to not have enough background. The authors use &gt; lots of terminology around VAEs but don't give enough rigorous background so the paper 
&gt; doesn't feel self contained. 

&gt; The same is true regarding "amortized inference" which I also feel isn't rigorously defined 
&gt; anywhere but often discussed. 

Thanks for your comment. We have revised the paper and added a paragraph “VAE and amortized inference” in section 3.2 which is a brief, self-contained introduction to VAEs and amortized inference.

&gt; The task for Section 4.1 (image inpainting) is not quite defined.

We have added a short description in 4.1 to make the task more clarified and well-defined. 
</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div><div class="note_with_children"><div id="note_B1lI6Wnah7" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>EDDI: EFFICIENT DYNAMIC DISCOVERY OF HIGH-VALUE INFORMATION WITH PARTIAL VAE</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HJl0jiRqtX&amp;noteId=B1lI6Wnah7"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper666 AnonReviewer3</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">05 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper666 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">The authors present an information discovery approach based on (partial) variational autoencoders and an information theoretic acquisition function that seeks to maximize the expected information gain over a set of unobserved variables. Results are presented on image inpainting, UCI datasets and health data, namely ICU and NHANES.

It is not clear why multiple recurrent steps improve perfromance. This is not conceptually justified and empirically (see Figure 8), it is also unclear whether PNP5 significantly outperforms PNP1. Further, results seem to support that PNP is always better than PN, so why introduce the methodology around PN or even present it at all. Note that the authors do not offer an explanation about the perfromance differences between PN and PNP.

In the inpainting regions section, the authors write about well-calibrated uncertainties without any context. What do they mean by calibration, well-calibrated and how can they support their claim about it?

In Figure 3 it is not clear that PNP+Ours outperforms PNP+SING. For Boston hosing seems to be marginally better but the error bars (which I assume are standard deviations, not stated) make difficult to ascertain whether the differences are significant. Although I understand the value of having "personalized" decisions, one wonders whether this personalization comes with any generalizable measurable gains given the results.

The results in Table 2 need to be clarified and further explained. 1) what are the error bars, considering multiple runs and datasets? 2) How can EDDI be so much better than SING when individual AUICs in Tables 6-11, the only significant difference (accounting for error bars) is on Boston data? 3) according to Tables 6-11, PNP is only the best in 1 of 5 datasets, so how come is the overall beast by a large margin? This being said, the results in Table 2 are at best misleading.

In Table 4, how can PNP-EDDI be so much better than PNP-SING, when in Figure 6 error bars overlap almost everywhere?

I enjoyed reading the paper, the motivation is clear and the problem is important. The approach is modestly novel compared to existing approaches and in general well explained despite the fact that the need for multiple recurrent steps is not well justified and the differences between PN and PNP, advantages/disadvantages and when to use each are not described or explored in the experiments.</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">5: Marginally below acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_rJlodiMx07" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Comment Part 2 On significance of experimental results</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HJl0jiRqtX&amp;noteId=rJlodiMx07"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper666 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">19 Nov 2018</span><span class="item">ICLR 2019 Conference Paper666 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">
&gt; The results in Table 2 need to be clarified and further explained. 1)
&gt; what are the error bars, considering multiple runs and datasets? 

We have revised accordingly in the paper. Regarding the error bars: in Table 2, for each run, we run all active learning strategies on each data point of each dataset. Then, we rank all strategies on an individual basis, which gives us $R * (\sum_j N_j)$ different rankings, where N_j is the size of the test set in the j-th dataset, and R is the number of runs. Finally, we simply compute the mean and standard error statistics based on these individual rankings. This procedure is explained in detail in section 4.2 in our revised version. 

&gt;2) How can EDDI be so much better than SING when individual AUICs in
&gt; Tables 6-11, the only significant difference (accounting for error
&gt; bars) is on Boston data? 

This is a good question. We have included discussions regarding this issue in Appendix B.2.2 and B.2.3. In particular, it seems that the avg. AUIC results in Tables 6-11  contradicts the avg. ranking of AUIC results in Table 2 of the main text. However, this is not the case. In Tables 6-11,  AUIC numbers only provide a simplified statistics of *marginal performances* of each method.  

On the contrary, the performance comparison problem is an example of the so-called *paired samples*, which refers to the situation that different algorithms are evaluated on exactly the same set of test data points. This introduces correlations between the performances of different algorithms. The average AUIC ranking measure actually takes into account this *joint performance* of all methods, meaning that ranking is a function of the performance of all methods.  With this additional information of correlations, this gives a more accurate evaluation regarding the actual performance of different methods. Notably, in the practical scenario of active variable selection, the latter setting is more sensible and fare.

The above conjecture is further validated and confirmed by applying the nonparametric statistical test on the performance results, namely the Wilcoxon signed-rank significance test on the performance samples of different methods, which are detailed in Appendix B.2.2 and B.2.3. Wilcoxon test is a very powerful statistical test which includes the information of the joint distribution in *paired samples*. In our case, the term *paired samples* refers to the situation that different algorithms are evaluated on exactly the same set of test data points, which introduces correlations between the performances of different algorithms. 



&gt; 3) according to Tables 6-11, PNP is only the
&gt; best in 1 of 5 datasets, so how come is the overall beast by a large
&gt; margin? This being said, the results in Table 2 are at best
&gt; misleading.

We believe this has been addressed in our previous reply on significance. 

Additionally, we would like to point out that the purpose of Tables 6-11 is to provide supplementary intuitive support that, our proposed methods, i.e., EDDI (+ PNP or PN) give the best result in 4 out of 6 datasets, compared with ZI based methods that currently dominates missing data problems in generative models. Which one to choose between PN and PNP depends on the application need.

&gt; In Table 4, how can PNP-EDDI be so much better than PNP-SING, when in
&gt; Figure 6 error bars overlap almost everywhere?

Please refer to our previous reply regarding the PNP-SING, the *joint performance* evaluation metric, and the Wilcoxon tests.

&gt; I enjoyed reading the paper, the motivation is clear and the problem
&gt; is important. The approach is modestly novel compared to existing
&gt; approaches and in general well explained despite the fact that the
&gt; need for multiple recurrent steps is not well justified and the
&gt; differences between PN and PNP, advantages/disadvantages and when to
&gt; use each are not described or explored in the experiments.

We are grateful that you enjoyed reading the paper and point out the part of the paper that needs clarification. We hope that we have fully addressed your concerns in the current revised version of the paper. Please let us know if you have further questions. 
</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_rke_8oGgCm" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Comment Part 1: on methodologies</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HJl0jiRqtX&amp;noteId=rke_8oGgCm"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper666 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">19 Nov 2018</span><span class="item">ICLR 2019 Conference Paper666 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">We thank reviewer 3 for the constructive review. We have replied the concerns to clarify possible misunderstandings and updated the paper accordingly. The original review is indented using &gt;. 


&gt; It is not clear why multiple recurrent steps improve perfromance. This
&gt; is not conceptually justified and empirically (see Figure 8), it is
&gt; also unclear whether PNP5 significantly outperforms PNP1. Further,
&gt; results seem to support that PNP is always better than PN, so why
&gt; introduce the methodology around PN or even present it at all. 

Thanks for your comment. We have agreed that the multiple recurrent steps is not crucial for performance improvement. Importantly, we agree that for the whole framework, the recurrent structure of PN is not critical for the presentation of the entire EDDI framework. Following your advice, we have replaced all PN5 result with the PN1 result in all the experiments in the paper. We have moved the recurrent PN to the Appendix as a possible extension and added a short discussion on whether one should use the recurrent version. 

&gt; Note that the authors do not offer an explanation about the performance
&gt; differences between PN and PNP.

We treat PN and PNP are two different settings of our framework. In our experiments, PNP setting performs better than PN setting for most of the evaluation.  Additionally, we have analyzed the use of PNP structure in Appendix C.1. In short, we have shown that PNP parameterization actually combines ZI-VAE (which dominates the applications of VAEs on missing data)  with PN-VAE. Therefore, we expect that PNP will enjoy the advantages from both PN and ZI, hence improve the performance. This conjecture is confirmed in the experimental results that you have mentioned.


&gt; In the inpainting regions section, the authors write about
&gt; well-calibrated uncertainties without any context. What do they mean
&gt; by calibration, well-calibrated and how can they support their claim
&gt; about it?

Thanks for pointing this out. We changed to “better-estimated uncertainties” instead of “well-calibrated uncertainties” to be more technically precise in the revised version of the paper.  We have also added more explanation about it. In this case, the term "better-estimated uncertainty" is reflected by the quality of the samples generated from p(x_U|x_O). Therefore, the quality of model uncertainty is quantitatively evaluated by the test ELBO (available in Table 1, and visualized in Figure 2) of inpainting on the partially observed MNIST dataset (averaged over test set). This is calculated by $1/(N) \sum_{n=1}^{N}  ELBO(n|x_O) $, where N is the size of the test set, and ELBO(n|x_O) corresponds to the conditional ELBO of the n-th data point (where the inference net q is conditioned on x_O). Please refer to the revised paper for details.

&gt; In Figure 3 it is not clear that PNP+Ours outperforms PNP+SING. For
&gt; Boston hosing seems to be marginally better but the error bars (which
&gt; I assume are standard deviations, not stated) make difficult to
&gt; ascertain whether the differences are significant. Although I
&gt; understand the value of having "personalized" decisions, one wonders
&gt; whether this personalization comes with any generalizable measurable
&gt; gains given the results.

Thank you for the comment. In all figures in the revised version of the paper,  error bars represent standard errors.  We have also performed the significance test and reported the results in Appendix B.2.3 (explained in detail for our reply for the later comments).  Our method is significantly better. 

Additionally,  if you also look at the enlarged subplot included in Fig 3 and Figure 9 in Appendix B.2.4, it is generally significant that the PNP+Ours curve is below the PNP+SING. The first variable selection step should be ignored when conducting such comparison since in theory, both methods should select exactly the same variable.

Here we would also like to first emphasize that the proposed SING-ordering method is already a very strong alternative setting of our proposed method. First, it makes use of the same Partial VAE information of our personalized method. Secondly,  in SING-ordering, it assumes that the whole test set is available *at the same time*:  the objective of the SING is to find the average information reward for the *whole test set* at each step, which is very unrealistic in practice. This gave SING unfair advantages over EDDI.
</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div><div class="note_with_children"><div id="note_HJgQ25LF27" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>A nice application model but some unclear points</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HJl0jiRqtX&amp;noteId=HJgQ25LF27"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper666 AnonReviewer2</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">02 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper666 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">The paper proposes Partial VAE to handle missing data and a variable-wise active learning method. The model combines Partial VAE with the acquisition function to design an intelligent information acquisition system. The paper nicely combines the missing value problem with an active learning strategy to in an acquisition pipeline and demonstrate the effectiveness on several datasets.

I have following comments/questions:

1.  Does p(x_i | z) include parameters? How do these parameters be trained?

2. Does sample from p(x_i | x_o) follow by sampling z from q(z|x_o) then sample x_i from p(x_i | z)? How to sample from p(x_\phi | x_i, x_o) in Eq (7)?

3. In Eq (9), it uses q(z_i|x_o), q(z_i | x_i, x_o),  q(z_i | x_i, x_o, x_\phi) while in Eq (4) it only shows how to learn q(z|x_o). Does it need to learn multiple partial inference networks for all combination of i and \phi ?

4. The comparison with similar algorithms seems to be weak in the experiment section. RAND is random feature selection, and SING is global feature selection by using the proposed method. These comparison methods cannot provide enough information on how well the proposed methods performs. There are plenty of works in the area of “active feature acquisition” and also many works in feature selection dated back to Lasso which should be considered as comparison targets.

5. In the “personalized” implementation of EDDI on each data instances, is the model trained independently for each data point or share some parameters across different data? If so, what are the shared parameters?</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">6: Marginally above acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_rk-Q2zgA7" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Thank you for your reviews. We have reivised the paper accoridingly and added the new baseline.</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HJl0jiRqtX&amp;noteId=rk-Q2zgA7"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper666 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">19 Nov 2018</span><span class="item">ICLR 2019 Conference Paper666 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">We thank you for your support of our work and valuable feedback. We have clarified all the concerns accordingly in the paper.  The original review is indented using &gt;. 


&gt; 1.  Does p(x_i | z) include parameters? How do these parameters be trained?

Yes,  p(x_i|z) is the generator component of our partial VAE, and is trained by optimizing the partial variational bound on already observed data (with missing data), we have clarified this in our revised version of the paper .

&gt; 2. Does sample from p(x_i | x_o) follow by sampling z from q(z|x_o)
&gt; then sample x_i from p(x_i | z)? How to sample from p(x_\phi | x_i,
&gt; x_o) in Eq (7)?

Yes, to sample from p(x_i | x_o), we first sample z from q(z|x_o), and then sample x_i from p(x_i | z). In the case of p(x_\phi | x_i,x_o) in Eq (7), as indicated after Eq(8), we first sample z from q(z|x_o, x_i), then sample p(x_\phi|z), since x_\phi is also an element of the set of all possible variables, x.


&gt; 3. In Eq (9), it uses q(z_i|x_o), q(z_i | x_i, x_o),  q(z_i | x_i,
&gt; x_o, x_\phi) while in Eq (4) it only shows how to learn q(z|x_o). Does
&gt; it need to learn multiple partial inference networks for all
&gt; combination of i and \phi ?

No, it does not. This is one of the main novelty of our approach: we call our partial VAE approach an "amortized" partial inference method since our partial VAE parameterization of q(z|x_o) is able to handle all possible lengths of features to be conditioned on. During training (due to missingness in data), the lengths of x_o^n (where we use $n$ to indicate the index of the data point in the training set here) are different from each other. This gives q(z|x_o) the ability to generalize to  q(z_i|x_o), q(z_i | x_i, x_o),  and q(z_i | x_i,x_o, x_\phi) on test data during test time, without the need for training multiple networks.

&gt; 4. The comparison with similar algorithms seems to be weak in the
&gt; experiment section. RAND is random feature selection, and SING is
&gt; global feature selection by using the proposed method. These
&gt; comparison methods cannot provide enough information on how well the
&gt; proposed methods performs. There are plenty of works in the area of
&gt; “active feature acquisition” and also many works in feature selection
&gt; dated back to Lasso which should be considered as comparison targets.

Thank you for your suggestion. 

We have added a new baseline adapted from LASSO in Appendix B.2.6 with UCI dataset, since LASSO requires fully observed data, and only works in problems with one-dimensional outputs. As LASSO is linear and non-probabilistic, for more fair comparison, we use the set of selected features returned by the LASSO to construct variable selection strategy and use the Partial VAE to evaluate predictive likelihoods. Please refer to our revised paper (Section 4.2) for details and results.

We would like to point out that our framework is different traditional feature selection such as LASSO.  For traditional feature selection methods,  they are non-sequential and they require fully observed dataset for both training and testing which is not the case for our problem setting. Additionally, their goal is also to choose a global subset of features from fully observed data to obtain the best performance instead of select the most informative feature with any given partial observation. 

Our problem setting also differs from active feature acquisition (AFA) methods. As discussed in our revised paper (Section 2.2),  AFA mainly studies the optimization of *optimal training set* that would result in the best classifier (model), under limited budget of costs. On the contrary, our framework studies the problem: given a pretrained model, how to identify and acquire high value information under uncertainty, with minimal costs. Hence, AFA can not be directly applied and compared. Also, AFA requires fully observed variables at test time, while our framework does not require this assumption. Last but not least, the realization of these framework relies on various heuristics and suffer from very limited scalability.  To the best of our knowledge, DRAL is the only prior work that shares the same problem setting. We have only compared DRAL to our EDDI on a single UCI dataset since DRAL is not scalable.

&gt; 5. In the “personalized” implementation of EDDI on each data
&gt; instances, is the model trained independently for each data point or
&gt; share some parameters across different data? If so, what are the
&gt; shared parameters?

The Partial VAE part of EDDI is trained on the training set. In the active variable selection experiments, all test data that are used to evaluate EDDI are never seen by the model before.  All model parameters are shared across different data points. In our paper, "personalized" simply means we evaluate Equation (9) on each data point individually.


We hope that we have fully addressed your concerns in the current revised version of the paper. Please let us know if you have further questions. 
</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div></div></main></div>
  </div>
</div>


    <!-- Footer -->
    <footer class="sitemap">
      <div class="container">
        <div class="row hidden-xs">
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/venues">All Venues</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="/contact">Contact</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
    
        <div class="row visible-xs-block">
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/contact">Contact</a></li>
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
      </div>
    </footer>
    
    <footer class="sponsor">
      <div class="container">
        <div class="row">
          <div class="col-sm-10 col-sm-offset-1">
            <p class="text-center">
              OpenReview is created by the <a href="http://www.iesl.cs.umass.edu/" target="_blank">Information Extraction and Synthesis Laboratory</a>, College of Information and Computer Science, University of Massachusetts Amherst. We gratefully acknowledge the support of the OpenReview sponsors:  Google,  Facebook, NSF, the University of Massachusetts Amherst Center for Data Science, and Center for Intelligent Information Retrieval, as well as the Google Cloud Platform for donating the computing and networking services on which OpenReview.net runs.
            </p>
          </div>
        </div>
      </div>
    </footer>

  <div id="feedback-modal" class="modal fade" tabindex="-1" role="dialog">
    <div class="modal-dialog">
      <div class="modal-content">
        <div class="modal-header">
          <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button>
          <h3 class="modal-title">Send Feedback</h3>
        </div>
        <div class="modal-body">
          <p>Enter your feedback below and we'll get back to you as soon as possible.</p>
          <form action="/feedback" method="POST">
            <div class="form-group">
              <input type="email" name="from" class="form-control" placeholder="Email" />
            </div>
            <div class="form-group">
              <input type="text" name="subject" class="form-control" placeholder="Subject" />
            </div>
            <div class="form-group">
              <textarea name="message" class="form-control feedback-input" rows="5" placeholder="Message" required=""></textarea>
            </div>
          <ul id="ui-id-2" tabindex="0" class="ui-menu ui-widget ui-widget-content" style="display: none;"></ul></form>
        </div>
        <div class="modal-footer">
          <button type="button" class="btn btn-default" data-dismiss="modal">Cancel</button>
          <button type="button" class="btn btn-primary">Send</button>
        </div>
      </div>
    </div>
  </div>

  <script type="text/javascript" async="" src="https://www.google-analytics.com/analytics.js"></script><script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js"></script>
  <script>window.jQuery || document.write('&lt;script src="/static/js/vendor/jquery-2.2.4.min.js"&gt;&lt;\/script&gt;')</script>

  <script src="/static/dist/vendor.min.js"></script>
  <script src="/static/dist/templates.min.js"></script>
  <script src="/static/dist/openreview.min.js"></script>

    <script>window.legacyScripts = true;</script>


    <script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-108703919-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() { dataLayer.push(arguments); }
      gtag('js', new Date());
      gtag('config', 'UA-108703919-1');
    </script>


<div role="status" aria-live="assertive" aria-relevant="additions" class="ui-helper-hidden-accessible"></div></body></html>
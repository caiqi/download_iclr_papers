<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" class="no-js"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>Successor Uncertainties: exploration and uncertainty in temporal difference learning | OpenReview</title>
  <meta name="description" content="" />

      <meta name="citation_title" content="Successor Uncertainties: exploration and uncertainty in temporal difference learning" />
        <meta name="citation_author" content="Anonymous" />
      <meta name="citation_publication_date" content="2018/09/27" />
      <meta name="citation_online_date" content="2018/09/27" />
      <meta name="citation_pdf_url" content="https://openreview.net/pdf?id=BklACjAqFm" />
      <meta name="twitter:card" content="summary" />
      <meta name="twitter:site" content="@openreviewnet" />
      <meta name="og:title" content="Successor Uncertainties: exploration and uncertainty in temporal..." />
      <meta name="og:description" content="We consider the problem of balancing exploration and exploitation in sequential decision making problems. To explore efficiently, it is vital to consider the uncertainty over all consequences of a..." />
      <meta name="og:image" content="https://openreview.net/static/images/openreview_logo_512.png" />

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans:400,400i,700,700i" />

  <link rel="stylesheet" href="/static/css/bootstrap.min.css" />
  <link rel="stylesheet" href="/static/css/jquery-ui.min.css" />
  <link rel="stylesheet" href="/static/css/main.min.css" />
</head>

<body class="forum">
  <nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
  
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand home push-link" href="/"><strong>OpenReview</strong>.net</a>
      </div>
  
      <div id="navbar" class="navbar-collapse collapse">
        <form class="navbar-form navbar-left profile-search" role="search">
          <div class="form-group has-feedback">
            <input id="search_input" type="text" class="form-control ui-autocomplete-input" placeholder="Search ICLR 2019 Conference" autocomplete="off" />
            <span class="glyphicon glyphicon-search form-control-feedback" aria-hidden="true"></span>
          </div>
  
          <input id="search_group" type="hidden" value="ICLR.cc/2019/Conference" />
          <input id="search_content" type="hidden" value="all" />
        <ul id="ui-id-1" tabindex="0" class="ui-menu ui-widget ui-widget-content ui-autocomplete ui-front" style="display: none;"></ul></form>
  
        <ul class="nav navbar-nav navbar-right">
        
            <li id="user-menu"><a href="/login">Login</a></li>
        </ul>
      </div>
  
    </div>
  </nav>

  <div id="or-banner" class="banner" style="">
  <div class="container">
    <div class="row">
      <div class="col-xs-12"><a href="/group?id=ICLR.cc/2019/Conference" title="Venue Homepage"><img class="icon" src="/static/images/arrow_left.svg" /> Go to <strong>ICLR 2019 Conference</strong> homepage</a></div>
    </div>
  </div>
</div>
<div id="flash-message-container" class="alert alert-danger" role="alert" style="display: none;">
  <div class="container">
    <div class="row">
      <div class="col-xs-12">
        <div class="alert-content">
          <button type="button" class="close" aria-label="Close"><span aria-hidden="true">×</span></button>
        </div>
      </div>
    </div>
  </div>
</div>

<div class="container">
  <div class="row">
    <div class="col-xs-12">
      <main id="content" class="clearfix openbanner-visible legacy-styles"><div id="note_BklACjAqFm" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Successor Uncertainties: exploration and uncertainty in temporal difference learning</a> <a class="note_content_pdf" href="/pdf?id=BklACjAqFm" title="Download PDF" target="_blank"><img src="/static/images/pdf_icon_blue.svg" /></a> </h2></div><div class="meta_row"><span class="signatures">Anonymous</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">28 Sep 2018 (modified: 11 Oct 2018)</span><span class="item">ICLR 2019 Conference Blind Submission</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span><span class="item"><a class="action-bibtex-modal" data-bibtex="@inproceedings{    &#10;anonymous2019successor,    &#10;title={Successor Uncertainties: exploration and uncertainty in temporal difference learning},    &#10;author={Anonymous},    &#10;booktitle={Submitted to International Conference on Learning Representations},    &#10;year={2019},    &#10;url={https://openreview.net/forum?id=BklACjAqFm},    &#10;note={under review}    &#10;}">Show Bibtex</a></span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Abstract: </span><span class="note_content_value">We consider the problem of balancing exploration and exploitation in sequential decision making problems. To explore efficiently, it is vital to consider the uncertainty over all consequences of a decision, and not just those that follow immediately; the uncertainties need to be propagated according to the dynamics of the problem. To this end, we develop Successor Uncertainties, a probabilistic model for the state-action function of a Markov Decision Process that propagates uncertainties in a coherent and scalable way. Our model achieves this by combining successor features and online Bayesian uncertainty estimation. We relate our approach to other classical and contemporary methods for exploration and present an empirical analysis of successor uncertainties.</span></div><div class="reply_row clearfix"><div class="item" id="reply_count">3 Replies</div></div></div><hr class="small" /><div id="note_children"><div class="note_with_children"><div id="note_rJlwFp0g6X" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Experimental results are too preliminary to assess the contribution</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=BklACjAqFm&amp;noteId=rJlwFp0g6X"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper941 AnonReviewer1</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">08 Nov 2018</span><span class="item">ICLR 2019 Conference Paper941 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">Summary/contribution:
This paper focuses on the problem of incorporating uncertainty into RL. The primary contribution is exploring the use of successor features for uncertainty prediction over Q-values. The proposed approach builds on O’Donoghue et al. (2018). The authors provide experiments that demonstrate improved performance on a chain MDP environment and a Tree environment. 

Pros:
- I found this paper to be above average in terms of clarity.

Cons:
- The experiments evaluation is restricted to simplistic environments. The authors make an argument for why using successor features would be more "stable", but I found the experimental evidence to support this claim to be underwhelming. 

Justification for rating:
This paper does a good job of articulating an interesting approach to the exploration problem using successor representations.  In the current form however, it is really lacking in experimental evidence to support the main claims/contributions. Currently the domains considered are somewhat toy which I do not find convincing enough to demonstrate the effectiveness of their approach. 

Other:
- I would appreciate a discussion on the relationship to Machado et al. 2018 which explored count based exploration with successor representations. </span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">4: Ok but not good enough - rejection</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">3: The reviewer is fairly confident that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_HkxMSaBJ67" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Exploration using successor features representations</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=BklACjAqFm&amp;noteId=HkxMSaBJ67"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper941 AnonReviewer3</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">07 Nov 2018</span><span class="item">ICLR 2019 Conference Paper941 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">The paper proposes an exploration approach (either based on posterior sampling or optimism) based on successor features representation. A high probability ellipsoid confidence set (defined by the Gram matrix \Sigma_t) is estimated based on linear regression (using some features \phi) to the immediate reward function. Now for any policy \pi, a confidence interval for the Q-value of any policy \pi can be derived by application of the \psi transformation, where \psi = expected sum of discounted future \phi under \pi. The algorithm selects action by posterior sampling (or UCB) in the \psi-space. 

It would be interesting to see if this approach would converge to a good policy, maybe by doing a regret-based analysis. 
Unfortunately there is no such analysis in the paper. However my main complaint is the soundness of the approach, for two reasons:
- First it is not clear that the uncertainty in the Q-values decreases with time. Indeed the uncertainty on Q^{\pi}(s,a) corresponds to the width of the confidence ellipsoid in the direction of the successor features \psi^{\pi}(s,a). However, although we know that the uncertainty shrinks in the directions of the features \phi_t (when action a_t is chosen in state s_t) because we do regression of the reward function, we do not have the same property for \psi_t, which defines the Q-function. And it is not obvious that the confidence set in the direction of \psi_t would shrink at all. Thus it could be the case that the uncertainty on the Q-values will never decrease. 
- Second, since the successor features are learnt on-policy, the uncertainty on the Q-values (assuming we can estimate them) corresponds to a mixture of the policies which have been used in the past, but not to the policy that will be used from there on, because the policy is non stationary (since the uncertainty decreases as more information is collected). I would recommend to be very careful when defining and using the successor features by emphasizing the policy under which those features are defined. 

So in the end the contribution is mainly algorithmic. However I find it hard to say anything about the proposed approach, whether it improves over previous ones or not, specially because the experiments are limited to toy problems. Theoretical analysis or more complex experiments would make the paper stronger.
</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">5: Marginally below acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_rke8bVNonm" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Okay paper, but needs more substantiation</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=BklACjAqFm&amp;noteId=rke8bVNonm"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper941 AnonReviewer2</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">03 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper941 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">This paper tackles the classical exploration / exploitation problem in reinforcement learning.
The paper argues that it is necessary to propagate uncertainty correctly and argue that they can do so using the successor representation to compute the Bayesian posterior over Q-values conditioned on the data already observed.

Novelty:
This work is similar to “The uncertainty bellman equation” (UBE) (O’Donoghue et al. 2018) which adds a head to a regular DQN agent to predict a function u which is an upper bound of the variance of the posterior distribution over Q-values. The difference here is that the successor features are used here to predict Q-values and the function u.
The successor features can be seen as a discounted state occupancy of the current policy and carry information about the future. While the relation with the UBE is highlighted in section 4.6 an empirical evaluation between the two methods would also be needed.

Clarity: The method is detailed comparing to contextual bandit methods, the authors then argue that applying directly these methods to reinforcement learning case does not propagate uncertainty over several timesteps. While this indeed true it is misleading and imply that propagating uncertainty is not considered by current exploration methods in RL.

Soundness:
The method presented here is relatively reductive. The estimated posterior over the value function is correct only if the transition model P is already known, otherwise Equation 4 would also need to incorporate uncertainty over P. Similarly, as the authors point out, this doesn’t include the max operation. At best, we are learning a posterior over the value function for a fixed policy, for when only the reward is unknown.

As a whole, the authors argue that their method allows a better propagation of Q-values uncertainty but provide little theoretical or experimental evidence that would back this claim.

From a deep RL perspective, the features \phi^l only carry local information. The authors argue that this leads to more stable features as these feature do not depend on the current policy. However it also means that in a sparse reward setting the reward observed would be zero most of the time and no useful features would be learned. In practice methods using the successor representation usually share parts of the network with other tasks to improve representation learning (see e.g. Figure 1 of Machado et al., Eigenoption discovery through the deep successor representation, 2017, &amp; also their 2018 paper).

Experiments:
The experiment are disappointing as they are only limited to tabular and deterministic problems. An obvious missing comparison is to UBE, at the minimum; and other “deep” algorithms such as BDQN, Bootstrap DQN, etc. Some of these algorithms have been shown to perform well on the Atari benchmark, and that seems like a reasonable point of comparison also.

The method also relies on knowing the successor features. While they can be learned easily in a tabular, deterministic MDP it is not clear how the posterior would behave in larger and/or non stochastic domains when it takes more time to learn these successor features.

Overall, I am not sure what I learned from reading this paper. While the idea of using the successor representation in exploration is interesting and has been considered recently, the method presented in this paper needs to be better justified and evaluated on more challenging tasks.


Minor comments
I would like to see a proof of Equation 4, which may be simple but is not immediate.

Some papers of relevance here:

An analysis of model-based Interval Estimation for Markov Decision
Processes, Strehl &amp; Littman (2008)
(More) efficient reinforcement learning via posterior sampling. Osband et al (2013)
Count-Based Exploration with the Successor Representation, Machado et al. (2018)
</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">4: Ok but not good enough - rejection</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></main></div>
  </div>
</div>


    <!-- Footer -->
    <footer class="sitemap">
      <div class="container">
        <div class="row hidden-xs">
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/venues">All Venues</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="/contact">Contact</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
    
        <div class="row visible-xs-block">
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/contact">Contact</a></li>
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
      </div>
    </footer>
    
    <footer class="sponsor">
      <div class="container">
        <div class="row">
          <div class="col-sm-10 col-sm-offset-1">
            <p class="text-center">
              OpenReview is created by the <a href="http://www.iesl.cs.umass.edu/" target="_blank">Information Extraction and Synthesis Laboratory</a>, College of Information and Computer Science, University of Massachusetts Amherst. We gratefully acknowledge the support of the OpenReview sponsors:  Google,  Facebook, NSF, the University of Massachusetts Amherst Center for Data Science, and Center for Intelligent Information Retrieval, as well as the Google Cloud Platform for donating the computing and networking services on which OpenReview.net runs.
            </p>
          </div>
        </div>
      </div>
    </footer>

  <div id="feedback-modal" class="modal fade" tabindex="-1" role="dialog">
    <div class="modal-dialog">
      <div class="modal-content">
        <div class="modal-header">
          <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button>
          <h3 class="modal-title">Send Feedback</h3>
        </div>
        <div class="modal-body">
          <p>Enter your feedback below and we'll get back to you as soon as possible.</p>
          <form action="/feedback" method="POST">
            <div class="form-group">
              <input type="email" name="from" class="form-control" placeholder="Email" />
            </div>
            <div class="form-group">
              <input type="text" name="subject" class="form-control" placeholder="Subject" />
            </div>
            <div class="form-group">
              <textarea name="message" class="form-control feedback-input" rows="5" placeholder="Message" required=""></textarea>
            </div>
          <ul id="ui-id-2" tabindex="0" class="ui-menu ui-widget ui-widget-content" style="display: none;"></ul></form>
        </div>
        <div class="modal-footer">
          <button type="button" class="btn btn-default" data-dismiss="modal">Cancel</button>
          <button type="button" class="btn btn-primary">Send</button>
        </div>
      </div>
    </div>
  </div>

  <script type="text/javascript" async="" src="https://www.google-analytics.com/analytics.js"></script><script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js"></script>
  <script>window.jQuery || document.write('&lt;script src="/static/js/vendor/jquery-2.2.4.min.js"&gt;&lt;\/script&gt;')</script>

  <script src="/static/dist/vendor.min.js"></script>
  <script src="/static/dist/templates.min.js"></script>
  <script src="/static/dist/openreview.min.js"></script>

    <script>window.legacyScripts = true;</script>


    <script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-108703919-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() { dataLayer.push(arguments); }
      gtag('js', new Date());
      gtag('config', 'UA-108703919-1');
    </script>


<div role="status" aria-live="assertive" aria-relevant="additions" class="ui-helper-hidden-accessible"></div></body></html>
<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" class="no-js"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>Encoder Discriminator Networks for Unsupervised Representation Learning | OpenReview</title>
  <meta name="description" content="" />

      <meta name="citation_title" content="Encoder Discriminator Networks for Unsupervised Representation Learning" />
        <meta name="citation_author" content="Anonymous" />
      <meta name="citation_publication_date" content="2018/09/27" />
      <meta name="citation_online_date" content="2018/09/27" />
      <meta name="citation_pdf_url" content="https://openreview.net/pdf?id=HJEhIjA9tQ" />
      <meta name="twitter:card" content="summary" />
      <meta name="twitter:site" content="@openreviewnet" />
      <meta name="og:title" content="Encoder Discriminator Networks for Unsupervised Representation..." />
      <meta name="og:description" content="Learning representations of data samples in an unsupervised way is needed whenever computers have to reason about unlabeled data. Applications range from compressing and denoising data to..." />
      <meta name="og:image" content="https://openreview.net/static/images/openreview_logo_512.png" />

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans:400,400i,700,700i" />

  <link rel="stylesheet" href="/static/css/bootstrap.min.css" />
  <link rel="stylesheet" href="/static/css/jquery-ui.min.css" />
  <link rel="stylesheet" href="/static/css/main.min.css" />
</head>

<body class="forum">
  <nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
  
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand home push-link" href="/"><strong>OpenReview</strong>.net</a>
      </div>
  
      <div id="navbar" class="navbar-collapse collapse">
        <form class="navbar-form navbar-left profile-search" role="search">
          <div class="form-group has-feedback">
            <input id="search_input" type="text" class="form-control ui-autocomplete-input" placeholder="Search ICLR 2019 Conference" autocomplete="off" />
            <span class="glyphicon glyphicon-search form-control-feedback" aria-hidden="true"></span>
          </div>
  
          <input id="search_group" type="hidden" value="ICLR.cc/2019/Conference" />
          <input id="search_content" type="hidden" value="all" />
        <ul id="ui-id-1" tabindex="0" class="ui-menu ui-widget ui-widget-content ui-autocomplete ui-front" style="display: none;"></ul></form>
  
        <ul class="nav navbar-nav navbar-right">
        
            <li id="user-menu"><a href="/login">Login</a></li>
        </ul>
      </div>
  
    </div>
  </nav>

  <div id="or-banner" class="banner" style="">
  <div class="container">
    <div class="row">
      <div class="col-xs-12"><a href="/group?id=ICLR.cc/2019/Conference" title="Venue Homepage"><img class="icon" src="/static/images/arrow_left.svg" /> Go to <strong>ICLR 2019 Conference</strong> homepage</a></div>
    </div>
  </div>
</div>
<div id="flash-message-container" class="alert alert-danger" role="alert" style="display: none;">
  <div class="container">
    <div class="row">
      <div class="col-xs-12">
        <div class="alert-content">
          <button type="button" class="close" aria-label="Close"><span aria-hidden="true">Ã—</span></button>
        </div>
      </div>
    </div>
  </div>
</div>

<div class="container">
  <div class="row">
    <div class="col-xs-12">
      <main id="content" class="clearfix openbanner-visible legacy-styles"><div id="note_HJEhIjA9tQ" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Encoder Discriminator Networks for Unsupervised Representation Learning</a> <a class="note_content_pdf" href="/pdf?id=HJEhIjA9tQ" title="Download PDF" target="_blank"><img src="/static/images/pdf_icon_blue.svg" /></a> </h2></div><div class="meta_row"><span class="signatures">Anonymous</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">28 Sep 2018 (modified: 11 Oct 2018)</span><span class="item">ICLR 2019 Conference Blind Submission</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span><span class="item"><a class="action-bibtex-modal" data-bibtex="@inproceedings{    &#10;anonymous2019encoder,    &#10;title={Encoder Discriminator Networks for Unsupervised Representation Learning},    &#10;author={Anonymous},    &#10;booktitle={Submitted to International Conference on Learning Representations},    &#10;year={2019},    &#10;url={https://openreview.net/forum?id=HJEhIjA9tQ},    &#10;note={under review}    &#10;}">Show Bibtex</a></span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Abstract: </span><span class="note_content_value">Learning representations of data samples in an unsupervised way is needed whenever computers have to reason about unlabeled data. Applications range from compressing and denoising data to super-resolution, generating new samples from a given sample distribution and much more.
In this work, we use information entropy and a little game to motivate a new encoder discriminator architecture in order to learn unsupervised latent representations. Inspired by the game "Taboo", we train an encoder network to generate a meaningful representation of one particular sample of a dataset. Using this description, a discriminator network then has to retrieve the same sample from the whole dataset. We show that learning in this manner on many different samples repeatedly minimizes the information entropy given the latent description and, thus, forces the encoder network to make precise descriptions that can be interpreted by the discriminator.
We provide first results of this method on the MNIST and the Fashion MNIST dataset.</span></div><div class="note_contents"><span class="note_content_field">Keywords: </span><span class="note_content_value">representation learning, unsupervised, encoder discriminator</span></div><div class="reply_row clearfix"><div class="item" id="reply_count">6 Replies</div></div></div><hr class="small" /><div id="note_children"><div class="note_with_children"><div id="note_Skgn1bqe6X" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Interesting Preliminary Idea but Needs More Work</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HJEhIjA9tQ&amp;noteId=Skgn1bqe6X"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper212 AnonReviewer2</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">08 Nov 2018</span><span class="item">ICLR 2019 Conference Paper212 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">The paper presents a new strategy for unsupervised learning. The idea is that a given a random sample, the encoder returns a compressed representation. The decoder then tries to use this representation to pick out the correct sample in the training set.

The idea is interesting but I have a number of concerns.

(1) I am not convinced that this approach will not degenerate to just learning some sort of hash function. What is encouraging similar images to have similar representations? 

For instance, if the discriminator had access to the encoder function it could just run the encoder on all the samples in the dataset and then pick out the one most similar to the description it has received. (I agree the discriminator doesn't have access to the encoder, but it can learn to mimic it based on a large number of samples)


(2) The math could be written a little more rigorously in Section 2.


(3) The experiments are not thorough and there is no comparison to existing approaches. 





</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">3: Clear rejection</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_SJe2s1yMpm" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Re: interesting preliminary idea but needs more work</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HJEhIjA9tQ&amp;noteId=SJe2s1yMpm"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper212 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">09 Nov 2018</span><span class="item">ICLR 2019 Conference Paper212 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Dear reviewer,

thanks a lot for your feedback!
Regarding your concerns:

(1) I am not convinced that this approach will not degenerate to just learning some sort of hash function. What is encouraging similar images to have similar representations? 

This indeed is an important point that probably needs to be stressed out a little further in the paper: In principle there is no guarantee that the encoder and decoder networks don't learn to encode / decode some kind of "random hash" representation. However the intuition is that the decoder will perform much better if the representations are structured in a "meaningful" way - presumably because the representations humans use for classification are based on similar hierarchical features that artificial neural networks are able to learn. Furthermore noise as well as small random affine transformations were applied separately on the inputs of the encoder / decoder in order to prevent the network from learning hash functions in the classical sense. One can argue whether the - I agree - preliminary experiments really support this intuition but the hope is that further experiments will provide more evidence.

(2) The math could be written a little more rigorously in Section 2.

ok, noted.

(3) The experiments are not thorough and there is no comparison to existing approaches.

Unfortunately there was very little time before the submission deadline but hopefully some further results are obtained until the end of the rebuttal phase.

Thank you again, best regards,
ICLR 2019 Conference Paper212 Authors</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div><div class="note_with_children"><div id="note_S1g2dnQkaX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Preliminary but interesting idea which requires more work before it can be published</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HJEhIjA9tQ&amp;noteId=S1g2dnQkaX"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper212 AnonReviewer3</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">06 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper212 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">The authors propose a method to learn "useful" latent representations in an unsupervised manner. Their model is different from the previously proposed models of either using an autoencoder architecture or using adversarial training. Instead, in the proposed model, the discriminator plays a cooperative game with an encoder to make it learn a representation which is meaningful. The entire model is trained end-to-end and the authors show some preliminary results on two fairly small scale datasets. 

While the proposed approach is quite interesting, there are a number of issues I have with the presented manuscript.

- The work presented is quite preliminary and I feel requires more polishing and results before one can deem it suitable for publication. 
- Given that the latent representation of the current input has to be measured against the representations of all the other inputs in the datasets, makes the approach not scalable to large datasets (having millions or more examples). 
- Why did the authors choose to embed the inputs in only two dimensional space? 
- The experimental results are rather weak: tested on only a couple of small scale datasets with very little quantitative experiments. 
- While the authors show clusters in the latent space, there is no verification on how useful these representations might be for the end goal. 

Given the various issues I feel that the paper is not ready for publication. The approach is definitely interesting and I hope the authors can work more to further validate the efficacy of the model and submit again when ready. </span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">4: Ok but not good enough - rejection</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_Hyxmop8gTX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Re: preliminary but interesting idea</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HJEhIjA9tQ&amp;noteId=Hyxmop8gTX"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper212 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">07 Nov 2018</span><span class="item">ICLR 2019 Conference Paper212 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Dear reviewer,

thank you very much for your constructive feedback!
Unfortunately, there was very little time to write up the paper and to do the experiments but hopefully the paper still can be improved until the end of the rebuttal phase.

Regarding your issues:

- The work presented is quite preliminary and I feel requires more polishing and results before one can deem it suitable for publication.
-&gt; totally agree. Hopefully there will be some more meaningful results on the CelebA dataset until the rebuttal deadline.

- Given that the latent representation of the current input has to be measured against the representations of all the other inputs in the datasets, makes the approach not scalable to large datasets (having millions or more examples).
-&gt; that's indeed a very important point that wasn't mentioned in the paper. At the moment only smaller random batches are considered (containing 100 samples - every sample of a batch is compared to every other sample in that same batch). In the future one might implement an importance sampling scheme based on the probabilistic distance as introduced in the paper. The hope is that these measures will ultimately make the method very scalable.

- Why did the authors choose to embed the inputs in only two dimensional space?
-&gt; At the moment, this was mainly for visualization purposes. Experiments using a higher dimensional latent space are underway.

- The experimental results are rather weak: tested on only a couple of small scale datasets with very little quantitative experiments.
-&gt; True. Hopefully there'll be some better results soon.

- While the authors show clusters in the latent space, there is no verification on how useful these representations might be for the end goal.
-&gt; Transfer learning experiments haven't started yet. Possibly (if time suffices) an additional transfer learning experiment will be performed on STL-10.

Thank you again, best regards,
ICLR 2019 Conference Paper212 Authors</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div><div class="note_with_children"><div id="note_Skxyj0WInQ" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>not yet ready to be published</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HJEhIjA9tQ&amp;noteId=Skxyj0WInQ"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper212 AnonReviewer1</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">31 Oct 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper212 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">The paper proposes a novel encoder-based unsupervised representation learning. The network consists an encoder and a discriminator. The encoder learns to generate sample-specific codes, and discriminator tries to assign the generated code to the corresponding sample, given the correct sample and a set of incorrect samples. The method is tested on two relatively small datasets: MNIST and Fashion MNIST. 
The essence of the method is novel and make sense. The text is short but clear. the method technically sounds. However, the experimental part lacks a quantitative evaluation as well as a comparison to state-of-the-art methods, which makes the assessment of the proposed model difficult. Qualitative results are informative but not enough. Another disappointing point in experiments is that the method is evaluated on two relatively small datasets, with very small latent space (d=2). 
I expected two major experiments: (1) applying the model on a bigger dataset, as mentioned in future works, (2) consider this game as a self-supervised representation learning method and use it as an initialization for a supervised task. It gives the opportunity to compare it against others as well.

other points:
- the paper lacks a comprehensive literature review. the topic is well studied and deserves to cite more than 8 references. 
- some details are missing in the text e.g. fully-connected size, training hyper-parameters, number of incorrect samples fed to discriminator during training, training time, number of parameters.
- ablation study: which one is a better feature learning network: Encoder or convolutional layers of Discriminator?

In general, I believe that some significant analyses are missing and it is not possible to accept a paper without having additional insights. </span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">3: Clear rejection</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_S1xiyXveTm" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Re: not yet ready to be published</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HJEhIjA9tQ&amp;noteId=S1xiyXveTm"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper212 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">07 Nov 2018</span><span class="item">ICLR 2019 Conference Paper212 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Dear reviewer,

thank you very much for your honest feedback!
Hopefully the paper still can be improved until the end of the rebuttal phase.
Unfortunately there was very little time and some important details were missed which will be definitively included in the final version.
In particular regarding quantitative results, the loss metric as well as discriminator accuracy and discriminator confidence will be included.
Furthermore an experiment on the CelebA dataset using higher latent dimensionality is underway.
The ablation study you proposed is a nice idea - if time permits it will be given a shot.

Thank you again, best regards,
ICLR 2019 Conference Paper212 Authors</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div></div></main></div>
  </div>
</div>


    <!-- Footer -->
    <footer class="sitemap">
      <div class="container">
        <div class="row hidden-xs">
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/venues">All Venues</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="/contact">Contact</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
    
        <div class="row visible-xs-block">
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/contact">Contact</a></li>
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
      </div>
    </footer>
    
    <footer class="sponsor">
      <div class="container">
        <div class="row">
          <div class="col-sm-10 col-sm-offset-1">
            <p class="text-center">
              OpenReview is created by the <a href="http://www.iesl.cs.umass.edu/" target="_blank">Information Extraction and Synthesis Laboratory</a>, College of Information and Computer Science, University of Massachusetts Amherst. We gratefully acknowledge the support of the OpenReview sponsors:  Google,  Facebook, NSF, the University of Massachusetts Amherst Center for Data Science, and Center for Intelligent Information Retrieval, as well as the Google Cloud Platform for donating the computing and networking services on which OpenReview.net runs.
            </p>
          </div>
        </div>
      </div>
    </footer>

  <div id="feedback-modal" class="modal fade" tabindex="-1" role="dialog">
    <div class="modal-dialog">
      <div class="modal-content">
        <div class="modal-header">
          <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">Ã—</span></button>
          <h3 class="modal-title">Send Feedback</h3>
        </div>
        <div class="modal-body">
          <p>Enter your feedback below and we'll get back to you as soon as possible.</p>
          <form action="/feedback" method="POST">
            <div class="form-group">
              <input type="email" name="from" class="form-control" placeholder="Email" />
            </div>
            <div class="form-group">
              <input type="text" name="subject" class="form-control" placeholder="Subject" />
            </div>
            <div class="form-group">
              <textarea name="message" class="form-control feedback-input" rows="5" placeholder="Message" required=""></textarea>
            </div>
          <ul id="ui-id-2" tabindex="0" class="ui-menu ui-widget ui-widget-content" style="display: none;"></ul></form>
        </div>
        <div class="modal-footer">
          <button type="button" class="btn btn-default" data-dismiss="modal">Cancel</button>
          <button type="button" class="btn btn-primary">Send</button>
        </div>
      </div>
    </div>
  </div>

  <script type="text/javascript" async="" src="https://www.google-analytics.com/analytics.js"></script><script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js"></script>
  <script>window.jQuery || document.write('&lt;script src="/static/js/vendor/jquery-2.2.4.min.js"&gt;&lt;\/script&gt;')</script>

  <script src="/static/dist/vendor.min.js"></script>
  <script src="/static/dist/templates.min.js"></script>
  <script src="/static/dist/openreview.min.js"></script>

    <script>window.legacyScripts = true;</script>


    <script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-108703919-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() { dataLayer.push(arguments); }
      gtag('js', new Date());
      gtag('config', 'UA-108703919-1');
    </script>


<div role="status" aria-live="assertive" aria-relevant="additions" class="ui-helper-hidden-accessible"></div></body></html>
<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" class="no-js"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>Neural Predictive Belief Representations | OpenReview</title>
  <meta name="description" content="" />

      <meta name="citation_title" content="Neural Predictive Belief Representations" />
        <meta name="citation_author" content="Anonymous" />
      <meta name="citation_publication_date" content="2018/09/27" />
      <meta name="citation_online_date" content="2018/09/27" />
      <meta name="citation_pdf_url" content="https://openreview.net/pdf?id=ryfz73C9KQ" />
      <meta name="twitter:card" content="summary" />
      <meta name="twitter:site" content="@openreviewnet" />
      <meta name="og:title" content="Neural Predictive Belief Representations" />
      <meta name="og:description" content="Unsupervised representation learning has succeeded with excellent results in many applications. It is an especially powerful tool  to learn a good representation of environments with partial or..." />
      <meta name="og:image" content="https://openreview.net/static/images/openreview_logo_512.png" />

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans:400,400i,700,700i" />

  <link rel="stylesheet" href="/static/css/bootstrap.min.css" />
  <link rel="stylesheet" href="/static/css/jquery-ui.min.css" />
  <link rel="stylesheet" href="/static/css/main.min.css" />
</head>

<body class="forum">
  <nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
  
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand home push-link" href="/"><strong>OpenReview</strong>.net</a>
      </div>
  
      <div id="navbar" class="navbar-collapse collapse">
        <form class="navbar-form navbar-left profile-search" role="search">
          <div class="form-group has-feedback">
            <input id="search_input" type="text" class="form-control ui-autocomplete-input" placeholder="Search ICLR 2019 Conference" autocomplete="off" />
            <span class="glyphicon glyphicon-search form-control-feedback" aria-hidden="true"></span>
          </div>
  
          <input id="search_group" type="hidden" value="ICLR.cc/2019/Conference" />
          <input id="search_content" type="hidden" value="all" />
        <ul id="ui-id-1" tabindex="0" class="ui-menu ui-widget ui-widget-content ui-autocomplete ui-front" style="display: none;"></ul></form>
  
        <ul class="nav navbar-nav navbar-right">
        
            <li id="user-menu"><a href="/login">Login</a></li>
        </ul>
      </div>
  
    </div>
  </nav>

  <div id="or-banner" class="banner" style="">
  <div class="container">
    <div class="row">
      <div class="col-xs-12"><a href="/group?id=ICLR.cc/2019/Conference" title="Venue Homepage"><img class="icon" src="/static/images/arrow_left.svg" /> Go to <strong>ICLR 2019 Conference</strong> homepage</a></div>
    </div>
  </div>
</div>
<div id="flash-message-container" class="alert alert-danger" role="alert" style="display: none;">
  <div class="container">
    <div class="row">
      <div class="col-xs-12">
        <div class="alert-content">
          <button type="button" class="close" aria-label="Close"><span aria-hidden="true">Ã—</span></button>
        </div>
      </div>
    </div>
  </div>
</div>

<div class="container">
  <div class="row">
    <div class="col-xs-12">
      <main id="content" class="clearfix openbanner-visible legacy-styles"><div id="note_ryfz73C9KQ" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Neural Predictive Belief Representations</a> <a class="note_content_pdf" href="/pdf?id=ryfz73C9KQ" title="Download PDF" target="_blank"><img src="/static/images/pdf_icon_blue.svg" /></a> </h2></div><div class="meta_row"><span class="signatures">Anonymous</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">28 Sep 2018 (modified: 11 Oct 2018)</span><span class="item">ICLR 2019 Conference Blind Submission</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span><span class="item"><a class="action-bibtex-modal" data-bibtex="@inproceedings{    &#10;anonymous2019neural,    &#10;title={Neural Predictive Belief Representations},    &#10;author={Anonymous},    &#10;booktitle={Submitted to International Conference on Learning Representations},    &#10;year={2019},    &#10;url={https://openreview.net/forum?id=ryfz73C9KQ},    &#10;note={under review}    &#10;}">Show Bibtex</a></span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Abstract: </span><span class="note_content_value">Unsupervised representation learning has succeeded with excellent results in many applications. It is an especially powerful tool  to learn a good representation of environments with partial or noisy observations. In partially observable domains it is important for the representation to encode a belief state---a sufficient statistic of the observations seen so far. In this paper, we investigate whether it is possible to learn such a belief representation using modern neural architectures. Specifically, we focus on one-step frame prediction and two variants of contrastive predictive coding (CPC)  as the objective functions to learn the representations. To evaluate these learned representations, we test how well they can predict various pieces of information about the underlying state of the environment, e.g., position of the agent in a 3D maze. We show that all three methods are able to learn belief representations of the environment---they encode not only the state information, but also its uncertainty, a crucial aspect of belief states. We also find that for CPC multi-step predictions and action-conditioning are critical for accurate belief representations in visually complex environments. The ability of neural representations to capture the belief information has the potential to spur new advances for learning and planning in partially observable domains, where leveraging uncertainty is essential for optimal decision making.</span></div><div class="note_contents"><span class="note_content_field">Keywords: </span><span class="note_content_value">belief states, representation learning, contrastive predictive coding, reinforcement learning, predictive state representations, deep reinforcement learning</span></div><div class="note_contents"><span class="note_content_field">TL;DR: </span><span class="note_content_value">We investigate the quality of belief state representations of partially observable dynamic environments learned with modern neural architectures.</span></div><div class="reply_row clearfix"><div class="item" id="reply_count">3 Replies</div></div></div><hr class="small" /><div id="note_children"><div class="note_with_children"><div id="note_HJgKV__a2X" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Review for "Neural Belief Representations"</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=ryfz73C9KQ&amp;noteId=HJgKV__a2X"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1339 AnonReviewer2</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">05 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper1339 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value"># Review for "Neural Belief Representations"



The authors argue in the favor of belief representations for partial observable Markov decision processes. The central argument is that uncertainty needs to be represented to make optimal decision making. For that aim, three belief representations based on sufficient statistics of the future are evaluated and compared in a set of disective studies. Those studies find that predicting the future results in uncertainty being represented in the state representations, although they differ in quality.

I found the paper hard to follow for various reasons. 

- NCE is reviewd, while CPC is not. I would have found a review of CPC as well to help my understanding, especially to draw the line between CPC and CPC|Action.
- In 2.1., $b_t$ is defined as a probability, while it is the output of a neural network later. This is formally incompatible, and I found  the connection not well explained. From my understanding, $b_t$ is a vector that represents the sufficient statistics if learning works. The probability interpretation is thus stretched.
- The architecture description (starting from the second paragraph on page 4) feels cluttered. It was clearly written as a caption to Figure 1 and hence should be placed as such. Still, stand alone texts are important and in my humble opinion should be augmented with equations instead of drawings. While the latter can help understanding, it lacks precision and makes reproduction hard.
- The MLP to predict the ground truth is not sufficiently described in the main text. I think it needs to go there, as it is quite central to the evaluation.

Since the manuscript is half a page under the limit, such improvements would have been feasible.

Apart from the quality of the manuscipt, I like the fact that a disective study was done in such a way. 

However, I would have liked to see more comparisons, e.g. in $(x, y, \theta)$Â environments it is also possible to obtain quite good approximations of the true posterior via particle filtering. Also, other more straightforward approaches such as MDN-RNNs can represent multiple maxima in the probability landscape; this would have enabled to examine the benefit of conditioning on actions in a different context.

Right now, it is unclear what the paper is about. On the one hand, it does a focused disective study with well controlled experiments, which would be a good fit if many different models were considered. On the other hand, it advertsises CPC|Action; but then it falls short in evaluating the method in more challenging environments.

To sum it up, I feel that the paper needs to be clearer in writing and in experimental structure. The currently tested hypothesis, "does CPC|Action perform better than CPC and FP in a set of well controlled toy environments" is, imho, not of broad enough interest.</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">4: Ok but not good enough - rejection</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">3: The reviewer is fairly confident that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_Hkgl4dA32Q" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Good paper, some details missing or unclear</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=ryfz73C9KQ&amp;noteId=Hkgl4dA32Q"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1339 AnonReviewer3</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">05 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper1339 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">** Summary **
The authors evaluate three different representation learning algorithms for partially observable environments. In particular, they investigate how well the learned representation encodes the true belief distribution, including its uncertainty. 
They propose an extension to a previous algorithm and evaluate all three algorithms on a range of tasks.

** Clarity **
The paper is well written and overall easy to follow.

** Quality **
The paper evaluates the described algorithms on a sufficiently large set of tasks. There is no theoretical analysis.

** Originality &amp; Significance **
While the authors propose a novel extension to an existing algorithm, I believe the value of this work lies in the detailed empirical analysis.

** Missing Citations **

I believe two recent papers (this year's ICML) should be mentioned in the related work section as they propose two representation learning algorithms for POMDPs that, as far as I can tell, are not yet mentioned in the paper but quite relevant to the discussed topic. [1] Because it also uses PSRs and [2] because it explicitly learns a belief state. It would be interesting to see how [2] compares in terms of performance to FP and CPC(|Action).

[1] Hefny, A., Marinho, Z., Sun, W., Srinivasa, S. &amp; Gordon, G.. (2018). Recurrent Predictive State Policy Networks. Proceedings of the 35th International Conference on Machine Learning, in PMLR 80:1949-1958

[2] Igl, M., Zintgraf, L., Le, T.A., Wood, F. &amp; Whiteson, S.. (2018). Deep Variational Reinforcement Learning for POMDPs. Proceedings of the 35th International Conference on Machine Learning, in PMLR 80:2117-2126

** Question **

I have several questions where I'm not sure I understand the paper correctly:

1.) Why can FP only predict the mean? For example, one could use a PixelCNN as decoder, which would allow to learn an entire distribution, not just the mean over images.
2.) The problem that CPC and CPC|Action is unable to predict objects if they don't influence the future trajectory doesn't seem surprising to me because whether an image is a positive or negative example can usually be determined by the background, the object is not necessary to do so. In other words, this is a problem of how the negative samples are chosen: If they were constructed using a simulator that shows the same background but without the objects, the belief would need to start encoding the presence of objects. Is this correct or am I missing something?
3.) Am I correct in thinking that CPC(|Action) would not be applicable to properly estimate the belief distribution in the presence of noise, i.e. for example when estimation the exact location based on sensors with Gaussian noise?

** Overall **

* Pros:
- Extensive, interesting evaluation
- Novel CPC|Action algorithm

* Cons:
- No theoretical analysis/justification for claims
- There are several subtleties that I am not sure are sufficiently discussed in the paper (see my questions above)</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">7: Good paper, accept</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_BJxAFigP27" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Interesting ideas, excellent experiments but a big question mark and significance hard to assess</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=ryfz73C9KQ&amp;noteId=BJxAFigP27"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1339 AnonReviewer1</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">31 Oct 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper1339 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">This paper learns a deep model encoding a representation of the state in a POMDP using one-step frame prediction or a  contrastive predictive coding loss function. They evaluate the learned representation and shows it can be used to construct a belief of the state of the agent. 

Using deep networks in POMDP is not new, as the authors pointed out in their related work section. Thus I believe the originality of the paper lies in the type of loss used and the evaluation of the learned representation trough the construction of a belief over current and previous states. I think this method to evaluate the hidden state has the potential to be useful should one wish to evaluate the quality of the hidden representation by itself. In addition, I found the experimental evaluation of this method to be rather extensive and well conducted, as the authors experimented on 3 different (toy) environments and use it to quantify and discuss the performance of the three model architecture they develop.

On the other hand, the authors mention that other works have already shown that learned representations can improve agent performance, can be learned by supervised learning (= predicting future observations) or can be useful for transfer learning. So in that context, I am not sure the contributions of this paper are highly significant as they are presented. To better highlight the strength the evaluation method, I think it could be interesting to check that the accuracy in belief prediction is correlated with an improvement in agent performance or in transfer learning tasks. To better highlight the interest of the CPC loss, I think it could be interesting to compare it to similar approaches, for example the one by Dosovitskiy &amp; Koltun (2017).

I found the paper reasonably clear. However, the following sentence in the appendix puzzled me. "The input to the [evaluation] MLP is the concatenation of b_t and a one-hot of the agentâ€™s initial discretised position and orientation." I may have missed something, but I do not understand how the model can contain the uncertainty shown in the experimental results if the agent's initial position is provided to the current or past position predictor.</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">5: Marginally below acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">3: The reviewer is fairly confident that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></main></div>
  </div>
</div>


    <!-- Footer -->
    <footer class="sitemap">
      <div class="container">
        <div class="row hidden-xs">
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/venues">All Venues</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="/contact">Contact</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
    
        <div class="row visible-xs-block">
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/contact">Contact</a></li>
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
      </div>
    </footer>
    
    <footer class="sponsor">
      <div class="container">
        <div class="row">
          <div class="col-sm-10 col-sm-offset-1">
            <p class="text-center">
              OpenReview is created by the <a href="http://www.iesl.cs.umass.edu/" target="_blank">Information Extraction and Synthesis Laboratory</a>, College of Information and Computer Science, University of Massachusetts Amherst. We gratefully acknowledge the support of the OpenReview sponsors:  Google,  Facebook, NSF, the University of Massachusetts Amherst Center for Data Science, and Center for Intelligent Information Retrieval, as well as the Google Cloud Platform for donating the computing and networking services on which OpenReview.net runs.
            </p>
          </div>
        </div>
      </div>
    </footer>

  <div id="feedback-modal" class="modal fade" tabindex="-1" role="dialog">
    <div class="modal-dialog">
      <div class="modal-content">
        <div class="modal-header">
          <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">Ã—</span></button>
          <h3 class="modal-title">Send Feedback</h3>
        </div>
        <div class="modal-body">
          <p>Enter your feedback below and we'll get back to you as soon as possible.</p>
          <form action="/feedback" method="POST">
            <div class="form-group">
              <input type="email" name="from" class="form-control" placeholder="Email" />
            </div>
            <div class="form-group">
              <input type="text" name="subject" class="form-control" placeholder="Subject" />
            </div>
            <div class="form-group">
              <textarea name="message" class="form-control feedback-input" rows="5" placeholder="Message" required=""></textarea>
            </div>
          <ul id="ui-id-2" tabindex="0" class="ui-menu ui-widget ui-widget-content" style="display: none;"></ul></form>
        </div>
        <div class="modal-footer">
          <button type="button" class="btn btn-default" data-dismiss="modal">Cancel</button>
          <button type="button" class="btn btn-primary">Send</button>
        </div>
      </div>
    </div>
  </div>

  <script type="text/javascript" async="" src="https://www.google-analytics.com/analytics.js"></script><script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js"></script>
  <script>window.jQuery || document.write('&lt;script src="/static/js/vendor/jquery-2.2.4.min.js"&gt;&lt;\/script&gt;')</script>

  <script src="/static/dist/vendor.min.js"></script>
  <script src="/static/dist/templates.min.js"></script>
  <script src="/static/dist/openreview.min.js"></script>

    <script>window.legacyScripts = true;</script>


    <script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-108703919-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() { dataLayer.push(arguments); }
      gtag('js', new Date());
      gtag('config', 'UA-108703919-1');
    </script>


<div role="status" aria-live="assertive" aria-relevant="additions" class="ui-helper-hidden-accessible"></div></body></html>
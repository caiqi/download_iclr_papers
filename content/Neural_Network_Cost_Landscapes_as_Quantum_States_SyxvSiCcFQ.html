<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" class="no-js"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>Neural Network Cost Landscapes as Quantum States | OpenReview</title>
  <meta name="description" content="" />

      <meta name="citation_title" content="Neural Network Cost Landscapes as Quantum States" />
        <meta name="citation_author" content="Anonymous" />
      <meta name="citation_publication_date" content="2018/09/27" />
      <meta name="citation_online_date" content="2018/09/27" />
      <meta name="citation_pdf_url" content="https://openreview.net/pdf?id=SyxvSiCcFQ" />
      <meta name="twitter:card" content="summary" />
      <meta name="twitter:site" content="@openreviewnet" />
      <meta name="og:title" content="Neural Network Cost Landscapes as Quantum States" />
      <meta name="og:description" content="Quantum computers promise significant advantages over classical computers for a number of different applications. We show that the complete loss function landscape of a neural network can be..." />
      <meta name="og:image" content="https://openreview.net/static/images/openreview_logo_512.png" />

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans:400,400i,700,700i" />

  <link rel="stylesheet" href="/static/css/bootstrap.min.css" />
  <link rel="stylesheet" href="/static/css/jquery-ui.min.css" />
  <link rel="stylesheet" href="/static/css/main.min.css" />
</head>

<body class="forum">
  <nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
  
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand home push-link" href="/"><strong>OpenReview</strong>.net</a>
      </div>
  
      <div id="navbar" class="navbar-collapse collapse">
        <form class="navbar-form navbar-left profile-search" role="search">
          <div class="form-group has-feedback">
            <input id="search_input" type="text" class="form-control ui-autocomplete-input" placeholder="Search ICLR 2019 Conference" autocomplete="off" />
            <span class="glyphicon glyphicon-search form-control-feedback" aria-hidden="true"></span>
          </div>
  
          <input id="search_group" type="hidden" value="ICLR.cc/2019/Conference" />
          <input id="search_content" type="hidden" value="all" />
        <ul id="ui-id-1" tabindex="0" class="ui-menu ui-widget ui-widget-content ui-autocomplete ui-front" style="display: none;"></ul></form>
  
        <ul class="nav navbar-nav navbar-right">
        
            <li id="user-menu"><a href="/login">Login</a></li>
        </ul>
      </div>
  
    </div>
  </nav>

  <div id="or-banner" class="banner" style="">
  <div class="container">
    <div class="row">
      <div class="col-xs-12"><a href="/group?id=ICLR.cc/2019/Conference" title="Venue Homepage"><img class="icon" src="/static/images/arrow_left.svg" /> Go to <strong>ICLR 2019 Conference</strong> homepage</a></div>
    </div>
  </div>
</div>
<div id="flash-message-container" class="alert alert-danger" role="alert" style="display: none;">
  <div class="container">
    <div class="row">
      <div class="col-xs-12">
        <div class="alert-content">
          <button type="button" class="close" aria-label="Close"><span aria-hidden="true">×</span></button>
        </div>
      </div>
    </div>
  </div>
</div>

<div class="container">
  <div class="row">
    <div class="col-xs-12">
      <main id="content" class="clearfix openbanner-visible legacy-styles"><div id="note_SyxvSiCcFQ" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Neural Network Cost Landscapes as Quantum States</a> <a class="note_content_pdf" href="/pdf?id=SyxvSiCcFQ" title="Download PDF" target="_blank"><img src="/static/images/pdf_icon_blue.svg" /></a> </h2></div><div class="meta_row"><span class="signatures">Anonymous</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">28 Sep 2018 (modified: 11 Oct 2018)</span><span class="item">ICLR 2019 Conference Blind Submission</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span><span class="item"><a class="action-bibtex-modal" data-bibtex="@inproceedings{    &#10;anonymous2019neural,    &#10;title={Neural Network Cost Landscapes as Quantum States},    &#10;author={Anonymous},    &#10;booktitle={Submitted to International Conference on Learning Representations},    &#10;year={2019},    &#10;url={https://openreview.net/forum?id=SyxvSiCcFQ},    &#10;note={under review}    &#10;}">Show Bibtex</a></span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Abstract: </span><span class="note_content_value">Quantum computers promise significant advantages over classical computers for a number of different applications. We show that the complete loss function landscape of a neural network can be represented as the quantum state output by a quantum computer. We demonstrate this explicitly for a binary neural network and, further, show how a quantum computer can train the network by manipulating this state using a well-known algorithm known as quantum amplitude amplification. We further show that with minor adaptation, this method can also represent the meta-loss landscape of a number of neural network architectures simultaneously. We search this meta-loss landscape with the same method to simultaneously train and design a binary neural network. </span></div><div class="note_contents"><span class="note_content_field">Keywords: </span><span class="note_content_value">quantum, neural networks, meta-learning</span></div><div class="note_contents"><span class="note_content_field">TL;DR: </span><span class="note_content_value">We show that NN parameter and hyperparamter cost landscapes can be generated as quantum states using a single quantum circuit and that these can be used for training and meta-training.</span></div><div class="reply_row clearfix"><div class="item" id="reply_count">3 Replies</div></div></div><hr class="small" /><div id="note_children"><div class="note_with_children"><div id="note_S1g9YoQonm" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Review TLDR: good paper interesting subject good fit for ICLR maybe even better for QIP </a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=SyxvSiCcFQ&amp;noteId=S1g9YoQonm"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper94 AnonReviewer1</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">03 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper94 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">Neural Network Cost Landscapes as Quantum States

The authors describe a method where a deep learning framework can be quantised, this is done by considering the two state form of a Bloch sphere/qubit and mapping binary neural network. onto the quantum object creating a quantum binary neural network

I have to say I liked the paper, it is indeed novel and I haven’t seen this anywhere else. More then that, it addresses the quantum aspects of deep learning which has only recently started getting so much attention rather the regular machine learning algorithms. And such I think it’s a good fit for ICLR.

With that I have a few concerns/ nitpicking issues I would like the authors to address if possible
1. While authors show basically a discreet network (much like Soudry’s work) there has also been recently a show of continues variable networks (<a href="https://arxiv.org/pdf/1806.06871.pdf)," target="_blank" rel="nofollow">https://arxiv.org/pdf/1806.06871.pdf),</a> how does your scaling compare to that ? Could one think of this is the continuum limit (albeit you showed a *very* small system) of your model ?
2. As a general style remark there is a lot of introduction on quantum information and I wondering if authors could just reference classical text such as Isaac Chuang, Michael Nielsen or for the CS flavour Classical and Quantum Computation  ? I would have liked to see all 3.1,3.2 maybe in an appendix and a lot more details on the experiments and setup for example 
3. At the end of section 3.2 authors mention the lack of correspondence principle in some quantum systems, I would be happy for a refinement in the aspect of quantum computing that is true and also in general quantum mechanics but there is a huge body of work and an entire field dedicated to just that, settling the difference in correspondence principle and it’s meaning (for example Chaos and the semiclassical limit of quantum mechanics (is the moon there when somebody looks?) by Michael Berry. While this is defiantly far from a deal breaker I would be happy for a bit more clarification on subtle difference. My guess is that authors are referring to the fact that an essential part of quantum computing is the lack of correspondence that can also be taken advantage of for quantum parallelism/ quantum speed ups ? Same for the last paragraph of 3.1.
4. In the method section  all of this procedure is described for a fault tolerant machine, can you say something about coupling to error correction codes for near term quantum devices ?
5. On the same note, there is a feeling that non linearities are swept under the rug, do you have a hunch how can one use non linear activation functions ? (General question, you don’t really have to answer and can take the fifth )
6. In the problem statement (4.2)  x is in fact the binary representation of the qubit state ?
7. In your method Fig. 2, should there be some sort of measurements ?
8. Can you elaborate what exactly goes into the U gates and how are they constructed in Fig.2 ? Or is it some  oracle model that can do all the actions 
9. You report a quadratic speedup, is there some relationship to random walk  is this in fact a case of a RW search over the parameter space ?
</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">5: Marginally below acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_ByxRMTMc3m" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>More appropriate for quantum computing literature</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=SyxvSiCcFQ&amp;noteId=ByxRMTMc3m"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper94 AnonReviewer3</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">03 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper94 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">Review of "Neural Network Cost Landscapes as Quantum States"

Paper summary:

The paper proposes a new algorithm "quantum amplitude amplification"
for training and model selection in binary neural networks. (in which
both weights and activations are restricted to the set -1, 1)

Section 2 references related work and gives some motivation, that some
quantum algorithms scale better (in terms of big-O notation) than
classical algorithms.

Section 3 explains the basics of quantum computing (qubits and quantum
gates).

Section 4 explains the proposed method. There are two toy
problems. The binary neural network has 8 weight parameters. There are
helpful Figures 1-2 which explain the network structure and the
quantum circuit.

Section 5 explains the results of using the proposed method in a
quantum computer simulator (not an actual quantum computer). On the
two toy problems the paper observes quadratic speedups with respect to
a brute force search.

Comments:

A strong point is that the paper is very well-written and easy to
understand. 

However there are several weak points which should be addressed before
publication. Major weak points are (1) only (noiseless?) toy data sets
are used, (2) some terms in the paper are unclear/undefined, and (3)
results are unconvincing.

It is not clear that this article should be published in the machine
learning literature. One of the hallmarks of machine learning is a
focus on algorithms for real data sets / problems. In contrast the
focus of this paper is quantum computations on toy data /
problems. Maybe this paper would be better suited for publication in
the quantum computation literature?

The toy problems are explained in section 4.2. Is there any noise or
are these noiseless simulations? How does your model/algo perform as a
function of the noise level? How many data points did you simulate
from the model? (e.g. what is the number of observations in the training set?)

The paper uses the terms "cost landscape" and "meta-cost landscape"
without explicitly defining them. Equations should be added to clarify
these terms.

Results could be made more convincing by
1. using a real quantum computer.
2. using real data rather than toy data.
3. adding error bars or confidence intervals to Figures 4-5.
4. using a more appropriate baseline -- why not try the algorithms mentioned in section 2.1?

Figure 3 could be clarified by providing ticks and labels on the x
axes.

</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">3: Clear rejection</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_HygvmHzF3m" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Interesting idea but insufficient clarity and technical depth </a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=SyxvSiCcFQ&amp;noteId=HygvmHzF3m"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper94 AnonReviewer2</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">02 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper94 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value"> This paper proposes a novel idea of outputting a quantum state that represents a complete cost landscape of all parameters for a given binary neural network, by constructing a quantum binary neural network (QBNN). And then the landscape state is utilized to training the neural network by using the standard quantum amplitude amplification method.   

Although this idea is interesting, I trend to reject this submission as I think its presentation is unclear and the technical detail is a little difficult to follow. So, the correctness and soundness of this work is difficult to verify. I urge the authors to revise their draft to provide more and clearer technical details.

Detailed comments and questions:

Could the authors further point out that what the scope of the binary features are, {0, 1} or {-1, +1}? To my understanding, it should be {-1, +1}, or the corresponding variables are always +1. In addition, the construction of the “multiplying values by binary weights” module implies that the value should take -1 or +1, rather than 0 or 1. However, at the bottom of page 5, the authors claim that the binary values take +1 and 0. Could the authors clearly explain the term “parameter” and “value”?
 
Could the author further explain how to construct the majority activation function?
In the part of “calculating accuracy”, the authors mention that “running the QBNN with the weights in superposition for each point in the training set separately” and “there are N qubits containing the prediction of the QBNN”. To my understanding, there are 3 qubits representing the 8 weights, several qubits representing the input values, and N qubits representing the predictions. But how to construct the final landscape state to be optimized with these qubits?
 
Could the author explain intuitively the main idea of the amplitude amplification method? Specifically, what is the relation between the qubits representing parameters and the qubits presenting prediction results?
 
During the amplitude amplification process, the probabilities change periodically. How to select the best number of steps k in advanced if we do not known the best parameter? Or how to judge if the training is success?
 
Overall speaking, I think this paper is interesting. However, the presentation is unclear and I suggest the authors to revise their draft by providing more technical details.</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">4: Ok but not good enough - rejection</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></main></div>
  </div>
</div>


    <!-- Footer -->
    <footer class="sitemap">
      <div class="container">
        <div class="row hidden-xs">
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/venues">All Venues</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="/contact">Contact</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
    
        <div class="row visible-xs-block">
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/contact">Contact</a></li>
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
      </div>
    </footer>
    
    <footer class="sponsor">
      <div class="container">
        <div class="row">
          <div class="col-sm-10 col-sm-offset-1">
            <p class="text-center">
              OpenReview is created by the <a href="http://www.iesl.cs.umass.edu/" target="_blank">Information Extraction and Synthesis Laboratory</a>, College of Information and Computer Science, University of Massachusetts Amherst. We gratefully acknowledge the support of the OpenReview sponsors:  Google,  Facebook, NSF, the University of Massachusetts Amherst Center for Data Science, and Center for Intelligent Information Retrieval, as well as the Google Cloud Platform for donating the computing and networking services on which OpenReview.net runs.
            </p>
          </div>
        </div>
      </div>
    </footer>

  <div id="feedback-modal" class="modal fade" tabindex="-1" role="dialog">
    <div class="modal-dialog">
      <div class="modal-content">
        <div class="modal-header">
          <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button>
          <h3 class="modal-title">Send Feedback</h3>
        </div>
        <div class="modal-body">
          <p>Enter your feedback below and we'll get back to you as soon as possible.</p>
          <form action="/feedback" method="POST">
            <div class="form-group">
              <input type="email" name="from" class="form-control" placeholder="Email" />
            </div>
            <div class="form-group">
              <input type="text" name="subject" class="form-control" placeholder="Subject" />
            </div>
            <div class="form-group">
              <textarea name="message" class="form-control feedback-input" rows="5" placeholder="Message" required=""></textarea>
            </div>
          <ul id="ui-id-2" tabindex="0" class="ui-menu ui-widget ui-widget-content" style="display: none;"></ul></form>
        </div>
        <div class="modal-footer">
          <button type="button" class="btn btn-default" data-dismiss="modal">Cancel</button>
          <button type="button" class="btn btn-primary">Send</button>
        </div>
      </div>
    </div>
  </div>

  <script type="text/javascript" async="" src="https://www.google-analytics.com/analytics.js"></script><script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js"></script>
  <script>window.jQuery || document.write('&lt;script src="/static/js/vendor/jquery-2.2.4.min.js"&gt;&lt;\/script&gt;')</script>

  <script src="/static/dist/vendor.min.js"></script>
  <script src="/static/dist/templates.min.js"></script>
  <script src="/static/dist/openreview.min.js"></script>

    <script>window.legacyScripts = true;</script>


    <script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-108703919-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() { dataLayer.push(arguments); }
      gtag('js', new Date());
      gtag('config', 'UA-108703919-1');
    </script>


<div role="status" aria-live="assertive" aria-relevant="additions" class="ui-helper-hidden-accessible"></div></body></html>
<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" class="no-js"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>Hierarchical interpretations for neural network predictions | OpenReview</title>
  <meta name="description" content="" />

      <meta name="citation_title" content="Hierarchical interpretations for neural network predictions" />
        <meta name="citation_author" content="Anonymous" />
      <meta name="citation_publication_date" content="2018/09/27" />
      <meta name="citation_online_date" content="2018/09/27" />
      <meta name="citation_pdf_url" content="https://openreview.net/pdf?id=SkEqro0ctQ" />
      <meta name="twitter:card" content="summary" />
      <meta name="twitter:site" content="@openreviewnet" />
      <meta name="og:title" content="Hierarchical interpretations for neural network predictions" />
      <meta name="og:description" content="Deep neural networks (DNNs) have achieved impressive predictive performance due to their ability to learn complex, non-linear relationships between variables. However, the inability to effectively..." />
      <meta name="og:image" content="https://openreview.net/static/images/openreview_logo_512.png" />

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans:400,400i,700,700i" />

  <link rel="stylesheet" href="/static/css/bootstrap.min.css" />
  <link rel="stylesheet" href="/static/css/jquery-ui.min.css" />
  <link rel="stylesheet" href="/static/css/main.min.css" />
</head>

<body class="forum">
  <nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
  
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand home push-link" href="/"><strong>OpenReview</strong>.net</a>
      </div>
  
      <div id="navbar" class="navbar-collapse collapse">
        <form class="navbar-form navbar-left profile-search" role="search">
          <div class="form-group has-feedback">
            <input id="search_input" type="text" class="form-control ui-autocomplete-input" placeholder="Search ICLR 2019 Conference" autocomplete="off" />
            <span class="glyphicon glyphicon-search form-control-feedback" aria-hidden="true"></span>
          </div>
  
          <input id="search_group" type="hidden" value="ICLR.cc/2019/Conference" />
          <input id="search_content" type="hidden" value="all" />
        <ul id="ui-id-1" tabindex="0" class="ui-menu ui-widget ui-widget-content ui-autocomplete ui-front" style="display: none;"></ul></form>
  
        <ul class="nav navbar-nav navbar-right">
        
            <li id="user-menu"><a href="/login">Login</a></li>
        </ul>
      </div>
  
    </div>
  </nav>

  <div id="or-banner" class="banner" style="">
  <div class="container">
    <div class="row">
      <div class="col-xs-12"><a href="/group?id=ICLR.cc/2019/Conference" title="Venue Homepage"><img class="icon" src="/static/images/arrow_left.svg" /> Go to <strong>ICLR 2019 Conference</strong> homepage</a></div>
    </div>
  </div>
</div>
<div id="flash-message-container" class="alert alert-danger" role="alert" style="display: none;">
  <div class="container">
    <div class="row">
      <div class="col-xs-12">
        <div class="alert-content">
          <button type="button" class="close" aria-label="Close"><span aria-hidden="true">×</span></button>
        </div>
      </div>
    </div>
  </div>
</div>

<div class="container">
  <div class="row">
    <div class="col-xs-12">
      <main id="content" class="clearfix openbanner-visible legacy-styles"><div id="note_SkEqro0ctQ" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Hierarchical interpretations for neural network predictions</a> <a class="note_content_pdf" href="/pdf?id=SkEqro0ctQ" title="Download PDF" target="_blank"><img src="/static/images/pdf_icon_blue.svg" /></a> </h2></div><div class="meta_row"><span class="signatures">Anonymous</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">28 Sep 2018 (modified: 09 Nov 2018)</span><span class="item">ICLR 2019 Conference Blind Submission</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span><span class="item"><a class="action-bibtex-modal" data-bibtex="@inproceedings{    &#10;anonymous2019hierarchical,    &#10;title={Hierarchical interpretations for neural network predictions},    &#10;author={Anonymous},    &#10;booktitle={Submitted to International Conference on Learning Representations},    &#10;year={2019},    &#10;url={https://openreview.net/forum?id=SkEqro0ctQ},    &#10;note={under review}    &#10;}">Show Bibtex</a></span><a class="note_content_pdf item" href="/revisions?id=SkEqro0ctQ" target="_blank">Show Revisions</a></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Abstract: </span><span class="note_content_value">Deep neural networks (DNNs) have achieved impressive predictive performance due to their ability to learn complex, non-linear relationships between variables. However, the inability to effectively visualize these relationships has led to DNNs being characterized as black boxes and consequently limited their applications. To ameliorate this problem, we introduce the use of hierarchical interpretations to explain DNN predictions through our proposed method: agglomerative contextual decomposition (ACD). Given a prediction from a trained DNN, ACD produces a hierarchical clustering of the input features, along with the contribution of each cluster to the final prediction. This hierarchy is optimized to identify clusters of features that the DNN learned are predictive. We introduce ACD using examples from Stanford Sentiment Treebank and ImageNet, in order to diagnose incorrect predictions, identify dataset bias, and extract polarizing phrases of varying lengths. Through human experiments, we demonstrate that ACD enables users both to identify the more accurate of two DNNs and to better trust a DNN's outputs. We also find that ACD's hierarchy is largely robust to adversarial perturbations, implying that it captures fundamental aspects of the input and ignores spurious noise.</span></div><div class="note_contents"><span class="note_content_field">Keywords: </span><span class="note_content_value">interpretability, natural language processing, computer vision</span></div><div class="note_contents"><span class="note_content_field">TL;DR: </span><span class="note_content_value">We introduce and validate hierarchical local interpretations, the first technique to automatically search for and display important interactions for individual predictions made by LSTMs and CNNs.</span></div><div class="reply_row clearfix"><div class="item" id="reply_count">9 Replies</div></div></div><hr class="small" /><div id="note_children"><div class="note_with_children"><div id="note_r1lzrabz6Q" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Modifications to paper in response to reviewers and commenters</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=SkEqro0ctQ&amp;noteId=r1lzrabz6Q"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper113 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">09 Nov 2018</span><span class="item">ICLR 2019 Conference Paper113 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">We thank the reviewers for their time and thoughtful comments. In response to their input, we have made the following changes to the manuscript: 

1. To address  reviewers 2 and 3’s concerns about the motivation of our agglomeration procedure, we added a paragraph at the beginning of Section 3.2 to give more intuition on our agglomeration procedure, before delving into the precise, mathematical details.
2. To address reviewer 1’s questions about the motivation of generalizing CD to CNNs, we added the fifth in Section 3.1 to give more details.
3. To address Shi Feng’s questions about comparing with Godin et al.’s concurrent work, and reviewer 1’s comments about motivating our generalization of CD, we added Figure S5 on page 27 to illustrate rationale for equations in CD and compare against Godin et al.
4. To address reviewer 2’s concerns about uncertainty estimates for our usability study, we added statistical significance analysis for human experiments in the third and fifth paragraphs on page 8.
5. Minor modifications for clarity in response to the reviewers (e.g. in the introduction, method section)

We should note that the pdfdiff is showing more changes than we actually made. This is because we had to move one of our larger figures to keep things in place, which appears to have triggered a change, e.g. the bottom half of page 8. In these cases, the actual text and layout of the paper has not been altered.</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_Hyx_i_0h3Q" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Interesting hierarchical approach to explainability</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=SkEqro0ctQ&amp;noteId=Hyx_i_0h3Q"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper113 AnonReviewer2</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">05 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper113 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">This paper proposes a hierarchical extension of contextual decomposition. The approach is validated in qualitative examples and a small scale usability study

Quality, 
The paper is well motivated. Contextual decomposition is briefly described but detailed enough to self-contained. The experimental evaluation produces usability evidence. Uncertainty could have been better explained, 

Clarity, 
The main methodological contribution (hierarchical CD) is well motivated but only  provided in the form of an algorithm. Could have been more precisely described and optimality discussed. 

Originality &amp; significance
The work builds heavily on CD but has the hierarchical extension is original and significant. 
Uncertainty estimates could have improved the significance of the usability study

pros and cons
+ interesting problem
+ well-motivated algorithmic extension of CD
- uncertainty of usability experiment?
</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">7: Good paper, accept</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">3: The reviewer is fairly confident that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_r1lU3TWMaQ" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Thanks for the feedback</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=SkEqro0ctQ&amp;noteId=r1lU3TWMaQ"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper113 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">09 Nov 2018</span><span class="item">ICLR 2019 Conference Paper113 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Thanks for the helpful comments and positive feedback. We’re glad you agree that the hierarchical notion of importance is important and well validated. We address some of your concerns below.

“The main methodological contribution (hierarchical CD) is well motivated but only provided in the form of an algorithm. Could have been more precisely described and optimality discussed.”

This is great feedback, we agree that we were missing a bigger picture, non-mathematical description of the algorithm. We have added a paragraph at the beginning of Section 3.2 giving intuition for our method before jumping into the technical details.

“Uncertainty estimates could have improved the significance of the usability study.” 

We agree, and have updated the paper to include statistical significance results. We’ve provided the details below, but the summary is that most of the big jumps in our plots were significant, with the exception of ImageNet in plot A, where the results were only “suggestive” (p values ranged from 0.07 to 0.15). Overall, it seems like the benefits of ACD are in fact statistically meaningful.

Statistical significance results summary:

Identifying an accurate model (one-sided two-proportion t-test)
Sentiment: gaps between ACD and IG, break-down are significant, ACD to CD is not
MNIST: nothing is significant
ImageNet: gaps between ACD and others are suggestive, but not significant (p values range from 0.07 to 0.15)

Ranking trust in model (permutation test with mean rank test statistic)
Sentiment/ImageNet: ACD’s mean rank is significantly higher than all other methods
MNIST: ACD is significantly higher than break down, everything else is not.</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div><div class="note_with_children"><div id="note_S1xxnzLo2m" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Related (and likely concurrent) work</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=SkEqro0ctQ&amp;noteId=S1xxnzLo2m"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures"><a href="/profile?id=~Shi_Feng1" class="profile-link">Shi Feng</a></span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">04 Nov 2018</span><span class="item">ICLR 2019 Conference Paper113 Public Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Godin et al. just presented at EMNLP an extension of CD to CNNs: <a href="https://arxiv.org/abs/1808.09551" target="_blank" rel="nofollow">https://arxiv.org/abs/1808.09551</a>
It should be noted that it was put on arxiv 2 months later than yours. But it would be interesting to compare the two, for example Godin et al. did not partition the bias.</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_SygJ7JMzp7" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Thanks for your interest in our work</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=SkEqro0ctQ&amp;noteId=SygJ7JMzp7"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper113 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">09 Nov 2018</span><span class="item">ICLR 2019 Conference Paper113 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Thanks for your interest in our work, Shi! I think it is worth clarifying that in both our work and Godin et al., the extension of CD is a relatively secondary contribution to the “meat” of the paper (for our work that is the hierarchical interpretation, for Godin et al. it is the analysis of character-level neural networks).

Interestingly, our original extension of CD to CNNs was quite similar to Godin et. al. However, when we tried this on ImageNet we found that the results were both qualitatively bad, and often produced very large importance scores (indicating that something was “blowing up”). To fix this, there were two main changes we made (which is also where we differ from Godin et al.): (1) partitioning the bias in a conv/linear layer and (2) modifying the decomposition for the ReLu nonlinearity.

We have added a paragraph to 3.1 and a supplementary figure (Fig S5) on page 27 both to show the difference between our approach and Godin et al. and to better motivate our generalized CD. Hopefully this can shed some light into the differences in behaviour in a vision setting.</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div><div class="note_with_children"><div id="note_SJgRJN1chm" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Contextual decomposition for general DNNs</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=SkEqro0ctQ&amp;noteId=SJgRJN1chm"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper113 AnonReviewer1</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">02 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper113 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">**Summary**

In this paper, the authors adapt an existing feature interpretation method for LSTMs for generic DNNs. 

**Strength**

1. Splitting information into binary groups at each layer is a neat approach to segregate interpretations.
2. Experiments are elaborate and cover the breadth of the proposed method well.
3. The paper is well presented and fairly easy to follow. 


**Weakness**

1. Limited contributions in terms of novelty. This approach for RNNs is presented fairly well in the previous paper [Beyond Word Importance: Contextual Decomposition to Extract Interactions from LSTMs](<a href="https://arxiv.org/abs/1801.05453)." target="_blank" rel="nofollow">https://arxiv.org/abs/1801.05453).</a>
2. It seems that there is not enough justification for the modifications in beta and gamma made for convolution and pooling layers.
</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">5: Marginally below acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_ryeseAZMaQ" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Thanks for your comments</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=SkEqro0ctQ&amp;noteId=ryeseAZMaQ"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper113 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">09 Nov 2018</span><span class="item">ICLR 2019 Conference Paper113 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Thanks for the helpful comments. We would like to address your concerns about the novelty of the work.

“1. Limited contributions in terms of novelty. This approach for RNNs is presented fairly well in the previous paper.”

As you correctly noted, one of the two contributions of this paper is to generalize CD from LSTMs to generic DNNs. However, we would like to clarify that the most important contribution of this paper is not generalizing CD, but introducing the concept (and implementation) of hierarchical importance for interpreting neural network predictions. 

The current state of the art for interpreting neural network predictions is word/pixel-level heat-maps, such as Figure 5 in [1]. Our main contribution is to introduce hierarchical interpretations, such as Figure 2 in our paper, and show that they improve over heat maps, the prior SOTA. In our human experiments, we compare our hierarchical interpretations (agglomerative CD, or ACD) against three non-hierarchical baselines, ultimately concluding that the hierarchy is in fact beneficial.

We hope that we have clarified that hierarchical interpretations are the main contribution of our paper, and that this addresses your concern around the novelty of this work. To address this, we have (slightly) modified our introduction and method sections. We tried to make this clear throughout the paper and would welcome suggestions on how to avoid similar misunderstandings for future readers.

“2. It seems that there is not enough justification for the modifications in beta and gamma made for convolution and pooling layers.”

Thanks for pointing this out - we realize we omitted much of our justification in making the modifications for convolution and pooling layers. To address this, we have added some intuition in the fifth paragraph of section 3.1. Additionally, we have added a figure in page 27 of the supplement (Fig S5) showing the effect of our modifications to the update equations for convolution and ReLU layers.


[1] <a href="https://arxiv.org/pdf/1612.08220.pdf" target="_blank" rel="nofollow">https://arxiv.org/pdf/1612.08220.pdf</a>
</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div><div class="note_with_children"><div id="note_BJgqJWpijm" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Interesting idea. Potentially convincing experiments. Limited methodological novelty</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=SkEqro0ctQ&amp;noteId=BJgqJWpijm"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper113 AnonReviewer3</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">23 Oct 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper113 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">This paper proposes a novel approach to explain neural network predictions by learning hierarchical representations of groups of input features and their contribution to the final prediction. The proposed method is a straightforward extension of the contextual decomposition work by (Murdoch et. al. 2018) which estimates feature interpretability for LSTMs. This work extends (Murdoch et. al. '18) to more general NN architectures and further employs agglomerative clustering to identify groups of features-- as opposed to individual features--that are predictive of the output. 

Results are shown using a LSTM trained on the standard Stanford sentiment task and a VCG DNN trained on ImageNet which show the superior performance of the proposed approach. In addition, the paper also provides some survey results where "humans" were asked to pick more interpretable models. 

The paper is nicely written and puts itself nicely in context of the previous work. Though, I have several concerns:

1). Biggest concern: Conditioning on the (Murdoch et. al. 18) paper, the methodological novelty of the proposed approach is minimal. Though, the experimental gains on the vision and NLP tasks are nice.

2). It was unclear to me how the agglomerative algorithm (Algorithm 1) was run. That is, was it run as part of the LSTM estimation for instance for the sentiment task OR was it run post-hoc after getting the model estimates from LSTM? If it was run post-hoc then I am unsure if we can assume that the "agglomeratively grouped CD scores of individual features" are the same as the "CD scores for the groups/interactions of features" in terms of their contribution to the final prediction.

3). Though, the paper mentions several times regarding generalizing (Murdoch et. al. 18) to architectures other than LSTMs but still the experimental results on the sentiment task uses an LSTM as the model. It would have been nice to show the comparative strength of the proposed approach on a different architecture even for the sentiment task. (I understand that the paper uses a different DNN architecture for the vision task).

4). The paper talks several times about diagnosing why a model went wrong e.g. the "negation" in the case of the LSTM model in Figure 2, but never discusses the bigger and more interesting problem. How can we build an improved LSTM model for the sentiment task which classifies that incorrect prediction correctly? 

</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">5: Marginally below acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_Syxrlyfzpm" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Thanks for your comments</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=SkEqro0ctQ&amp;noteId=Syxrlyfzpm"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper113 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">09 Nov 2018</span><span class="item">ICLR 2019 Conference Paper113 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Thank you very much for the exceptionally detailed and thoughtful review. We address your concerns below

1) We’d like to emphasize that our main source of novelty lies in moving from the word/pixel-level heat maps (e.g. Figure 5 in [1]), which are the current SOTA for interpreting individual DNN predictions, to hierarchical interpretations, such as Figure 2 in our paper. In our human experiments, we compare our hierarchical interpretations against three non-hierarchical baselines, ultimately concluding that the hierarchy is in fact beneficial.

Given that the experimental gains across NLP and vision are meaningful, we feel that the simplicity of our method should be an argument for its acceptance, not against. In machine learning, there is often the temptation to propose complicated “highly novel” approaches, many of which are never adopted. In contrast, we explicitly tried to identify the simplest approach that could produce a meaningful improvement over the current SOTA. In interpretability, we feel simplicity is particularly important, as we must consider the human component in providing simple, easy to understand insights into the model. We have found that the more complicated the interpretation method, the harder it is to convince users to use, understand, and trust the method’s output.

2) As R2 also pointed out, section 3.2 was too heavy with mathematical details and lacking intuition. We have now added a paragraph to the beginning of section 3.2, which should hopefully make it clearer. 

To answer your question, the agglomeration algorithm was run post-hoc - ACD does not modify the original prediction of the LSTM. 

The agglomeration algorithm is simply an approach for constructing the hierarchy of phrases/pixels, but does not alter the CD scores produced for each node in the hierarchy. That is, the score for each node in the hierarchy is simply the CD score for that particular phrase/pixel-blob, which I believe is what you mean by “CD scores for the groups/interactions of features". By "agglomeratively grouped CD scores of individual features", I think you’re referring to the sum of the CD scores for the sub-phrases/words contained within a phrase. This value isn’t displayed in the hierarchy, as summing importance scores can’t capture interactions, such as the negation between “n’t lift” and “this heartfelt enterprise out of the familiar.” that occurs in Figure 2.

3) We agree that it could be interesting to see whether CNNs and LSTMs produce similar importance scores and/or hierarchies on the same dataset, and this is something we have thought about for future work (e.g. “Do LSTMs and CNNs capture different kinds of interactions?”). Unfortunately, in a conference paper we don’t feel we have the space to do such an analysis in a defensible manner. Moreover, we feel the existing results are more important to justifying the main part of the paper - hierarchical interpretations.

4) The problem of using interpretations to improve accuracy is quite interesting, and one that we have spent a lot of time thinking about it. The short answer is that it is not immediately clear how to do so, but we are optimistic that improved interpretations like ACD should prove useful in improving model’s accuracy

However, even if ACD never leads to increased prediction performance, we think it’s important to stress that there are many uses for interpretations that have no effect on predictive performance. As we discuss in the first paragraph of our introduction, in scientific applications [2-4], it is the interpretations themselves which are the findings, and are ultimately reported in publications. In industry, interpretability is important in determining the fairness of a model [5], and satisfying regulatory concerns [6]. Finally, as we show in our human experiments, improved interpretations help users to better trust the predictions of their models, which is helpful even if it does not change the predictions themselves.

[1] <a href="https://arxiv.org/pdf/1612.08220.pdf" target="_blank" rel="nofollow">https://arxiv.org/pdf/1612.08220.pdf</a>
[2] https://arxiv.org/abs/1702.05747 
[3]https://www.researchgate.net/publication/261538344_The_Emergence_of_Machine_Learning_Techniques_in_Criminology 
[4] http://msb.embopress.org/content/12/7/878 
[5] https://arxiv.org/abs/1104.3913 
[6] https://arxiv.org/abs/1606.08813 </span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div></div></main></div>
  </div>
</div>


    <!-- Footer -->
    <footer class="sitemap">
      <div class="container">
        <div class="row hidden-xs">
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/venues">All Venues</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="/contact">Contact</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
    
        <div class="row visible-xs-block">
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/contact">Contact</a></li>
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
      </div>
    </footer>
    
    <footer class="sponsor">
      <div class="container">
        <div class="row">
          <div class="col-sm-10 col-sm-offset-1">
            <p class="text-center">
              OpenReview is created by the <a href="http://www.iesl.cs.umass.edu/" target="_blank">Information Extraction and Synthesis Laboratory</a>, College of Information and Computer Science, University of Massachusetts Amherst. We gratefully acknowledge the support of the OpenReview sponsors:  Google,  Facebook, NSF, the University of Massachusetts Amherst Center for Data Science, and Center for Intelligent Information Retrieval, as well as the Google Cloud Platform for donating the computing and networking services on which OpenReview.net runs.
            </p>
          </div>
        </div>
      </div>
    </footer>

  <div id="feedback-modal" class="modal fade" tabindex="-1" role="dialog">
    <div class="modal-dialog">
      <div class="modal-content">
        <div class="modal-header">
          <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button>
          <h3 class="modal-title">Send Feedback</h3>
        </div>
        <div class="modal-body">
          <p>Enter your feedback below and we'll get back to you as soon as possible.</p>
          <form action="/feedback" method="POST">
            <div class="form-group">
              <input type="email" name="from" class="form-control" placeholder="Email" />
            </div>
            <div class="form-group">
              <input type="text" name="subject" class="form-control" placeholder="Subject" />
            </div>
            <div class="form-group">
              <textarea name="message" class="form-control feedback-input" rows="5" placeholder="Message" required=""></textarea>
            </div>
          <ul id="ui-id-2" tabindex="0" class="ui-menu ui-widget ui-widget-content" style="display: none;"></ul></form>
        </div>
        <div class="modal-footer">
          <button type="button" class="btn btn-default" data-dismiss="modal">Cancel</button>
          <button type="button" class="btn btn-primary">Send</button>
        </div>
      </div>
    </div>
  </div>

  <script type="text/javascript" async="" src="https://www.google-analytics.com/analytics.js"></script><script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js"></script>
  <script>window.jQuery || document.write('&lt;script src="/static/js/vendor/jquery-2.2.4.min.js"&gt;&lt;\/script&gt;')</script>

  <script src="/static/dist/vendor.min.js"></script>
  <script src="/static/dist/templates.min.js"></script>
  <script src="/static/dist/openreview.min.js"></script>

    <script>window.legacyScripts = true;</script>


    <script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-108703919-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() { dataLayer.push(arguments); }
      gtag('js', new Date());
      gtag('config', 'UA-108703919-1');
    </script>


<div role="status" aria-live="assertive" aria-relevant="additions" class="ui-helper-hidden-accessible"></div></body></html>
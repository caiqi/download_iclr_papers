<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" class="no-js"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>Diverse Machine Translation with a Single Multinomial Latent Variable | OpenReview</title>
  <meta name="description" content="" />

      <meta name="citation_title" content="Diverse Machine Translation with a Single Multinomial Latent Variable" />
        <meta name="citation_author" content="Anonymous" />
      <meta name="citation_publication_date" content="2018/09/27" />
      <meta name="citation_online_date" content="2018/09/27" />
      <meta name="citation_pdf_url" content="https://openreview.net/pdf?id=BJgnmhA5KQ" />
      <meta name="twitter:card" content="summary" />
      <meta name="twitter:site" content="@openreviewnet" />
      <meta name="og:title" content="Diverse Machine Translation with a Single Multinomial Latent Variable" />
      <meta name="og:description" content="There are many ways to translate a sentence into another language. Explicit modeling of such uncertainty may enable better model fitting to the data and it may enable users to express a preference..." />
      <meta name="og:image" content="https://openreview.net/static/images/openreview_logo_512.png" />

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans:400,400i,700,700i" />

  <link rel="stylesheet" href="/static/css/bootstrap.min.css" />
  <link rel="stylesheet" href="/static/css/jquery-ui.min.css" />
  <link rel="stylesheet" href="/static/css/main.min.css" />
</head>

<body class="forum">
  <nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
  
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand home push-link" href="/"><strong>OpenReview</strong>.net</a>
      </div>
  
      <div id="navbar" class="navbar-collapse collapse">
        <form class="navbar-form navbar-left profile-search" role="search">
          <div class="form-group has-feedback">
            <input id="search_input" type="text" class="form-control ui-autocomplete-input" placeholder="Search ICLR 2019 Conference" autocomplete="off" />
            <span class="glyphicon glyphicon-search form-control-feedback" aria-hidden="true"></span>
          </div>
  
          <input id="search_group" type="hidden" value="ICLR.cc/2019/Conference" />
          <input id="search_content" type="hidden" value="all" />
        <ul id="ui-id-1" tabindex="0" class="ui-menu ui-widget ui-widget-content ui-autocomplete ui-front" style="display: none;"></ul></form>
  
        <ul class="nav navbar-nav navbar-right">
        
            <li id="user-menu"><a href="/login">Login</a></li>
        </ul>
      </div>
  
    </div>
  </nav>

  <div id="or-banner" class="banner" style="">
  <div class="container">
    <div class="row">
      <div class="col-xs-12"><a href="/group?id=ICLR.cc/2019/Conference" title="Venue Homepage"><img class="icon" src="/static/images/arrow_left.svg" /> Go to <strong>ICLR 2019 Conference</strong> homepage</a></div>
    </div>
  </div>
</div>
<div id="flash-message-container" class="alert alert-danger" role="alert" style="display: none;">
  <div class="container">
    <div class="row">
      <div class="col-xs-12">
        <div class="alert-content">
          <button type="button" class="close" aria-label="Close"><span aria-hidden="true">×</span></button>
        </div>
      </div>
    </div>
  </div>
</div>

<div class="container">
  <div class="row">
    <div class="col-xs-12">
      <main id="content" class="clearfix openbanner-visible legacy-styles"><div id="note_BJgnmhA5KQ" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Diverse Machine Translation with a Single Multinomial Latent Variable</a> <a class="note_content_pdf" href="/pdf?id=BJgnmhA5KQ" title="Download PDF" target="_blank"><img src="/static/images/pdf_icon_blue.svg" /></a> </h2></div><div class="meta_row"><span class="signatures">Anonymous</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">28 Sep 2018 (modified: 15 Nov 2018)</span><span class="item">ICLR 2019 Conference Blind Submission</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span><span class="item"><a class="action-bibtex-modal" data-bibtex="@inproceedings{    &#10;anonymous2019diverse,    &#10;title={Diverse Machine Translation with a Single Multinomial Latent Variable},    &#10;author={Anonymous},    &#10;booktitle={Submitted to International Conference on Learning Representations},    &#10;year={2019},    &#10;url={https://openreview.net/forum?id=BJgnmhA5KQ},    &#10;note={under review}    &#10;}">Show Bibtex</a></span><a class="note_content_pdf item" href="/revisions?id=BJgnmhA5KQ" target="_blank">Show Revisions</a></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Abstract: </span><span class="note_content_value">There are many ways to translate a sentence into another language. Explicit modeling of such uncertainty may enable better model fitting to the data and it may enable users to express a preference for how to translate a piece of content. Latent variable models are a natural way to represent uncertainty. Prior work investigated the use of multivariate continuous and discrete latent variables, but their interpretation and use for generating a diverse set of hypotheses have been elusive. In this work, we drastically simplify the model, using just a single multinomial latent variable. The resulting mixture of experts model can be trained efficiently via hard-EM and can generate a diverse set of hypothesis by parallel greedy decoding. We perform extensive experiments on three WMT benchmark datasets that have multiple human references, and we show that our model provides a better trade-off between quality and diversity of generations compared to all baseline methods.\footnote{Code to reproduce this work is available at: anonymized URL.}</span></div><div class="note_contents"><span class="note_content_field">Keywords: </span><span class="note_content_value">machine translation, latent variable models, diverse decoding</span></div><div class="reply_row clearfix"><div class="item" id="reply_count">7 Replies</div></div></div><hr class="small" /><div id="note_children"><div class="note_with_children"><div id="note_Bye_FWf3nX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Interesting but somewhat incremental approach; related work a bit weak</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=BJgnmhA5KQ&amp;noteId=Bye_FWf3nX"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1397 AnonReviewer3</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">04 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper1397 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">The authors aim to increase diversity in machine translation using a multinomial latent variable that captures uncertainty in the target sentence. Modeling uncertainty with latent variables is of course relatively common in ML, and this work has similarities with latent variables models for MT [Zhang et al., 2016] and for other generation tasks such as dialogue [Serban et al., 2017; etc.]. The key difference is that the authors here use a Mixture of Expert (MoE) approach while most relevant prior works use variational approaches. Experiments show improvements in diversity over variational NMT [Zhang et al., 2016] and decoding-time approaches (e.g., diversity constraints [Vijayakumar et al., 2016]).

Overall, the proposed approach (hard-MoE) is well motivated and the experimental results are relatively promising. I think the authors did a good job analyzing and justifying their approach against the soft version of their model (i.e., soft-MoE causes experts to “die” during training) and variational alternatives (i.e., variational approaches often have failure modes where the latent variable is effectively ignored.) 

However, I find related work a bit weak because the problem of producing diverse output has been a much bigger focus in tasks other than MT, such as dialogue and image captioning. The paper glosses over related approaches on these tasks, but the need to model uncertainty for these other tasks is much bigger since source and target are usually not semantically equivalent. So it would have been nice to see argumentative (or even empirical) comparisons with popular models such as VHRED for dialogue [Serban et al., 2017], as many of these models are not intrinsic to either MT or dialogue (the only aspect specific to dialogue in VHRED is context, but it can be set to empty and thus VHRED could have been used as a baseline in the paper.) It would be interesting to compare the work against Serban et al. [2017]’s justification for using a latent variable, which is quite different (see their bit on “shallow generation”, and the idea that their latent variable encapsulates “the high-level semantic content of of the output”).  

One technical caveat is that there appears to be some inconsistency in the comparison between human and systems in Table 1. If N is the number of references, then systems are evaluated on N references while the human “system” on only N-1 because of leave-one-out. While this difference might have less of an impact on “average oracle BLEU” than standard BLEU, having one less reference might still penalize the human “system”, and this might partially explain why “beam search’s average oracle BLEU is fairly close to human’s average oracle BLEU”. The right thing to do would be to evaluate both human and all systems in a leave-one-out approach (i.e., let references [r1 … rN] and systems [s1 … sM], then evaluate each element of [s1 … sM r1] on references [r2 … rN], etc.). In that manner, all the “systems” including human are consistently evaluated on *exactly* the same references. 

Minor comments: 

 “By putting the model in evaluation mode during minimization we also speed up training and reduce memory consumption, since the K forward passes have no gradient computation or storage.” In other words, does this mean the algorithm is easy to *parallelize* because sharing parameters is often what kills the effectiveness of parallelized SGD and variants? If so, “parallelizing” is key word to mention here otherwise I don’t see how we can speed that up by increasing K.

Figure 2: performance drops with K approaching 20. What happens with K=50 or 100 or more? This is a bit of a concern because (1) larger K could require a massive amount parallelization and (2) competing approaches such as VHRED can handle latent variables with higher capacities.

Practical considerations subsection is too vague: parameter sharing is not formally/mathematically explained and the work could be hard to reproduce exactly (as there are often different ways to share parameters). 

Why no “#ref covered” for human in Table 1, and why no comparison with Variational NMT? Zhang et al [2016] is the most talked about competing model, so it should probably be evaluated on both settings.

Missed reference: Mutual Information and Diverse Decoding Improve Neural Machine Translation.
Jiwei Li, Dan Jurafsky. <a href="https://arxiv.org/abs/1601.00372" target="_blank" rel="nofollow">https://arxiv.org/abs/1601.00372</a></span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">6: Marginally above acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_H1gWie8cTQ" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Response to AnonReviewer3 (continued)</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=BJgnmhA5KQ&amp;noteId=H1gWie8cTQ"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1397 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">15 Nov 2018</span><span class="item">ICLR 2019 Conference Paper1397 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">“By putting the model in evaluation mode during minimization we also speed up training and reduce memory consumption, since the K forward passes have no gradient computation or storage.” 
Learning a Soft-MoE model with K experts requires K-1 times more work in both the forward and backward pass compared to a baseline (single expert) model. In contrast, our Hard-MoE model requires K times more work in the forward pass (to choose z), but the backwards pass is the same work as the baseline (see Algorithm 1). Moreover, the K forward passes can be very efficiently parallelized since they do not require storing any intermediate values for backpropagation and therefore require less GPU memory (e.g., using the torch.no_grad option in PyTorch).
With K=10, the training time of our model is roughly twice that of a baseline model on the same hardware. At test time we can generate K hypotheses from each value of the latent variable in parallel via greedy decoding.

“Small/big value of K”
In this paper we aim at generating order 10 hypotheses, as we think that's a reasonable amount to present to users in practical applications, while still capturing the most significant diversity. This also matches the number of references we have available for evaluation. We leave to future work scaling to a much larger number of states and properly evaluating in that setting. Note that although competing approaches like VHRED or Variational NMT have the potential to model a larger variety of hypotheses by introducing continuous latent variables, they actually fail to use the latent variable and cannot generate different hypotheses from different values of z. It seems that the benefits of those approaches are mostly due to their implicit regularization (due to the addition of noise in the latent space), more than better modeling ability.

“Parameter sharing”
We share all parameters among the experts, except that each expert has a unique beginning-of-sentence embedding in the decoder (see paragraph 2, Sec. 3.2). We also tried other parameterizations, such as to add or concatenate the latent variable's embedding with the input word embeddings at each time step, and to inject it into each decoder layer, but found similar results. Therefore we adopt the simplest approach described above.

“#ref covered”
We could divide all human translations into half and half, use one set as reference and the other as hypothesis to compute the coverage number. However this approach doesn't make full use of all human references, and different divisions lead to different numbers.  Besides, “#ref covered” serves the same purpose as “pairwise BLEU”, both of which measure diversity. We therefore consider “pairwise BLEU” as a more direct metric for comparing both the diversity of human references and the diversity of system hypotheses. 
“Variational NMT”
Variational NMT fails to use the latent variable on the IWSLT dataset. It degenerates to the baseline NMT model and cannot generate different hypotheses (see table 2) unless we use diverse decoding strategies (sampling, beam, diverse beam). Therefore we did not test it on the larger WMT datasets.

“Missing citation”
The beam search diversification heuristic proposed by Li and Jurafsky (2016) is outperformed by diverse beam search (Vijayakumar et al., 2016), which is a baseline in our paper. It's indeed relevant and we have added a reference to it in our updated version.</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_H1lEMxL9TQ" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Response to AnonReviewer3</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=BJgnmhA5KQ&amp;noteId=H1lEMxL9TQ"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1397 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">15 Nov 2018</span><span class="item">ICLR 2019 Conference Paper1397 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">We thank the reviewer for the feedback and comments. We address each of them in turn:

The VHRED model for dialogue (Serban et al., 2017) has a Gaussian latent variable for each utterance given the context and is trained with the VAE objective. Applying this model to machine translation is equivalent to having a latent variable for the target sentence given the source--- which is exactly the variational machine translation baseline (Zhang et al., 2016) we compare to (see Table 2). Our method is not limited to MT and can be applied to other text generation tasks such as dialogue and image captioning. In this work we choose MT because this is an application where the importance of modeling uncertainty has been underestimated so far. People often think that source and target sentences should be semantically equivalent, but neglect the different translation styles (e.g., formal/informal, literal/not literal) and information asymmetry between different languages. For example, Chinese has no tense, while English requires tense specification, and our experiments show that the latent variable captures this phenomenon (Sec. 5.5). More examples include grammatical gender, honorifics, etc. We believe it's important to provide such a variety of translations, which is an unresolved problem in current MT systems. Moreover, compared to dialogue and other applications, MT has a more widely established metric, BLEU, which enables us to do systematic evaluation against a set of reference translations.

The reviewer is right that when computing average oracle BLEU among human references, each reference is evaluated against other N-1 references, while each system hypothesis is evaluated against N references, which could put the score for human at a disadvantage. We have added a note  about this in the updated version.
We also conducted a leave-one-out “average oracle BLEU” evaluation for system hypotheses, i.e. each hypothesis is evaluated against all N-1 subset of N references, followed by averaging. This is equivalent to pair each hypothesis to its best matching reference N-1 times, and its second best once. On the WMT’17 Zh-En dataset for which we only have 3 human references (and therefore, the two evaluations will differ the most), the results are:
                                against all refs (as in the paper)   leave-one-out
    Sampling           17.7                                                    15.9
    Beam                 30.7                                                     27.8
    Diverse beam   28.6                                                    25.8
    Hard-MoE         28.9                                                     26.1
    Human                                                                          33.6
We can see that the relative rankings between the models stay the same, this different evaluation just slightly change the absolute value of this metric. Therefore, all our conclusions hold the same.</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div><div class="note_with_children"><div id="note_H1x1dumo3Q" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Review for Diverse MT with a Single Multinomial Latent Variable</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=BJgnmhA5KQ&amp;noteId=H1x1dumo3Q"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1397 AnonReviewer1</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">03 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper1397 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">This paper studies the diverse text generation problem, specifically on machine translation problem. The authors use a simple method, which just using a single multinomial latent variable compared with previous approaches that using multi latent variables. They named the approach: Hard-MoE. They use parallel greedy decoding to generate the diverse translations and the experiments on three WMT datasets show the approach make a trade-off between diversity and quality.
In general, I think generating the diverse translations for machine translation problem may not so important and piratically in actual scenarios. In fact, how to generate fluent and correct translations is more important. 

For the details, there are some problems. 1) The only modification for this work is to make the soft probability of p(z|x) to be 1/K. The others are several experimental studies. To be an formal ICLR paper, this may not be interesting enough to draw my attention. 2) In case of the results, though the authors claimed they achieved better trade-off between diversity and quality, in my opinion, the beam original beam search is good enough from the results in Table 1. 3) In table 2, what means k=0 for the BLEU score? 4) I want to indicate that the purpose of VAE approach related to this work is to increase the model performance w.r.t. the BLEU score instead of the diversity, same as the original MoE method. 5) There are some related works to this work, but their methods are also very effective in terms of the BLEU score, e.g., the author can check this one in EMNLP this year: “Sequence to Sequence Mixture Model for Diverse Machine Translation”. Authors may need a more discussion between those works and this work.
</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">5: Marginally below acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_SkxgQb8cpm" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Response to AnonReviewer1</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=BJgnmhA5KQ&amp;noteId=SkxgQb8cpm"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1397 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">15 Nov 2018</span><span class="item">ICLR 2019 Conference Paper1397 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">“generating the diverse translations for machine translation problem may not so important and piratically in actual scenarios” 
MT systems are approaching human level performance on several language pairs (see recent results of WMT competitions, for instance). Improving translation quality remains a big challenge on low resource languages, but not as much on high resource languages such as those considered in this work. Instead, providing the user with a diverse set of translations that capture different translation styles (e.g., formal/informal, literal/not literal) and information asymmetry between different languages (e.g., when translating from a language without tense to a language that requires tense specification) may become the next important feature of MT systems.
More generally, the study of how to model uncertainty is key to the advance of AI systems in non-deterministic settings and for prediction tasks that are inherently multi-modal. The MT task serves as a good test bed application for this. See the first two paragraphs of the introduction.

“1) The only modification for this work is to make the soft probability of p(z|x) to be 1/K.”
This statement is not correct. As we explain in Sec. 3.1, in addition to the change in prior we also introduce a new training procedure that includes inference of the latent variable and selectively backpropagating through only the optimal latent variable assignment.

“2) ... the beam original beam search is good enough from the results in Table 1”
This statement is not correct. Comparing the “pairwise BLEU” (lower numbers indicate more diversity) and “#refs covered” columns in Table 1, we show that beam search is about 20 (pairwise) BLEU points less diverse than our approach! The qualitative results in Table 3 further illustrate the significant improvement in diversity of our approach compared to beam search.

“3) In table 2, what means k=0 for the BLEU score?”
In this experiment, we use different models to generate 2 hypotheses and compute the BLEU score of the first generated hypothesis (k=0) and the second generated hypothesis (k=1) w.r.t. the reference respectively. We have changed the notation to make this clearer, see new table 2.

“4)  I want to indicate that the purpose of VAE approach related to this work is to increase the model performance...”
A general discussion about the purpose of latent variable models is beyond the scope of this rebuttal. 
In short, latent variables are one major and principled approach to describe uncertainty of distributions, and VAE is a density estimation framework equipped with latent variables. The conditional distribution we aim to model has uncertainty (as there are several plausible ways to translate a source sentence). Such uncertainty is partly captured  by the output distribution of the decoder and partly modeled by the stochastic latent variables.
The potential advantage of VAEs may stem from the implicit regularization induced by the use of latent variables at training time (which is what the reviewer seems to be referring to) or from the better modeling of the underlying uncertainty (which is what we are studying in this paper).  
 
5) Relation to “Sequence to Sequence Mixture Model for Diverse Machine Translation”
This paper is concurrent to ours and was not available at submission time. They also consider the same problem and propose a similar approach. The major differences are:
a) we select only one expert while they use all of them. This means that their model is much more expensive in terms of memory and computation at training time; in fact for larger number of latent states they also propose to select one latent value but they do so by sampling as opposed to via minimization.
b) the parameterization is different.
c) we study the collapses of latent variable models and provide insights on how to prevent these failures.
d) their evaluation is limited to the small IWSLT dataset and to small baseline models, while we use the much bigger WMT datasets, state-of-the-art baselines and we leverage multiple references for each source sentence in our evaluation. Our paper proposes metrics and reports a more in depth analysis of diversity both quantitatively and qualitatively. 
We have added a reference to this paper in the revised version. Thank you for the suggestion.
</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div><div class="note_with_children"><div id="note_Byxs0v_937" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Interesting contribution</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=BJgnmhA5KQ&amp;noteId=Byxs0v_937"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1397 AnonReviewer2</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">03 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper1397 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">This paper proposes a sequence to sequence model augmented with a multinomial latent variable. This variable can be used to generate multiple candidate translations during decoding. This approach is simpler than previous work using continuous latent variables or modifying beam search to encourage diversity, obtaining more diverse translations with a smaller drop in translation accuracy.   

Strengths:
- Simple model that succeeds in achieving its goal of generating diverse translations.
- Provides insights into training models with categorical latent variables. 
Weaknesses:
- More insight into what the latent variable is learning to represent would strengthen the paper. 

While the model is simple, its simplicity has significant strengths: In contrast to more complex latent space, the latent variable assignments can be enumerated explicitly, which enables it to be used to control the generation and compare outputs. The simplicity of the model will force the latent variable towards capturing diversity - modelling uncertainty in how to express the output rather than uncertainty in the content. 

One question about the model architecture is just whether it is sufficient to feed the latent variable embedding only once, as it effect might be diluted across long output sequences (as opposed to, say, feeding the latent variable at each time step). 

The paper provides some interesting insights, such as the need to do hard EM-style training and turning off dropout when inferring the best latent variable assignment during training, to avoid mode collapse. 

What is the effect of initialization? This often has a large impact in EM-style training, and could also lead to mode collapse, though in this case the restricted parameterization might prevent that. 

What is the training time and computational resource requirements? Are multiple DGX-1s running in parallel required to train the model?

What is not clear enough from the paper is what kind of structure the latent variables learn to capture. In particular this model is not biassed towards any explicit notion of the kind of diversity one would like to learn. While there is some qualitative analysis, further analysis would strengthen the paper. 

Overall this is a very interesting contributions that offer useful insights into designing controllable sequence generation models.</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">7: Good paper, accept</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_HyeWvWIc6X" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Response to AnonReviewer2</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=BJgnmhA5KQ&amp;noteId=HyeWvWIc6X"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1397 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">15 Nov 2018</span><span class="item">ICLR 2019 Conference Paper1397 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">We thank the reviewer for the feedback and comments.

“whether it is sufficient to feed the latent variable embedding only once”
In addition to feeding the latent variable embedding once as the beginning-of-sentence (&lt;bos&gt;) token, we also tried other model architectures, including adding or concatenating the latent variable embedding with the input word embeddings at each time step, and injecting it into each decoder layer. We found that they have similar results, therefore we adopt the simplest replacing &lt;bos&gt; strategy. We hypothesize that the latent variable's effect does not dilute across long output sequences because the decoder in Transformer has a self-attention mechanism. When generating each word it can always attend to the latent variable directly without being affected by distance.

“Effect of initialization”
In our experiments, we randomly initialize all weights following the reference Transformer implementation, and our findings are quite consistent across random seeds. As the reviewer conjectures, the particular choice of parameter sharing between experts is key to avoid the common failure mode of one expert taking over all the others, as their parameters are always updated even when they are not selected for a particular input example. 

“What is the training time and computational resource requirements? Are multiple DGX-1s running in parallel required to train the model?”
Training the Hard-MoE model with 10 states takes about twice as long as training the baseline without latent variable. We train the big WMT En-De model with 10 latents in ~3.5 hours on 128 GPUs. An equivalent model can be trained on a single machine with 8 GPUs in ~1.5 days (due to faster inter-GPU communication), or with 1 GPU in about a week.

“Structure captured by the latent variable?”
The reviewer is correct that in the proposed approach there is no constraint on what each latent value represents.
As a result the different translation styles captured by each latent value are often mixed and have no clear structure. From Sec. 5.5 and Table 4 we can see that z=1 captures past tense, “that” and “per cent”, while z=3 captures present tense, “this” and “%”, for instance. We are working towards adding a similar analysis on the En-De dataset, following your suggestion. 
In general, we would like to investigate models with richer and more structured latent representations in future work.
</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div></div></main></div>
  </div>
</div>


    <!-- Footer -->
    <footer class="sitemap">
      <div class="container">
        <div class="row hidden-xs">
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/venues">All Venues</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="/contact">Contact</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
    
        <div class="row visible-xs-block">
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/contact">Contact</a></li>
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
      </div>
    </footer>
    
    <footer class="sponsor">
      <div class="container">
        <div class="row">
          <div class="col-sm-10 col-sm-offset-1">
            <p class="text-center">
              OpenReview is created by the <a href="http://www.iesl.cs.umass.edu/" target="_blank">Information Extraction and Synthesis Laboratory</a>, College of Information and Computer Science, University of Massachusetts Amherst. We gratefully acknowledge the support of the OpenReview sponsors:  Google,  Facebook, NSF, the University of Massachusetts Amherst Center for Data Science, and Center for Intelligent Information Retrieval, as well as the Google Cloud Platform for donating the computing and networking services on which OpenReview.net runs.
            </p>
          </div>
        </div>
      </div>
    </footer>

  <div id="feedback-modal" class="modal fade" tabindex="-1" role="dialog">
    <div class="modal-dialog">
      <div class="modal-content">
        <div class="modal-header">
          <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button>
          <h3 class="modal-title">Send Feedback</h3>
        </div>
        <div class="modal-body">
          <p>Enter your feedback below and we'll get back to you as soon as possible.</p>
          <form action="/feedback" method="POST">
            <div class="form-group">
              <input type="email" name="from" class="form-control" placeholder="Email" />
            </div>
            <div class="form-group">
              <input type="text" name="subject" class="form-control" placeholder="Subject" />
            </div>
            <div class="form-group">
              <textarea name="message" class="form-control feedback-input" rows="5" placeholder="Message" required=""></textarea>
            </div>
          <ul id="ui-id-2" tabindex="0" class="ui-menu ui-widget ui-widget-content" style="display: none;"></ul></form>
        </div>
        <div class="modal-footer">
          <button type="button" class="btn btn-default" data-dismiss="modal">Cancel</button>
          <button type="button" class="btn btn-primary">Send</button>
        </div>
      </div>
    </div>
  </div>

  <script type="text/javascript" async="" src="https://www.google-analytics.com/analytics.js"></script><script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js"></script>
  <script>window.jQuery || document.write('&lt;script src="/static/js/vendor/jquery-2.2.4.min.js"&gt;&lt;\/script&gt;')</script>

  <script src="/static/dist/vendor.min.js"></script>
  <script src="/static/dist/templates.min.js"></script>
  <script src="/static/dist/openreview.min.js"></script>

    <script>window.legacyScripts = true;</script>


    <script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-108703919-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() { dataLayer.push(arguments); }
      gtag('js', new Date());
      gtag('config', 'UA-108703919-1');
    </script>


<div role="status" aria-live="assertive" aria-relevant="additions" class="ui-helper-hidden-accessible"></div></body></html>
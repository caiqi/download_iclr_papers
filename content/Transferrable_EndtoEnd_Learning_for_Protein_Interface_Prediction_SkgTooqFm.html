<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" class="no-js"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>Transferrable End-to-End Learning for Protein Interface Prediction | OpenReview</title>
  <meta name="description" content="" />

      <meta name="citation_title" content="Transferrable End-to-End Learning for Protein Interface Prediction" />
        <meta name="citation_author" content="Anonymous" />
      <meta name="citation_publication_date" content="2018/09/27" />
      <meta name="citation_online_date" content="2018/09/27" />
      <meta name="citation_pdf_url" content="https://openreview.net/pdf?id=SkgToo0qFm" />
      <meta name="twitter:card" content="summary" />
      <meta name="twitter:site" content="@openreviewnet" />
      <meta name="og:title" content="Transferrable End-to-End Learning for Protein Interface Prediction" />
      <meta name="og:description" content="While there has been an explosion in the number of experimentally determined, atomically detailed structures of proteins, how to represent these structures in a machine learning context remains an..." />
      <meta name="og:image" content="https://openreview.net/static/images/openreview_logo_512.png" />

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans:400,400i,700,700i" />

  <link rel="stylesheet" href="/static/css/bootstrap.min.css" />
  <link rel="stylesheet" href="/static/css/jquery-ui.min.css" />
  <link rel="stylesheet" href="/static/css/main.min.css" />
</head>

<body class="forum">
  <nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
  
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand home push-link" href="/"><strong>OpenReview</strong>.net</a>
      </div>
  
      <div id="navbar" class="navbar-collapse collapse">
        <form class="navbar-form navbar-left profile-search" role="search">
          <div class="form-group has-feedback">
            <input id="search_input" type="text" class="form-control ui-autocomplete-input" placeholder="Search ICLR 2019 Conference" autocomplete="off" />
            <span class="glyphicon glyphicon-search form-control-feedback" aria-hidden="true"></span>
          </div>
  
          <input id="search_group" type="hidden" value="ICLR.cc/2019/Conference" />
          <input id="search_content" type="hidden" value="all" />
        <ul id="ui-id-1" tabindex="0" class="ui-menu ui-widget ui-widget-content ui-autocomplete ui-front" style="display: none;"></ul></form>
  
        <ul class="nav navbar-nav navbar-right">
        
            <li id="user-menu"><a href="/login">Login</a></li>
        </ul>
      </div>
  
    </div>
  </nav>

  <div id="or-banner" class="banner" style="">
  <div class="container">
    <div class="row">
      <div class="col-xs-12"><a href="/group?id=ICLR.cc/2019/Conference" title="Venue Homepage"><img class="icon" src="/static/images/arrow_left.svg" /> Go to <strong>ICLR 2019 Conference</strong> homepage</a></div>
    </div>
  </div>
</div>
<div id="flash-message-container" class="alert alert-danger" role="alert" style="display: none;">
  <div class="container">
    <div class="row">
      <div class="col-xs-12">
        <div class="alert-content">
          <button type="button" class="close" aria-label="Close"><span aria-hidden="true">×</span></button>
        </div>
      </div>
    </div>
  </div>
</div>

<div class="container">
  <div class="row">
    <div class="col-xs-12">
      <main id="content" class="clearfix openbanner-visible legacy-styles"><div id="note_SkgToo0qFm" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Transferrable End-to-End Learning for Protein Interface Prediction</a> <a class="note_content_pdf" href="/pdf?id=SkgToo0qFm" title="Download PDF" target="_blank"><img src="/static/images/pdf_icon_blue.svg" /></a> </h2></div><div class="meta_row"><span class="signatures">Anonymous</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">28 Sep 2018 (modified: 15 Nov 2018)</span><span class="item">ICLR 2019 Conference Blind Submission</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span><span class="item"><a class="action-bibtex-modal" data-bibtex="@inproceedings{    &#10;anonymous2019transferrable,    &#10;title={Transferrable End-to-End Learning for Protein Interface Prediction},    &#10;author={Anonymous},    &#10;booktitle={Submitted to International Conference on Learning Representations},    &#10;year={2019},    &#10;url={https://openreview.net/forum?id=SkgToo0qFm},    &#10;note={under review}    &#10;}">Show Bibtex</a></span><a class="note_content_pdf item" href="/revisions?id=SkgToo0qFm" target="_blank">Show Revisions</a></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Abstract: </span><span class="note_content_value">While there has been an explosion in the number of experimentally determined, atomically detailed structures of proteins, how to represent these structures in a machine learning context remains an open research question.  In this work we demonstrate that representations learned from raw atomic coordinates can outperform hand-engineered structural features while displaying a much higher degree of transferrability.  To do so, we focus on a central problem in biology: predicting how proteins interact with one another—that is, which surfaces of one protein bind to which surfaces of another protein.  We present Siamese Atomic Surfacelet Network (SASNet), the first end-to-end learning method for protein interface prediction.  Despite using only spatial coordinates and identities of atoms as inputs, SASNet outperforms state-of-the-art methods that rely on hand-engineered, high-level features.  These results are particularly striking because we train the method entirely on a significantly biased data set that does not account for the fact that proteins deform when binding to one another.  Demonstrating the first successful application of transfer learning to atomic-level data, our network maintains high performance, without retraining, when tested on real cases in which proteins do deform.</span></div><div class="note_contents"><span class="note_content_field">Keywords: </span><span class="note_content_value">transfer learning, protein interface prediction, deep learning, structural biology</span></div><div class="note_contents"><span class="note_content_field">TL;DR: </span><span class="note_content_value">We demonstrate the first successful application of transfer learning to atomic-level data in order to build a state-of-the-art end-to-end learning model for the protein interface prediction problem.</span></div><div class="reply_row clearfix"><div class="item" id="reply_count">7 Replies</div></div></div><hr class="small" /><div id="note_children"><div class="note_with_children"><div id="note_S1gJdPVn3m" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Nice writing. Lack of significant contribution. Insufficient experimental evidence.</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=SkgToo0qFm&amp;noteId=S1gJdPVn3m"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper661 AnonReviewer3</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">04 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper661 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">For the task of predicting interaction contact among atoms of protein complex consisting of two interacting proteins, the authors propose to train a Siamese convolutional neural network, noted as SASNet, and to use the contact map of two binding proteins’ native structure.
The authors claim that the proposed method outperforms methods that use hand crafted features; also the authors claim that the proposed method has better transferability.

My overall concern is that the experiment result doesn’t really fully support the claim in the two aspects: 1) the SASNet takes the enriched dataset as input to the neural net but it also uses the complex (validation set) to train the optimal parameters, so strictly it doesn’t really fit in the “transfer” learning scenario. Also, the compared methods don’t really use the validation set from the complex data for training at all. Thus the experiment comparison is not really fair. 2) The experiment results include standard errors for different replicates where such replicates correspond to different training random seeds (or different samples from the enriched set?), however, it doesn’t include any significance of the sampling. Specifically, the testing dataset is fixed. A more rigorous setting is to, for N runs, each run splitting the validation and testing set differently.

Since this paper is an application paper, rather than a theoretical paper that bears theoretical findings, I would expect much more thorough experimental setup and analysis. Currently it is still missing discussion such as, when SASNet would perform better and when it would perform worse, what it is that the state of the art features can’t capture while SASNet can. Moreover, it is the prediction performance that matters to such task, but the authors remove the non-structure features from the compared methods. Results and discussion about how the previous methods with full features perform compared to SASNet, and also how we can include those features into SASNet should complete the paper.

Overall the paper is well written, and I do think the paper could be much stronger the issues above are addressed.


Some minor issues:
1)	on page 4, Section 3, the first paragraph, shouldn’t “C_p^{val} of 55” be “C_p^{test} of 55”?

2)	It is not clear what the “replicates” refer to in the experiments.

3)	Some discussion on why the “SASNet ensemble” would yield better performance would be good; could it be overfitting?
</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">5: Marginally below acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">3: The reviewer is fairly confident that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_B1gm0gxqp7" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Response to Reviewer 3 [1/2]</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=SkgToo0qFm&amp;noteId=B1gm0gxqp7"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper661 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">15 Nov 2018</span><span class="item">ICLR 2019 Conference Paper661 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">We thank the reviewer for their comments.  We address their comments individually below.

&gt; My overall concern is that the experiment result doesn’t really fully support the claim in the two aspects: 1) the SASNet takes the enriched dataset as input to the neural net but it also uses the complex (validation set) to train the optimal parameters, so strictly it doesn’t really fit in the “transfer” learning scenario. 

Response: Our work is indeed not classical transfer learning -- it is in fact an even stricter variant.  We do not re-train the parameters of the neural network at all using C_p, which is typically done as a “fine-tuning” step in the transfer learning scenario. So while we do use C_p^{val} for model selection (i.e., hyperparameter tuning), this is still much less use of the data-poor dataset than in the common transfer learning setting of actually fine-tuning the parameters of the neural network using a subset of the data from the data-poor dataset.

The use of C_p^{val} for hyperparameter tuning was incidental and not a central point of our paper.  To really make this clear, we have updated the paper to demonstrate that even if we do not use C_p^{val} for model selection, and instead select from the same class of models we previously generated by using a randomly selected held-out set C_r^{val}, we still obtain state-of-the-art performance (0.892 [0.885 +/- 0.009]).  In this formulation, C_p is not used at all by our method until test time.

&gt; Also, the compared methods don’t really use the validation set from the complex data for training at all. Thus the experiment comparison is not really fair. 

The competing models do make use of validation set C_p^{val} from the complex data to select amongst the most important hyperparameters of their model -- which is equivalent to what we did in our initial formulation, and favors the competing methods compared to if we use C_r^{val} for hyperparameter search instead. 

&gt; 2) The experiment results include standard errors for different replicates where such replicates correspond to different training random seeds (or different samples from the enriched set?), however, it doesn’t include any significance of the sampling. Specifically, the testing dataset is fixed. A more rigorous setting is to, for N runs, each run splitting the validation and testing set differently.

Response: The replicates correspond to different training and validation samples of the enriched set -- we have clarified this in the paper.  While it is true that the hyperparameter validation set was initially fixed, the switch to use C_r^{val} as above resolves this. The testing data C_p^{test} is that which has been used in the prior works we compare to (Fout et al. 2017; Sanchez-Garcia et al. 2018).  Furthermore, use of this subset for performance evaluation is justified as as C_p^{test} corresponds to latest released structures in C_p, leading to a more accurate assessment of how such methods would perform on unreleased structures (as they do no sequence identity pruning).  Thus our experimental set up is rigorous and justified.

&gt; Since this paper is an application paper, rather than a theoretical paper that bears theoretical findings, I would expect much more thorough experimental setup and analysis. Currently it is still missing discussion such as, when SASNet would perform better and when it would perform worse, what it is that the state of the art features can’t capture while SASNet can.

Response: As we discuss above, we believe our experimental setup and analysis is sufficient to demonstrate that our atomic representation transfers much better across atomic tasks.  We have also added to our discussion, making clear that our method represents a significant advantage over competing methods when detailed atomic information is available.  Competitors rely on amino acid-level features that fail to capture specific atomic positions but can be better when the structural is less detailed or accurate.</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_H1etg-g5pX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Response to Reviewer 3 [2/2]</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=SkgToo0qFm&amp;noteId=H1etg-g5pX"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper661 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">15 Nov 2018</span><span class="item">ICLR 2019 Conference Paper661 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">&gt; Moreover, it is the prediction performance that matters to such task, but the authors remove the non-structure features from the compared methods. Results and discussion about how the previous methods with full features perform compared to SASNet, and also how we can include those features into SASNet should complete the paper.

Response: As our paper is primarily about the power and transferrability of our structural features for atomic tasks, we believe a detailed investigation of non-structural features is mostly outside of the scope of this work.  To show that we can easily include these features, we have included in our appendix some results including non-structural features.  When adding in the sequence features used by Fout et al. via a simple linear model combining our final hidden layer and the additional sequence features, we are able to achieve a superior performance of 0.921 (0.914 +/- 0.009) versus their performance of 0.896 (0.894 +/- 0.004).  While BIPSPI (Sanchez-Garcia et al. 2018) does achieve the best combined performance at 0.942, they also use additional sequence correlation features (note their structure-only performance is comparable to that of Fout et al).

&gt; Some discussion on why the “SASNet ensemble” would yield better performance would be good; could it be overfitting?

Response: We have removed the SASNet ensemble from the paper, as it was based on C_p^{val} and confuses the point we are making about minimally relying on C_p for training and validation.  We could definitely investigate further why this mild ensembling yields a small performance increase, but we see this as tangential to the overarching points of the paper.</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div></div></div><div class="note_with_children"><div id="note_Skl6siujnm" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Decent application paper and setup for siamese networks</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=SkgToo0qFm&amp;noteId=Skl6siujnm"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper661 AnonReviewer2</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">04 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper661 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">Summary:
This paper uses siamese networks to define a discriminative function for predicting protein-protein interaction interfaces. They show improvements in predictive performance over some other recent deep learning methods. 
The work is more suitable for a bioinformatics audience though, as the bigger contribution is on the particular application, rather than the model / method itself.

Novelty:
The main contribution of this paper is the representation of the protein interaction data in the input layer of the CNN

Clarity:
- The paper is well written, with ample background into the problem.

Significance:
- Their method improves over prior deep learning approaches to this problem. However, the results are a bit misleading in their reporting of the std error. They should try different train/test splits and report the performance.
- This is an interesting application paper and would be of interest to computational biologists and potentially some other members of the ICLR community
- Protein conformation information is not required by their method

Comments:
- The authors should include citations and motivation for some of their choices (what sequence identity is used, what cut-offs are used etc)

-  The authors should compare to at least some popular previous approaches that use a feature engineering based methodology such as - IntPred

- The authors use a balanced ratio of positive and negative examples. The true distribution of interacting residues is not balanced -- there are several orders of magnitude more non-interacting residues than interacting ones. Can they show performance at various ratios of positive:negative examples? In case there is a consistent improvement over prior methods, then this would be a clear winner
</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">5: Marginally below acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">3: The reviewer is fairly confident that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_BklQEZg5TX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Response to Reviewer 2</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=SkgToo0qFm&amp;noteId=BklQEZg5TX"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper661 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">15 Nov 2018</span><span class="item">ICLR 2019 Conference Paper661 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">We thank the reviewer for their comments.  We address their comments individually below.

&gt; The work is more suitable for a bioinformatics audience though, as the bigger contribution is on the particular application, rather than the model / method itself.  The main contribution of this paper is the representation of the protein interaction data in the input layer of the CNN

Response: The main contribution and novelty of this paper is the demonstration of the transferrability and power of the learned representation, and thus is a good fit for ICLR.  We use the application of protein interface prediction as a test case for this, but applications can range widely from drug discovery, to RNA folding, to small molecule quantum mechanical calculations.   As many of these tasks are very data-poor, this demonstrated transferrability opens up novel avenues through which these problems can be tackled.

&gt; - Their method improves over prior deep learning approaches to this problem. However, the results are a bit misleading in their reporting of the std error. They should try different train/test splits and report the performance.

Response: We do use different subsets of the train set for different replicates.  However, the train and test sets cannot be mixed as they come from different data distributions (P_r and P_p) and we are trying to show we can transfer with no retraining from P_r to P_p.  Thus our reported metrics are correct and justified for this problem, though we have clarified the exact nature of the replicates in the text to ensure this is not misleading.

&gt; - The authors should include citations and motivation for some of their choices (what sequence identity is used, what cut-offs are used etc)

Response: We do provide citations for these choices.  See the second and third paragraphs of section 3 on page 4 for motivation/citations for sequence identity and cut-offs used, respectively.

&gt; -  The authors should compare to at least some popular previous approaches that use a feature engineering based methodology such as - IntPred

Response: Fout et al. and Sanchez-Garcia et al. are feature engineering approaches -- they both use high-level features as inputs to their models (not atomic coordinates).  Sanchez-Garcia et al. use a tree ensemble model that has no end-to-end learning aspects at all.  Another popular pure feature engineering approach is PAIRPred (Minhas et al., Protein 2014), which uses an SVM trained on high-level features.  However, we do not compare to them as their performance on C_p^{test} (0.863)  was already superseded in Fout et al.’s work. IntPred [Northey et al., Bioinformatics 2017] addresses the binding site prediction problem (given one protein, which residues can be interfacial with any other protein), which is different than the problem we present. 

&gt; - The authors use a balanced ratio of positive and negative examples. The true distribution of interacting residues is not balanced -- there are several orders of magnitude more non-interacting residues than interacting ones. Can they show performance at various ratios of positive:negative examples? In case there is a consistent improvement over prior methods, then this would be a clear winner

Response: We can demonstrate consistent performance at different ratios of positive:negative examples.  Running tests on C_p^{test} at 1:3, 1:5, and 1:10 ratios demonstrate no significant impact on performance (0.889 [0.882 +/- 0.012], 0.889 [0.882 +/- 0.011], and 0.895 [0.886 +/- 0.015], respectively).  The AUROC metric we use is insensitive to class imbalance, and thus is a good measure to use when evaluating on datasets with varying amounts of imbalance.</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div><div class="note_with_children"><div id="note_SkeItzcq3m" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>good idea but unclear model</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=SkgToo0qFm&amp;noteId=SkeItzcq3m"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper661 AnonReviewer1</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">03 Nov 2018 (modified: 10 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper661 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span><a class="note_content_pdf item" href="/revisions?id=SkeItzcq3m" target="_blank">Show Revisions</a></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">This manuscript applies transfer learning for protein surface prediction. The problem is important and  the idea is novel and interesting. However, the  transfer learning model is unclear. 
Pros:  interesting and novel idea
Cons:  unclear transfer learning model, insufficient experiments. 

Detail: section 4 describes the transfer learning model used in the work, but the description is unclear. It is unknown the used model is a new model or existing model. Besides, in the experiments, the proposed method is not compared to other transfer learning methods.  Thus, the evidence of the experiments is not enough. </span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">5: Marginally below acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_H1lU_ZlqaX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Response to Reviewer 1</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=SkgToo0qFm&amp;noteId=H1lU_ZlqaX"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper661 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">15 Nov 2018</span><span class="item">ICLR 2019 Conference Paper661 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Response: We thank the reviewer for their comments.  We would like to clarify one of the central points of this paper, as the cons presented are built upon a misunderstanding of this point.  We are not proposing a new transfer learning model -- we are demonstrating the transferrability of the atomic features we have learned.  We train our structural features on C_r and show that with no re-training they can achieve state-of-the-art results of C_p.  Applying a classical transfer learning algorithm might improve performance even further, as then we could fine-tune results on C_p.  Though this is an interesting direction, it is outside the scope of the work we present here, which concerns itself with the learned representations themselves.  Thus, instead of comparing transfer learning methods, we evaluate the transferrability of both our own structural features as well as those of competitors.</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div></div></main></div>
  </div>
</div>


    <!-- Footer -->
    <footer class="sitemap">
      <div class="container">
        <div class="row hidden-xs">
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/venues">All Venues</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="/contact">Contact</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
    
        <div class="row visible-xs-block">
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/contact">Contact</a></li>
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
      </div>
    </footer>
    
    <footer class="sponsor">
      <div class="container">
        <div class="row">
          <div class="col-sm-10 col-sm-offset-1">
            <p class="text-center">
              OpenReview is created by the <a href="http://www.iesl.cs.umass.edu/" target="_blank">Information Extraction and Synthesis Laboratory</a>, College of Information and Computer Science, University of Massachusetts Amherst. We gratefully acknowledge the support of the OpenReview sponsors:  Google,  Facebook, NSF, the University of Massachusetts Amherst Center for Data Science, and Center for Intelligent Information Retrieval, as well as the Google Cloud Platform for donating the computing and networking services on which OpenReview.net runs.
            </p>
          </div>
        </div>
      </div>
    </footer>

  <div id="feedback-modal" class="modal fade" tabindex="-1" role="dialog">
    <div class="modal-dialog">
      <div class="modal-content">
        <div class="modal-header">
          <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button>
          <h3 class="modal-title">Send Feedback</h3>
        </div>
        <div class="modal-body">
          <p>Enter your feedback below and we'll get back to you as soon as possible.</p>
          <form action="/feedback" method="POST">
            <div class="form-group">
              <input type="email" name="from" class="form-control" placeholder="Email" />
            </div>
            <div class="form-group">
              <input type="text" name="subject" class="form-control" placeholder="Subject" />
            </div>
            <div class="form-group">
              <textarea name="message" class="form-control feedback-input" rows="5" placeholder="Message" required=""></textarea>
            </div>
          <ul id="ui-id-2" tabindex="0" class="ui-menu ui-widget ui-widget-content" style="display: none;"></ul></form>
        </div>
        <div class="modal-footer">
          <button type="button" class="btn btn-default" data-dismiss="modal">Cancel</button>
          <button type="button" class="btn btn-primary">Send</button>
        </div>
      </div>
    </div>
  </div>

  <script type="text/javascript" async="" src="https://www.google-analytics.com/analytics.js"></script><script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js"></script>
  <script>window.jQuery || document.write('&lt;script src="/static/js/vendor/jquery-2.2.4.min.js"&gt;&lt;\/script&gt;')</script>

  <script src="/static/dist/vendor.min.js"></script>
  <script src="/static/dist/templates.min.js"></script>
  <script src="/static/dist/openreview.min.js"></script>

    <script>window.legacyScripts = true;</script>


    <script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-108703919-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() { dataLayer.push(arguments); }
      gtag('js', new Date());
      gtag('config', 'UA-108703919-1');
    </script>


<div role="status" aria-live="assertive" aria-relevant="additions" class="ui-helper-hidden-accessible"></div></body></html>
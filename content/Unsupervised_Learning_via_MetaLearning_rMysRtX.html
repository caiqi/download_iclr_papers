<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" class="no-js"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>Unsupervised Learning via Meta-Learning | OpenReview</title>
  <meta name="description" content="" />

      <meta name="citation_title" content="Unsupervised Learning via Meta-Learning" />
        <meta name="citation_author" content="Anonymous" />
      <meta name="citation_publication_date" content="2018/09/27" />
      <meta name="citation_online_date" content="2018/09/27" />
      <meta name="citation_pdf_url" content="https://openreview.net/pdf?id=r1My6sR9tX" />
      <meta name="twitter:card" content="summary" />
      <meta name="twitter:site" content="@openreviewnet" />
      <meta name="og:title" content="Unsupervised Learning via Meta-Learning" />
      <meta name="og:description" content="A central goal of unsupervised learning is to acquire representations from unlabeled data or experience that can be used for more effective learning of downstream tasks from modest amounts of..." />
      <meta name="og:image" content="https://openreview.net/static/images/openreview_logo_512.png" />

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans:400,400i,700,700i" />

  <link rel="stylesheet" href="/static/css/bootstrap.min.css" />
  <link rel="stylesheet" href="/static/css/jquery-ui.min.css" />
  <link rel="stylesheet" href="/static/css/main.min.css" />
</head>

<body class="forum">
  <nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
  
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand home push-link" href="/"><strong>OpenReview</strong>.net</a>
      </div>
  
      <div id="navbar" class="navbar-collapse collapse">
        <form class="navbar-form navbar-left profile-search" role="search">
          <div class="form-group has-feedback">
            <input id="search_input" type="text" class="form-control ui-autocomplete-input" placeholder="Search ICLR 2019 Conference" autocomplete="off" />
            <span class="glyphicon glyphicon-search form-control-feedback" aria-hidden="true"></span>
          </div>
  
          <input id="search_group" type="hidden" value="ICLR.cc/2019/Conference" />
          <input id="search_content" type="hidden" value="all" />
        <ul id="ui-id-1" tabindex="0" class="ui-menu ui-widget ui-widget-content ui-autocomplete ui-front" style="display: none;"></ul></form>
  
        <ul class="nav navbar-nav navbar-right">
        
            <li id="user-menu"><a href="/login">Login</a></li>
        </ul>
      </div>
  
    </div>
  </nav>

  <div id="or-banner" class="banner" style="">
  <div class="container">
    <div class="row">
      <div class="col-xs-12"><a href="/group?id=ICLR.cc/2019/Conference" title="Venue Homepage"><img class="icon" src="/static/images/arrow_left.svg" /> Go to <strong>ICLR 2019 Conference</strong> homepage</a></div>
    </div>
  </div>
</div>
<div id="flash-message-container" class="alert alert-danger" role="alert" style="display: none;">
  <div class="container">
    <div class="row">
      <div class="col-xs-12">
        <div class="alert-content">
          <button type="button" class="close" aria-label="Close"><span aria-hidden="true">×</span></button>
        </div>
      </div>
    </div>
  </div>
</div>

<div class="container">
  <div class="row">
    <div class="col-xs-12">
      <main id="content" class="clearfix openbanner-visible legacy-styles"><div id="note_r1My6sR9tX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Unsupervised Learning via Meta-Learning</a> <a class="note_content_pdf" href="/pdf?id=r1My6sR9tX" title="Download PDF" target="_blank"><img src="/static/images/pdf_icon_blue.svg" /></a> </h2></div><div class="meta_row"><span class="signatures">Anonymous</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">28 Sep 2018 (modified: 20 Nov 2018)</span><span class="item">ICLR 2019 Conference Blind Submission</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span><span class="item"><a class="action-bibtex-modal" data-bibtex="@inproceedings{    &#10;anonymous2019unsupervised,    &#10;title={Unsupervised Learning via Meta-Learning},    &#10;author={Anonymous},    &#10;booktitle={Submitted to International Conference on Learning Representations},    &#10;year={2019},    &#10;url={https://openreview.net/forum?id=r1My6sR9tX},    &#10;note={under review}    &#10;}">Show Bibtex</a></span><a class="note_content_pdf item" href="/revisions?id=r1My6sR9tX" target="_blank">Show Revisions</a></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Abstract: </span><span class="note_content_value">A central goal of unsupervised learning is to acquire representations from unlabeled data or experience that can be used for more effective learning of downstream tasks from modest amounts of labeled data. Many prior unsupervised learning works aim to do so by developing proxy objectives based on reconstruction, disentanglement, prediction, and other metrics. Instead, we develop an unsupervised meta-learning method that explicitly optimizes for the ability to learn a variety of tasks from small amounts of data. To do so, we construct tasks from unlabeled data in an automatic way and run meta-learning over the constructed tasks. Surprisingly, we find that, when integrated with meta-learning, relatively simple task construction mechanisms, such as clustering embeddings, lead to good performance on a variety of downstream, human-specified tasks. Our experiments across four image datasets indicate that our unsupervised meta-learning approach acquires a learning algorithm without any labeled data that is applicable to a wide range of downstream classification tasks, improving upon the embedding learned by four prior unsupervised learning methods.</span></div><div class="note_contents"><span class="note_content_field">Keywords: </span><span class="note_content_value">unsupervised learning, meta-learning</span></div><div class="note_contents"><span class="note_content_field">TL;DR: </span><span class="note_content_value">An unsupervised learning method that uses meta-learning to enable efficient learning of downstream image classification tasks, outperforming state-of-the-art methods.</span></div><div class="reply_row clearfix"><div class="item" id="reply_count">8 Replies</div></div></div><hr class="small" /><div id="note_children"><div class="note_with_children"><div id="note_rkgGnSmOam" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Paper updated to address reviewer feedback</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=r1My6sR9tX&amp;noteId=rkgGnSmOam"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper766 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">13 Nov 2018</span><span class="item">ICLR 2019 Conference Paper766 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">We have updated the paper with the following changes to address reviewer comments:
- combined sections 2.1 and 2.3, and sections 2.2 and 2.4 (R2)
- reduced redundancy in the exposition (R2)
- added more mathematical details to section 2 (R2)
- added comparison to clustering on pixels (R2)
- added further discussion of limitations of our method in the discussion (R2)
- provided more motivation and justification for our approach in section 2.2 (R1, R2)
- improved the clarity of the problem statement and its motivation in sections 1 and 2.1 (R1, R2)
- emphasized throughout the text that the downstream tasks we evaluate on at meta-test time are standard benchmark few-shot learning tasks (R1, R2)
- added a brief discussion on sampling clusters in section 2.2 (R3)
- added a set of experiments based on Prototypical Networks (R3)

We would appreciate it if the reviewers could take a look at our changes and additional results, and let us know if they would like to either revise their rating of the paper, or request additional changes that would alleviate their concerns. Thank you!</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_SklSFCJyaQ" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Interesting approach but still not finished</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=r1My6sR9tX&amp;noteId=SklSFCJyaQ"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper766 AnonReviewer1</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">06 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper766 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">The paper proposes to employ metalearning techniques for unsupervised tasks. The authors construct tasks in an automatic way from unlabeled data and run meta-learning over the constructed tasks.

Although the paper presents a novel approach and the experiments included in the work show promising results, in my opinion, the paper is still not mature. There are some importants problems:
* The motivation of the paper is weak. The authors include the problem statement as well as the definitions used in the paper without knowing what is the goal of the proposed algorithm. A clear example of a real problem where the proposed framework could be applied is necessary to motivate the work.
* The paper is difficult to read and follow. The paper is composed by a set of parts without many links. This makes difficult to read the paper to not very experienced readers. A running example could be useful to increase the readability of the work. In my opinion, the paper contains too much material for the length of the conference. In fact, some important information has been moved to the appendices. 
*Experimental section is specially hard to follow. The authors want to solve too many questions in a short space. Comparisons with other related papers should be included. 

</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">4: Ok but not good enough - rejection</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">3: The reviewer is fairly confident that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_rkels4tJp7" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Thank you for the feedback. Can you elaborate on your suggestions?</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=r1My6sR9tX&amp;noteId=rkels4tJp7"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper766 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">07 Nov 2018</span><span class="item">ICLR 2019 Conference Paper766 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Thank you for your comments. Our evaluation tests on few-shot Omniglot, miniImageNet, and CelebA classification datasets, which are a real-world few-shot image classification task proposed by [1,2,3] respectively, and evaluated in virtually all few-shot classification papers since 2016: [1,2,3,4,5,6,7,8,9]. We can of course evaluate our method on other problems as well, but the current tasks are real-world image datasets and problems that have been studied extensively in the literature, for which our method achieves excellent results. Are there particular additional datasets that the reviewer would prefer a comparison to? Or anything else we can do to address the concern about the motivation?

We would be happy to revise the problem statement and writing as per the reviewer's suggestions, though we would appreciate more specific pointers about what in particular is difficult to follow. The problem statement is quite simple: we aim to propose an algorithm whereby meta-learning can be used to acquire an efficient few-shot learning procedure without any hand-specified labels during meta-training. This problem is important for two reasons: (1) meta-learning currently relies on large labeled datasets, and in practice, the burden of obtaining such labeled datasets is a major obstacle to widespread use of meta-learning for few-shot classification, and (2) state-of-the-art unsupervised learning methods often neglect downstream use-cases, such as few-shot classification, leaving substantial room for improvement. Our work proposed a way to begin addressing these challenges, and compares extensively to four prior papers [10,11,12,13] and several ablations. Beyond updating the problem statement, are there important comparisons that we missed?

[1] Santoro et al. ICML 2016, <a href="http://proceedings.mlr.press/v48/santoro16.pdf" target="_blank" rel="nofollow">http://proceedings.mlr.press/v48/santoro16.pdf</a>
[2] Ravi &amp; Larochelle ICLR 2017, https://openreview.net/pdf?id=rJY0-Kcll
[3] Finn et al NIPS 2018, https://arxiv.org/abs/1806.02817
[4] Vinyals et al. NIPS 2016, https://papers.nips.cc/paper/6385-matching-networks-for-one-shot-learning
[5] Munkhdalai et al. ICML 2017, https://arxiv.org/abs/1703.00837
[6] Finn et al. ICML 2017, https://arxiv.org/abs/1703.03400
[7] Snell et al NIPS 2017, https://papers.nips.cc/paper/6996-prototypical-networks-for-few-shot-learning
[8] Oreshkin et al. NIPS 2018,
https://arxiv.org/abs/1805.10123
[9] Yoon et al. NIPS 2018, https://arxiv.org/abs/1806.03836
[10] Donahue et al. ICLR 2017, https://arxiv.org/abs/1605.09782
[11] Caron et al. ECCV 2018, https://arxiv.org/abs/1807.05520
[12] Berthelot et al. arXiv 2018, https://arxiv.org/pdf/1807.07543
[13] Chen et al. NIPS 2016, https://arxiv.org/abs/1606.03657</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div><div class="note_with_children"><div id="note_B1lYZ6Ht37" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Great paper tackling important problem with nice experiments</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=r1My6sR9tX&amp;noteId=B1lYZ6Ht37"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper766 AnonReviewer3</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">02 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper766 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">In this paper, the task of performing meta-learning based on the unsupervised dataset is considered. The high-level idea is to generate 'pseudo-labels' via clustering of the given dataset using existing unsupervised learning techniques. Then the meta-learning algorithm is trained to easily discriminate between such labels. This paper seems to be tackling an important problem that has not been addressed yet to my knowledge. While the proposed method/contribution is quite simple, it possesses great potential for future applications and deeper exploration. The empirical results look strong and tried to address important aspects of the algorithm. The writing was clear and easy to follow. I especially liked how the authors tried to exploit possible pitfalls of their experimental design. 

Minor comments and questions:
- Although the problem of interest is non-trivial and important, the proposed algorithm can be seen as just a naive combination of clustering and meta-learning. It would have been great to see some clustering algorithm that was specifically designed for this type of problem. Especially, the proposed CACTUs algorithm relies on sampling without replacement from the clustered dataset in order to enforce "balance" of the labels among the generated task. This might be leading to suboptimal results since the popularity of each cluster (i.e., how much it represents the whole dataset) is not considered. 

- CACTUs seems to be relying on having random scaling of the k-means algorithm in order to induce diversity on the set of partitions being generated. I am a bit skeptical about the effectiveness of such a method for diversity. If this holds, it would be interesting to see the visualization of such a concept.

- Although only MAML was considered as the meta-learning algorithm, it would have been nice to consider one or more candidates to show that the proposed framework is generalizable. Still, I think the experiment is persuasive enough to expect that the algorithm would working well at practice.

- Would there be a trivial generalization of the algorithm to semi-supervised learning?  </span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">8: Top 50% of accepted papers, clear accept</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">3: The reviewer is fairly confident that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_HJlTH6DZT7" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Thank you for your insightful comments and feedback!</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=r1My6sR9tX&amp;noteId=HJlTH6DZT7"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper766 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">08 Nov 2018</span><span class="item">ICLR 2019 Conference Paper766 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">“Although only MAML was considered as the meta-learning algorithm, it would have been nice to consider one or more candidates to show that the proposed framework is generalizable. Still, I think the experiment is persuasive enough to expect that the algorithm would working well at practice.”
To address your suggestion, we have updated the paper to add results (in Tables 1, 2, and 3) obtained with Prototypical Networks [1] as the meta-learner instead of MAML. We find that the improvement of CACTUs over the comparison methods still generally holds, with a few exceptions. We hypothesize the exceptions are due to a dependence of ProtoNets performance on matching train shot with test shot, i.e. on providing the meta-learner with tasks that have supervision commensurate to that expected in held-out tasks. We elaborate on this in the updated paper (“Benefit of Meta-Learning” in Section 4.2).

“Although the problem of interest is non-trivial and important, the proposed algorithm can be seen as just a naive combination of clustering and meta-learning. It would have been great to see some clustering algorithm that was specifically designed for this type of problem.”
The reviewer is correct in that some more sophisticated clustering methods may be better-suited for our method. We found that this simple procedure (with hyperparameter k fixed) worked surprisingly well across datasets and task structures, and did not see a need to make the method more complex. 

“Especially, the proposed CACTUs algorithm relies on sampling without replacement from the clustered dataset in order to enforce "balance" of the labels among the generated task. This might be leading to suboptimal results since the popularity of each cluster (i.e., how much it represents the whole dataset) is not considered.”
If we view k-means as the hard limit of a mixture of Gaussians and decompose the joint embedding-cluster distribution p(z,c)=p(c)p(z|c), one way the reviewer’s proposal can be realized is sampling from p(c). However, as we mention in Section 5, the datasets we consider (Omniglot and miniImageNet) are evenly balanced amongst classes, and we fear that comparing between sampling from U(c) and p(c) on these datasets may be misleading, as in general datasets can be heavily imbalanced. We leave a thorough evaluation of the question of how to better sample clusters for tasks to future work, but there are a couple of hints we can already think about. First, consider a toy imbalanced dataset for which, after clustering, there is one heavily populated cluster and four small ones. Because we have no guarantees about the meta-test distribution, it is “safer” for the meta-learner to learn to distinguish between all clusters equally well than to have the popular cluster dominate the meta-training task distribution. Second, prior work [2] also considers a similar question (“Trivial parametrization”, page 6), and concludes that uniform sampling over clusters is more suitable.

“CACTUs seems to be relying on having random scaling of the k-means algorithm in order to induce diversity on the set of partitions being generated. I am a bit skeptical about the effectiveness of such a method for diversity. If this holds, it would be interesting to see the visualization of such a concept.”
We found that this diversity was helpful but not critical for our method to perform well: compare the P=1 and P={50,100} entries in the tables of Appendix F. Other mechanisms for encouraging task diversity would be an interesting direction for future work, and we welcome any suggestions on this front!

“Would there be a trivial generalization of the algorithm to semi-supervised learning?”
For the scenario in which some labeled data, not necessarily from the same classes as in tasks from meta-test time, is available during meta-training, there are indeed some obvious extensions. One can: i) have some of the tasks be generated only from the labeled data and others from CACTUs, ii) encourage the calculation of partitions to respect the labeled data, and/or iii) use the labeled data as meta-validation to do early stopping and hyperparameter tuning. We leave this for future work.

References
[1] Snell et al. NIPS 2017, <a href="https://papers.nips.cc/paper/6996-prototypical-networks-for-few-shot-learning" target="_blank" rel="nofollow">https://papers.nips.cc/paper/6996-prototypical-networks-for-few-shot-learning</a>
[2] Caron et al. ECCV 2018, https://arxiv.org/abs/1807.05520
</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div><div class="note_with_children"><div id="note_HJldF4T8hQ" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Interesting approach but motivation is not clear.</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=r1My6sR9tX&amp;noteId=HJldF4T8hQ"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper766 AnonReviewer2</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">31 Oct 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper766 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">This paper proposes to construct multiple classification tasks from unsupervised data.

Quality:
The detail of the proposed method is not mathematically presented and its performance is not theoretically analyzed.
Although the proposed method is empirically shown to be superior to other approaches, the motivation is not clearly presented.
Hence the overall quality of this paper is not high.

Clarity:
The readability of this paper is not high as it is redundant or unclear at several points.
For example, Sections 2.1, 2.3 and Sections 2.2, 2.4 can be integrated, respectively, and more mathematical details can be included instead.

Originality:
The proposal of constructing meta-learning based on unsupervised learning seems to be original.

Significance:
- The motivation is not clear. The proposed method artificially generates a number of classification tasks. But how to use such classifiers for artificially generated labels in real-world applications is not motivated.
  It is better to give a representative application, to which the proposed method fits.
- There is no theoretical analysis on the proposed method.
  For example, why is the first embedding step required? Clustering can be directly performed on the give dataset D = {x_i}.
- Although the paper discusses using unsupervised learning for meta-learning, only k-means is considered in the proposed method.
  There are a number of types of unsupervised learning, including other clustering algorithms and other tasks such as outlier detection, hence analyzing them is also interesting.
- The proposed method includes several hyper-parameters. But how to set them in practice it not clear.

Pros:
- An interesting approach to meta-learning is presented.

Cons:
- Motivation is not clear.
- There is no theoretical analysis.
</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">5: Marginally below acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">3: The reviewer is fairly confident that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_Skxii3P-a7" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>[1/2] Thank you for your review. Can you elaborate on your feedback?</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=r1My6sR9tX&amp;noteId=Skxii3P-a7"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper766 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">08 Nov 2018</span><span class="item">ICLR 2019 Conference Paper766 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Thank you for your time in reviewing our work! We would like to improve the paper based on your feedback, and would benefit from a few clarifications on your part.

“The motivation is not clear. The proposed method artificially generates a number of classification tasks. But how to use such classifiers for artificially generated labels in real-world applications is not motivated. It is better to give a representative application, to which the proposed method fits.”
Our evaluation and results are on real-world image classification tasks first proposed by prior work (Omniglot: [1], miniImageNet: [2], CelebA: [3]) and used by virtually all few-shot learning works in the last few years [1, 2, 3, 4, 5, 6, 7, 8, 9]. The test tasks are not artificially generated, but are real few-shot image classification tasks. We give the general use-case of our method in the last sentence of Section 2.1. We have clarified these points in our revision. Do you still find a lack of representative application? If so, do you have suggestions for better evaluation tasks?

“The detail of the proposed method is not mathematically presented”, “ … more mathematical details can be included instead.”
We have added the optimization objective of k-means to the paper. Are there any other parts of the method that require more formalism?

“The readability of this paper is not high as it is redundant or unclear at several points.
For example, Sections 2.1, 2.3 and Sections 2.2, 2.4 can be integrated, respectively, and more mathematical details can be included instead.”
We have implemented your suggested re-organization to reduce redundancy. Which portions of the text, specifically, remain redundant or unclear?

References
[1] Santoro et al. ICML 2016, <a href="http://proceedings.mlr.press/v48/santoro16.pdf" target="_blank" rel="nofollow">http://proceedings.mlr.press/v48/santoro16.pdf</a>
[2] Ravi &amp; Larochelle ICLR 2017, https://openreview.net/pdf?id=rJY0-Kcll
[3] Finn et al. NIPS 2018, https://arxiv.org/abs/1806.02817
[4] Vinyals et al. NIPS 2016, https://papers.nips.cc/paper/6385-matching-networks-for-one-shot-learning
[5] Munkhdalai et al. ICML 2017, https://arxiv.org/abs/1703.00837
[6] Finn et al. ICML 2017, https://arxiv.org/abs/1703.03400
[7] Snell et al NIPS 2017, https://papers.nips.cc/paper/6996-prototypical-networks-for-few-shot-learning
[8] Oreshkin et al. NIPS 2018,
https://arxiv.org/abs/1805.10123
[9] Yoon et al. NIPS 2018, https://arxiv.org/abs/1806.03836
</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_rkxrw3v-6X" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>[2/2] Additional responses to the reviewer’s points.</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=r1My6sR9tX&amp;noteId=rkxrw3v-6X"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper766 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">08 Nov 2018 (modified: 16 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper766 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">“Although the paper discusses using unsupervised learning for meta-learning, only k-means is considered in the proposed method.”
We do consider multiple types of unsupervised learning: this is described in “Different embedding spaces” and “Task construction” in Section 4. For the embeddings, we consider and evaluate four unsupervised learning methods/objectives covering discriminative clustering, generative modeling, interpolation, and information maximization. For constructing tasks from embeddings, we consider and evaluate random sampling and hyperplane slicing in addition to k-means.

“why is the first embedding step required? Clustering can be directly performed on the give dataset D = {x_i}.”
Given that the x_i in our experiments are images, we believe it is clear from intuition that clustering on x_i would not work well: distance metrics in pixel-space do not correspond well to semantic meaning. We will add this as a comparison in the paper. 

“The proposed method includes several hyper-parameters. But how to set them in practice it not clear.”
The hyperparameters associated with the embedding learning stage can be tuned on the unlabeled meta-validation split. For clustering, we fix the number of clusters k across all dataset/embedding/task difficulty combinations presented in the main text. We demonstrate that the number of partitions P is unimportant for our method: P=1 and P=50/100 (for miniImagenet and CelebA / Omniglot) both perform well (Section 4.2). There is ample justification of the hyperparameters used for the task construction: choose N, the number of classes in each task, by upper-bounding the number of classes expected to be seen in a downstream task, and choose K to be 1 (Section 4.1). As motivated in the first paragraph of Section 4.1, all other hyperparameters were selected based on prior work.

&gt;&gt; “performance is not theoretically analyzed.”
We found that, given the generality of the problem statement, it was difficult to make headway on theoretical analysis. We therefore opted to prioritize a solid experimental evaluation of the proposed method. Historically, theoretical analysis has not been a requirement for high-quality contributions in this community. There are numerous examples of high-quality, impactful papers devoid of theoretical analysis or guarantees presented at ICLR in recent years [1, 2, 3, 4, 5].

References
[1] Zoph et al. ICLR 2017, <a href="https://openreview.net/forum?id=r1Ue8Hcxg" target="_blank" rel="nofollow">https://openreview.net/forum?id=r1Ue8Hcxg</a>
[2] Karras et al. ICLR 2018, https://openreview.net/forum?id=Hk99zCeAb
[3] Jaderberg et al. ICLR 2017, https://openreview.net/forum?id=SJ6yPD5xg
[4] Lazaridou et al. ICLR 2017, https://openreview.net/forum?id=Hk8N3Sclg
[5] Ravi &amp; Larochelle ICLR 2017, https://openreview.net/pdf?id=rJY0-Kcll
</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div></div></main></div>
  </div>
</div>


    <!-- Footer -->
    <footer class="sitemap">
      <div class="container">
        <div class="row hidden-xs">
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/venues">All Venues</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="/contact">Contact</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
    
        <div class="row visible-xs-block">
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/contact">Contact</a></li>
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
      </div>
    </footer>
    
    <footer class="sponsor">
      <div class="container">
        <div class="row">
          <div class="col-sm-10 col-sm-offset-1">
            <p class="text-center">
              OpenReview is created by the <a href="http://www.iesl.cs.umass.edu/" target="_blank">Information Extraction and Synthesis Laboratory</a>, College of Information and Computer Science, University of Massachusetts Amherst. We gratefully acknowledge the support of the OpenReview sponsors:  Google,  Facebook, NSF, the University of Massachusetts Amherst Center for Data Science, and Center for Intelligent Information Retrieval, as well as the Google Cloud Platform for donating the computing and networking services on which OpenReview.net runs.
            </p>
          </div>
        </div>
      </div>
    </footer>

  <div id="feedback-modal" class="modal fade" tabindex="-1" role="dialog">
    <div class="modal-dialog">
      <div class="modal-content">
        <div class="modal-header">
          <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button>
          <h3 class="modal-title">Send Feedback</h3>
        </div>
        <div class="modal-body">
          <p>Enter your feedback below and we'll get back to you as soon as possible.</p>
          <form action="/feedback" method="POST">
            <div class="form-group">
              <input type="email" name="from" class="form-control" placeholder="Email" />
            </div>
            <div class="form-group">
              <input type="text" name="subject" class="form-control" placeholder="Subject" />
            </div>
            <div class="form-group">
              <textarea name="message" class="form-control feedback-input" rows="5" placeholder="Message" required=""></textarea>
            </div>
          <ul id="ui-id-2" tabindex="0" class="ui-menu ui-widget ui-widget-content" style="display: none;"></ul></form>
        </div>
        <div class="modal-footer">
          <button type="button" class="btn btn-default" data-dismiss="modal">Cancel</button>
          <button type="button" class="btn btn-primary">Send</button>
        </div>
      </div>
    </div>
  </div>

  <script type="text/javascript" async="" src="https://www.google-analytics.com/analytics.js"></script><script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js"></script>
  <script>window.jQuery || document.write('&lt;script src="/static/js/vendor/jquery-2.2.4.min.js"&gt;&lt;\/script&gt;')</script>

  <script src="/static/dist/vendor.min.js"></script>
  <script src="/static/dist/templates.min.js"></script>
  <script src="/static/dist/openreview.min.js"></script>

    <script>window.legacyScripts = true;</script>


    <script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-108703919-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() { dataLayer.push(arguments); }
      gtag('js', new Date());
      gtag('config', 'UA-108703919-1');
    </script>


<div role="status" aria-live="assertive" aria-relevant="additions" class="ui-helper-hidden-accessible"></div></body></html>
<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" class="no-js"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>Generalized Label Propagation Methods for Semi-Supervised Learning | OpenReview</title>
  <meta name="description" content="" />

      <meta name="citation_title" content="Generalized Label Propagation Methods for Semi-Supervised Learning" />
        <meta name="citation_author" content="Qimai Li" />
        <meta name="citation_author" content="Xiao-Ming Wu" />
        <meta name="citation_author" content="Zhichao Guan." />
      <meta name="citation_publication_date" content="2018/09/27" />
      <meta name="citation_online_date" content="2018/09/27" />
      <meta name="citation_pdf_url" content="https://openreview.net/pdf?id=SygjB3AcYX" />
      <meta name="twitter:card" content="summary" />
      <meta name="twitter:site" content="@openreviewnet" />
      <meta name="og:title" content="Generalized Label Propagation Methods for Semi-Supervised Learning" />
      <meta name="og:description" content="The key challenge in semi-supervised learning is how to effectively leverage unlabeled data to improve learning performance. The classical label propagation method, despite its popularity, has..." />
      <meta name="og:image" content="https://openreview.net/static/images/openreview_logo_512.png" />

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans:400,400i,700,700i" />

  <link rel="stylesheet" href="/static/css/bootstrap.min.css" />
  <link rel="stylesheet" href="/static/css/jquery-ui.min.css" />
  <link rel="stylesheet" href="/static/css/main.min.css" />
</head>

<body class="forum">
  <nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
  
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand home push-link" href="/"><strong>OpenReview</strong>.net</a>
      </div>
  
      <div id="navbar" class="navbar-collapse collapse">
        <form class="navbar-form navbar-left profile-search" role="search">
          <div class="form-group has-feedback">
            <input id="search_input" type="text" class="form-control ui-autocomplete-input" placeholder="Search ICLR 2019 Conference" autocomplete="off" />
            <span class="glyphicon glyphicon-search form-control-feedback" aria-hidden="true"></span>
          </div>
  
          <input id="search_group" type="hidden" value="ICLR.cc/2019/Conference" />
          <input id="search_content" type="hidden" value="all" />
        <ul id="ui-id-1" tabindex="0" class="ui-menu ui-widget ui-widget-content ui-autocomplete ui-front" style="display: none;"></ul></form>
  
        <ul class="nav navbar-nav navbar-right">
        
            <li id="user-menu"><a href="/login">Login</a></li>
        </ul>
      </div>
  
    </div>
  </nav>

  <div id="or-banner" class="banner" style="">
  <div class="container">
    <div class="row">
      <div class="col-xs-12"><a href="/group?id=ICLR.cc/2019/Conference" title="Venue Homepage"><img class="icon" src="/static/images/arrow_left.svg" /> Go to <strong>ICLR 2019 Conference</strong> homepage</a></div>
    </div>
  </div>
</div>
<div id="flash-message-container" class="alert alert-danger" role="alert" style="display: none;">
  <div class="container">
    <div class="row">
      <div class="col-xs-12">
        <div class="alert-content">
          <button type="button" class="close" aria-label="Close"><span aria-hidden="true">×</span></button>
        </div>
      </div>
    </div>
  </div>
</div>

<div class="container">
  <div class="row">
    <div class="col-xs-12">
      <main id="content" class="clearfix openbanner-visible legacy-styles"><div id="note_SygjB3AcYX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Generalized Label Propagation Methods for Semi-Supervised Learning</a> <a class="note_content_pdf" href="/pdf?id=SygjB3AcYX" title="Download PDF" target="_blank"><img src="/static/images/pdf_icon_blue.svg" /></a> </h2></div><div class="meta_row"><span class="signatures"><a href="/profile?email=csqmli%40comp.polyu.edu.hk" class="profile-link" data-toggle="tooltip" data-placement="bottom" title="" data-original-title="csqmli@comp.polyu.edu.hk">Qimai Li</a>, <a href="/profile?email=xiao-ming.wu%40polyu.edu.hk" class="profile-link" data-toggle="tooltip" data-placement="bottom" title="" data-original-title="xiao-ming.wu@polyu.edu.hk">Xiao-Ming Wu</a>, <a href="/profile?email=zcguan%40zju.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="bottom" title="" data-original-title="zcguan@zju.edu.cn">Zhichao Guan.</a></span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">28 Sep 2018 (modified: 20 Nov 2018)</span><span class="item">ICLR 2019 Conference Withdrawn Submission</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span><a class="note_content_pdf item" href="/revisions?id=SygjB3AcYX" target="_blank">Show Revisions</a></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Abstract: </span><span class="note_content_value">The key challenge in semi-supervised learning is how to effectively leverage unlabeled data to improve learning performance. The classical label propagation method, despite its popularity, has limited modeling capability in that it only exploits graph information for making predictions. In this paper, we consider label propagation from a graph signal processing perspective and decompose it into three components: signal, filter, and classifier. By extending the three components, we propose a simple generalized label propagation (GLP) framework for semi-supervised learning. GLP naturally integrates graph and data feature information, and offers the flexibility of selecting appropriate filters and domain-specific classifiers for different applications. Interestingly, GLP also provides new insight into the popular graph convolutional network and elucidates its working mechanisms. Extensive experiments on three citation networks, one knowledge graph, and one image dataset demonstrate the efficiency and effectiveness of GLP.</span></div><div class="note_contents"><span class="note_content_field">Keywords: </span><span class="note_content_value">semi-supervised learning, label propagation, graph convolutional networks</span></div><div class="note_contents"><span class="note_content_field">TL;DR: </span><span class="note_content_value">We extend the classical label propation methods to jointly model graph and feature information from a graph filtering perspective, and show connections to the graph convlutional networks.</span></div><div class="reply_row clearfix"><div class="item" id="reply_count">9 Replies</div></div></div><hr class="small" /><div id="note_children"><div class="note_with_children"><div id="note_rygepnnp67" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Submission Withdrawn by the Authors</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=SygjB3AcYX&amp;noteId=rygepnnp67"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1575 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">18 Nov 2018</span><span class="item">ICLR 2019 Conference Paper1575 Withdraw Submission</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Withdrawal confirmation: </span><span class="note_content_value">I have read and agree with the withdrawal statement on behalf of myself and my co-authors.</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_r1gQa5X9nQ" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Not sure about the novelty: a slight generalization of [Hein and Maier 2007]</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=SygjB3AcYX&amp;noteId=r1gQa5X9nQ"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1575 AnonReviewer3</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">03 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper1575 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">In classical Label Propagation (LP)-based semi-supervised learning, only the given graph structure and labelled data are taken account (e.g. in citation networks). However, this can be limiting as feature representations for data vertices (given by the matrix X) are not fully exploited. The proposed approach proposes to break this limitation.

The authors consider LP from a signal processing perspective by showing that it behaves as a low pass filter: It amplifies contributions of small eigenvalues (of the graph Laplacian) and attenuate contributions of large eigenvalues leading to smoother signal.

Such insight is exploited by replacing the input signal Y by X: Which has the result of smoothing features in X such as data points of the same class would have similar features. Then, a classifier is trained on the labelled data points using the filtered features. This classifier is finally used for classifying unlabelled data points.

The authors reveal a connection between the proposed approach (GLP) and graph convolutional neural networks (GCN) by showing that the former is a special case of the first, which gives a natural and intuitive explanation to the inner workings of GCNS. 

Finally, experiments on 5 datasets have been conducted showing that the proposed approach consistently outperforms recent and classical semi-supervised approaches by a large margin, especially when the number of data points is very small. 

This paper is well motivated and written. However, the novelty is limited as similar ideas have been undertaken by [Hein and Maier 2007] although in different contexts. 

Although a discussion about [Hein and Maier 2007] has been provided in the related work section, it is not enough to faithfully compare both approaches. The authors should give proper credit to [Hein and Maier 2007] for the original ideas of smoothing the signal X and provide throughput qualitative and quantitative comparisons with [Hein and Maier 2007]:
As stated by the authors, this approach is perhaps not directly applicable to citation networks. However, it is applicable to MNIST, and a comparison in this context is necessary. Also, it would be interesting to qualitatively compare the denoising ability of both approaches by showing some example images (on MNIST as provided by [Hein and Maier 2007]).

In addition, I think this paper would benefit from:

•	Providing comparisons with recently proposed Gan-based semi-supervised approaches (e.g. Salimans et.al 2016)
•	Giving more details about hyper-parameter selection (alpha and k).
</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">4: Ok but not good enough - rejection</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_ryvqK2ppm" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>The problem addressed, the method proposed, and the analysis developed in this manuscript are all different from [Hein and Maier 2007] </a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=SygjB3AcYX&amp;noteId=ryvqK2ppm"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1575 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">17 Nov 2018 (modified: 18 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper1575 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Thank you for your comments. 

1. The problem considered in this paper is different from Manifold Denoising (MD) ([Hein and Maier 2007]). We consider the problem of jointly modeling graph similarity W and feature similarity X (both contain different information) to design new methods for semi-supervised learning, while MD considers denoising the feature matrix X with the matrix itself and the use of the denoised X is to construct a better graph for applying a label propagation algorithm. 

2. The semi-supervised learning methods proposed by us and MD are different. The focus of this paper is to solve semi-supervised classification problem on datasets with  a given graph W and a feature matrix X such as citation networks. The fact that MD cannot be directly applied or is not going to work well on such datasets is enough to show the differences between MD and our methods. 

3. We would like to compare MD on the MNIST (70k data samples used in our paper), but it requires iteratively constructing a data graph (which involves computing a distance matrix each time) and  feature smoothing (by doing matrix inversion each time), which is a tedious process and very time consuming. Moreover, there is no code available for MD.  The purpose of the MNIST experiment is to showcase the flexibility of our method by using CNN as a classifier. It is not the main focus of the paper. 

4. Our method is inspired by GCN, and we feel it is more related to GCN than MD. 
</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div><div class="note_with_children"><div id="note_rygxYQZt3Q" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>The paper is not very novel and does not have strong results</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=SygjB3AcYX&amp;noteId=rygxYQZt3Q"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1575 AnonReviewer2</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">02 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper1575 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">Review for GENERALIZED LABEL PROPAGATION METHODS FOR SEMI-SUPERVISED LEARNING
Summary:
The paper proposes an extension to label propagation where they replace the label matrix with a feature matrix in the label propagation objective and they replace the Laplacian with functions of the Laplacian. These new features that are the solution to this new objective are then used in supervised classifiers.
Novelty/Significance:
It is not very clear what the novelty of this paper is. The paper proposes a new algorithm for semi-supervised learning, which is claimed to have better performance than current algorithms. Their proposed method is more on the lines of smoothing features using both labeled and unlabeled data so that they can train supervised learners on few labeled points. It is not exactly semi-supervised because there is no synergy between the process that uses all the data and learning the classifier.
The main concern about the novelty is that the proposed method seems like a slight variation on label propagation in order to get nicer features and then just using whatever classifier. Overall the amount of content in the paper feels lacking and there seems to be large amounts of review, repetitiveness, and unnecessary details.
Questions/Clarity:
What is the intuition behind why GLP which is a “multi-stage” process, works better than jointly modeling graph and feature information? Normally multi-stage methods work worse than joint models because they essentially model independently or in a greedy fashion (1 step before the next).
In section 4.1, the paper explains why normalization, 2 layers, and re-normalization are all important due to their effects on the eigenvalues. Is there intuition on why it is better for the eigenvalues to have the certain shaped explain in that section?
Part of the introduction is repeated in the related works section. This section should be moved to the front as it is wasting space being repeated at the end.
The datasets seem to all be ones where more classical learning techniques are known to do worse than neural networks. It seems like the majority of the improvement in accuracy is due to the use of the neural network, not the feature smoothing/learning part. An obvious example of this is that the SVM with GLP features in Table 5 are worse/marginally better than ManifReg, which does semi-supervised SVMs.
In the experiments GCN does worse than GLP, but in the paper it is shown that GCN is a special case of GLP with the ReLU function removed from Eq. 9. Why does removing this function make it worse? Is it not the ReLU part, but that GLP uses the Laplacian and not one of the other filters? If this is the case, why could the Laplacian not be replaced with one of the other filters, which are essentially functions of the Laplacian.
The filters in section 5 should be summarized in a chart or something and the details left in the appendix. The filters are not new, and the details take unnecessary space in the main part of the paper. 
The references do not have a consistent format.


</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">3: Clear rejection</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_S1e2NX26pQ" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Response to AnonReviewer2</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=SygjB3AcYX&amp;noteId=S1e2NX26pQ"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1575 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">17 Nov 2018</span><span class="item">ICLR 2019 Conference Paper1575 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Thank you for your comments.

1. Label propagation (LP) can also be considered as a two-step process: first computing the data proximity matrix (I+\alpha L)^{-1} by doing matrix inversion in an unsupervised manner and then assigning labels to unlabeled data in a supervised manner. 

2. Our method works well because it provides a principled way to jointly model the graph (W) and feature information (X).  It works under the assumption that W and X contain complement information. 

3. The explanations of GCN mechanisms in section 4.1 are based on the principle that the contributions of small eigenvalues should be amplified, and the contributions of large eigenvalues should be reduced.

4. We used default parameters for SVM in Table 5. The performance will be improved with tuned parameters. This experiment is intended to demonstrate the usefulness of the filtered features, not to compare with the baselines.

5. The reason for the performance gain of our method GLP over GCN is explained in section 6. 
</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div><div class="note_with_children"><div id="note_S1x9orjuhm" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Convincing application of graph filtering techniques in classification</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=SygjB3AcYX&amp;noteId=S1x9orjuhm"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1575 AnonReviewer1</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">02 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper1575 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">This paper gives an overview of the recently proposed techniques for filtering graph signals. Then, the classification performance of several types of graph filters is studied over a few data sets. In my understanding, the main contribution of the paper is an elaboration on the existing graph filtering approaches and different filtering strategies in the problem of classification and studying their links to the recent graph CNNs, rather than the development of a novel and original methodology. Nevertheless, I think that the study might be worth presenting as it is well-written and it offers a nice treatment towards better comprehension of graph filtering techniques in data analysis problems, with convincing performance figures.

Some minor comments:

- Can you please briefly describe what the classification tasks are in the experiments?
- Typos in the sentence above (1) “The objective OF OF”, and in (1): “Laplcacian”</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">6: Marginally above acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_Byg-9WnTa7" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Thank you for your comments.</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=SygjB3AcYX&amp;noteId=Byg-9WnTa7"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1575 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">17 Nov 2018</span><span class="item">ICLR 2019 Conference Paper1575 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">We will add descriptions of the classification tasks and correct the typos in the revised version. </span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div><div class="note_with_children"><div id="note_SklJ3jz05X" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Miss results of GAT</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=SygjB3AcYX&amp;noteId=SklJ3jz05X"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">(anonymous)</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">12 Oct 2018</span><span class="item">ICLR 2019 Conference Paper1575 Public Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">You discussed GAT in your related work, but did not include the experimental results of GAT which are better than yours. You should include and explain what aspect your model is comparative with GAT. </span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_BkeBqAq_hQ" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Comparison with GAT</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=SygjB3AcYX&amp;noteId=BkeBqAq_hQ"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1575 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">01 Nov 2018 (modified: 02 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper1575 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Thank you for your comments. We have tested GAT on the citation networks Cora, CiteSeer, and PubMed using the same setting as in our manuscript. That is, we did not use an additional validation set with 500 labeled data as in GCN and GAT. Instead, we tuned trainable parameters on the training set. The purpose is to compare all methods in a more realistic and fair setting. 

The results are averaged over 10 random splits of each dataset. With 20 labels per class, the results of GAT on Cora, CiteSeer, and PubMed are 80.6%, 68.1%, and 76.2% respectively. With 4 labels per class, the results of GAT on Cora, CiteSeer, and PubMed are 64.7%, 54.8%, and 64.9% respectively. We will include the results in the revised version.

One can see from Table 1 in our manuscript that the performance of GAT is comparable to GCN and our method GLP for the case of 20 labels per class, but not as good as GLP for the case of 4 labels per class. The performance gain of GLP over GAT or GCN comes from the use of stronger filters to extract higher level features to improve performance when label rate is low, as explained in section 6 of our manuscript. As GAT contains more trainable parameters (almost 4 times more than GCN), it works better with validation.</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div></div></main></div>
  </div>
</div>


    <!-- Footer -->
    <footer class="sitemap">
      <div class="container">
        <div class="row hidden-xs">
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/venues">All Venues</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="/contact">Contact</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
    
        <div class="row visible-xs-block">
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/contact">Contact</a></li>
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
      </div>
    </footer>
    
    <footer class="sponsor">
      <div class="container">
        <div class="row">
          <div class="col-sm-10 col-sm-offset-1">
            <p class="text-center">
              OpenReview is created by the <a href="http://www.iesl.cs.umass.edu/" target="_blank">Information Extraction and Synthesis Laboratory</a>, College of Information and Computer Science, University of Massachusetts Amherst. We gratefully acknowledge the support of the OpenReview sponsors:  Google,  Facebook, NSF, the University of Massachusetts Amherst Center for Data Science, and Center for Intelligent Information Retrieval, as well as the Google Cloud Platform for donating the computing and networking services on which OpenReview.net runs.
            </p>
          </div>
        </div>
      </div>
    </footer>

  <div id="feedback-modal" class="modal fade" tabindex="-1" role="dialog">
    <div class="modal-dialog">
      <div class="modal-content">
        <div class="modal-header">
          <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button>
          <h3 class="modal-title">Send Feedback</h3>
        </div>
        <div class="modal-body">
          <p>Enter your feedback below and we'll get back to you as soon as possible.</p>
          <form action="/feedback" method="POST">
            <div class="form-group">
              <input type="email" name="from" class="form-control" placeholder="Email" />
            </div>
            <div class="form-group">
              <input type="text" name="subject" class="form-control" placeholder="Subject" />
            </div>
            <div class="form-group">
              <textarea name="message" class="form-control feedback-input" rows="5" placeholder="Message" required=""></textarea>
            </div>
          <ul id="ui-id-2" tabindex="0" class="ui-menu ui-widget ui-widget-content" style="display: none;"></ul></form>
        </div>
        <div class="modal-footer">
          <button type="button" class="btn btn-default" data-dismiss="modal">Cancel</button>
          <button type="button" class="btn btn-primary">Send</button>
        </div>
      </div>
    </div>
  </div>

  <script type="text/javascript" async="" src="https://www.google-analytics.com/analytics.js"></script><script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js"></script>
  <script>window.jQuery || document.write('&lt;script src="/static/js/vendor/jquery-2.2.4.min.js"&gt;&lt;\/script&gt;')</script>

  <script src="/static/dist/vendor.min.js"></script>
  <script src="/static/dist/templates.min.js"></script>
  <script src="/static/dist/openreview.min.js"></script>

    <script>window.legacyScripts = true;</script>


    <script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-108703919-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() { dataLayer.push(arguments); }
      gtag('js', new Date());
      gtag('config', 'UA-108703919-1');
    </script>


<div role="status" aria-live="assertive" aria-relevant="additions" class="ui-helper-hidden-accessible"></div></body></html>
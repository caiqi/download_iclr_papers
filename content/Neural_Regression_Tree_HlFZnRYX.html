<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" class="no-js"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>Neural Regression Tree | OpenReview</title>
  <meta name="description" content="" />

      <meta name="citation_title" content="Neural Regression Tree" />
        <meta name="citation_author" content="Anonymous" />
      <meta name="citation_publication_date" content="2018/09/27" />
      <meta name="citation_online_date" content="2018/09/27" />
      <meta name="citation_pdf_url" content="https://openreview.net/pdf?id=H1lFZnR5YX" />
      <meta name="twitter:card" content="summary" />
      <meta name="twitter:site" content="@openreviewnet" />
      <meta name="og:title" content="Neural Regression Tree" />
      <meta name="og:description" content="Regression-via-Classification (RvC) is the process of converting a regression problem to a classification one. Current approaches for RvC use ad-hoc discretization strategies and are suboptimal. We..." />
      <meta name="og:image" content="https://openreview.net/static/images/openreview_logo_512.png" />

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans:400,400i,700,700i" />

  <link rel="stylesheet" href="/static/css/bootstrap.min.css" />
  <link rel="stylesheet" href="/static/css/jquery-ui.min.css" />
  <link rel="stylesheet" href="/static/css/main.min.css" />
</head>

<body class="forum">
  <nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
  
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand home push-link" href="/"><strong>OpenReview</strong>.net</a>
      </div>
  
      <div id="navbar" class="navbar-collapse collapse">
        <form class="navbar-form navbar-left profile-search" role="search">
          <div class="form-group has-feedback">
            <input id="search_input" type="text" class="form-control ui-autocomplete-input" placeholder="Search ICLR 2019 Conference" autocomplete="off" />
            <span class="glyphicon glyphicon-search form-control-feedback" aria-hidden="true"></span>
          </div>
  
          <input id="search_group" type="hidden" value="ICLR.cc/2019/Conference" />
          <input id="search_content" type="hidden" value="all" />
        <ul id="ui-id-1" tabindex="0" class="ui-menu ui-widget ui-widget-content ui-autocomplete ui-front" style="display: none;"></ul></form>
  
        <ul class="nav navbar-nav navbar-right">
        
            <li id="user-menu"><a href="/login">Login</a></li>
        </ul>
      </div>
  
    </div>
  </nav>

  <div id="or-banner" class="banner" style="">
  <div class="container">
    <div class="row">
      <div class="col-xs-12"><a href="/group?id=ICLR.cc/2019/Conference" title="Venue Homepage"><img class="icon" src="/static/images/arrow_left.svg" /> Go to <strong>ICLR 2019 Conference</strong> homepage</a></div>
    </div>
  </div>
</div>
<div id="flash-message-container" class="alert alert-danger" role="alert" style="display: none;">
  <div class="container">
    <div class="row">
      <div class="col-xs-12">
        <div class="alert-content">
          <button type="button" class="close" aria-label="Close"><span aria-hidden="true">×</span></button>
        </div>
      </div>
    </div>
  </div>
</div>

<div class="container">
  <div class="row">
    <div class="col-xs-12">
      <main id="content" class="clearfix openbanner-visible legacy-styles"><div id="note_H1lFZnR5YX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Neural Regression Tree</a> <a class="note_content_pdf" href="/pdf?id=H1lFZnR5YX" title="Download PDF" target="_blank"><img src="/static/images/pdf_icon_blue.svg" /></a> </h2></div><div class="meta_row"><span class="signatures">Anonymous</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">28 Sep 2018 (modified: 11 Oct 2018)</span><span class="item">ICLR 2019 Conference Blind Submission</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span><span class="item"><a class="action-bibtex-modal" data-bibtex="@inproceedings{    &#10;anonymous2019neural,    &#10;title={Neural Regression Tree},    &#10;author={Anonymous},    &#10;booktitle={Submitted to International Conference on Learning Representations},    &#10;year={2019},    &#10;url={https://openreview.net/forum?id=H1lFZnR5YX},    &#10;note={under review}    &#10;}">Show Bibtex</a></span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Abstract: </span><span class="note_content_value">Regression-via-Classification (RvC) is the process of converting a regression problem to a classification one. Current approaches for RvC use ad-hoc discretization strategies and are suboptimal. We propose a neural regression tree model for RvC. In this model, we employ a joint optimization framework where we learn optimal discretization thresholds while simultaneously optimizing the features for each node in the tree. We empirically show the validity of our model by testing it on two challenging regression tasks where we establish the state of the art.</span></div><div class="note_contents"><span class="note_content_field">Keywords: </span><span class="note_content_value">regression-via-classification, discretization, regression tree, neural model, optimization</span></div><div class="note_contents"><span class="note_content_field">TL;DR: </span><span class="note_content_value">A novel neural regression tree for optimal discretization in regression-via-classification problems.</span></div><div class="reply_row clearfix"><div class="item" id="reply_count">3 Replies</div></div></div><hr class="small" /><div id="note_children"><div class="note_with_children"><div id="note_H1eB8QXqam" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Clearly written and well thought out paper with somewhat lackluster motivation and results </a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=H1lFZnR5YX&amp;noteId=H1eB8QXqam"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1192 AnonReviewer1</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">15 Nov 2018</span><span class="item">ICLR 2019 Conference Paper1192 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">This paper presents a new approach to regression via classification problem utilizing a hybrid model between a neural network and a decision tree. The paper is very well written and easy to follow. It presents results on two very similar regression tasks and claims state of the art performance on both.  The paper however does not motivate its contributions sufficiently, and does not provide enough experimental results to justify their method. 

The authors could significantly improve the paper by spending more time motivating their work. For example, it is unclear why RvC is the best strategy for the tasks they study and what other tasks one should approach from a RvC standpoint. The paper would also be significantly more compelling if the strategy was applied to more varied tasks. Furthermore  the two baseline models used are 11 and 34 years old respectively and i do not believe they represent a thorough review of the potential approaches to this problem.  Significant work could also be done to explore the effect of using different neural network structures for the NRT - in this paper only a fairly simple 3 layer architecture is used.  

Section 4.4 is interesting and i believe the paper would be improved if more time was spent exploring the explanability of this new proposed model. 

Finally the scan method mentioned in the conclusion could have more emphasis placed on it in the text.  

Over all the paper is well written and easy to follow but is limited by its lack of well detailed motivation and insufficient baselines and applied tasks. 

</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">5: Marginally below acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">3: The reviewer is fairly confident that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_S1lO457jnm" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Failed to motivate the significance and poor experimental baselines.</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=H1lFZnR5YX&amp;noteId=S1lO457jnm"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1192 AnonReviewer3</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">03 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper1192 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">Summary:

This paper presents a neural network based tree model for the regression via classification problem. The paper is easy to follow but it failed to give motivations for the significance of this work.  I do not understand why regression via classification is any useful and what value it brings to the well studied regression problem with many different function approximators. The paper neither explain why regression via classification is any useful nor does it motivates the need for the presented model. The presented experiments are also not thorough, there are stronger and simpler baselines for regression like random forests, gradient boosted trees  or kernel ridge regression which are not evaluated and compared. I think this work do not pass the acceptance bar at ICLR conference. 

Comments:

1. I was not aware of this age and height estimation tasks. i-vectors are the standard features for speaker recognition.  Can the authors please elaborate in a  line or two why i-vectors would be suitable for age and height estimation?.

2. The regressor function r() simply gives out the mean value of the bin. The authors could have provided on details on why this choice ? and how it affects MAE ?

3. Each node in the NRT is successively being trained on a lesser amount of data. why do all the node-specific neural networks need the same parameter size then ?

4. In Conclusion the authors say,  "In addition, we proposed a scan method and a gradient method to optimize the tree." The authors do not very clearly mention these two methods in the text, neither are the results demonstrated in that way.

Miscellaneous comments:

1. This line seems incomplete in Section 1: "Traditional methods for defining the partition T by prior knowledge, such as equally probable intervals, equal width intervals, k-means clustering, etc. [4, 5, 3]." 

2. The notations used inside the nodes in Figure 1 has not been defined in the paper. 

3. Figure 2 and 3 axes don't have labels. Figure 3 caption says age, but it is for heights.

4.  In Section 4.4: Figure 4.4 should be Figure 4 and at one point "This is visible in 4.4" should be "This is visible in Figure 4"</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">3: Clear rejection</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_rke_Ie993Q" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Technically interesting contribution but would need more considerations and evidences</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=H1lFZnR5YX&amp;noteId=rke_Ie993Q"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1192 AnonReviewer2</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">03 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper1192 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">Summary:
The paper presents a novel supervised-learning method for regression using decision trees and neural nets. The core idea is based on a 90s technique called "regression via classification" by first apply discretization of target response y by some clustering, and apply any "classification" to those discretized values as class labels. Because real-valued y is one-dimensional and ordered, discretization means setting up any thresholds to give N-partitions of training {y_i}s. The proposed method tries to jointly learn these thresholds as well as node splitters of decision trees using neural nets. Because each node splitters are given by neural nets here, probability outputs for binary classification are also available. Regarding these probabilities as probabilistic splitting at each node, response y weighted by the path probabilities to leaves is the final prediction. The learning is in a greedy manner as in standard tree learning because exact joint learning is computationally hard.  Experiments on speaker profiling illustrate the performance improvements against standard nonlinear regression such as SVR and regression trees.

Comment:
This is a technically very interesting contribution, but several points can be considered more carefully as below.

- To be honest, it would be unconvincing that the approach "regression via classification (RvC)" is still valid. The proposed approach is an elaborate extension of this approach, but if we want prediction performance for regression, we would use some ensembles of regression trees such as Random forest, GBDT, ExtraTrees, ... instead of a single CART. Or even we can directly use deep learning based regression. The experiments against CART and SVR would be too naive in the current context of supervised learning. On the other hand, single CARTs are well interpretable and can be a nice tool to get some interpretations of the given data. But the proposed method seems to lose this type of interpretability because of introducing node splitters by neural nets. So the merits of the proposed approach would be somewhat unclear.

- In the context of tree learning, we need to consider two things. 

First of all, node splitting by general binary splitters are called "multivariate trees", but interestingly this does not always bring the good prediction performance on current quite high-dimensional data. So I guess that both optimizing "threshold for RvC" and "nonlinear node splitters" cannot always bring the prediction performance. Limitations and conditions would need to be clarified more carefully. 

Second of all, probabilistic consideration of decision trees such as eq(4) is almost like so-called "probabilistic decision trees" also known as "hierarchical mixtures of experts (HME)" in machine learning. See famous widely-cited papers of Jordan &amp; Jacobs 1994 and Bishop &amp; Svensen 2003. This can bring joint learning of probabilistic node splitter (gating networks) and decision functions at leaves (expert networks), and is also known to bring the smoothing effect into discrete and unstable regression trees, and hence the improved prediction performance. So which of probabilistic consideration or RvC contributes to the observed improvement is unclear... 

- The target joint optimization of eq (3) is actually optimized by a number of heuristic ways, and it is quite unclear how it is truly optimized. In contrast, HME learning is formulated as a joint optimization (and solved by EM in the case of Jordan &amp; Jacobs, for example).

- The experiments on single datasets of a very specific speaker profiling problem would be somewhat misleading. Probably, for this specific problem, there would be other existing methods. On the other hand, if this is for benchmarking purpose, a regression by neural nets and tree ensemble (random forest or something) can be included as other baselines, and also other types of regression problems can be tested.
</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">4: Ok but not good enough - rejection</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></main></div>
  </div>
</div>


    <!-- Footer -->
    <footer class="sitemap">
      <div class="container">
        <div class="row hidden-xs">
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/venues">All Venues</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="/contact">Contact</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
    
        <div class="row visible-xs-block">
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/contact">Contact</a></li>
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
      </div>
    </footer>
    
    <footer class="sponsor">
      <div class="container">
        <div class="row">
          <div class="col-sm-10 col-sm-offset-1">
            <p class="text-center">
              OpenReview is created by the <a href="http://www.iesl.cs.umass.edu/" target="_blank">Information Extraction and Synthesis Laboratory</a>, College of Information and Computer Science, University of Massachusetts Amherst. We gratefully acknowledge the support of the OpenReview sponsors:  Google,  Facebook, NSF, the University of Massachusetts Amherst Center for Data Science, and Center for Intelligent Information Retrieval, as well as the Google Cloud Platform for donating the computing and networking services on which OpenReview.net runs.
            </p>
          </div>
        </div>
      </div>
    </footer>

  <div id="feedback-modal" class="modal fade" tabindex="-1" role="dialog">
    <div class="modal-dialog">
      <div class="modal-content">
        <div class="modal-header">
          <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button>
          <h3 class="modal-title">Send Feedback</h3>
        </div>
        <div class="modal-body">
          <p>Enter your feedback below and we'll get back to you as soon as possible.</p>
          <form action="/feedback" method="POST">
            <div class="form-group">
              <input type="email" name="from" class="form-control" placeholder="Email" />
            </div>
            <div class="form-group">
              <input type="text" name="subject" class="form-control" placeholder="Subject" />
            </div>
            <div class="form-group">
              <textarea name="message" class="form-control feedback-input" rows="5" placeholder="Message" required=""></textarea>
            </div>
          <ul id="ui-id-2" tabindex="0" class="ui-menu ui-widget ui-widget-content" style="display: none;"></ul></form>
        </div>
        <div class="modal-footer">
          <button type="button" class="btn btn-default" data-dismiss="modal">Cancel</button>
          <button type="button" class="btn btn-primary">Send</button>
        </div>
      </div>
    </div>
  </div>

  <script type="text/javascript" async="" src="https://www.google-analytics.com/analytics.js"></script><script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js"></script>
  <script>window.jQuery || document.write('&lt;script src="/static/js/vendor/jquery-2.2.4.min.js"&gt;&lt;\/script&gt;')</script>

  <script src="/static/dist/vendor.min.js"></script>
  <script src="/static/dist/templates.min.js"></script>
  <script src="/static/dist/openreview.min.js"></script>

    <script>window.legacyScripts = true;</script>


    <script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-108703919-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() { dataLayer.push(arguments); }
      gtag('js', new Date());
      gtag('config', 'UA-108703919-1');
    </script>


<div role="status" aria-live="assertive" aria-relevant="additions" class="ui-helper-hidden-accessible"></div></body></html>
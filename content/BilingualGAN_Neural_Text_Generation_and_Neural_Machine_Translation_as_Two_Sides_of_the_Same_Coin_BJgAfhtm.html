<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" class="no-js"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>Bilingual-GAN: Neural Text Generation and Neural Machine Translation as Two Sides of the Same Coin | OpenReview</title>
  <meta name="description" content="" />

      <meta name="citation_title" content="Bilingual-GAN: Neural Text Generation and Neural Machine Translation as Two Sides of the Same Coin" />
        <meta name="citation_author" content="Ahmad Rashid" />
        <meta name="citation_author" content="Alan Do-Omri" />
        <meta name="citation_author" content="Mehdi Rezagholizadeh" />
        <meta name="citation_author" content="Md. Akmal Haidar" />
        <meta name="citation_author" content="Hamed Sadeghi" />
      <meta name="citation_publication_date" content="2018/09/27" />
      <meta name="citation_online_date" content="2018/09/27" />
      <meta name="citation_pdf_url" content="https://openreview.net/pdf?id=BJgAfh09tm" />
      <meta name="twitter:card" content="summary" />
      <meta name="twitter:site" content="@openreviewnet" />
      <meta name="og:title" content="Bilingual-GAN: Neural Text Generation and Neural Machine..." />
      <meta name="og:description" content="Latent space based GAN methods and attention based encoder-decoder architectures have achieved impressive results in text generation and Unsupervised NMT respectively. Leveraging the two domains..." />
      <meta name="og:image" content="https://openreview.net/static/images/openreview_logo_512.png" />

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans:400,400i,700,700i" />

  <link rel="stylesheet" href="/static/css/bootstrap.min.css" />
  <link rel="stylesheet" href="/static/css/jquery-ui.min.css" />
  <link rel="stylesheet" href="/static/css/main.min.css" />
</head>

<body class="forum">
  <nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
  
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand home push-link" href="/"><strong>OpenReview</strong>.net</a>
      </div>
  
      <div id="navbar" class="navbar-collapse collapse">
        <form class="navbar-form navbar-left profile-search" role="search">
          <div class="form-group has-feedback">
            <input id="search_input" type="text" class="form-control ui-autocomplete-input" placeholder="Search ICLR 2019 Conference" autocomplete="off" />
            <span class="glyphicon glyphicon-search form-control-feedback" aria-hidden="true"></span>
          </div>
  
          <input id="search_group" type="hidden" value="ICLR.cc/2019/Conference" />
          <input id="search_content" type="hidden" value="all" />
        <ul id="ui-id-1" tabindex="0" class="ui-menu ui-widget ui-widget-content ui-autocomplete ui-front" style="display: none;"></ul></form>
  
        <ul class="nav navbar-nav navbar-right">
        
            <li id="user-menu"><a href="/login">Login</a></li>
        </ul>
      </div>
  
    </div>
  </nav>

  <div id="or-banner" class="banner" style="">
  <div class="container">
    <div class="row">
      <div class="col-xs-12"><a href="/group?id=ICLR.cc/2019/Conference" title="Venue Homepage"><img class="icon" src="/static/images/arrow_left.svg" /> Go to <strong>ICLR 2019 Conference</strong> homepage</a></div>
    </div>
  </div>
</div>
<div id="flash-message-container" class="alert alert-danger" role="alert" style="display: none;">
  <div class="container">
    <div class="row">
      <div class="col-xs-12">
        <div class="alert-content">
          <button type="button" class="close" aria-label="Close"><span aria-hidden="true">×</span></button>
        </div>
      </div>
    </div>
  </div>
</div>

<div class="container">
  <div class="row">
    <div class="col-xs-12">
      <main id="content" class="clearfix openbanner-visible legacy-styles"><div id="note_BJgAfh09tm" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Bilingual-GAN: Neural Text Generation and Neural Machine Translation as Two Sides of the Same Coin</a> <a class="note_content_pdf" href="/pdf?id=BJgAfh09tm" title="Download PDF" target="_blank"><img src="/static/images/pdf_icon_blue.svg" /></a> </h2></div><div class="meta_row"><span class="signatures"><a href="/profile?email=ahmadrash%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="bottom" title="" data-original-title="ahmadrash@gmail.com">Ahmad Rashid</a>, <a href="/profile?email=alan.do-omri%40mail.mcgill.ca" class="profile-link" data-toggle="tooltip" data-placement="bottom" title="" data-original-title="alan.do-omri@mail.mcgill.ca">Alan Do-Omri</a>, <a href="/profile?email=mehdi.rezagholizadeh%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="bottom" title="" data-original-title="mehdi.rezagholizadeh@gmail.com">Mehdi Rezagholizadeh</a>, <a href="/profile?email=md.akmal.haidar%40huawei.com" class="profile-link" data-toggle="tooltip" data-placement="bottom" title="" data-original-title="md.akmal.haidar@huawei.com">Md. Akmal Haidar</a>, <a href="/profile?email=haamed.sadeghi%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="bottom" title="" data-original-title="haamed.sadeghi@gmail.com">Hamed Sadeghi</a></span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">28 Sep 2018 (modified: 17 Nov 2018)</span><span class="item">ICLR 2019 Conference Withdrawn Submission</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Abstract: </span><span class="note_content_value">Latent space based GAN methods and attention based encoder-decoder architectures have achieved impressive results in text generation and Unsupervised NMT respectively. Leveraging the two domains, we propose an adversarial latent space based architecture capable of generating parallel sentences in two languages concurrently and translating bidirectionally. The bilingual generation goal is achieved by sampling from the latent space that is adversarially constrained to be shared between both languages. First an NMT model is trained, with back-translation and an adversarial setup, to enforce a latent state between the two languages. The encoder and decoder are shared for the two translation directions. Next, a GAN is trained to generate ‘synthetic’ code mimicking the languages’ shared latent space. This code is then fed into the decoder to generate text in either language. We perform our experiments on Europarl and Multi30k datasets, on the English-French language pair, and document our performance using both Supervised and Unsupervised NMT.</span></div><div class="note_contents"><span class="note_content_field">Keywords: </span><span class="note_content_value">Text Generation, Machine Translation, Deep Learning, GAN</span></div><div class="note_contents"><span class="note_content_field">TL;DR: </span><span class="note_content_value">We present a novel method for Bilingual Text Generation producing parallel concurrent sentences in two languages.</span></div><div class="reply_row clearfix"><div class="item" id="reply_count">4 Replies</div></div></div><hr class="small" /><div id="note_children"><div class="note_with_children"><div id="note_HygK1_BGTX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Submission Withdrawn by the Authors</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=BJgAfh09tm&amp;noteId=HygK1_BGTX"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1312 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">09 Nov 2018</span><span class="item">ICLR 2019 Conference Paper1312 Withdraw Submission</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Withdrawal confirmation: </span><span class="note_content_value">I have read and agree with the withdrawal statement on behalf of myself and my co-authors.</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_H1lKM5Z537" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>The paper could be more readable, the contribution is limited. The machine translation experiments should be compared with previous work on a benchmark setup. The generation experiments should consider obvious baseline such as sampling from a language model.</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=BJgAfh09tm&amp;noteId=H1lKM5Z537"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1312 AnonReviewer1</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">03 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper1312 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">Bilingual GANs


Paper Summary:

The paper proposes to learn a generative model of sentences leveraging machine translation.
A first task learns a model which auto-encodes and translates sequences in a language agnostic continuous space (a first GAN objective penalizes including language information in the code). The second GAN task learns a generator that allows sampling could that cannot be distinguished with genuine sentence codes from the encoder of the first task. The first model is evaluated in a supervised and unsupervised translation setup. The second model is evaluated by generating text, measuring language model perplexity.

Review:

Readability:

This paper could be more readable. In particular, it is not easy to understand how the two models interact: do you share the encoder and decoder parameters between the two tasks? Does the generation task fine tune these parameters? The evaluation protocol is unclear: what is the difference between supervised and half supervised MT? I do not understand what BLEU means for unconditional generation. E.g. when you generate 40k sentence sentences from the Europarl model, you compute the precision of your prediction with respect to which reference?


Contribution:

The contribution in terms of (un)-supervised MT is limited at best compared to (Artetxe et al 2017,2018) or (Lample et al, 2017, 2018). In particular, I do not see any reason not to use the empirical setup used in these papers and compare your results with them. The experimental setup seems weak with only short sentences &lt; 20 words, with a small vocabulary and no attempt to deal with unknown replacements or subword units.

The contribution for unconditional generation is more interesting as relying on a space defined by translation seems a good idea. But it is hard to assess. Again, the paper lacks comparison with baselines. In particular, sampling from a large language model to generate text seems an obvious baseline. It is also necessary to compare with a monolingual GAN (Zhao et al 2017), since it would quantify the benefit of the bilingual latent space.

Related Work:

Previous work is mischaracterized: Schwenk &amp; Douze 2017, Lample et al 2018, Artexte et al 2017b are not relying on adversarial training. 

Review Summary:

The paper could be more readable, the contribution is limited. The machine translation experiments should be compared with previous work on a benchmark setup. The generation experiments should consider obvious baseline such as sampling from a language model.


</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">3: Clear rejection</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_HkxXuveK3m" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Interesting idea, weak experiments</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=BJgAfh09tm&amp;noteId=HkxXuveK3m"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1312 AnonReviewer2</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">02 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper1312 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">This paper proposes a new method to generate parallel sentences combining NMT and GANs. While I think that the paper contains many interesting ideas, it lacks a good motivation and, more importantly, I find the experimental design (as well as some results) to be very weak. Please find my comments below:

- The paper is not properly motivated. Why would one want to generate parallel sentences? I do not mean that the problem is uninteresting, I am just saying that the motivation is not there. My initial expectation (before I read the paper) was that the NMT part would benefit (or at least be influenced by) the text generation part, but that is not the case, as the NMT model is trained offline before the generator.

- You do not compare your results to any other system or baseline in your experiments. A simple baseline would be to generate sentences monolingually, and translate them using machine translation (either supervised or unsupervised). I think that some baseline like this is necessary.

- The translation BLEU scores are very weak. 8 BLEU points in fr-en Europarl seems way too low to take these results seriously.

- Given that the (unsupervised) machine translation part is completely independent from the text generation unit, its evaluation seems of little relevance, as there is nothing new on it.

- The training set seems very small for natural language generation (200k sentences for Europarl and 12-29k for Multi30k), so I am not sure about how meaningful the reported results are.

- I do not understand what the "generation BLEU" is, but evaluating a text generator with BLEU does not seem to make much sense, as there is no reference to compare to.

- I am not sure if I understand how perplexity is used in your evaluation. Do you train a separate language model and use it to measure the perplexity of your generated text? If so, this seems unusual and problematic to me. Do you have any reference of anybody else doing this?</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">4: Ok but not good enough - rejection</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">3: The reviewer is fairly confident that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_rkxXnFKu2X" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Experiments not convincing; not well-motivated</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=BJgAfh09tm&amp;noteId=rkxXnFKu2X"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1312 AnonReviewer3</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">01 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper1312 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">[Summary]
This paper proposed an adversarial latent space based architecture capable of generating parallel sentences in two languages concurrently and translating bidirectionally. More specifically, there are two units in the framework: (1) A translation unit, which consists of two NMT models, that can translate sentences from one domain to another. The two NMT models are trained in a similar way to (Lample et al 2018a). The outputs from the two encoders of NMT models are regularized by a GAN. (2) A text generation unit, that can map a random noise into a code $c$. $c$ can be decoded into two different languages with the decoders of the NMT models. Experiments on on Europarl and Multi30k datasets are carried out to verify the proposed algorithm.

[Details]
1.	What is the motivation of this work? I am not fully convinced that building “an adversarial latent space based architecture capable of generating parallel sentences in two languages concurrently and translating bidirectionally” is a well-motivated topic, because in this system, (1) Do the NMT models have better performance due to the joint training? I found that leaving out the GAN loss can lead to better performance. (See Table 1) (2) Why do I need such a generator? Can it generate sentences with specific semantic? Hope the authors can give stronger motivations for this work.
2.	For NMT experiments, why don’t you work on WMT En-&gt;Fr (36M data after filtration) or En-&gt;De (4.5M data) tasks, which are more popular. It is strange to see that: (1) In Section 4.1, 2nd paragraph, “we removed sentences longer than 20 words”. That is, you only work on extremely short sentences, which is not a common practice. You should also use the official test sets, i.e., newstest series to evaluate your models. (2) For supervised setting, why don’t you use Transformer [ref1], a much strong baseline in NMT? Even if for using LSTM, a deep model like GNMT [ref2]? For unsupervised settings, why not follow (Lample et al 2018), which is the state-of-the-art unsupervised NMT model? (3) In Table 1, the rows with “NoAdv” have higher BLEU scores. Then, what is the role of the GAN in your NMT system?
3.	I am very confused by the evaluation of text generation. (1) Can you give a detailed explanation how the sentences are generated? (2) After generating a pair of sentences, how to choose the references for “Generation BLEU”? (3) Even if for translation BLEU, given the input is a synthesis sentence instead of a natural sentence, how can Google Translation give a correct “reference sentence”? 

[Typos]
(1) Section 4.3, first line: results=&gt; results 
(2) reference (Lample et al 2018a) and (Lample et al 2018b) are the same one. Please correct them.

[ref1] Vaswani, Ashish, et al. "Attention is all you need." Advances in Neural Information Processing Systems. 2017.
[ref2] Wu, Yonghui, et al. "Google's neural machine translation system: Bridging the gap between human and machine translation." arXiv preprint arXiv:1609.08144 (2016).
</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">4: Ok but not good enough - rejection</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></main></div>
  </div>
</div>


    <!-- Footer -->
    <footer class="sitemap">
      <div class="container">
        <div class="row hidden-xs">
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/venues">All Venues</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="/contact">Contact</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
    
        <div class="row visible-xs-block">
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/contact">Contact</a></li>
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
      </div>
    </footer>
    
    <footer class="sponsor">
      <div class="container">
        <div class="row">
          <div class="col-sm-10 col-sm-offset-1">
            <p class="text-center">
              OpenReview is created by the <a href="http://www.iesl.cs.umass.edu/" target="_blank">Information Extraction and Synthesis Laboratory</a>, College of Information and Computer Science, University of Massachusetts Amherst. We gratefully acknowledge the support of the OpenReview sponsors:  Google,  Facebook, NSF, the University of Massachusetts Amherst Center for Data Science, and Center for Intelligent Information Retrieval, as well as the Google Cloud Platform for donating the computing and networking services on which OpenReview.net runs.
            </p>
          </div>
        </div>
      </div>
    </footer>

  <div id="feedback-modal" class="modal fade" tabindex="-1" role="dialog">
    <div class="modal-dialog">
      <div class="modal-content">
        <div class="modal-header">
          <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button>
          <h3 class="modal-title">Send Feedback</h3>
        </div>
        <div class="modal-body">
          <p>Enter your feedback below and we'll get back to you as soon as possible.</p>
          <form action="/feedback" method="POST">
            <div class="form-group">
              <input type="email" name="from" class="form-control" placeholder="Email" />
            </div>
            <div class="form-group">
              <input type="text" name="subject" class="form-control" placeholder="Subject" />
            </div>
            <div class="form-group">
              <textarea name="message" class="form-control feedback-input" rows="5" placeholder="Message" required=""></textarea>
            </div>
          <ul id="ui-id-2" tabindex="0" class="ui-menu ui-widget ui-widget-content" style="display: none;"></ul></form>
        </div>
        <div class="modal-footer">
          <button type="button" class="btn btn-default" data-dismiss="modal">Cancel</button>
          <button type="button" class="btn btn-primary">Send</button>
        </div>
      </div>
    </div>
  </div>

  <script type="text/javascript" async="" src="https://www.google-analytics.com/analytics.js"></script><script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js"></script>
  <script>window.jQuery || document.write('&lt;script src="/static/js/vendor/jquery-2.2.4.min.js"&gt;&lt;\/script&gt;')</script>

  <script src="/static/dist/vendor.min.js"></script>
  <script src="/static/dist/templates.min.js"></script>
  <script src="/static/dist/openreview.min.js"></script>

    <script>window.legacyScripts = true;</script>


    <script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-108703919-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() { dataLayer.push(arguments); }
      gtag('js', new Date());
      gtag('config', 'UA-108703919-1');
    </script>


<div role="status" aria-live="assertive" aria-relevant="additions" class="ui-helper-hidden-accessible"></div></body></html>
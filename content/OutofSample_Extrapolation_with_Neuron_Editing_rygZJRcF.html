<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" class="no-js"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>Out-of-Sample Extrapolation with Neuron Editing | OpenReview</title>
  <meta name="description" content="" />

      <meta name="citation_title" content="Out-of-Sample Extrapolation with Neuron Editing" />
        <meta name="citation_author" content="Anonymous" />
      <meta name="citation_publication_date" content="2018/09/27" />
      <meta name="citation_online_date" content="2018/09/27" />
      <meta name="citation_pdf_url" content="https://openreview.net/pdf?id=rygZJ2RcF7" />
      <meta name="twitter:card" content="summary" />
      <meta name="twitter:site" content="@openreviewnet" />
      <meta name="og:title" content="Out-of-Sample Extrapolation with Neuron Editing" />
      <meta name="og:description" content="While neural networks can be trained to map from one specific dataset to another, they usually do not learn a generalized transformation that can extrapolate accurately outside the space of..." />
      <meta name="og:image" content="https://openreview.net/static/images/openreview_logo_512.png" />

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans:400,400i,700,700i" />

  <link rel="stylesheet" href="/static/css/bootstrap.min.css" />
  <link rel="stylesheet" href="/static/css/jquery-ui.min.css" />
  <link rel="stylesheet" href="/static/css/main.min.css" />
</head>

<body class="forum">
  <nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
  
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand home push-link" href="/"><strong>OpenReview</strong>.net</a>
      </div>
  
      <div id="navbar" class="navbar-collapse collapse">
        <form class="navbar-form navbar-left profile-search" role="search">
          <div class="form-group has-feedback">
            <input id="search_input" type="text" class="form-control ui-autocomplete-input" placeholder="Search ICLR 2019 Conference" autocomplete="off" />
            <span class="glyphicon glyphicon-search form-control-feedback" aria-hidden="true"></span>
          </div>
  
          <input id="search_group" type="hidden" value="ICLR.cc/2019/Conference" />
          <input id="search_content" type="hidden" value="all" />
        <ul id="ui-id-1" tabindex="0" class="ui-menu ui-widget ui-widget-content ui-autocomplete ui-front" style="display: none;"></ul></form>
  
        <ul class="nav navbar-nav navbar-right">
        
            <li id="user-menu"><a href="/login">Login</a></li>
        </ul>
      </div>
  
    </div>
  </nav>

  <div id="or-banner" class="banner" style="">
  <div class="container">
    <div class="row">
      <div class="col-xs-12"><a href="/group?id=ICLR.cc/2019/Conference" title="Venue Homepage"><img class="icon" src="/static/images/arrow_left.svg" /> Go to <strong>ICLR 2019 Conference</strong> homepage</a></div>
    </div>
  </div>
</div>
<div id="flash-message-container" class="alert alert-danger" role="alert" style="display: none;">
  <div class="container">
    <div class="row">
      <div class="col-xs-12">
        <div class="alert-content">
          <button type="button" class="close" aria-label="Close"><span aria-hidden="true">×</span></button>
        </div>
      </div>
    </div>
  </div>
</div>

<div class="container">
  <div class="row">
    <div class="col-xs-12">
      <main id="content" class="clearfix openbanner-visible legacy-styles"><div id="note_rygZJ2RcF7" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Out-of-Sample Extrapolation with Neuron Editing</a> <a class="note_content_pdf" href="/pdf?id=rygZJ2RcF7" title="Download PDF" target="_blank"><img src="/static/images/pdf_icon_blue.svg" /></a> </h2></div><div class="meta_row"><span class="signatures">Anonymous</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">28 Sep 2018 (modified: 11 Oct 2018)</span><span class="item">ICLR 2019 Conference Blind Submission</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span><span class="item"><a class="action-bibtex-modal" data-bibtex="@inproceedings{    &#10;anonymous2019out-of-sample,    &#10;title={Out-of-Sample Extrapolation with Neuron Editing},    &#10;author={Anonymous},    &#10;booktitle={Submitted to International Conference on Learning Representations},    &#10;year={2019},    &#10;url={https://openreview.net/forum?id=rygZJ2RcF7},    &#10;note={under review}    &#10;}">Show Bibtex</a></span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Abstract: </span><span class="note_content_value">While neural networks can be trained to map from one specific dataset to another, they usually do not learn a generalized transformation that can extrapolate accurately outside the space of training. For instance, a generative adversarial network (GAN) exclusively trained to transform images of cars from light to dark might not have the same effect on images of horses. This is because neural networks are good at generation within the manifold of the data that they are trained on. However, generating new samples outside of the manifold or extrapolating "out-of-sample" is a much harder problem that has been less well studied. To address this, we introduce a technique called neuron editing that learns how neurons encode an edit for a particular transformation in a latent space. We use an autoencoder to decompose the variation within the dataset into activations of different neurons and generate transformed data by defining an editing transformation on those neurons. By performing the transformation in a latent trained space, we encode fairly complex and non-linear transformations to the data with much simpler distribution shifts to the neuron's activations. We showcase our technique on image domain/style transfer and two biological applications: removal of batch artifacts representing unwanted noise and modeling the effect of drug treatments to predict synergy between drugs.</span></div><div class="note_contents"><span class="note_content_field">Keywords: </span><span class="note_content_value">generative adversarial networks, computational biology, generating, generation, extrapolation, out-of-sample, neural network inference</span></div><div class="note_contents"><span class="note_content_field">TL;DR: </span><span class="note_content_value">We reframe the generation problem as one of editing existing points, and as a result extrapolate better than traditional GANs.</span></div><div class="reply_row clearfix"><div class="item" id="reply_count">3 Replies</div></div></div><hr class="small" /><div id="note_children"><div class="note_with_children"><div id="note_H1xmTQtGpX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Novel but Limited on Image Data</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=rygZJ2RcF7&amp;noteId=H1xmTQtGpX"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper958 AnonReviewer2</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">09 Nov 2018</span><span class="item">ICLR 2019 Conference Paper958 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">The authors present a way to transform data from a source distribution to have characteristics of a target distribution.
This is accomplished by applying a "NeuronEdit" function to the encoding of the input; this edited input is then decoded.
The NeuronEdit function is parametrized by the target distribution's statistics. The edit function does a sort of simple histogram matching, so that the ith percentile values of the source distribution's bottleneck representations instead become the ith percentile values of the target distribution's bottleneck representations.
Experiments are on CIFAR-10 and biology datasets (the latter of which are not my strong suit).

This paper is well-written and original. It is original because there are only a few works which directly manipulate the latent space (one example is latent space interpolation used to visualize GANs), and this is distinct from those.
The problem they aim to solve also has not received much attention, which enhances the novelty of this paper.
The presented method is simple and easy to implement, since the editing function is not learned but is instead deterministic. It is encapsulated in Equation 1.

The fact that the editing function is fixed may greatly hinder its flexibility and applicability.
In Section 3.1 and Figure 1, we are shown that NeuronEditting can turn images of horses with white backgrounds into images of horses with dark backgrounds (horses are an unseen class).
NeuronEditting turns the horse darker as well. It seems that one could change the brightness and contrast of the image to obtain a similar effect, or one could or take the geometric mean of the image in [0,1] with the average target image and obtain a similar effect. Such traditional methods are also robust to unseen classes. Moreover, NeuronEditting's ability to change the brightness of the image is not that surprising given that brightness is some of the most basic image information. (In point of fact it is captured by the DC Coefficient, the very first coefficient from the discrete cosine transform which is used in JPEG.) What else can NeuronEditting do in the image domain? Can this be used to rotate or reflect MNIST digits? The biological experiments also appear to involve simple input transformations.

Fine points:
- "an edit function between the the"
- I am not sure the speculation about this method's loose relation to word2vec belongs in a scientific work. Both involve modifications to a neural representations, but no further relation is justified in the paper.
- Was the dataset partitioning for the CIFAR-10 experiment done manually? If not, what process partitioned the dataset?</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">5: Marginally below acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">3: The reviewer is fairly confident that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_SklGFZbphQ" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>border-line paper</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=rygZJ2RcF7&amp;noteId=SklGFZbphQ"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper958 AnonReviewer1</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">05 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper958 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">The paper demonstrates that we can harness (semantically meaningful) features learned by a pre-trained autoencoder AE to define a determinisc transformation (e.g. math operations on latent space) to transform one distribution A into another distribution B.
The original AE was pre-trained on a larger distribution that includes both A and B.

A key contribution of this paper is the interesting demonstration that this method (called Neuron Editing) allows us to perform a transformation T that transforms  pre-treatment observations into post-treatment observations, which is useful in the medical or biological setting.

+ Novelty
Neuron editing is essentially a common technique of performing arithmetics in the latent space e.g. King - Man + Woman = Queen (in NLP) or Man wearing sunglass - Man + Woman = Woman wearing sunglasses (e.g. in image domain e.g. in Alec Radford et al. 2015).
Therefore, the novelty is limited.

+ Significance
The main contribution of this paper is the empirical demonstration that such transformation T is better defined, rather than learned directly from data (e.g. via GANs).

I should note that I'm not too familiar with the biology datasets in Sec. 3.2 and Sec 3.3 in order to fully appreciate the practical impact of Neuron Editing.

+ Clarity

I think some key reasons behind why Neuron Editing works could be more clearly presented.
That is, the key here is we use pre-trained AEs to perform a pre-defined transformation.
I think the key might not be whether we use GANs or not, it is how we use them.
I guess if we use ALI (i.e. training a GAN concurrently with an AE) to perform Neuron Editing, the result should work as well.</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">6: Marginally above acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">3: The reviewer is fairly confident that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_ryeR_EJ937" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Interesting idea in improving data transformation generalization across input data distributions in an unsupervised way</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=rygZJ2RcF7&amp;noteId=ryeR_EJ937"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper958 AnonReviewer3</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">02 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper958 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">The authors proposed a novel method of making data transformation that is much easier to extend to the cases where the input distribution is different from the one that is used to the train the model (in-sample vs out-sample). This has a lot of application in removing experimental noise in biological data (also known as batch effects).
The idea is to learn a representation that separates background (dimensions that do NOT vary across data points, but may be subject to change in a data transformation) and foreground (dimensions that vary between data points under the same background) and then apply a *fixed* linear transformation in the learned representation space. This is different from other approaches, such as GAN, where the transformation is learned entirely based on the data. In addition, it mitigates some known problems, such as the "mode collapse" in GAN, by just learning a good representation. This is proposed to be done by an autoencoder trained on both in-samples and out-samples (the transformation is however adjusted based on the in-samples only). Experimental results are appealing in different applications compared to GAN, ResnetGAN, and CycleGAN. 
Here are my major concerns:
- The idea seems to be very general and indeed is applicable to any latent representation learning method, and not just autoencoders. Is there any reason that other more complicated unsupervised representation learning methods were not used for benchmarking in the paper?

- The method heavily relies on the quality of the unsupervised learned representation. How one is guaranteed that the transformation in the learned space be simple and piecewise linear? Shouldn't we consider a regularization method to guide the unsupervised learning more appropriately? 

- The method also implicitly assumes that the same neurons model background and foreground in the in-sample and out-sample data points. How is that guaranteed in practice?</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">6: Marginally above acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></main></div>
  </div>
</div>


    <!-- Footer -->
    <footer class="sitemap">
      <div class="container">
        <div class="row hidden-xs">
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/venues">All Venues</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="/contact">Contact</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
    
        <div class="row visible-xs-block">
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/contact">Contact</a></li>
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
      </div>
    </footer>
    
    <footer class="sponsor">
      <div class="container">
        <div class="row">
          <div class="col-sm-10 col-sm-offset-1">
            <p class="text-center">
              OpenReview is created by the <a href="http://www.iesl.cs.umass.edu/" target="_blank">Information Extraction and Synthesis Laboratory</a>, College of Information and Computer Science, University of Massachusetts Amherst. We gratefully acknowledge the support of the OpenReview sponsors:  Google,  Facebook, NSF, the University of Massachusetts Amherst Center for Data Science, and Center for Intelligent Information Retrieval, as well as the Google Cloud Platform for donating the computing and networking services on which OpenReview.net runs.
            </p>
          </div>
        </div>
      </div>
    </footer>

  <div id="feedback-modal" class="modal fade" tabindex="-1" role="dialog">
    <div class="modal-dialog">
      <div class="modal-content">
        <div class="modal-header">
          <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button>
          <h3 class="modal-title">Send Feedback</h3>
        </div>
        <div class="modal-body">
          <p>Enter your feedback below and we'll get back to you as soon as possible.</p>
          <form action="/feedback" method="POST">
            <div class="form-group">
              <input type="email" name="from" class="form-control" placeholder="Email" />
            </div>
            <div class="form-group">
              <input type="text" name="subject" class="form-control" placeholder="Subject" />
            </div>
            <div class="form-group">
              <textarea name="message" class="form-control feedback-input" rows="5" placeholder="Message" required=""></textarea>
            </div>
          <ul id="ui-id-2" tabindex="0" class="ui-menu ui-widget ui-widget-content" style="display: none;"></ul></form>
        </div>
        <div class="modal-footer">
          <button type="button" class="btn btn-default" data-dismiss="modal">Cancel</button>
          <button type="button" class="btn btn-primary">Send</button>
        </div>
      </div>
    </div>
  </div>

  <script type="text/javascript" async="" src="https://www.google-analytics.com/analytics.js"></script><script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js"></script>
  <script>window.jQuery || document.write('&lt;script src="/static/js/vendor/jquery-2.2.4.min.js"&gt;&lt;\/script&gt;')</script>

  <script src="/static/dist/vendor.min.js"></script>
  <script src="/static/dist/templates.min.js"></script>
  <script src="/static/dist/openreview.min.js"></script>

    <script>window.legacyScripts = true;</script>


    <script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-108703919-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() { dataLayer.push(arguments); }
      gtag('js', new Date());
      gtag('config', 'UA-108703919-1');
    </script>


<div role="status" aria-live="assertive" aria-relevant="additions" class="ui-helper-hidden-accessible"></div></body></html>
<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" class="no-js"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>Stacking for Transfer Learning | OpenReview</title>
  <meta name="description" content="" />

      <meta name="citation_title" content="Stacking for Transfer Learning" />
        <meta name="citation_author" content="Anonymous" />
      <meta name="citation_publication_date" content="2018/09/27" />
      <meta name="citation_online_date" content="2018/09/27" />
      <meta name="citation_pdf_url" content="https://openreview.net/pdf?id=ryxOIsA5FQ" />
      <meta name="twitter:card" content="summary" />
      <meta name="twitter:site" content="@openreviewnet" />
      <meta name="og:title" content="Stacking for Transfer Learning" />
      <meta name="og:description" content="In machine learning tasks, overtting frequently crops up when the number of samples of target domain is insufﬁcient, for the generalization ability of the classiﬁer is poor in this circumstance. To..." />
      <meta name="og:image" content="https://openreview.net/static/images/openreview_logo_512.png" />

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans:400,400i,700,700i" />

  <link rel="stylesheet" href="/static/css/bootstrap.min.css" />
  <link rel="stylesheet" href="/static/css/jquery-ui.min.css" />
  <link rel="stylesheet" href="/static/css/main.min.css" />
</head>

<body class="forum">
  <nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
  
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand home push-link" href="/"><strong>OpenReview</strong>.net</a>
      </div>
  
      <div id="navbar" class="navbar-collapse collapse">
        <form class="navbar-form navbar-left profile-search" role="search">
          <div class="form-group has-feedback">
            <input id="search_input" type="text" class="form-control ui-autocomplete-input" placeholder="Search ICLR 2019 Conference" autocomplete="off" />
            <span class="glyphicon glyphicon-search form-control-feedback" aria-hidden="true"></span>
          </div>
  
          <input id="search_group" type="hidden" value="ICLR.cc/2019/Conference" />
          <input id="search_content" type="hidden" value="all" />
        <ul id="ui-id-1" tabindex="0" class="ui-menu ui-widget ui-widget-content ui-autocomplete ui-front" style="display: none;"></ul></form>
  
        <ul class="nav navbar-nav navbar-right">
        
            <li id="user-menu"><a href="/login">Login</a></li>
        </ul>
      </div>
  
    </div>
  </nav>

  <div id="or-banner" class="banner" style="">
  <div class="container">
    <div class="row">
      <div class="col-xs-12"><a href="/group?id=ICLR.cc/2019/Conference" title="Venue Homepage"><img class="icon" src="/static/images/arrow_left.svg" /> Go to <strong>ICLR 2019 Conference</strong> homepage</a></div>
    </div>
  </div>
</div>
<div id="flash-message-container" class="alert alert-danger" role="alert" style="display: none;">
  <div class="container">
    <div class="row">
      <div class="col-xs-12">
        <div class="alert-content">
          <button type="button" class="close" aria-label="Close"><span aria-hidden="true">×</span></button>
        </div>
      </div>
    </div>
  </div>
</div>

<div class="container">
  <div class="row">
    <div class="col-xs-12">
      <main id="content" class="clearfix openbanner-visible legacy-styles"><div id="note_ryxOIsA5FQ" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Stacking for Transfer Learning</a> <a class="note_content_pdf" href="/pdf?id=ryxOIsA5FQ" title="Download PDF" target="_blank"><img src="/static/images/pdf_icon_blue.svg" /></a> </h2></div><div class="meta_row"><span class="signatures">Anonymous</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">28 Sep 2018 (modified: 11 Oct 2018)</span><span class="item">ICLR 2019 Conference Blind Submission</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span><span class="item"><a class="action-bibtex-modal" data-bibtex="@inproceedings{    &#10;anonymous2019stacking,    &#10;title={Stacking for Transfer Learning},    &#10;author={Anonymous},    &#10;booktitle={Submitted to International Conference on Learning Representations},    &#10;year={2019},    &#10;url={https://openreview.net/forum?id=ryxOIsA5FQ},    &#10;note={under review}    &#10;}">Show Bibtex</a></span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Abstract: </span><span class="note_content_value">In machine learning tasks, overtting frequently crops up when the number of samples of target domain is insufﬁcient, for the generalization ability of the classiﬁer is poor in this circumstance. To solve this problem, transfer learning utilizes the knowledge of similar domains to improve the robustness of the learner. The main idea of existing transfer learning algorithms is to reduce the dierence between domains by sample selection or domain adaptation. However, no matter what transfer learning algorithm we use, the difference always exists and the hybrid training of source and target data leads to reducing ﬁtting capability of the learner on target domain. Moreover, when the relatedness between domains is too low, negative transfer is more likely to occur. To tackle the problem, we proposed a two-phase transfer learning architecture based on ensemble learning, which uses the existing transfer learning algorithms to train the weak learners in the ﬁrst stage, and uses the predictions of target data to train the ﬁnal learner in the second stage. Under this architecture, the ﬁtting capability and generalization capability can be guaranteed at the same time. We evaluated the proposed method on public datasets, which demonstrates the effectiveness and robustness of our proposed method.</span></div><div class="note_contents"><span class="note_content_field">Keywords: </span><span class="note_content_value">data diversiﬁcation, domain adaptation, transfer learning, stacked generalization</span></div><div class="note_contents"><span class="note_content_field">TL;DR: </span><span class="note_content_value">How to use stacked generalization to improve the performance of existing transfer learning algorithms when limited labeled data is available.</span></div><div class="reply_row clearfix"><div class="item" id="reply_count">3 Replies</div></div></div><hr class="small" /><div id="note_children"><div class="note_with_children"><div id="note_BJx9irP76X" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Recommend Reject as the contribution is incremental </a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=ryxOIsA5FQ&amp;noteId=BJx9irP76X"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper186 AnonReviewer3</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">10 Nov 2018</span><span class="item">ICLR 2019 Conference Paper186 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">This paper proposed to solve the instance-based transfer learning and feature-based transfer learning by stacking with a two-phase training strategy. The source data and target data are hybrid together first to train weak learners, and then the ensembled super learner is utilized to get the final prediction. Details for the stacking process are provided. Experimental results on MNIST-USPS, COIL, and Office-Caltech datasets show the proposed method can boost the performance, compared to TrAdaboost. 

Pros:
The paper proposes to using stacking or ensembling to solve the domain adaptation problem, which shows some insight for further domain adaptation research.

Cons:
1. One of the main issues of this paper is the lack of novelty. The framework is incremented from the previous domain adaptation method such as TrAdaboost or BDA. For feature-based transfer learning, Equation (7)(8)(9) directly from the previous method. 
2. Some arguments in this paper are not solid. For example, in the abstract,   the authors claim that under the two-stage training architecture, the fitting capability and generalization capability can be guaranteed at the same time. However, this is not well-justified in the following literature. Another example is "the settings of \lamda and N should be taken into consideration, if \lambda is too large, the performance of each learner can't be guaranteed, if \lambda is too small, training data can't be diversified enough" (page 7line 9~11)
3. This paper is weakened by the experimental part. Firstly, only TraDaboost method is used as a baseline. The paper can be largely improved by comparing with the state-of-the-art ensembling method for domain adaptation, for example:
Self-ensembling for visual domain adaptation, Geoff French,  ICLR 2018.
Secondly, the datasets used in this paper is small-scale and biased. It would be exciting to see how the proposed method will perform on the state-of-the-art large-scale domain adaptation dataset, for example, Office-Home dataset, Syn2Real dataset. 

 Others:
1. Some terminologies used in this paper are confusing: (1) the h_t and c are not defined in Equation (2). in Algorithm 2, how to construct kernel matrix K_t using k_t?   
2. The written of this paper can be largely improved. Some sentences are grammarly mistaken. Typos examples: 
Abstract line 1: overtting -&gt; overfitting
Section 2.1, we use TraAdaboost -&gt; We use TrAdaboost
3. The citation style used in this paper is not correct.

Problems:
1. In section 2.2, what's the difference between the kernel matrix K with the unbiased estimate of MK-MMD (proposed by Gretton, NIPS 2012, also used in Deep adaptation network, Long, et al. ICML2015)?</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">3: Clear rejection</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_rkeGG_6OhX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Recommend rejection of the paper due to the limited contributions and preliminary experiments.</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=ryxOIsA5FQ&amp;noteId=rkeGG_6OhX"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper186 AnonReviewer1</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">02 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper186 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">The authors proposed a stacking method for both instance-based and feature-based transfer learning based on a two-phase strategy. It first introduced some self-defined parameters to diversify the data or the model, and then adopted some existing transfer learning to train the model.

Strength:
1) A stacking method for both instance-based and feature-based transfer learning.

Weakness:
1) Incremental contributions and limited novelty.
2) Some claims are not well supported.
3) Experimental results are preliminary.

The technical contribution of this work is limited. The main difference between the proposed instance-based stacking method and TrAdaboost are twofold: 1) using a self-defined threshold to select a subset of source samples for training; 2) using stacking instead of TrAdaboost to get the final output. The improvements upon TrAdaboost are marginal. Also, for the proposed feature-based stacking method, it just used the different kernel parameter values to diversify the model. The novelty is trivial. 

Several claims in the paper are not well discussed and/or evidence-supported, such as：
1) “When the similarity between domains is low, the final estimator can still achieve good performance on target training set.” 
2) “When source domain is not related enough, stacking performs better.”
3) “We reduce the risk of negative transfer in a simple and effective way without a similarity measure.”
More discussions should be given, for example, how to measure the domain similarity and how to reduce the risk of negative transfer. Also, there are no experimental results to support the claims.

For the evaluation, it is inappropriate to choose Randomforest as the weak leaners since Randomforest is an ensemble method. It is better to give some explanation on how the data distribution and similarity between domains change with the kernel parameters in Figure 5.

For the algorithm comparison, only TrAdaboost is used as the baseline to compare with the proposed instance-based stacking method. The results could be more convincing if some recent ensemble-based transfer learning methods are included for comparison. For the evaluation of the proposed feature-based stacking method, the authors should at least compare their method with BDA since BDA is used as its base algorithm.

Some symbols used in equations are not defined, such as h_t and c in Equation (2).

The paper needs a careful proofreading to correct the grammar errors and typos, such as:
1) Line 1 of page 7: moreover -&gt; Moreover?
2) Line 1 of Abstract: overtting -&gt; overfitting?

In summary, the paper has to make significant improvements before it can meet the bar of ICLR.
</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">4: Ok but not good enough - rejection</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_SkeeJ9ku3Q" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>No technical contributions, a lot of typos and grammar errors</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=ryxOIsA5FQ&amp;noteId=SkeeJ9ku3Q"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper186 AnonReviewer2</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">01 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper186 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">In this paper, the authors proposed to learn a stacked classifier on top of the outputs of well-known transfer learning models for transfer learning. The authors claimed that their proposed solution can avoid negative transfer.

Technically, there are no contributions. The proposed solution is a straight-forward A+B, where both A and B are well-known. Specifically, in the proposed solution, different well-known transfer learning models are used as the 1st level classifiers to generate intermediate outputs, then a stacked classifier is trained with the intermediate outputs as its inputs. Stacking techniques are also well-known in ensemble learning. Therefore, I do not see any new technical ideas. 

Moreover, the proposed solution cannot really avoid negative transfer. If two domains are indeed very different, the performance of the basic transfer learning models would be very bad, e.g., worse than random guess. In this case building a stacked classifier cannot help to boost the final performance. 

The datasets used to conduct experiments are all of toy sizes.

There are a lot of typos and grammar errors. The format of citations in the main text are incorrect. 

In summary, the quality of this paper is far below the standard of top conferences.</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">2: Strong rejection</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></main></div>
  </div>
</div>


    <!-- Footer -->
    <footer class="sitemap">
      <div class="container">
        <div class="row hidden-xs">
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/venues">All Venues</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="/contact">Contact</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
    
        <div class="row visible-xs-block">
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/contact">Contact</a></li>
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
      </div>
    </footer>
    
    <footer class="sponsor">
      <div class="container">
        <div class="row">
          <div class="col-sm-10 col-sm-offset-1">
            <p class="text-center">
              OpenReview is created by the <a href="http://www.iesl.cs.umass.edu/" target="_blank">Information Extraction and Synthesis Laboratory</a>, College of Information and Computer Science, University of Massachusetts Amherst. We gratefully acknowledge the support of the OpenReview sponsors:  Google,  Facebook, NSF, the University of Massachusetts Amherst Center for Data Science, and Center for Intelligent Information Retrieval, as well as the Google Cloud Platform for donating the computing and networking services on which OpenReview.net runs.
            </p>
          </div>
        </div>
      </div>
    </footer>

  <div id="feedback-modal" class="modal fade" tabindex="-1" role="dialog">
    <div class="modal-dialog">
      <div class="modal-content">
        <div class="modal-header">
          <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button>
          <h3 class="modal-title">Send Feedback</h3>
        </div>
        <div class="modal-body">
          <p>Enter your feedback below and we'll get back to you as soon as possible.</p>
          <form action="/feedback" method="POST">
            <div class="form-group">
              <input type="email" name="from" class="form-control" placeholder="Email" />
            </div>
            <div class="form-group">
              <input type="text" name="subject" class="form-control" placeholder="Subject" />
            </div>
            <div class="form-group">
              <textarea name="message" class="form-control feedback-input" rows="5" placeholder="Message" required=""></textarea>
            </div>
          <ul id="ui-id-2" tabindex="0" class="ui-menu ui-widget ui-widget-content" style="display: none;"></ul></form>
        </div>
        <div class="modal-footer">
          <button type="button" class="btn btn-default" data-dismiss="modal">Cancel</button>
          <button type="button" class="btn btn-primary">Send</button>
        </div>
      </div>
    </div>
  </div>

  <script type="text/javascript" async="" src="https://www.google-analytics.com/analytics.js"></script><script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js"></script>
  <script>window.jQuery || document.write('&lt;script src="/static/js/vendor/jquery-2.2.4.min.js"&gt;&lt;\/script&gt;')</script>

  <script src="/static/dist/vendor.min.js"></script>
  <script src="/static/dist/templates.min.js"></script>
  <script src="/static/dist/openreview.min.js"></script>

    <script>window.legacyScripts = true;</script>


    <script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-108703919-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() { dataLayer.push(arguments); }
      gtag('js', new Date());
      gtag('config', 'UA-108703919-1');
    </script>


<div role="status" aria-live="assertive" aria-relevant="additions" class="ui-helper-hidden-accessible"></div></body></html>
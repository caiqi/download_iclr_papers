<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" class="no-js"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>Guiding Physical Intuition with Neural Stethoscopes | OpenReview</title>
  <meta name="description" content="" />

      <meta name="citation_title" content="Guiding Physical Intuition with Neural Stethoscopes" />
        <meta name="citation_author" content="Anonymous" />
      <meta name="citation_publication_date" content="2018/09/27" />
      <meta name="citation_online_date" content="2018/09/27" />
      <meta name="citation_pdf_url" content="https://openreview.net/pdf?id=BylctiCctX" />
      <meta name="twitter:card" content="summary" />
      <meta name="twitter:site" content="@openreviewnet" />
      <meta name="og:title" content="Guiding Physical Intuition with Neural Stethoscopes" />
      <meta name="og:description" content="Model interpretability and systematic, targeted model adaptation present central challenges in deep learning. In the domain of intuitive physics, we study the task of visually predicting stability..." />
      <meta name="og:image" content="https://openreview.net/static/images/openreview_logo_512.png" />

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans:400,400i,700,700i" />

  <link rel="stylesheet" href="/static/css/bootstrap.min.css" />
  <link rel="stylesheet" href="/static/css/jquery-ui.min.css" />
  <link rel="stylesheet" href="/static/css/main.min.css" />
</head>

<body class="forum">
  <nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
  
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand home push-link" href="/"><strong>OpenReview</strong>.net</a>
      </div>
  
      <div id="navbar" class="navbar-collapse collapse">
        <form class="navbar-form navbar-left profile-search" role="search">
          <div class="form-group has-feedback">
            <input id="search_input" type="text" class="form-control ui-autocomplete-input" placeholder="Search ICLR 2019 Conference" autocomplete="off" />
            <span class="glyphicon glyphicon-search form-control-feedback" aria-hidden="true"></span>
          </div>
  
          <input id="search_group" type="hidden" value="ICLR.cc/2019/Conference" />
          <input id="search_content" type="hidden" value="all" />
        <ul id="ui-id-1" tabindex="0" class="ui-menu ui-widget ui-widget-content ui-autocomplete ui-front" style="display: none;"></ul></form>
  
        <ul class="nav navbar-nav navbar-right">
        
            <li id="user-menu"><a href="/login">Login</a></li>
        </ul>
      </div>
  
    </div>
  </nav>

  <div id="or-banner" class="banner" style="">
  <div class="container">
    <div class="row">
      <div class="col-xs-12"><a href="/group?id=ICLR.cc/2019/Conference" title="Venue Homepage"><img class="icon" src="/static/images/arrow_left.svg" /> Go to <strong>ICLR 2019 Conference</strong> homepage</a></div>
    </div>
  </div>
</div>
<div id="flash-message-container" class="alert alert-danger" role="alert" style="display: none;">
  <div class="container">
    <div class="row">
      <div class="col-xs-12">
        <div class="alert-content">
          <button type="button" class="close" aria-label="Close"><span aria-hidden="true">Ã—</span></button>
        </div>
      </div>
    </div>
  </div>
</div>

<div class="container">
  <div class="row">
    <div class="col-xs-12">
      <main id="content" class="clearfix openbanner-visible legacy-styles"><div id="note_BylctiCctX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Guiding Physical Intuition with Neural Stethoscopes</a> <a class="note_content_pdf" href="/pdf?id=BylctiCctX" title="Download PDF" target="_blank"><img src="/static/images/pdf_icon_blue.svg" /></a> </h2></div><div class="meta_row"><span class="signatures">Anonymous</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">28 Sep 2018 (modified: 11 Oct 2018)</span><span class="item">ICLR 2019 Conference Blind Submission</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span><span class="item"><a class="action-bibtex-modal" data-bibtex="@inproceedings{    &#10;anonymous2019guiding,    &#10;title={Guiding Physical Intuition with Neural Stethoscopes},    &#10;author={Anonymous},    &#10;booktitle={Submitted to International Conference on Learning Representations},    &#10;year={2019},    &#10;url={https://openreview.net/forum?id=BylctiCctX},    &#10;note={under review}    &#10;}">Show Bibtex</a></span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Abstract: </span><span class="note_content_value">Model interpretability and systematic, targeted model adaptation present central challenges in deep learning. In the domain of intuitive physics, we study the task of visually predicting stability of block towers with the goal of understanding and influencing the model's reasoning. Our contributions are two-fold. Firstly, we introduce neural stethoscopes as a framework for quantifying the degree of importance of specific factors of influence in deep networks as well as for actively promoting and suppressing information as appropriate. In doing so, we unify concepts from multitask learning as well as training with auxiliary and adversarial losses. Secondly, we deploy the stethoscope framework to provide an in-depth analysis of a state-of-the-art deep neural network for stability prediction, specifically examining its physical reasoning. We show that the baseline model is susceptible to being misled by incorrect visual cues. This leads to a performance breakdown to the level of random guessing when training on scenarios where visual cues are inversely correlated with stability. Using stethoscopes to promote meaningful feature extraction increases performance from 51% to 90% prediction accuracy. Conversely, training on an easy dataset where visual cues are positively correlated with stability, the baseline model learns a bias leading to poor performance on a harder dataset. Using an adversarial stethoscope, the network is successfully de-biased, leading to a performance increase from 66% to 88%.</span></div><div class="note_contents"><span class="note_content_field">Keywords: </span><span class="note_content_value">Deep Learning, Intuitive Physics, Stability Prediction, Adversarial Training, Auxiliary Training, Multi-Task Learning</span></div><div class="note_contents"><span class="note_content_field">TL;DR: </span><span class="note_content_value">Combining auxiliary and adversarial training to interrogate and help physical understanding.</span></div><div class="reply_row clearfix"><div class="item" id="reply_count">6 Replies</div></div></div><hr class="small" /><div id="note_children"><div class="note_with_children"><div id="note_B1lChPhJpQ" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>A well-written paper with limited implication.</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=BylctiCctX&amp;noteId=B1lChPhJpQ"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper473 AnonReviewer3</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">07 Nov 2018</span><span class="item">ICLR 2019 Conference Paper473 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">The paper focuses on the stability prediction task on the ShapeStacks dataset. Specifically, the paper creates a new extension to the dataset, and it proposes the use of "Neural Stethoscopes" framework to analyze deep neural nets' physical reasoning of local stability v.s. global stability. It is shown in the paper neural nets tend to be misled by local stability when the task is to predict global stability. Then the paper utilizes the proposed framework to de-bias the misleading correlation to achieve a state-of-the-art on the dataset.

The paper is very well-written and easy to follow. The main idea is simple and the experiments are detailed. Specifically on the task of stability prediction, it is quite interesting to know that neural nets can be misled by visual cues (local stability).

However, my concern is that the paper focuses only on a very specific application domain,  and an improvement over the niche dataset with much more supervision (from the extension) is not surprising at all. In the mean time, the notion of "Neural Stethoscopes" could be much more  generally applied. Without applications in other domains, it is not immediately clear what the paper's implication is.</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">6: Marginally above acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_HJe-nmVXTQ" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Reply to Reviewer 3</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=BylctiCctX&amp;noteId=HJe-nmVXTQ"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper473 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">10 Nov 2018</span><span class="item">ICLR 2019 Conference Paper473 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Thank you for your review and the overall positive assessment. In particular, we are delighted that you see the potential of the stethoscope framework lending itself to much broader applications. We agree - particularly for applications regarding the interpretability of deep representations as well as the manipulation of biases contained therein. This is a key consideration in our belief that it makes for a valuable contribution to the community. 

We have opted, in this submission, to focus on our primary application domain, which is intuitive physics. In particular, we demonstrate the efficacy of neural stethoscopes in interpreting, promoting and suppressing specific information in the context of the complex interplay between visual clues and physical properties in stability prediction. Our work is primarily motivated by the question as to what extent neural networks learn about physical principles or whether they merely follow visual clues and how we can guide the learning process. We showcase the stethoscope framework here to that effect and, based on its application, provide some interesting and novel [according to Reviewer 1] insights into representations for visual stability prediction.

As regards the implications of the paper, we would like to address this in the context of the reviewerâ€™s comment that increased performance is not surprising given the additional supervision provided. Our submission argues that the manner in which this information is provided really does matter. Figure 6 addresses this point in that multi-task learning fails to leverage the potential of the additional training labels (and, indeed, leads to a detrimental effect, Fig 6b) whereas the stethoscope framework allows the specification of whether the information considered should be promoted or suppressed. This leads to the performance gains shown in Fig 6a.
</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div><div class="note_with_children"><div id="note_SklxtSc93Q" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Preliminary report, the idea could be shaped into a better one</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=BylctiCctX&amp;noteId=SklxtSc93Q"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper473 AnonReviewer2</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">03 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper473 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">This paper combines the global and local stability prediction and tries to get interpretable results using the stethoscope design, which is actually a weighted subbranch for the main branch. There are several concerns regarding the proposed framework. 

1) How to choose \lambda? A better design could be a learnable \lambda. Instead of just one scalar value, it could be better to learn a map of \lambdas, which indicates the distribution of local stability and how it is related to global stability. The visualization of the \lambda map might be more interpretable for understanding the stability prediction. 

2) The global stability prediction does not have a consistent correlation with the local stability prediction, as shown by the easy and hard examples. This complex relationship will confuse the network during the training. That is, the current design hasn't well considered the local and global stability relation, but just simply sum them up. This is hard to provide a meaningful interpretation of the task. 
</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">4: Ok but not good enough - rejection</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">3: The reviewer is fairly confident that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_S1eolmNX6m" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Reply to Reviewer 2</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=BylctiCctX&amp;noteId=S1eolmNX6m"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper473 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">10 Nov 2018</span><span class="item">ICLR 2019 Conference Paper473 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Thank you for your review and we would be delighted to address your concerns, but do require some clarifications.

While a learnable lambda could be considered we would argue that the learning of this parameter beyond the grid-search applied in the submission is somewhat tangential to our primary contribution: a unified framework which lends itself to targeted representation analysis and modification. 

1)
The notion of a map of \lambdas sounds interesting. However, at present, it is not clear to us what this refers to as \lambda is a weighting on a loss term. Clarification would be much appreciated so we can fully engage with this point. As far as the existing approach is concerned, Figure 6 illustrates the influence of \lambda on the accuracy and correlation of global and local stability prediction.

2)
The inconsistent correlations between the two tasks are exactly the scenarios where stethoscopes come into their own: testing positive and negative regimes of lambda (corresponding to auxiliary and adversarial training, respectively) reveals the interplay between the two tasks and potentially allows for de-biasing the algorithm as shown in Figure 6a. Therefore, in contrast to the design not considering these relationships, it explicitly addresses them.

Could you please elaborate on the comment â€™the current design [â€¦] simply sums them upâ€™? The stethoscope module has its own trainable parameters and a separate loss function. Only the encoder shares weights between main and secondary task.
</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div><div class="note_with_children"><div id="note_rJgLrhZq2X" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>nice solid paper</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=BylctiCctX&amp;noteId=rJgLrhZq2X"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper473 AnonReviewer1</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">03 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper473 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">This paper is about using "neural stethoscopes", small complementary neural networks that are added to a main network which with their auxilary loss functions can measure suitability of features or guide the learning process. The idea is incremental to multi-task learning and enable, in a single framework, to validate intermediate features for additional related tasks. Moreover it can promote or suppress the correlation of such features to the tasks related to the main one. The framework is applied to the task of visual stability prediction of block towers. The paper builds upon Groth et al. 2018, adding the concept of local stability as correlated secondary task, used with the proposed neural stethoscopes. Experiments with an extension of ShapeStacks (Groth et al. 2018) dataset where the local stability is added to the global stability class, show that it is possibile increase the performance using the additional task. Moreover, it is shown that neural stethoscopes can suppress nuisance information when using a biased training dataset where the local and global stability are purposely inversely correlated.

Strengths:
+ A very nice paper, well written and easy to read. Figures are helpful and the structure is clear.
+ The concept of neural stethoscope is interesting and simplify the concepts behind multitask learning.
+ Experiments are convincing, interesting and there is some novelty in vision stability prediction.

Weaknesses:
- The novelty is limited related to multitask learning, thus it is an incremental paper.
</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">7: Good paper, accept</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">3: The reviewer is fairly confident that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_HyeOuMN7pm" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Reply to Reviewer 1</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=BylctiCctX&amp;noteId=HyeOuMN7pm"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper473 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">10 Nov 2018</span><span class="item">ICLR 2019 Conference Paper473 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Thank you for your review. We believe it captures the essence of what we are proposing and are delighted with the overall very positive assessment. As regards the weakness mentioned, we accept the characterisation of our work as incremental in the sense that it draws together a number of known techniques from areas such as multi-task and adversarial learning. We argue, however, that the contribution of our submission lies exactly in the unification of these approaches into the stethoscope framework, which lends itself to targeted representation analysis and modification. We showcase stethoscopes to provide insights into a particular application domain, stability prediction in intuitive physics, but believe that the methods presented here will provide a ready toolkit for researchers addressing a variety of challenges in network interpretability and (de)biasing.</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div></div></main></div>
  </div>
</div>


    <!-- Footer -->
    <footer class="sitemap">
      <div class="container">
        <div class="row hidden-xs">
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/venues">All Venues</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="/contact">Contact</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
    
        <div class="row visible-xs-block">
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/contact">Contact</a></li>
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
      </div>
    </footer>
    
    <footer class="sponsor">
      <div class="container">
        <div class="row">
          <div class="col-sm-10 col-sm-offset-1">
            <p class="text-center">
              OpenReview is created by the <a href="http://www.iesl.cs.umass.edu/" target="_blank">Information Extraction and Synthesis Laboratory</a>, College of Information and Computer Science, University of Massachusetts Amherst. We gratefully acknowledge the support of the OpenReview sponsors:  Google,  Facebook, NSF, the University of Massachusetts Amherst Center for Data Science, and Center for Intelligent Information Retrieval, as well as the Google Cloud Platform for donating the computing and networking services on which OpenReview.net runs.
            </p>
          </div>
        </div>
      </div>
    </footer>

  <div id="feedback-modal" class="modal fade" tabindex="-1" role="dialog">
    <div class="modal-dialog">
      <div class="modal-content">
        <div class="modal-header">
          <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">Ã—</span></button>
          <h3 class="modal-title">Send Feedback</h3>
        </div>
        <div class="modal-body">
          <p>Enter your feedback below and we'll get back to you as soon as possible.</p>
          <form action="/feedback" method="POST">
            <div class="form-group">
              <input type="email" name="from" class="form-control" placeholder="Email" />
            </div>
            <div class="form-group">
              <input type="text" name="subject" class="form-control" placeholder="Subject" />
            </div>
            <div class="form-group">
              <textarea name="message" class="form-control feedback-input" rows="5" placeholder="Message" required=""></textarea>
            </div>
          <ul id="ui-id-2" tabindex="0" class="ui-menu ui-widget ui-widget-content" style="display: none;"></ul></form>
        </div>
        <div class="modal-footer">
          <button type="button" class="btn btn-default" data-dismiss="modal">Cancel</button>
          <button type="button" class="btn btn-primary">Send</button>
        </div>
      </div>
    </div>
  </div>

  <script type="text/javascript" async="" src="https://www.google-analytics.com/analytics.js"></script><script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js"></script>
  <script>window.jQuery || document.write('&lt;script src="/static/js/vendor/jquery-2.2.4.min.js"&gt;&lt;\/script&gt;')</script>

  <script src="/static/dist/vendor.min.js"></script>
  <script src="/static/dist/templates.min.js"></script>
  <script src="/static/dist/openreview.min.js"></script>

    <script>window.legacyScripts = true;</script>


    <script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-108703919-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() { dataLayer.push(arguments); }
      gtag('js', new Date());
      gtag('config', 'UA-108703919-1');
    </script>


<div role="status" aria-live="assertive" aria-relevant="additions" class="ui-helper-hidden-accessible"></div></body></html>
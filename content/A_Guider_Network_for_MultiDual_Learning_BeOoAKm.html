<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" class="no-js"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>A Guider Network for Multi-Dual Learning | OpenReview</title>
  <meta name="description" content="" />

      <meta name="citation_title" content="A Guider Network for Multi-Dual Learning" />
        <meta name="citation_author" content="Anonymous" />
      <meta name="citation_publication_date" content="2018/09/27" />
      <meta name="citation_online_date" content="2018/09/27" />
      <meta name="citation_pdf_url" content="https://openreview.net/pdf?id=B1eO9oA5Km" />
      <meta name="twitter:card" content="summary" />
      <meta name="twitter:site" content="@openreviewnet" />
      <meta name="og:title" content="A Guider Network for Multi-Dual Learning" />
      <meta name="og:description" content="A large amount of parallel data is needed to train a strong neural machine translation (NMT) system. This is a major challenge for low-resource languages. Building on recent work on unsupervised..." />
      <meta name="og:image" content="https://openreview.net/static/images/openreview_logo_512.png" />

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans:400,400i,700,700i" />

  <link rel="stylesheet" href="/static/css/bootstrap.min.css" />
  <link rel="stylesheet" href="/static/css/jquery-ui.min.css" />
  <link rel="stylesheet" href="/static/css/main.min.css" />
</head>

<body class="forum">
  <nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
  
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand home push-link" href="/"><strong>OpenReview</strong>.net</a>
      </div>
  
      <div id="navbar" class="navbar-collapse collapse">
        <form class="navbar-form navbar-left profile-search" role="search">
          <div class="form-group has-feedback">
            <input id="search_input" type="text" class="form-control ui-autocomplete-input" placeholder="Search ICLR 2019 Conference" autocomplete="off" />
            <span class="glyphicon glyphicon-search form-control-feedback" aria-hidden="true"></span>
          </div>
  
          <input id="search_group" type="hidden" value="ICLR.cc/2019/Conference" />
          <input id="search_content" type="hidden" value="all" />
        <ul id="ui-id-1" tabindex="0" class="ui-menu ui-widget ui-widget-content ui-autocomplete ui-front" style="display: none;"></ul></form>
  
        <ul class="nav navbar-nav navbar-right">
        
            <li id="user-menu"><a href="/login">Login</a></li>
        </ul>
      </div>
  
    </div>
  </nav>

  <div id="or-banner" class="banner" style="">
  <div class="container">
    <div class="row">
      <div class="col-xs-12"><a href="/group?id=ICLR.cc/2019/Conference" title="Venue Homepage"><img class="icon" src="/static/images/arrow_left.svg" /> Go to <strong>ICLR 2019 Conference</strong> homepage</a></div>
    </div>
  </div>
</div>
<div id="flash-message-container" class="alert alert-danger" role="alert" style="display: none;">
  <div class="container">
    <div class="row">
      <div class="col-xs-12">
        <div class="alert-content">
          <button type="button" class="close" aria-label="Close"><span aria-hidden="true">×</span></button>
        </div>
      </div>
    </div>
  </div>
</div>

<div class="container">
  <div class="row">
    <div class="col-xs-12">
      <main id="content" class="clearfix openbanner-visible legacy-styles"><div id="note_B1eO9oA5Km" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>A Guider Network for Multi-Dual Learning</a> <a class="note_content_pdf" href="/pdf?id=B1eO9oA5Km" title="Download PDF" target="_blank"><img src="/static/images/pdf_icon_blue.svg" /></a> </h2></div><div class="meta_row"><span class="signatures">Anonymous</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">28 Sep 2018 (modified: 11 Oct 2018)</span><span class="item">ICLR 2019 Conference Blind Submission</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span><span class="item"><a class="action-bibtex-modal" data-bibtex="@inproceedings{    &#10;anonymous2019a,    &#10;title={A Guider Network for Multi-Dual Learning},    &#10;author={Anonymous},    &#10;booktitle={Submitted to International Conference on Learning Representations},    &#10;year={2019},    &#10;url={https://openreview.net/forum?id=B1eO9oA5Km},    &#10;note={under review}    &#10;}">Show Bibtex</a></span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Abstract: </span><span class="note_content_value">A large amount of parallel data is needed to train a strong neural machine translation (NMT) system. This is a major challenge for low-resource languages. Building on recent work on unsupervised and semi-supervised methods, we propose a multi-dual learning framework to improve the performance of NMT by using an almost infinite amount of available monolingual data and some parallel data of other languages. Since our framework involves multiple languages and components, we further propose a timing optimization method that uses reinforcement learning (RL) to optimally schedule the different components in order to avoid imbalanced training. Experimental results  demonstrate the validity of our model, and confirm its superiority to existing dual learning methods.</span></div><div class="reply_row clearfix"><div class="item" id="reply_count">3 Replies</div></div></div><hr class="small" /><div id="note_children"><div class="note_with_children"><div id="note_r1lJnkygam" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Review</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=B1eO9oA5Km&amp;noteId=r1lJnkygam"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper547 AnonReviewer2</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">07 Nov 2018</span><span class="item">ICLR 2019 Conference Paper547 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">The paper proposes a guider network which utilized unlabeled monolingual data as an augmentation to the usual dual learning framework to improve NMT performance. Furthermore, a deep Q-learning style scheduling algorithm is proposed to optimize the overall architecture.

The writing of the paper needs a major improvement. As a reviewer, I had a very hard time trying to understand the paper, while the proposed idea turns out to be conceptually simple. A few points regarding the writing:
1) Figure 1 is impossible to understand, especially that zero explanation is given in the caption.
2) Too many unnecessary definitions and acronyms such as ISE, CISE, GLF, GDL, AE etc. Essentially, only the notion of bi-direction attention entropy is relevant for the purpose of the paper. Much effort should have been dedicated to explaining the idea of the of bi-direction attention entropy instead of irrelevant terminologies.
3) No objective function or algorithm description is ever shown.

Technically, I am skeptical about the use of deep Q-learning as a scheduling algorithm. Usually, a Q-net requires training before it can be deployed in an evaluation environment. However, here the paper seems to suggest that the Q-net is trained and deployed together with the NMT architecture in an online fashion. Why use a Q-net in an online setting is beyond my understanding. Ideally, one would choose a truly online algorithm (i.e. UCB for stochastic bandits) in such scenarios, which I believe would work even better than deep Q-learning in practice.</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">4: Ok but not good enough - rejection</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">3: The reviewer is fairly confident that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_rJeSu1F5hQ" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Review</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=B1eO9oA5Km&amp;noteId=rJeSu1F5hQ"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper547 AnonReviewer3</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">03 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper547 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">This paper make two contributions: (1) it propose a new framework for semi-supervised training for NMT by introduce constraint of encoder and decoder states. (2) It apply Q-learning to schedule the updates of different components. I personally highly believe find the relation between encoder and decoder hidden states is a very good direction for utilizing pair data. Model scheduling is also an important problem for multilingual-NMT. 

However,  this paper is very hard to follow. 
1. It has lots of acronyms, e.g. section 3.1. It also try to over-complicated the algorithm and I don't think these acronyms are necessarily to be defined.  
2. It try to link it to information theory but most of study is just empirical (which is fine, but avoid it can simplify the writing and make it more readable), e.g. " According to information theory and the attention mechanism
(Bahdanau et al., 2014), it is clear that we.." I agree with the intuition but how it can be "if and only if"? 
3. It said Figure 2 shows BDE better aligned with BLUE, is there a quantitative measure, e .g. correlation? Or I missed something.
4. What is the NMT network structure?
5. I have trouble to understand "In this process, one monolingual data Si of language i would first be translated to hidden states (ISD) of deci through NMTi , then ISDi is used to reconstruct..." "Guided Dual Learning" part.

The experimental results looks good, especially for low-resource case. But addressing of similarity and comparison with some previous methods could be improved. At least there is simply baseline which use pre-training. Adding some published SOTA results in the table can also help to understand how well it is.

In summary, the paper provide some interesting perspectives. However, it's hard to follow on the algorithm part and lack of relevant baseline.</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">5: Marginally below acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_HkxHWLGthm" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Not easy to follow; experiments not convincing</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=B1eO9oA5Km&amp;noteId=HkxHWLGthm"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper547 AnonReviewer1</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">02 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper547 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">[Summary]
This paper proposes an extension of the dual learning framework, with a guider network and multiple languages included: (1) Each language $i$ has a guider network $GN_i$, that can be used to reconstruct the source sentence from either the output of the encoder or the output of the decoder. (2) Multiple languages are used in this framework, where each language also has a $GN_i$  for guiding the training according to the reconstruction error. The authors work on MultiUN dataset to verify their algorithms.
 
[Clarity]
This work is not easy to follow. My suggestions to revise the paper are shown as follows:
(1) Please use the \begin{equation}…\end{equation} environment to clearly describe your framework and training objectives, with each notation, function and hyper-parameter clearly defined. Actually, I do not find the training objective function in this paper.
Besides, currently, in this paper, there are many undefined notations and typos, for example, (1) in section 3.1, first paragraph, what is the $n$? Then in Eqn.(1) ,what is $N$ and $M$? Also, it is very confusing to use subscripts $i$ and $j$ to distinguish the hidden states from the encoder and decoder. (2) What is the mathematical definition of $ISE_i$? (3) In page 5, 3rd line, “then ISD_i is used to reconstruct Si = GNi(ISE_i , \theta)…” Should the ISE_i be ISD_i?
(2) Please use \begin{algorithm}…\end{algorithm} to tell the readers how your framework works.
 
[Details]
1. The first question is “why this problem”. In the 3rd paragraph of page 1, you mentioned that “However, the best direction to update parameters heavily relies on the quality of sampled translations ... which may be far from real translations Y due to inaccurate translations existing in the sampled ones……” But in practice, dual learning as well as back-translation [ref1] works well for many language pairs. In particular, the dual learning and back-translation works for the unsupervised NMT [ref2], where no labeled data is available. Therefore, I am not fully convinced by this claim and then, the motivation of this work. What’s more, this paper does not work on standard WMT dataset, while previous dual learning and back-translation work on that most commonly used dataset. Therefore, the comparison between the guider network and dual learning are not fair.
2. I am not sure how the BDE in Eqn. (1) is related to the NMT translation quality. Any reference or theoretical/empirical proofs? 
3. It is hard to reproduce such a complex NMT system with NMT, GN and an RL scheduler. Any open-source code or any simple solutions?
4. Do you use a single-layer LSTM or a deep LSTM? Transformer [ref3] is the state-of-the-art NMT system. Why don’t you choose this system? Also, you do not work on WMT dataset to verify your GLF-2L (Table 1). Therefore, I cannot justify whether the proposed algorithm is efficient compared to the current NMT algorithms. I am not convinced by the experimental results.
5. The connection/difference between this work and (Tu et al 2017) should be discussed clearly, and you should implement (Tu et al 2017) as your baseline.  Besides, for the 3-language setting, no multilingual baseline is implemented.
 
[Pros &amp; Cons]
(+) This paper tries to extend dual learning from word level to hidden state level;
(+) Multiple languages are involved in this framework;
(-) Experiments are not convincing; the models are weak; many important baselines are missing; no results on widely used WMT datasets;
(-) The paper is not easy to follow. (See [clarify] part for details);
(-) Training process is a little complex; not easy to implement;
 
References
[ref1] Edunov, Sergey, et al. "Understanding back-translation at scale." EMNLP 2018
[ref2] Lample, Guillaume, et al. "Phrase-Based &amp; Neural Unsupervised Machine Translation." EMNLP 2018
[ref3] Vaswani, Ashish, et al. "Attention is all you need." Advances in Neural Information Processing Systems. 2017.
 </span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">4: Ok but not good enough - rejection</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></main></div>
  </div>
</div>


    <!-- Footer -->
    <footer class="sitemap">
      <div class="container">
        <div class="row hidden-xs">
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/venues">All Venues</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="/contact">Contact</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
    
        <div class="row visible-xs-block">
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/contact">Contact</a></li>
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
      </div>
    </footer>
    
    <footer class="sponsor">
      <div class="container">
        <div class="row">
          <div class="col-sm-10 col-sm-offset-1">
            <p class="text-center">
              OpenReview is created by the <a href="http://www.iesl.cs.umass.edu/" target="_blank">Information Extraction and Synthesis Laboratory</a>, College of Information and Computer Science, University of Massachusetts Amherst. We gratefully acknowledge the support of the OpenReview sponsors:  Google,  Facebook, NSF, the University of Massachusetts Amherst Center for Data Science, and Center for Intelligent Information Retrieval, as well as the Google Cloud Platform for donating the computing and networking services on which OpenReview.net runs.
            </p>
          </div>
        </div>
      </div>
    </footer>

  <div id="feedback-modal" class="modal fade" tabindex="-1" role="dialog">
    <div class="modal-dialog">
      <div class="modal-content">
        <div class="modal-header">
          <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button>
          <h3 class="modal-title">Send Feedback</h3>
        </div>
        <div class="modal-body">
          <p>Enter your feedback below and we'll get back to you as soon as possible.</p>
          <form action="/feedback" method="POST">
            <div class="form-group">
              <input type="email" name="from" class="form-control" placeholder="Email" />
            </div>
            <div class="form-group">
              <input type="text" name="subject" class="form-control" placeholder="Subject" />
            </div>
            <div class="form-group">
              <textarea name="message" class="form-control feedback-input" rows="5" placeholder="Message" required=""></textarea>
            </div>
          <ul id="ui-id-2" tabindex="0" class="ui-menu ui-widget ui-widget-content" style="display: none;"></ul></form>
        </div>
        <div class="modal-footer">
          <button type="button" class="btn btn-default" data-dismiss="modal">Cancel</button>
          <button type="button" class="btn btn-primary">Send</button>
        </div>
      </div>
    </div>
  </div>

  <script type="text/javascript" async="" src="https://www.google-analytics.com/analytics.js"></script><script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js"></script>
  <script>window.jQuery || document.write('&lt;script src="/static/js/vendor/jquery-2.2.4.min.js"&gt;&lt;\/script&gt;')</script>

  <script src="/static/dist/vendor.min.js"></script>
  <script src="/static/dist/templates.min.js"></script>
  <script src="/static/dist/openreview.min.js"></script>

    <script>window.legacyScripts = true;</script>


    <script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-108703919-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() { dataLayer.push(arguments); }
      gtag('js', new Date());
      gtag('config', 'UA-108703919-1');
    </script>


<div role="status" aria-live="assertive" aria-relevant="additions" class="ui-helper-hidden-accessible"></div></body></html>
<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" class="no-js"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>Differentiable Greedy Networks | OpenReview</title>
  <meta name="description" content="" />

      <meta name="citation_title" content="Differentiable Greedy Networks" />
        <meta name="citation_author" content="Anonymous" />
      <meta name="citation_publication_date" content="2018/09/27" />
      <meta name="citation_online_date" content="2018/09/27" />
      <meta name="citation_pdf_url" content="https://openreview.net/pdf?id=r1GaAjRcF7" />
      <meta name="twitter:card" content="summary" />
      <meta name="twitter:site" content="@openreviewnet" />
      <meta name="og:title" content="Differentiable Greedy Networks" />
      <meta name="og:description" content="Optimal selection of a subset of items from a given set is a hard problem that requires combinatorial optimization. In this paper, we propose a subset selection algorithm that is trainable with..." />
      <meta name="og:image" content="https://openreview.net/static/images/openreview_logo_512.png" />

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans:400,400i,700,700i" />

  <link rel="stylesheet" href="/static/css/bootstrap.min.css" />
  <link rel="stylesheet" href="/static/css/jquery-ui.min.css" />
  <link rel="stylesheet" href="/static/css/main.min.css" />
</head>

<body class="forum">
  <nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
  
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand home push-link" href="/"><strong>OpenReview</strong>.net</a>
      </div>
  
      <div id="navbar" class="navbar-collapse collapse">
        <form class="navbar-form navbar-left profile-search" role="search">
          <div class="form-group has-feedback">
            <input id="search_input" type="text" class="form-control ui-autocomplete-input" placeholder="Search ICLR 2019 Conference" autocomplete="off" />
            <span class="glyphicon glyphicon-search form-control-feedback" aria-hidden="true"></span>
          </div>
  
          <input id="search_group" type="hidden" value="ICLR.cc/2019/Conference" />
          <input id="search_content" type="hidden" value="all" />
        <ul id="ui-id-1" tabindex="0" class="ui-menu ui-widget ui-widget-content ui-autocomplete ui-front" style="display: none;"></ul></form>
  
        <ul class="nav navbar-nav navbar-right">
        
            <li id="user-menu"><a href="/login">Login</a></li>
        </ul>
      </div>
  
    </div>
  </nav>

  <div id="or-banner" class="banner" style="">
  <div class="container">
    <div class="row">
      <div class="col-xs-12"><a href="/group?id=ICLR.cc/2019/Conference" title="Venue Homepage"><img class="icon" src="/static/images/arrow_left.svg" /> Go to <strong>ICLR 2019 Conference</strong> homepage</a></div>
    </div>
  </div>
</div>
<div id="flash-message-container" class="alert alert-danger" role="alert" style="display: none;">
  <div class="container">
    <div class="row">
      <div class="col-xs-12">
        <div class="alert-content">
          <button type="button" class="close" aria-label="Close"><span aria-hidden="true">Ã—</span></button>
        </div>
      </div>
    </div>
  </div>
</div>

<div class="container">
  <div class="row">
    <div class="col-xs-12">
      <main id="content" class="clearfix openbanner-visible legacy-styles"><div id="note_r1GaAjRcF7" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Differentiable Greedy Networks</a> <a class="note_content_pdf" href="/pdf?id=r1GaAjRcF7" title="Download PDF" target="_blank"><img src="/static/images/pdf_icon_blue.svg" /></a> </h2></div><div class="meta_row"><span class="signatures">Anonymous</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">28 Sep 2018 (modified: 18 Nov 2018)</span><span class="item">ICLR 2019 Conference Blind Submission</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span><span class="item"><a class="action-bibtex-modal" data-bibtex="@inproceedings{    &#10;anonymous2019differentiable,    &#10;title={Differentiable Greedy Networks},    &#10;author={Anonymous},    &#10;booktitle={Submitted to International Conference on Learning Representations},    &#10;year={2019},    &#10;url={https://openreview.net/forum?id=r1GaAjRcF7},    &#10;note={under review}    &#10;}">Show Bibtex</a></span><a class="note_content_pdf item" href="/revisions?id=r1GaAjRcF7" target="_blank">Show Revisions</a></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Abstract: </span><span class="note_content_value">Optimal selection of a subset of items from a given set is a hard problem that requires combinatorial optimization. In this paper, we propose a subset selection algorithm that is trainable with gradient based methods yet achieves near optimal performance via submodular optimization. We focus on the task of identifying a relevant set of sentences for claim verification in the context of the FEVER task. Conventional methods for this task look at sentences on their individual merit and thus do not optimize the informativeness of sentences as a set. We show that our proposed method which builds on the idea of unfolding a greedy algorithm into a computational graph allows both interpretability and gradient based training. The proposed differentiable greedy network (DGN) outperforms discrete optimization algorithms as well as other baseline methods in terms of precision and recall.</span></div><div class="note_contents"><span class="note_content_field">Keywords: </span><span class="note_content_value">submodular optimization, fact verification, differentiable module, deep unfolding</span></div><div class="note_contents"><span class="note_content_field">TL;DR: </span><span class="note_content_value">We propose a subset selection algorithm that is trainable with gradient based methods yet achieves near optimal performance via submodular optimization.</span></div><div class="reply_row clearfix"><div class="item" id="reply_count">7 Replies</div></div></div><hr class="small" /><div id="note_children"><div class="note_with_children"><div id="note_Skl5TujAaX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Revised version of paper is uploaded.</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=r1GaAjRcF7&amp;noteId=Skl5TujAaX"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper940 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">18 Nov 2018</span><span class="item">ICLR 2019 Conference Paper940 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">We thanks reviewer for the comments and feedback. The paper is revised and updated based on the reviewers' comments. </span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_ByljKffLaQ" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Needs more work</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=r1GaAjRcF7&amp;noteId=ByljKffLaQ"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper940 AnonReviewer4</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">12 Nov 2018</span><span class="item">ICLR 2019 Conference Paper940 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">Synopsis: The paper proposes a neural network based model that integrates a
submodular function. The proposal combines gradient based optimization technique
with submodular framework named `Differentiable Greedy Network' (DGN). The
proposal is focused on retrieval tasks especially directed towards the subtask
of retrieving evidence sentences given a claim on the FEVER dataset. The
proposal involves building a neural network that recursively selects sentences
that support the claim with a greedy algorithm that maximizes the submodular
function. The proposal core of the proposal exploits sums of concave composed
with monotone modular functions (SCMM) and ideas from gumbel-softmax based
literature to build a submodular function. The proposed submodular function has
learnable parameters and the submodular function uses a softmax with a
temperature hyperparameter. The paper shows that the proposal is competitive and
outperfoms a couple of baselines. 

Positives: The paper is well motivated and proposes fairly well grounded
solution. 

Problems: 
* While the paper seems to be well motivated, some of the claims are
justified in a hand-waving manner and could be better justified with either a
more theoretical exposition or empirical analysis. For eg., the utility of ReLU,
while the theoretical justification is clear, how important was the
non-linearity in the entire scheme of DGN? Or the relation to attention
architectures - while the proposed method is superior to simple attentional architectures 
can this be related to decomposable attention [1] or the hierarchical attention architecture[2]?

* Ablation between different families of claims: I suppose the submodular
function is going to be very useful when the number of evidences are more than
two. The paper could have benefitted from ablation between different types of
claims: claims with one/two sentence as evidence vs claims with more than two
sentences as evidences.

* The claim that greedy DGN outperforming conventional discrete opitmization
  algorithms is strong given sparse comparisons to conventional techniques. 

Questions:

* From the experiments in the paper it seems like the temperature is
  a very delicate hyperparameter and the range from $(3, 6)$ seems like the
  function is not close to argmax. Would this mean that the trained model is
  suboptimal? I would also suggest the authors to kindly add the ablations of
  temperature (with annealing) to the appendix. 

* The descriptions of encoder and deepencoder are very confusing. Is the only
  addition to the deep encoder is an additional non-linear layer? In any case,
  Table 2 suggests the deep encoder performs comparably to DGN, apart from the
  problems with class imbalance, given its performance, is it correct to say
  that deepencoder learns robust representations? In other words, the advantages
  of DGN are still not clear. Is the greedy algorithm helping in selecting the
  k sentences? If so, how many of the cases have k&gt;2 and was DGN better there? 

* What happens when the similarity is computed using say euclidean distance?
  How would the temperature hyperparameter change?



Other Issues: 
* The sections in paper need rewriting, especially section 4. 

* Comparisons: it would have been ideal to have the comparisons to attention
  based approaches (simple attention, hierarchical attention) with standard
  optimization techniques. 


[1] Parikh, Ankur P., et al. "A decomposable attention model for natural language inference." arXiv preprint arXiv:1606.01933 (2016).
[2] Yang, Zichao, et al. "Hierarchical attention networks for document classification." Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. 2016.
</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">5: Marginally below acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_ryepqBjR67" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a> Response to Reviewer 4 </a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=r1GaAjRcF7&amp;noteId=ryepqBjR67"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper940 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">18 Nov 2018</span><span class="item">ICLR 2019 Conference Paper940 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Thanks for your feedback.  We provide here a pointwise response to your comments highlighting the changes we have made to  address your concerns and make the paper better.

1) "While the paper seems to be well motivated, some of the claims are justified in a hand-waving manner and could be better justified with either a more theoretical exposition or empirical analysis. For eg., the utility of ReLU, while the theoretical justification is clear, how important was the non-linearity in the entire scheme of DGN? Or the relation to attention architectures - while the proposed method is superior to simple attentional architectures can this be related to decomposable attention [1] or the hierarchical attention architecture[2]?"
    
- We have better explained our decision to use the ReLU in the paper. It is important to the DGN because of the monotonicity requirement of the forward greedy algorithm to maintain the approximation guarantee. We were also motivated by the general stability of ReLU \citep{nair2010rectified}. The DGN has a different way of modeling dependence compared to attention mechanisms. Whereas attention would compare the claim to each sentence in order to capture all semantic facets of of the claim, the SCMM objective for the DGN goes further by modeling the dependence between sentences. The DGN dependence model can even potentially be used in conjunction with attention. 

2) "The claim that greedy DGN outperforming conventional discrete optimization algorithms is strong given sparse comparisons to conventional techniques." 
  
- Top-K and Greedy in Table 1 cover baseline discrete optimizations that we compared against.

3) "From the experiments in the paper it seems like the temperature is a very delicate hyperparameter and the range from $(3, 6)$ seems like the function is not close to argmax. Would this mean that the trained model is suboptimal? I would also suggest the authors to kindly add the ablations of temperature (with annealing) to the appendix." 
			
- We found temperature was very important for training, and there was an apparent trade-off between closely approximating the argmax and the stability of the gradients. Consistent with \citep{Gumbel2017Jang}, we found that higher temperatures decreased the variance of the gradient and led to better performance ( i.e. lower temperatures (i.e. close to zero) cause larger gradients and as a result higher variance and more instability during training. On the other hand, higher temperatures (i.e. larger than 1) result in smaller gradients and stable training but slower.) 
The trained model still maintains its test-time guarantees since it uses an argmax. We have added the temperature annealing experiments to the paper.
            
4) "What happens when the similarity is computed using say euclidean distance? How would the temperature hyperparameter change?"
    
- That would probably motivate the use of a different submodular objective function. In that case, something like facility location that naturally incorporates distances would be a good fit. However, keeping track of pairwise distances for every sentence becomes intractable for large datasets. The temperature hyperparameter has more to do with the greedy procedure itself and less to do with the actual function, though if the submodular objective changes significantly in scale, with a range of [0,100] instead of [0,1], then the temperature would need to be scaled appropriately.
    
5) "The sections in paper need rewriting, especially section 4." 

- We have restructured the paper to be more clear as suggested.
</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div><div class="note_with_children"><div id="note_Syl6mt95nX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Needs major improvement to be acceptable</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=r1GaAjRcF7&amp;noteId=Syl6mt95nX"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper940 AnonReviewer1</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">03 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper940 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">This paper uses a differentiable submodular function to the task of selecting evidence sentences for claims. The paper is not ready to be accepted in a top venue in its current form. Details below.

1) Writing: Needs major work. There are 3.5 pages of introduction and unnecessary background on submodular functions and two paragraphs in sec 3.2 of what the method proposed in this paper does. Only mentioning what the submodular function is, and may be a couple of references for it should have been enough. Proposition 1 is redundant, just mentioning the result in a single sentence is more than enough. I do not see the benefit of talking about a substantial subset of the submodular literature. The intro itself needs major revisions to be readable, there are a lot of holes. e.g. what is "unfolding" of the greedy algorithm that the  authors refer to?  Use of \tau in f() should be explicitly written as an equation, so the reader doesnâ€™t have to look at the paper by Jang et al to know that the exact expression is used in the training. The experimental task itself could have been explained better. What is  the DeepEncoder architecture? Why was it used as a baseline? Why cant diversity arguments not be made by easily altering the DeepEncoder cost function? It may not have been designed to have marginal gains over other selections, and may be selects sentences as standalone evidences. The motivation of the proposed approach is unclear, and warrants a separate point. There are minor typos (e.g. see Table 1 caption  "the recall improves recall "), which could be ignored for now.

2) Motivation: The authors mention "We choose the ReLU function specifically because the submodularity of the SCMM function requires non-negativity ". This is not a suitable reason to design experiments. The guarantees should follow from the function that empirically works best, the functions should not be designed to get some theoretical result and show it works "reasonably well" in practice. The "attention mechanism " motivation is very weak and does not justify the design or the greedy regularization. Why select a subset when the full problem can be tractably solved ? Again this could just be lazy writing. 

3) Empirical evaluation: One task and evaluation does not suggest that the proposed methodology is useful. Even ignoring the holes in writing, a single task and empirical evaluation on one dataset with precision/recall/F1 scores at different k is not evidence that the proposed method is verified. It does not even justify the title. Are there no other baselines that the proposed method could be compared against? This paper is not about "Differentiable Greedy Networks", it is about "greedy evidence selection for verifying claims using Recurrent NN". </span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">2: Strong rejection</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_BJl2CHiRp7" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Response to Reviewer 1</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=r1GaAjRcF7&amp;noteId=BJl2CHiRp7"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper940 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">18 Nov 2018</span><span class="item">ICLR 2019 Conference Paper940 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Thanks for your feedback.  We provide here a pointwise response to your comments highlighting the changes we have made to the paper to address your concerns

1. "Writing:....."
    
- We have reduced our background discussion on submodular functions. However we do feel that some introductory material is warranted to set the context for the rest of the paper.
    
2. " The intro itself needs major revisions to be readable, there are a lot of holes. e.g. what is "unfolding" of the greedy algorithm that the  authors refer to Use of $\tau$ in f() should be explicitly written as an equation, so the reader doesn't have to look at the paper by Jang et al to know that the exact expression is used in the training. "
    
- As recommended we have made the introduction easier to read.
    
3. "What is  the DeepEncoder architecture? Why was it used as a baseline? Why cant diversity arguments not be made by easily altering the DeepEncoder cost function? It may not have been designed to have marginal gains over other selections, and may be selects sentences as standalone evidences. The motivation of the proposed approach is unclear, and warrants a separate point. There are minor typos (e.g. see Table 1 caption  "the recall improves recall "), which could be ignored for now."
    
- We have moved the description of the deep encoder to the experiment section and expanded on the definition and fixed the mentioned typos. We are not sure what you mean by the DeepEncoder cost function question, but since that model is a deep feedforward network, it considers each sentence independently, which we argue is a disadvantage since it treats sentences independently.
    
4. "The authors mention "We choose the ReLU function specifically because the submodularity of the SCMM function requires non-negativity ". This is not a suitable reason to design experiments. The guarantees should follow from the function that empirically works best, the functions should not be designed to get some theoretical result and show it works "reasonably well" in practice. The "attention mechanism " motivation is very weak and does not justify the design or the greedy regularization. Why select a subset when the full problem can be tractably solved? Again this could just be lazy writing. "
    
- The ReLU function is a important part of our algorithm design. We don't restrict baseline methods to be ReLU in order to compare. ReLU is known to be a non-linearity of choice in many recent papers~\cite{nair2010rectified}. The full problem cannot be tractably solved at scale since all subsets need to be considered and this can get prohibitively large. Furthermore, it would be both prohibitively expensive and counterproductive to use every sentence as evidence from a large dataset in a recognizing textual entailment task.
    
5. "Empirical evaluation: One task and evaluation does not suggest that the proposed methodology is useful. Even ignoring the holes in writing, a single task and empirical evaluation on one dataset with precision/recall/F1 scores at different k is not evidence that the proposed method is verified. It does not even justify the title. Are there no other baselines that the proposed method could be compared against? This paper is not about "Differentiable Greedy Networks", it is about "greedy evidence selection for verifying claims using Recurrent NN". 
    
- Thank you for the feedback. Experimental results on diverse tasks will help to make our claims stronger.</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div><div class="note_with_children"><div id="note_HyepNcyenX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Incremental method of applying greedy algorithm to the outputs of a shallow network, without strong support from experimental comparisons</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=r1GaAjRcF7&amp;noteId=HyepNcyenX"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper940 AnonReviewer3</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">26 Oct 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper940 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">This paper proposes a neural network that aims to select a subset of elements, for example, selecting k sentences that are mostly related to a claim from a set of retrieved docs. It firstly computes a multi-dimensional similarity score vector per element. The proposed network, DGN, takes the score vectors of all the candidates as inputs, processes them by linear+ReLU, and then runs the forward greedy algorithm maximizing a submodular function, which selects a subset of score vectors. The submodular function is defined as a weighted sum of multiple submodular functions, each corresponding to a dimension of the score vector, and is a concave function of the sum of the selected elements' scores on that dimension. The weights used to produce the weighted sum are learnable parameters of the submodular function. They show that DGN outperforms some baseline methods on FEVER dataset. 

Major concerns:

1) The idea is incremental: it applies the greedy algorithm to the outputs of a Linear+ReLU layer, whose inputs are the pre-computed similarity scores. Unfolding the greedy algorithm produces a simple RNN with each unit computing the marginal gain conditioned on the previously selected elements (the previous state), but it does not increase the depth and thus does not improve representativeness. 

2) Since the transformation applied to the input similarity scores is linear, it might not be very helpful and the final performance might largely depend on the quality of the similarity metric used to compute the input scores. In addition, the idea of learning the weights in a submodular function has been studied in many previous works such as learning submodular mixture and deep submodular functions, and the idea can be applied to more general submodular functions rather than the specific one used in this paper. Hence, the contribution and novelty of this paper are very limited.

3) During training, softmax is used to approximate argmax and make the computational graph differentiable. Why not using Gumbel-softmax (which was studied in the paper that the authors cited to support their use of softmax here), which is a better approximation of argmax? In addition, the differentiability comes from using softmax, but this makes the training not exactly optimizing for the original greedy algorithm but a soft version of it.

4) None of any previous works has been compared in the experiments except baselines created by the authors. At least, attention-based models and RNN such as Transformer and LSTM should be compared, since the proposed model is similar to them on some main ideas: it can be explained as an attention mechanism using the marginal gain of the submodular function as the attention score function; and it can be also explained as an unfolded simple RNN.

5) In experiments, the proposed DGN has the same performance or shows slight advantages when comparing to "Encoder", which does not use any greedy procedure at all. Does this suggest that the greedy procedure is not necessary?

Minor comments:

1) Proposition 1 had already been proved in classical submodular textbooks.

2) Is the ground truth labels L in Eq.(5) a subset (as defined above the equation) or a subsequence (as indexed in the equation)? Which one provides better training signals?</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">4: Ok but not good enough - rejection</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_Hyg9RIjRpX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Response to Reviewer 3</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=r1GaAjRcF7&amp;noteId=Hyg9RIjRpX"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper940 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">18 Nov 2018</span><span class="item">ICLR 2019 Conference Paper940 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Thanks for your feedback.  We provide here a pointwise response to your comments highlighting the changes we have made to address your concerns and make the paper better.

1) "The idea is incremental: it applies the greedy algorithm to the outputs of a Linear+ReLU layer, whose inputs..."

- The approach is generally applicable to a number of discrete optimization algorithms and discrete objective functions. With respect to RNNs, the unfolding process is not sensitive to order like a RNN architecture. The proposed technique does not increase depth but is targeted towards better sentence selection via a submodular loss function. Moreover, from the unfolding perspective, we can start untying the layers and make deep networks that are inspired by greedy optimization.


2) "In addition, the idea of learning the weights in a submodular function has been studied in many previous works such as learning submodular mixture and deep submodular functions, and the idea can be applied to more general submodular functions rather than the specific one used in this paper. Hence, the contribution and novelty of this paper are very limited."

- The difference between our approach and approaches like deep submodular functions is that we learn the parameters of a function through the optimization algorithm itself. Our approach can be applied to arbitrary submodular functions such as a deep submodular function \cite{BilmesB17}, not just the SCMM we used for our experiments because the point is that we are unfolding the inference algorithm, the forward greedy algorithm in this case, which itself can be used to optimize many different discrete functions. \citep{sipos2012} and \citep{tschiatschek2018differentiable} are more similar to our approach, though the model proposed by \citep{sipos2012} learns the weights of the function in a structured support vector machine framework, and the algorithms used by \citep{tschiatschek2018differentiable} rely on probabilistic algorithms. 
 
3) "During training, softmax is used to approximate argmax and make the computational graph differentiable. Why not using Gumbel-softmax (which was studied in the paper that the authors cited to support their use of softmax here), which is a better approximation of argmax? In addition, the differentiability comes from using softmax, but this makes the training not exactly optimizing for the original greedy algorithm but a soft version of it."

- We agree that in the general case Gumbel-softmax should help but for our particular data set with very few valid claims it didn't improve results. Gumbel-softmax is stochastic on the forward pass, so it is not suitable for using at test-time. Also, yes, the softmax is a necessary side effect of making it differentiable, and the reason we explored the effect of softmax temperatures. Lower temperatures (i.e. close to zero) cause larger gradients and as a result higher variance and more instability during training. On the other hand, higher temperatures (i.e. larger than 1) result in smaller gradients and stable training but slower. 

4) "None of any previous works has been compared in the experiments except baselines created by the authors. At least, attention-based models and RNN such as Transformer and LSTM..."

- The main focus of this work is to introduce this new optimization scheme rather than focus on a complex model for sentence retrieval. More complex models such as Transformer can potentially improve the sentence selection itself but they don't address the problem of selecting the right \it{set} of sentences.

5) "In experiments, the proposed DGN has the same performance or shows slight advantages when comparing to "Encoder", which does not use any greedy procedure at all..."

- The DGN maintains some other advantages, like its robustness to class imbalances, and that it can directly model inter-sentence dependencies. We suspect that the close gap in performance is in part due to the fact most of the claims in the dataset have one or two evidence sentences per claim.

6) "Proposition 1 had already been proved in classical submodular textbooks."

- Yes, it was not intended as a new result. We provided it for completeness, but have moved it to the appendix.

7) "Is the ground truth labels L in Eq.(5) a subset (as defined above the equation) or a subsequence (as indexed in the equation)? Which one provides better training signals?"
    
- The labels are evaluated in sequence, since at each iteration the greedy algorithm conditions choices on the choice from the previous iteration. We did train apply shuffling to the labels while training, which in theory should help, but did not.</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div></div></main></div>
  </div>
</div>


    <!-- Footer -->
    <footer class="sitemap">
      <div class="container">
        <div class="row hidden-xs">
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/venues">All Venues</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="/contact">Contact</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
    
        <div class="row visible-xs-block">
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/contact">Contact</a></li>
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
      </div>
    </footer>
    
    <footer class="sponsor">
      <div class="container">
        <div class="row">
          <div class="col-sm-10 col-sm-offset-1">
            <p class="text-center">
              OpenReview is created by the <a href="http://www.iesl.cs.umass.edu/" target="_blank">Information Extraction and Synthesis Laboratory</a>, College of Information and Computer Science, University of Massachusetts Amherst. We gratefully acknowledge the support of the OpenReview sponsors:  Google,  Facebook, NSF, the University of Massachusetts Amherst Center for Data Science, and Center for Intelligent Information Retrieval, as well as the Google Cloud Platform for donating the computing and networking services on which OpenReview.net runs.
            </p>
          </div>
        </div>
      </div>
    </footer>

  <div id="feedback-modal" class="modal fade" tabindex="-1" role="dialog">
    <div class="modal-dialog">
      <div class="modal-content">
        <div class="modal-header">
          <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">Ã—</span></button>
          <h3 class="modal-title">Send Feedback</h3>
        </div>
        <div class="modal-body">
          <p>Enter your feedback below and we'll get back to you as soon as possible.</p>
          <form action="/feedback" method="POST">
            <div class="form-group">
              <input type="email" name="from" class="form-control" placeholder="Email" />
            </div>
            <div class="form-group">
              <input type="text" name="subject" class="form-control" placeholder="Subject" />
            </div>
            <div class="form-group">
              <textarea name="message" class="form-control feedback-input" rows="5" placeholder="Message" required=""></textarea>
            </div>
          <ul id="ui-id-2" tabindex="0" class="ui-menu ui-widget ui-widget-content" style="display: none;"></ul></form>
        </div>
        <div class="modal-footer">
          <button type="button" class="btn btn-default" data-dismiss="modal">Cancel</button>
          <button type="button" class="btn btn-primary">Send</button>
        </div>
      </div>
    </div>
  </div>

  <script type="text/javascript" async="" src="https://www.google-analytics.com/analytics.js"></script><script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js"></script>
  <script>window.jQuery || document.write('&lt;script src="/static/js/vendor/jquery-2.2.4.min.js"&gt;&lt;\/script&gt;')</script>

  <script src="/static/dist/vendor.min.js"></script>
  <script src="/static/dist/templates.min.js"></script>
  <script src="/static/dist/openreview.min.js"></script>

    <script>window.legacyScripts = true;</script>


    <script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-108703919-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() { dataLayer.push(arguments); }
      gtag('js', new Date());
      gtag('config', 'UA-108703919-1');
    </script>


<div role="status" aria-live="assertive" aria-relevant="additions" class="ui-helper-hidden-accessible"></div></body></html>
<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" class="no-js"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>Overcoming Catastrophic Forgetting  via Model Adaptation | OpenReview</title>
  <meta name="description" content="" />

      <meta name="citation_title" content="Overcoming Catastrophic Forgetting  via Model Adaptation" />
        <meta name="citation_author" content="Anonymous" />
      <meta name="citation_publication_date" content="2018/09/27" />
      <meta name="citation_online_date" content="2018/09/27" />
      <meta name="citation_pdf_url" content="https://openreview.net/pdf?id=ryGvcoA5YX" />
      <meta name="twitter:card" content="summary" />
      <meta name="twitter:site" content="@openreviewnet" />
      <meta name="og:title" content="Overcoming Catastrophic Forgetting  via Model Adaptation" />
      <meta name="og:description" content="Learning multiple tasks sequentially is important for the development of AI and lifelong learning systems. However, standard neural network architectures suffer from catastrophic forgetting which..." />
      <meta name="og:image" content="https://openreview.net/static/images/openreview_logo_512.png" />

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans:400,400i,700,700i" />

  <link rel="stylesheet" href="/static/css/bootstrap.min.css" />
  <link rel="stylesheet" href="/static/css/jquery-ui.min.css" />
  <link rel="stylesheet" href="/static/css/main.min.css" />
</head>

<body class="forum">
  <nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
  
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand home push-link" href="/"><strong>OpenReview</strong>.net</a>
      </div>
  
      <div id="navbar" class="navbar-collapse collapse">
        <form class="navbar-form navbar-left profile-search" role="search">
          <div class="form-group has-feedback">
            <input id="search_input" type="text" class="form-control ui-autocomplete-input" placeholder="Search ICLR 2019 Conference" autocomplete="off" />
            <span class="glyphicon glyphicon-search form-control-feedback" aria-hidden="true"></span>
          </div>
  
          <input id="search_group" type="hidden" value="ICLR.cc/2019/Conference" />
          <input id="search_content" type="hidden" value="all" />
        <ul id="ui-id-1" tabindex="0" class="ui-menu ui-widget ui-widget-content ui-autocomplete ui-front" style="display: none;"></ul></form>
  
        <ul class="nav navbar-nav navbar-right">
        
            <li id="user-menu"><a href="/login">Login</a></li>
        </ul>
      </div>
  
    </div>
  </nav>

  <div id="or-banner" class="banner" style="">
  <div class="container">
    <div class="row">
      <div class="col-xs-12"><a href="/group?id=ICLR.cc/2019/Conference" title="Venue Homepage"><img class="icon" src="/static/images/arrow_left.svg" /> Go to <strong>ICLR 2019 Conference</strong> homepage</a></div>
    </div>
  </div>
</div>
<div id="flash-message-container" class="alert alert-danger" role="alert" style="display: none;">
  <div class="container">
    <div class="row">
      <div class="col-xs-12">
        <div class="alert-content">
          <button type="button" class="close" aria-label="Close"><span aria-hidden="true">×</span></button>
        </div>
      </div>
    </div>
  </div>
</div>

<div class="container">
  <div class="row">
    <div class="col-xs-12">
      <main id="content" class="clearfix openbanner-visible legacy-styles"><div id="note_ryGvcoA5YX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Overcoming Catastrophic Forgetting  via Model Adaptation</a> <a class="note_content_pdf" href="/pdf?id=ryGvcoA5YX" title="Download PDF" target="_blank"><img src="/static/images/pdf_icon_blue.svg" /></a> </h2></div><div class="meta_row"><span class="signatures">Anonymous</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">28 Sep 2018 (modified: 11 Oct 2018)</span><span class="item">ICLR 2019 Conference Blind Submission</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span><span class="item"><a class="action-bibtex-modal" data-bibtex="@inproceedings{    &#10;anonymous2019overcoming,    &#10;title={Overcoming Catastrophic Forgetting  via Model Adaptation},    &#10;author={Anonymous},    &#10;booktitle={Submitted to International Conference on Learning Representations},    &#10;year={2019},    &#10;url={https://openreview.net/forum?id=ryGvcoA5YX},    &#10;note={under review}    &#10;}">Show Bibtex</a></span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Abstract: </span><span class="note_content_value">Learning multiple tasks sequentially is important for the development of AI and lifelong learning systems. However, standard neural network architectures suffer from catastrophic forgetting which makes it difficult to learn a sequence of tasks. Several continual learning methods have been proposed to address the problem. In this paper, we propose a very different approach, called model adaptation, to dealing with the problem. The proposed approach learns to build a model, called the solver, with two sets of parameters. The first set is shared by all tasks learned so far and the second set is dynamically generated to adapt the solver to suit each individual test example in order to classify it. Extensive experiments have been carried out to demonstrate the effectiveness of the proposed approach.</span></div><div class="reply_row clearfix"><div class="item" id="reply_count">9 Replies</div></div></div><hr class="small" /><div id="note_children"><div class="note_with_children"><div id="note_r1gH2AauTm" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>paper needs major revision to improve clarity and empirical validation</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=ryGvcoA5YX&amp;noteId=r1gH2AauTm"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper542 AnonReviewer2</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">14 Nov 2018</span><span class="item">ICLR 2019 Conference Paper542 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">This paper proposes a method for continual learning. The model has three components: a) a data generator to be used at training time to replay past examples, b) a parameter generator that takes the input observation to produce parameters for c) the actual classifier. The authors demonstrate the method on simple datasets with a stream of 2 or 3 tasks.

Strenghts:
- the combination of components is novel
- the method does not rely on task descriptors neither at training nor test time
Weaknesses:
- the paper needs a major rewrite to improve fluency and to better organize and describe the proposed approach
- the empirical validation is weak.

Relevance
Learning in a continual setting is certainly very relevant for this venue.

Novelty
While each component is by itself not very novel (replay methods for continual learning have already been used, networks predicting parameters have also become a fairly common approach in meta-learning literature), the proposed combination is novel in this sub-field.

Clarity
Clarity is very poor and definitely does not meet the acceptance bar for this conference. I believe that the authors would need to make a major revision to address this issue. While ICLR allows authors to revise papers, I think the revision needed to fix this draft goes beyond the acceptable limit, as reviewers would then need to make a whole new revision.
First, fluency is very poor. There are lots of grammatical errors (see first sentence of introduction "neural networks suffers.."),  a plethora of un-necessary acronyms which force the reader to go back and forth to figure out what they refer to (MA, DG, DPG, DPG&amp;S, ...), and several sentences are not well formed (e.g., read first sentence of introduction).
Second, some statements are contradictory; e.g., the authors define "basic unit" as "simple MLP with one hidden layer", but then say it "is an activation function plus a matrix transformation"..
Third, graphics and formulas are too small and not legible.
Fourth, the organization of the paper is poor, it is very wordy yet vague. For instance, the authors should precisely describe how the data generator is trained in sec. 2.3. The authors should provide an algorithm summarizing how the different components interplay both at training and test time. At present, I am making educated guesses about how this system works.
For instance, how are real and generated examples interleaved? how is forgetting prevented in the data generator?   

References to prior work
While there are lots of references in sec. 4, they are not sufficiently well described - see third paragraph of sec. 4 where the authors cite almost 20 papers by simply saying they are "some other approaches". 
Also, I did not find mention to methods predicting parameters in the meta-learning community but also others like:
Denil et al. "Predicting network parameters in deep learning" NIPS 2013
 
Empirical validation
The empirical evaluation does show an advantage of the proposed approach on some simple streams composed by up to three tasks. However, a) the tasks are really simple because of the small number of tasks considered and b) the baselines are weak. For instance, EWC is now a bit out-dated as there are variants that work a bit better, like:
Chaundry et al. "Riemannian Walk ..." ECCV 2018
and there are other methods like "Progress and Compress" Schwartz ICML 2018 the authors could have compared against.
Besides, the authors do not mention anything about memory and time cost both at training and test time, possibly including the time to cross validate all the hyper-parameters of this method.
Overall, I am left with the sense that the proposed approach will be hard to scale to many more tasks and more realistic images (for which we do not quite know how to train efficiently and well generators).

Other comments
I did not find the formalization in eq. 9 very useful. The first and last term in that equation can be very big and there is no sense of how lose this bound is.
Also, it is not clear whether there is a general principle to partition the set of parameters (to determine which ones should be shared).</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">4: Ok but not good enough - rejection</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_SylEV_-3TQ" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Thank you for your comments.</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=ryGvcoA5YX&amp;noteId=SylEV_-3TQ"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper542 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">16 Nov 2018 (modified: 17 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper542 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Thank you for your comments. We are happy to discuss to clear some confusions. Below, we respond to each of your comments. We appreciate your further feedback.

1.	Re: “While ICLR allows authors to revise papers, I think the revision needed to fix this draft goes beyond the acceptable limit, as reviewers would then need to make a whole new revision.”

That is sad. It seems you will ignore our response and won’t reconsider your decision. The clarity issue that you mentioned is not difficult to address. We will improve the organization of the paper to make everything clearer. 

2.	Re: “the tasks are really simple because of the small number of tasks considered”

We used the same setting in terms of the number of tasks as the previous works (EWC and IMM) for easy comparison. We have just conducted additional experiments on 5 tasks. Here are the results. 
(1) On shuffled MNIST, the accuracy of GR is 94.536, the accuracy of IMM is 96.088, and the accuracy of our MA is 96.774 (GR and IMM are the best baselines, see Table 2). 
(2) On disjoint MNIST (2 classes per task), the accuracy of GR is 75.473, the accuracy of IMM is 67.250, and the accuracy of our MA is 81.700.
(3) On disjoint DBPedia (3,3,3,3,2 classes in the 5 tasks), the accuracy of GR is 63.714, the accuracy of IMM is 64.040, and the accuracy of our MA is 69.680. As you can see, our method is still markedly better than the baselines.

3.	Re: “the baselines are weak. For instance, EWC is now a bit out-dated as there are variants that work a bit better” 

EWC is indeed an early system, but it is used as a baseline by most papers on continual learning including "Progress and Compress" Schwartz ICML 2018. Please notice that we have not only compared with EWC. IMM and GR are not weak or out-dated baselines.  Also, we will compare those papers you recommended, thanks.

4.	Re: “the authors do not mention anything about memory and time cost both at training and test time, possibly including the time to cross validate all the hyper-parameters of this method.”

Memory
1)	The memory used by our model is around 151.49MB, by IMM is around 38.96MB * task_num (task_num will be 3 if there are three tasks), and by GR is around 70.13MB. The memory required by all these systems are very small as compared to the total memory available in a modern computer.
2)	Furthermore, our data generator DG has around 1,460,361 parameters, which is fixed. Saving data would need much more memory. Taking the MNIST dataset as an example. It has 60,000 training samples and the size of each sample is 28*28. The memory needed to store the data is 28*28*60,000 = 47,040,000. And this number multiplies when the number of tasks increases.

Training and Test time
Taking the CIFAR10 dataset as an instance (others are similar), the total time used by our model and baselines are shown below. We can see that our method needs a bit more time than baselines but not too much (under 25% for training and under 28% for testing compared with GR)  

                                        Time      |      IMM     |      GR     |      Ours
----------------------------------------------------------------------------------------------
Training Time/per epoch (s)     |      4.93      |    8.673  |    10.836
----------------------------------------------------------------------------------------------
                             Test time(s）   |     0.707     |    0.728  |     0.930 

We did not give the memory and time costs in the paper as existing papers on the topic generally do not give such numbers. 

5.	Re: “it is not clear whether there is a general principle to partition the set of parameters (to determine which ones should be shared).”

Based to our ablation experiments (see Table 3), replacing any portion of the parameters (20%, 40% …) in our model outperforms the baselines. Cross validation can be used to find the best partition. 
</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div><div class="note_with_children"><div id="note_H1eXILQeaX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>why dynamic parameter generator works ?</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=ryGvcoA5YX&amp;noteId=H1eXILQeaX"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">(anonymous)</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">07 Nov 2018</span><span class="item">ICLR 2019 Conference Paper542 Public Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Comment: in section 2.4 question2, authors said " If X0 k is a row low rank matrix, w∗i,k can be trained to ﬁt the new tasks. Otherwise, especially if X0 k is a row full rank matrix, w∗i,k cannot be trained and therefore cannot learn new tasks. However, beneﬁting from dynamic parameter generation, our approach will not suffer from this problem. "

 I could not understand this well. In my understanding  w∗i,k is generated from DPG parameters, when the X matrix is full rank, the author said that  w∗i,k can not be trained , why the parameters which used to generate w∗i,k  can be trained ? Thanks.</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_ryeOkVsg67" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Thanks for your interest in our paper and a good question.</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=ryGvcoA5YX&amp;noteId=ryeOkVsg67"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper542 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">08 Nov 2018</span><span class="item">ICLR 2019 Conference Paper542 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">It is the adaptability of our model on different tasks that avoids the issue you quoted. Please see formula 8 and the explanation for question 2 in the paper. The stacked X denotes the input of the layer where the constraints are used,
and w∗i,k cannot be changed if X is a row full rank matrix; otherwise formula 8 will get a huge loss and the w∗i,k learned from old tasks cannot be trained to fit the new samples without forgetting. However, in our model, a part of w∗i,k is generated by DPG, which means that each sample from a different task has a different w∗i,k. In that case, we can train DPG such that without w∗i,k for samples from old tasks being changed, the new task can still be learned because its samples get their own w∗i,k’s. In other words, constraints on w∗i,k for samples from old tasks won't interfere with the training of w∗i,k in the new task.

If you still have any doubts, please feel free to tell us.
Thanks again.</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div><div class="note_with_children"><div id="note_r1xJTLFtnQ" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Unclear description of algorithm, experiments could be improved. </a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=ryGvcoA5YX&amp;noteId=r1xJTLFtnQ"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper542 AnonReviewer3</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">02 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper542 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">Summary: 
- In this paper, an algorithm to improve the catastrophic forgetting of the model is proposed. The key idea consists of 1) introducing the dynamic parameter generator (DPG) for "model's adaptation" to data at test time and 2) data generator (DG) for remembering previously trained dataset. 

Pros: 
- Empirical results seem strong. The proposed result outperforms existing algorithms by quite large margin.

Cons:
- In general, I felt that the paper is unorganized and hard to read. Clarity should be definitely improved if this paper is to be published as a conference paper.

- Output of dynamic parameter generator is very high dimensional (it requires weight with dimension of input dim x NN weight dim). I think this approach is not scalable to higher dimension and typically requires even more memory than storing the whole dataset. 

- Although auto-encoder and generative replay was considered to reduce memory consumption, there is no description of how much memory is saved by them. In order to make the argument more convincing, the authors should explicitly describe the amount of memory consumed by each algorithms. 

- There seems to be a lot of ideas introduced, i.e, DPG for generation of weights, auto-encoders for generation of data and layer output constraint, i.e., Equation (7).  I think each of introduced method deserves some amount of empirical evaluation to validate its contribution to the performance.  

- Experiments only consider 2~3 tasks, which does not seem very representative for the lifelong learning tasks.
</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">5: Marginally below acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">3: The reviewer is fairly confident that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_SylAVCLE6m" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Thank you for your comments. </a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=ryGvcoA5YX&amp;noteId=SylAVCLE6m"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper542 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">10 Nov 2018</span><span class="item">ICLR 2019 Conference Paper542 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Thank you for your comments. We apologize for the slow response as one of the authors is traveling. 
We are happy to discuss to clear some confusions. Below, we respond to each of your comments. We appreciate your further feedback. 

1.	Re: "the paper is unorganized and hard to read”

We will improve the organization of the paper to make everything clearer. 

2. Re: "Output of dynamic parameter generator is very high dimensional"

If we generate all the parameters in the model, the output will be very high dimensional. However, there is no need to generate all the parameters. We show that it suffices to generate and replace only the parameters in the last layer, which is very low dimensional (e.g., in our MNIST experiment setting, the dimension is around 200*60). We discuss this operation in equation 4 and its context. Table 3 also shows that our approach can achieve very good results by only replacing a portion of the parameters of the last layer.

3. Re: "description of how much memory is saved"

Saving data would need much more memory. Taking the MNIST dataset as an example. It has 60,000 training samples and the size of each sample is 28*28. The memory needed to store the data is 28*28*60,000 = 47,040,000. This number multiplies when the number of tasks increases, while our DG has only around 1,460,361 parameters, which is fixed. 

4. Re: "each of introduced method deserves some amount of empirical evaluation"

Thank you for pointing out that. The third column in Table 3 (our model replacing 0% parameters) can be regarded as removing the DPG in our model. We can see a significant drop compared with the seventh column (replacing 80% parameters), which shows the effectiveness of DPG. The third column in Table 3 shows the performance of our model when only DG and constraints are used. We have conducted a new experiment for our model without using constraints (DG+label(like GR)) but replacing them with the replay method (which needs to predict the labels as we discussed in the third paragraph to the last in Section 1). We get the accuracy of 0.8821 ± 0.0281, which is poorer than DG+Constraint (90.96±0.69) and DPG+DG+Constraints (96.07±0.62). For DG, we can’t remove it because our method won’t work without it.

5. Re: "Experiments only consider 2~3 tasks".

We used the same setting in terms of the number of tasks as the previous works (EWC and IMM) for easy comparison. We have just conducted additional experiments on 5 tasks. Here are the results. (1) On shuffled MNIST, the accuracy of GR is 94.536, the accuracy of IMM is 96.088, and the accuracy of our MA is 96.774 (GR and IMM are the best baselines, see Table 2). (2) On disjoint MNIST (2 classes per task), the accuracy of GR is 75.473, the accuracy of IMM is 67.250, and the accuracy of our MA is 81.700. (3) On disjoint DBPedia (3,3,3,3,2 classes in the 5 tasks), the accuracy of GR is 63.714, the accuracy of IMM is 64.040, and the accuracy of our MA is 69.680. As you can see, our method is still markedly better than the baselines. 
</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_B1gUCH7gT7" class="note panel trashed"><div class="title_pdf_row clearfix"><h2 class="note_content_title">  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=ryGvcoA5YX&amp;noteId=B1gUCH7gT7"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">[Deleted]</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="item">ICLR 2019 Conference Paper542 Public Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div><div class="note_with_children"><div id="note_SJxhhsOmhm" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Interesting ideas and results. Needs improvement in writing, formalization and possibly more ablation studies.</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=ryGvcoA5YX&amp;noteId=SJxhhsOmhm"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper542 AnonReviewer1</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">29 Oct 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper542 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">This paper proposes a Dynamic Parameter Generator (DPG) that given a test input modifies the parameters of a classification model. They also propose to regularize the training using a Data Generator (DG) to slow down catastrophic forgetting. DG is used to constrain the training that the internal representations of data generated by DG does not rapidly change. DG removes the need for storage of data or labels.

Positives:
- Both ideas of DPG and DG are novel in preventing catastrophic forgetting.
- DG is novel because it does not require storage of data and does not depend on labels.
- Experimental results are significantly better than the previous state-of-the-art.

Suggestions and clarification requests:
- Figures are very small and equations are cramped because of reduced spacing.
- There are some vague explanations in the intro that could be reduced. It would be nice to first introduce concrete math then give the intuitions. That saves some space.
- It would nice to compare to the recent Progress &amp; compress [1]. Unfortunately, they have not provided results on benchmark MNIST tasks.
- This work is related to a recently proposed idea in architecture search [2] that learns to predict the weights of a network given its architecture.
- Can you clarify whether you have used DG at test time?
- Can you report results without using DG? It is not clear whether DPG is accountable for preventing the catastrophic forgetting or the sluggishness enforced by DG.
- Questions 1 and 2 need more formalization if the authors want to clearly prove a statement.
- As the answer to Question 1 suggests, have you explored enforcing a Lipschitz constraint?
- The answer to Question 2 is interesting. Could you rewrite it more formally? It seems like you can argue that DG’s objective encourages the employment of unused parameters which is important in tackling catastrophic forgetting.
- Can you elaborate on how much forgetting happens for DG?
- It seems that in figure 3.f and 3.c the MA method is unable to reach the best possible performance on the last task. Can you also report the table of accuracies on the last task?

[1] Schwarz, Jonathan, et al. "Progress &amp; Compress: A scalable framework for continual learning." arXiv preprint arXiv:1805.06370 (2018).
[2] Brock, Andrew, et al. "SMASH: one-shot model architecture search through hypernetworks." arXiv preprint arXiv:1708.05344 (2017).</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">7: Good paper, accept</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_BkeciPPVaQ" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Thank you for your positive and constructive feedback （Part two）</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=ryGvcoA5YX&amp;noteId=BkeciPPVaQ"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper542 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">10 Nov 2018</span><span class="item">ICLR 2019 Conference Paper542 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">8.	Re：“Can you elaborate on how much forgetting happens for DG?”

We have two understandings for your question. The first one is how much forgetting happens for DG before using constraints. DG suffers from the same forgetting problem as the classifier (solver in our paper) as it is also trained using the same SGD-like method, which only optimizes the current task without considering the previous tasks. The second is how much forgetting happens for DG after using the constraints. This is hard to measure. However, the degree of forgetting is indirectly reflected in the final accuracy. Furthermore, we obtained a better result for using DG + constraints only (without DPG) than GR, which shows that our method suffers less forgetting.

9.	Re: “It seems that in figure 3.f and 3.c the MA method is unable to reach the best possible performance on the last task. Can you also report the table of accuracies on the last task?”

Yes, ADAM gets the best accuracy on the last task as Adam optimizer learns the new task only and does not need to worry about the forgetting problem on the old tasks. For the last task, Our MA system obtained comparable accuracies on average with the baselines designed for overcoming forgetting. However, we are much better at preventing forgetting of old tasks. The results for the last task are given in the table below. Note that although EWC is quite good at the last task but it suffers seriously from forgetting as shown in Table 2 or Figure 3, which is consistent with results reported in other papers.
-----------------------------------------------------------------------------------------------------------------------------------------------
               |                                                  Last task  Accuracy (%)                                                                      
               | ---------------------------------------------------------------------------------------------------------------------------------
  Model | Shuffle MNIST | Disjoint MNIST | Disjointed CIFAR10 | THUCNews | DBPedia77| DBPedia554 
------------------------------------------------------------------------------------------------------------------------------------------------
 ADAM  |        98.30           |         97.28          |           83.98                |       93.56      |      95.30     |       97.52   
  EWC    |        98.12           |         96.97          |           75.38                |       86.72      |      96.11     |       96.55    
    GR     |        98.10           |         96.34          |           77.82                |       87.20      |      93.18     |       89.40    
  IMM    |        97.06           |         95.07          |           48.74                |       65.08      |      93.84     |       85.72    
Our MA|        98.15           |         96.22          |           73.75                |       86.36      |      96.01     |       91.14    
------------------------------------------------------------------------------------------------------------------------------------------------</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_BJxh4PwEpm" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Thank you for your positive and constructive feedback （Part one）</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=ryGvcoA5YX&amp;noteId=BJxh4PwEpm"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper542 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">10 Nov 2018</span><span class="item">ICLR 2019 Conference Paper542 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Thank you for your positive and constructive feedback. We apologise for the slow response as one of the authors is traveling. Below, we respond to each of your comments.

1.	Re: “small figures” and “There are some vague explanations in the intro that could be reduced”

Thanks for your suggestions. We will enlarge the figures and improve the intro.

2.	Re: “It would nice to compare to the recent Progress &amp; compress [1]. Unfortunately, they have not provided results on benchmark MNIST tasks.”

Yes, we will consider to use this method as a baseline. As we could not find their code on the Internet, it is hard to compare with it in the response period.

3.	Re: “Can you clarify whether you have used DG at test time?”

No. DG is only used in training. It is not used at the test time.

4.	Re: “Can you report results without using DG? It is not clear whether DPG is accountable for preventing the catastrophic forgetting or the sluggishness enforced by DG.”

DG is an essential component for our framework. We cannot remove DG since our method won’t work without it. We showed that DPG is very useful in preventing catastrophic forgetting by the ablation study in Table 3.

5.	Re: “This work is related to a recently proposed idea in architecture search [2]”

Thanks for pointing out this. We will cite and discuss [2] in the related work. The parameter generations in the two papers are for very different purposes. Paper [2] aims to accelerate architecture selection by learning an auxiliary HyperNet that generates weights for a main model conditioned on that model’s architecture. Our method aims to use the generated parameters for model adaption, which greatly reduces the parameter generation dimensions. 

6.	Re: “Questions 1 and 2 need more formalization if the authors want to clearly prove a statement.” and “The answer to Question 2 is interesting. Could you rewrite it more formally? It seems like you can argue that DG’s objective encourages the employment of unused parameters which is important in tackling catastrophic forgetting.”

Thank you for your suggestion. We will rewrite and add more formalization to make these two questions clearer.

7.	Re: “As the answer to Question 1 suggests, have you explored enforcing a Lipschitz constraint?”

We have not enforced a Lipschitz constraint in our experiments. We give the proof of Question 1, aiming to provide a theoretical guarantee and an upper bound for using the replayed data x’ in Formula 7. But thanks for the good suggestion and we will explore this experiment.

**Due to the limitation of character number, we divide our responses into two parts, please also see the second part.**
</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div></div></main></div>
  </div>
</div>


    <!-- Footer -->
    <footer class="sitemap">
      <div class="container">
        <div class="row hidden-xs">
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/venues">All Venues</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="/contact">Contact</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
    
        <div class="row visible-xs-block">
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/contact">Contact</a></li>
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
      </div>
    </footer>
    
    <footer class="sponsor">
      <div class="container">
        <div class="row">
          <div class="col-sm-10 col-sm-offset-1">
            <p class="text-center">
              OpenReview is created by the <a href="http://www.iesl.cs.umass.edu/" target="_blank">Information Extraction and Synthesis Laboratory</a>, College of Information and Computer Science, University of Massachusetts Amherst. We gratefully acknowledge the support of the OpenReview sponsors:  Google,  Facebook, NSF, the University of Massachusetts Amherst Center for Data Science, and Center for Intelligent Information Retrieval, as well as the Google Cloud Platform for donating the computing and networking services on which OpenReview.net runs.
            </p>
          </div>
        </div>
      </div>
    </footer>

  <div id="feedback-modal" class="modal fade" tabindex="-1" role="dialog">
    <div class="modal-dialog">
      <div class="modal-content">
        <div class="modal-header">
          <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button>
          <h3 class="modal-title">Send Feedback</h3>
        </div>
        <div class="modal-body">
          <p>Enter your feedback below and we'll get back to you as soon as possible.</p>
          <form action="/feedback" method="POST">
            <div class="form-group">
              <input type="email" name="from" class="form-control" placeholder="Email" />
            </div>
            <div class="form-group">
              <input type="text" name="subject" class="form-control" placeholder="Subject" />
            </div>
            <div class="form-group">
              <textarea name="message" class="form-control feedback-input" rows="5" placeholder="Message" required=""></textarea>
            </div>
          <ul id="ui-id-2" tabindex="0" class="ui-menu ui-widget ui-widget-content" style="display: none;"></ul></form>
        </div>
        <div class="modal-footer">
          <button type="button" class="btn btn-default" data-dismiss="modal">Cancel</button>
          <button type="button" class="btn btn-primary">Send</button>
        </div>
      </div>
    </div>
  </div>

  <script type="text/javascript" async="" src="https://www.google-analytics.com/analytics.js"></script><script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js"></script>
  <script>window.jQuery || document.write('&lt;script src="/static/js/vendor/jquery-2.2.4.min.js"&gt;&lt;\/script&gt;')</script>

  <script src="/static/dist/vendor.min.js"></script>
  <script src="/static/dist/templates.min.js"></script>
  <script src="/static/dist/openreview.min.js"></script>

    <script>window.legacyScripts = true;</script>


    <script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-108703919-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() { dataLayer.push(arguments); }
      gtag('js', new Date());
      gtag('config', 'UA-108703919-1');
    </script>


<div role="status" aria-live="assertive" aria-relevant="additions" class="ui-helper-hidden-accessible"></div></body></html>
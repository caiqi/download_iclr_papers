<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" class="no-js"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>Neural Logic Machines | OpenReview</title>
  <meta name="description" content="" />

      <meta name="citation_title" content="Neural Logic Machines" />
        <meta name="citation_author" content="Anonymous" />
      <meta name="citation_publication_date" content="2018/09/27" />
      <meta name="citation_online_date" content="2018/09/27" />
      <meta name="citation_pdf_url" content="https://openreview.net/pdf?id=B1xY-hRctX" />
      <meta name="twitter:card" content="summary" />
      <meta name="twitter:site" content="@openreviewnet" />
      <meta name="og:title" content="Neural Logic Machines" />
      <meta name="og:description" content="We propose Neural Logic Machines (NLMs), a neural-symbolic architecture for both inductive learning and logic reasoning. NLMs exploit the power of both neural networks—as function approximators for..." />
      <meta name="og:image" content="https://openreview.net/static/images/openreview_logo_512.png" />

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans:400,400i,700,700i" />

  <link rel="stylesheet" href="/static/css/bootstrap.min.css" />
  <link rel="stylesheet" href="/static/css/jquery-ui.min.css" />
  <link rel="stylesheet" href="/static/css/main.min.css" />
</head>

<body class="forum">
  <nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
  
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand home push-link" href="/"><strong>OpenReview</strong>.net</a>
      </div>
  
      <div id="navbar" class="navbar-collapse collapse">
        <form class="navbar-form navbar-left profile-search" role="search">
          <div class="form-group has-feedback">
            <input id="search_input" type="text" class="form-control ui-autocomplete-input" placeholder="Search ICLR 2019 Conference" autocomplete="off" />
            <span class="glyphicon glyphicon-search form-control-feedback" aria-hidden="true"></span>
          </div>
  
          <input id="search_group" type="hidden" value="ICLR.cc/2019/Conference" />
          <input id="search_content" type="hidden" value="all" />
        <ul id="ui-id-1" tabindex="0" class="ui-menu ui-widget ui-widget-content ui-autocomplete ui-front" style="display: none;"></ul></form>
  
        <ul class="nav navbar-nav navbar-right">
        
            <li id="user-menu"><a href="/login">Login</a></li>
        </ul>
      </div>
  
    </div>
  </nav>

  <div id="or-banner" class="banner" style="">
  <div class="container">
    <div class="row">
      <div class="col-xs-12"><a href="/group?id=ICLR.cc/2019/Conference" title="Venue Homepage"><img class="icon" src="/static/images/arrow_left.svg" /> Go to <strong>ICLR 2019 Conference</strong> homepage</a></div>
    </div>
  </div>
</div>
<div id="flash-message-container" class="alert alert-danger" role="alert" style="display: none;">
  <div class="container">
    <div class="row">
      <div class="col-xs-12">
        <div class="alert-content">
          <button type="button" class="close" aria-label="Close"><span aria-hidden="true">×</span></button>
        </div>
      </div>
    </div>
  </div>
</div>

<div class="container">
  <div class="row">
    <div class="col-xs-12">
      <main id="content" class="clearfix openbanner-visible legacy-styles"><div id="note_B1xY-hRctX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Neural Logic Machines</a> <a class="note_content_pdf" href="/pdf?id=B1xY-hRctX" title="Download PDF" target="_blank"><img src="/static/images/pdf_icon_blue.svg" /></a> </h2></div><div class="meta_row"><span class="signatures">Anonymous</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">28 Sep 2018 (modified: 11 Oct 2018)</span><span class="item">ICLR 2019 Conference Blind Submission</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span><span class="item"><a class="action-bibtex-modal" data-bibtex="@inproceedings{    &#10;anonymous2019neural,    &#10;title={Neural Logic Machines},    &#10;author={Anonymous},    &#10;booktitle={Submitted to International Conference on Learning Representations},    &#10;year={2019},    &#10;url={https://openreview.net/forum?id=B1xY-hRctX},    &#10;note={under review}    &#10;}">Show Bibtex</a></span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Abstract: </span><span class="note_content_value">We propose Neural Logic Machines (NLMs), a neural-symbolic architecture for both inductive learning and logic reasoning. NLMs exploit the power of both neural networks—as function approximators for probabilistic distributions, and logic programming—as symbolic processor for objects with properties, relations, logic connectives, and quantifiers. After being trained on small-scale tasks (such as sorting short arrays), NLMs can learn the underlying logic rules, and generalize to arbitrarily large-scale tasks (such as sorting arbitrarily long arrays). In our experiments, NLMs achieve perfect generalization in a number of tasks, from relational reasoning tasks on family tree and general graphs, to decision making tasks including sorting, finding shortest paths, and the blocks world. Most of these tasks are hard to accomplish for neural networks or logical programming alone.</span></div><div class="note_contents"><span class="note_content_field">Keywords: </span><span class="note_content_value">Neural-symbolic, first-order logic, perfect generalization</span></div><div class="note_contents"><span class="note_content_field">TL;DR: </span><span class="note_content_value">A fully differentiable neural-symbolic architecture to conduct first-order logic reasoning</span></div><div class="reply_row clearfix"><div class="item" id="reply_count">6 Replies</div></div></div><hr class="small" /><div id="note_children"><div class="note_with_children"><div id="note_H1g19nL6Tm" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Clarification on Scalability</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=B1xY-hRctX&amp;noteId=H1g19nL6Tm"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1193 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">17 Nov 2018</span><span class="item">ICLR 2019 Conference Paper1193 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">We thank all reviewers for their thoughts and comments. In addition to the specific responses below, here we clarify on the scalability question asked by some reviewers. We will include related discussions in our revision.

It should be clarified that scalability mentioned in the paper mainly refers to the complexity of reasoning (e.g., number of steps before producing a desired predicate), not the number of objects/entities or relations. This is highlighted in #2 at the bottom of page 1: “We expect the learning system to scale with the number of logic rules. Existing logic-based algorithms like ILP suffer an exponential computational complexity with respect to the number of logic rules”.

Knowledge-graph tasks involve many entities (e.g. &gt; 10M) and relations as reviewers pointed out, but the rules involved in the reasoning steps are usually restricted. For example, the rules considered in the knowledge base reasoning work (Yang et al., 2017) are restricted in a “chain-like” form (their eqn 1.), which is query(Y,X)&lt;-Rn (Y,Zn) ∧ · · · ∧ R1 (Z1,X), while R1, . . . , Rn are *known* relations in the knowledge base. Such knowledge-graph reasoning tasks represent an interesting yet different class of problems outside of the current scope of our paper.

In contrast, learning predicates that have a complex structure (such as the ShouldMove example below) pose a scalability challenge to existing ILP methods.  In dILP [Evans et al.], for example, suppose each rule has C possible choices from the templates and R rules are need to be learned, then the possible space is at least O(C^R) --- the number of the set of possible rules is exponential w.r.t. the number of rules.  On the other hand, our method is only quadratic in the number of rules (or in this case, equivalently, number of predicates).

**********************************************************************
                          A Blocks World Example                             
**********************************************************************
This example shows what we mean by complex reasoning in the seemingly simple Blocks World domain.  Suppose we are interested in knowing whether a block should be moved in order to reach the target configuration.  Here, a block should be moved if (1) it is moveable; and (2) there is at least one block below it that does not match the target configuration.  Call the desired predicate “ShouldMove(x)”.

Inputs Relations (as specified in the last paragraph of page 7):
SameWorldID, SmallerWorldID, LargerWorldID;
SameID, SmallerID, LargerID;
Left, SameX, Right, Below, SameY, Above.
The relations are given on all pairs of objects across both worlds.

Here is one way to produce the desired predicate by defining several helper predicates, designed by “human experts”:
1. IsGround(x) ← ∀y Above(y, x)
2. SameXAbove(x, y) ← SameWorldID(x, y) ∧ SameX(x, y) ∧ Above(x, y)
3. Clear(x) ← ∀y ¬SameXAbove(y, x)
4. Moveable(x) ← Clear(x) ∧ ¬IsGround(x)
5. InitialWorld(x) ← ∀y ¬SmallerWorldID(y, x)
6. Match(x, y) ← ¬SameWorldID(x, y) ∧ SameID(x, y) ∧ SameX(x, y) ∧ SameY(x, y)
7. Matched(x) ← ∃y Match(x, y)
8. HaveUnmatchedBelow(x) ← ∃y SameXAbove(x, y) ∧ ¬Matched(y) 
9. ShouldMove(x) ← InitialWorld(x) ∧ Moveable(x) ∧ HaveUnmatchedBelow(x)
We can also write the logic forms in one line:
ShouldMove(x) ← (∀y ¬SmallerWorldID(y, x)) ∧ (∀y ¬(SameWorldID(y, x) ∧ SameX(y, x) ∧ Above(y, x))) ∧ ¬(∀y Above(y, x)) ∧ ((∃y SameWorldID(x, y) ∧ SameX(x, y) ∧ Above(x, y)) ∧ ¬(∃z ¬SameWorldID(y, z) ∧ SameID(y, z) ∧ SameX(y, z) ∧ SameY(y, z)) )

Note that this is only a part of the logic needed to complete the Blocks World challenge. The learner also needs to figure out where should the block be moved onto. The proposed NLM can learn policies that solve the Blocks World from the sparse reward signal indicating only whether the agent has finished the game. More importantly, the learned policy generalizes well to larger instances (consisting more blocks).
**********************************************************************
</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_rylWbydT3Q" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Interesting approach to model FOL in NN, with concerns in scalability</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=B1xY-hRctX&amp;noteId=rylWbydT3Q"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1193 AnonReviewer1</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">05 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper1193 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">This paper presents a model to combine neural network and logic programming. It proposes to use 3 primitive logic rules to model first-order predicate calculus in the neural networks. Specifically, relations with different numbers of arguments over all permutations of the groups of objects are represented as tensors with corresponding dimensions. In each layer, a MLP (shared among different permutations) is applied to transform the tensor. Multiple layers captures multiple steps of deduction. On several synthetic tasks, the proposed method is shown to outperform the memory network baseline and shows strong generalization.  

The paper is well written, but some of the contents are still a bit dense, especially for readers who are not familiar with first-order predicate calculus. 

The small Python example in the Appendix helps to clarify the details. It would be good to include the details of the architectures, for example, the number of layers, and the number of hidden sizes in each layer, in the experiment details in the appendix. 

The idea of using the 3 primitive logic rules and applying the same MLP to all the permutations are interesting. However, due to the permutation step, my concern is whether it can scale to real-world problems with a large number of entities and different types of relations, for example, a real-world knowledge graph.

Specifically:

1. Each step of the reasoning (one layer) is applied to all the permutations for each predicate over each group of objects, which might be prohibitive in real-world scenario. For example, although there are usually only binary relations in real-world KG, the number of entities is usually &gt;10M. 

2. Although the inputs or preconditions could be sparse, thus efficient to store and process, the intermediate representations are dense due to the probabilistic view, which makes the (soft) deduction computationally expensive. 

Some clarification questions: 

Is there some references for the Remark on page 3? 

Why is there a permutation before MLP? I thought the [m, m-1, …, m-n+1] dimensions represent the permutations. For example, if there are two objects, {x1, x2}. Then the [0, 1, 0] represents the first predicate applied on x1, and x2. [1, 0, 0] represents the first predicate applied on x2 and x1. Some clarifications would definitely help here. 

I think this paper presents an interesting approach to model FOPC in neural networks. So I support the acceptance of the paper. However, I am concerned with its scalability beyond the toy datasets. 
</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">6: Marginally above acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">3: The reviewer is fairly confident that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_rkgpGkN52Q" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Review</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=B1xY-hRctX&amp;noteId=rkgpGkN52Q"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1193 AnonReviewer2</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">03 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper1193 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">In this paper the authors propose a neural-symbolic architecture, called Neural Logic Machines (NLMs), that can learn logic rules.

The paper is pretty clear and well-written and the proposed system is compelling. I have only some small concerns.
One issue concerns the learning time. In the experimental phase the authors do not state how long training is for different datasets.
Moreover it seems that the “rules” learnt by NSMs cannot be expressed in a logical formalism, isn’t it? If I am right, I think this is a major difference between dILP (Evans et. al) and NLMs and the authors should discuss about that. If I am wrong, I think the authors should describe how to extract rules from NLMs.
In conclusion I think that, once these little issues are fixed, the paper could be considered for acceptance.

[minor comments]
p. 4
“tenary” -&gt; “ternary”
 p. 5
“ov varying size” -&gt; “of varying size”
“The number of parameters in the block described above is…”. It is not clear to me how the number of parameters is computed.
“In Eq. equation 4” -&gt; “In Eq. 4”

p. 16
“Each lesson contains the example with same number of objects in our experiments.”. This sentence sounds odd.
</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">7: Good paper, accept</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_r1gMP1TKnQ" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>interesting directions but unclear novelty and some claims that are too strong</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=B1xY-hRctX&amp;noteId=r1gMP1TKnQ"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1193 AnonReviewer3</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">02 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper1193 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">The paper introduces Neural Logic Machines, a particular way to combine neural networks and first order but finite logic. 

The paper is very well written and structured. However, there are also some downsides.

First of all, Section 2.1 is rather simple from a logical perspective and hence it is not clear what this gets a special term. Moreover, why do mix Boolean logic (propostional logic) and first order logic? Any how to you deal with the free variables, i.e., the variables that are not bounded by a quantifier? The semantics you define later actually assumes that all free variables (in your notation) are bounded by all quantifiers since you apply the same rule to all ground instances. Given that you argue that you want a neural extension of symbolic logic ("NLM is a neural realization of (symbolic) logic machines") this has to be clarified as it would not be an extension otherwise. 

Furthermore, Section 2.2 argues that we can use a MLP with a sigmoid output to encode any joint distribution. This should be proven. It particular, given that the input to the network are the marginals of the ground atoms. So this is more like a conditional distribution? Moreover, it is not clear how this is different to other approaches that encode the weight of weighted logical rule (e.g. in a MLN) using neural networks, see
e.g. 

Marco Lippi, Paolo Frasconi:
Prediction of protein beta-residue contacts by Markov logic networks with grounding-specific weights. 
Bioinformatics 25(18): 2326-2333 (2009)

Now of course, and this is the nice part of the present paper, by stacking several of the rules, we could directly specify that we may need a certain number of latent predicates. 
This is nice but it is not argued that this is highly novel. Consider again the work by Lippi and Frasconi. We unroll a given NN-parameterized MLN for s fixed number of forward chaining steps. This gives us essentially a computational graph that could also be made differentiable and hence we could also have end2end training. The major difference seems to be that now objects are directly attached with vector encodings, which are not present in Lippi and Frasconi's approach. This is nice but also follows from Rocktaeschel and Riedel's differentiable Prolog work (when combined with Lippi and Frasconi's approach).
Moreover, there have been other combinations of tensors and logic, see e.g. 

Ivan Donadello, Luciano Serafini, Artur S. d'Avila Garcez:
Logic Tensor Networks for Semantic Image Interpretation. 
IJCAI 2017: 1596-1602
 
Here you can also have vector encodings of constants. This also holds for 

Robin Manhaeve, Sebastijan Dumancic, Angelika Kimmig, Thomas Demeester, Luc De Raedt:
DeepProbLog: Neural Probabilistic Logic Programming. CoRR abs/1805.10872 (2018)

The authors should really discuss this missing related work. This should also involve
a clarification of the "ILP systems do not scale" statement. At least if one views statistical relational learning methods as an extension of ILP, this is not true. Probabilistic ILP aka statistical relational learning has been used to learn models on electronic health records, see e.g., the papers collectively discussed in 

Sriraam Natarajan, Kristian Kersting, Tushar Khot, Jude W. Shavlik:
Boosted Statistical Relational Learners - From Benchmarks to Data-Driven Medicine. Springer Briefs in Computer Science, Springer 2014, ISBN 978-3-319-13643-1, pp. 1-68

So the authors should either discuss SRL and its successes, separating SRL from ILP, or they cannot argue that ILP does not scale. In the related work section, they decided to view both as ILP, and, in turn, the statement that ILP does not scale is not true. Moreover, many of the learning tasks considered have been solved with ILP, too, of course in the ILP setting. Any ILP systems have been shown to scale beyond those toy domains.   
This also includes the blocks world. Here relational MDP solvers can deal e.g. with BW worlds composed of 10 blocks, resulting in MDPs with several million states. And the can compute relational policies that solve e.g. the goal on(a,b) for arbitrary number of blocks. This should be incorporated in the discussion of the introduction in order to avoid the wrong impression that existing methods just work for toy examples. 

Coming back to scaling, the current examples are on rather small datasets, too, namely &lt;12 training instances. Moreover, given that we learn a continuous approximation with a limit depth of reasoning, it is also very likely that the models to not generate well to larger test instances. So the scaling issue has to be qualified to avoid to give the wrong impression that the present paper solves this issue. 

Finally, the BW experiments should indicate some more information on the goal configuration. This would help to understand whether an average number of moves of 84 is good or bad. Moreover, some hints about the MDP formulation should be provided, given that there have been relational MDPs that solve many of the probabilistic planning competition tasks. And, given that the conclusions argue that NLMs can learn the "underlying logical rules", the learned rules should actually be shown. 

Nevertheless, the direction is really interesting but there several downsides that have to be addressed. </span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">5: Marginally below acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_rJxii0IT6Q" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Response to AnonReviewer3</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=B1xY-hRctX&amp;noteId=rJxii0IT6Q"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1193 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">17 Nov 2018</span><span class="item">ICLR 2019 Conference Paper1193 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">We thank the reviewer for many comments and pointers, and will revise our paper to emphasize further our contributions and novelties compared to previous work.

1. Section 2.1 and the handling of free variables.
Section 2.1 lists three primitive rules that serve as building blocks in later subsections to implement a Neural Logic Machine.  This is necessary for providing terminology and notation used throughout the rest of the paper.  We are not claiming them as novel contributions.
Section 2.1 does *not* describe propositional logic.  The rule for “Boolean logic” is used in NLM as a component for realizing first-order logic (probabilistically, as described in section 2.2): they are used to operate on predicates grounded on objects.  An example in the Blocks World domain may look like:
      IsGround(A) V Clear(A) -&gt; Placeable(A)
where A is one object in the Blocks World domain; and notably, IsGround(.), Clear(.) and Placeable(.) are not manually specified but are learned by the network.
Our model supports free variables.  The arity of a predicate is its number of free variable.  For example, the arity of a binary predicate is 2, and NLM uses a matrix (a tensor of dimension 2) to represent the predicate’s values for all possible grounding; the 1st paragraph of section 2.2 gives further details.  The three rules (eqns 1-3) keep the same number of free variables, increase it by 1, and decrease it by 1, respectively.

2. The probability distributions modeled by MLPs.
We would like to thank R3 for the comment about “joint distribution”, and briefly clarify technical details in Section 2.2 &amp; 2.3 to avoid potential misunderstanding.

Let’s define the input of each layer k as H_k (whose each element is in [0, 1]) recursively in the following:

(1) The initial layer is H_1 = prob(B) representing boolean values 0 or 1, where B is a set of base predicates.
(2) For each layer k, the probabilistic boolean expression in the building block is defined above Eqn. 4:
   Expression(H_1, ... , H_k)  ==&gt;  H_{k+1}
where Expression in NLM is represented by some neural network structure. As illustrated in Figure 2 &amp; 3, we use (a) grouped MLP with weights \theta_k and activation \sigma, and (b) ReduceOrExpand that computes
   H'_k = \sigma(MLP(H_1, ... , H_k; \theta_k)),
   H_{k+1} = ReduceOrExpand(H'_k).
This building block keeps all elements of H_{k+1} in [0, 1] and becomes the input of next layer k+1. Therefore, such a series of building blocks is able to model a complex expression. 

We will not use “joint distribution” to avoid confusion, and make it more clear in the revision.

3. The difference with other approaches that encode the weight of weighted logic rules using neural networks.
Thanks for the pointers. We will cite and discuss the papers in the revision. Our work differs substantially from MLN with weights computed by NNs, e.g., the mentioned L&amp;F paper:
Their logic rules (called “knowledge base” in L&amp;F) are designed by experts; see sec 2.3 of L&amp;F).  Here, our NLM uses deep NNs to learn such rules from data. The Blocks World example in our response to the scalability question shows the complexity of the rules that NLMs can handle.
Consequently, our NLM needs to learn weights that form those rules. In contrast, MLN only needs to learn a real-valued weight for each hand-designed logic rule.

4. The difference with the unrolled computation graph of MLN.
One of our main contributions is to use deep NN to learn logic rules.  Unrolling NN-parameterized MLNs is limited by the need and quality of expert-designed logic rules.

5. The encoding of objects.
It is unclear to us what the reviewer means by “objects are … vector encodings” and hence the similarity to DeepProbLog, as we do *not* encode objects by vectors.  Data representations in NLM are all tensors that encode the (probabilistic) true/false values of grounded predicates; see the 1st paragraph of section 2.2 (page 3).
</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_S1l4CCI66Q" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Response to AnonReviewer3 Continued</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=B1xY-hRctX&amp;noteId=S1l4CCI66Q"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1193 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">17 Nov 2018 (modified: 18 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper1193 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">6. The scalability discussion with ILP systems and SRL methods.
Thank you for the comment.  Please see our response to the scalability claim.  We will revise the paper accordingly to clarify.

7. Generalization w.r.t. the number of objects.
Different from the reviewer’s hypothesis, our results actually verify that NLM models do generalize well to larger test instances.  For example, Table 2 shows that our learned model achieves 100% accuracy on test instances with more blocks, and the same for Table 1. We have also conducted experiments testing this ability using several trained model in extreme cases which consist of 500 blocks (1000 numbers for sorting), no failure cases were found. The models will be made public along with our code after the paper decision. This ability is one of our main findings, as highlighted in the abstract (“NLMs ... generalize to arbitrarily large-scale tasks”).

8. The goal configuration of Blocks World.
We present the generation of Blocks World instances in Appendix B.4. We will make it more clear in the revision. The goal configuration is randomly and independently generated as the initial configuration. One can compute that the expected optimal number of steps needed for solving the Blocks World is approximately 2m - o(m) steps are required to solve the case, where m is the number of blocks, which is 50 in the test instances. In average 84 steps means the model learns a fairly good solution. The reviewer is also welcome to check our demo in the footnote of Page 8: <a href="https://sites.google.com/view/neural-logic-machines" target="_blank" rel="nofollow">https://sites.google.com/view/neural-logic-machines</a> .

9. MDP formulation of the Blocks World.
Thanks for the nice suggestion. We discuss the MDP formulation in section 3.4, and we will make it more clear. We input the current world and the target world with tensors describing relations between objects. At each time step, the agents take actions to move one block onto another. We use sparse rewards to train the agents: The agents get the reward only when they finish the task.

10. NLM learns the underlying logical rules.
Thanks for the comment.  We intend to mean that the learned NLM generalizes well to problems with varying sizes, in the same way logical rules do.  We will reword the sentence to avoid confusions, and discuss rule extraction as future work.
</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div></div></div></div></main></div>
  </div>
</div>


    <!-- Footer -->
    <footer class="sitemap">
      <div class="container">
        <div class="row hidden-xs">
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/venues">All Venues</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="/contact">Contact</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
    
        <div class="row visible-xs-block">
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/contact">Contact</a></li>
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
      </div>
    </footer>
    
    <footer class="sponsor">
      <div class="container">
        <div class="row">
          <div class="col-sm-10 col-sm-offset-1">
            <p class="text-center">
              OpenReview is created by the <a href="http://www.iesl.cs.umass.edu/" target="_blank">Information Extraction and Synthesis Laboratory</a>, College of Information and Computer Science, University of Massachusetts Amherst. We gratefully acknowledge the support of the OpenReview sponsors:  Google,  Facebook, NSF, the University of Massachusetts Amherst Center for Data Science, and Center for Intelligent Information Retrieval, as well as the Google Cloud Platform for donating the computing and networking services on which OpenReview.net runs.
            </p>
          </div>
        </div>
      </div>
    </footer>

  <div id="feedback-modal" class="modal fade" tabindex="-1" role="dialog">
    <div class="modal-dialog">
      <div class="modal-content">
        <div class="modal-header">
          <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button>
          <h3 class="modal-title">Send Feedback</h3>
        </div>
        <div class="modal-body">
          <p>Enter your feedback below and we'll get back to you as soon as possible.</p>
          <form action="/feedback" method="POST">
            <div class="form-group">
              <input type="email" name="from" class="form-control" placeholder="Email" />
            </div>
            <div class="form-group">
              <input type="text" name="subject" class="form-control" placeholder="Subject" />
            </div>
            <div class="form-group">
              <textarea name="message" class="form-control feedback-input" rows="5" placeholder="Message" required=""></textarea>
            </div>
          <ul id="ui-id-2" tabindex="0" class="ui-menu ui-widget ui-widget-content" style="display: none;"></ul></form>
        </div>
        <div class="modal-footer">
          <button type="button" class="btn btn-default" data-dismiss="modal">Cancel</button>
          <button type="button" class="btn btn-primary">Send</button>
        </div>
      </div>
    </div>
  </div>

  <script type="text/javascript" async="" src="https://www.google-analytics.com/analytics.js"></script><script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js"></script>
  <script>window.jQuery || document.write('&lt;script src="/static/js/vendor/jquery-2.2.4.min.js"&gt;&lt;\/script&gt;')</script>

  <script src="/static/dist/vendor.min.js"></script>
  <script src="/static/dist/templates.min.js"></script>
  <script src="/static/dist/openreview.min.js"></script>

    <script>window.legacyScripts = true;</script>


    <script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-108703919-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() { dataLayer.push(arguments); }
      gtag('js', new Date());
      gtag('config', 'UA-108703919-1');
    </script>


<div role="status" aria-live="assertive" aria-relevant="additions" class="ui-helper-hidden-accessible"></div></body></html>
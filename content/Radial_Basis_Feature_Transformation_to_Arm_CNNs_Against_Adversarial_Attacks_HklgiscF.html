<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" class="no-js"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>Radial Basis Feature Transformation to Arm CNNs Against Adversarial Attacks | OpenReview</title>
  <meta name="description" content="" />

      <meta name="citation_title" content="Radial Basis Feature Transformation to Arm CNNs Against Adversarial Attacks" />
        <meta name="citation_author" content="Anonymous" />
      <meta name="citation_publication_date" content="2018/09/27" />
      <meta name="citation_online_date" content="2018/09/27" />
      <meta name="citation_pdf_url" content="https://openreview.net/pdf?id=Hklgis0cF7" />
      <meta name="twitter:card" content="summary" />
      <meta name="twitter:site" content="@openreviewnet" />
      <meta name="og:title" content="Radial Basis Feature Transformation to Arm CNNs Against Adversarial..." />
      <meta name="og:description" content="The linear and non-flexible nature of deep convolutional models makes them vulnerable to carefully crafted adversarial perturbations. To tackle this problem, in this paper, we propose a nonlinear..." />
      <meta name="og:image" content="https://openreview.net/static/images/openreview_logo_512.png" />

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans:400,400i,700,700i" />

  <link rel="stylesheet" href="/static/css/bootstrap.min.css" />
  <link rel="stylesheet" href="/static/css/jquery-ui.min.css" />
  <link rel="stylesheet" href="/static/css/main.min.css" />
</head>

<body class="forum">
  <nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
  
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand home push-link" href="/"><strong>OpenReview</strong>.net</a>
      </div>
  
      <div id="navbar" class="navbar-collapse collapse">
        <form class="navbar-form navbar-left profile-search" role="search">
          <div class="form-group has-feedback">
            <input id="search_input" type="text" class="form-control ui-autocomplete-input" placeholder="Search ICLR 2019 Conference" autocomplete="off" />
            <span class="glyphicon glyphicon-search form-control-feedback" aria-hidden="true"></span>
          </div>
  
          <input id="search_group" type="hidden" value="ICLR.cc/2019/Conference" />
          <input id="search_content" type="hidden" value="all" />
        <ul id="ui-id-1" tabindex="0" class="ui-menu ui-widget ui-widget-content ui-autocomplete ui-front" style="display: none;"></ul></form>
  
        <ul class="nav navbar-nav navbar-right">
        
            <li id="user-menu"><a href="/login">Login</a></li>
        </ul>
      </div>
  
    </div>
  </nav>

  <div id="or-banner" class="banner" style="">
  <div class="container">
    <div class="row">
      <div class="col-xs-12"><a href="/group?id=ICLR.cc/2019/Conference" title="Venue Homepage"><img class="icon" src="/static/images/arrow_left.svg" /> Go to <strong>ICLR 2019 Conference</strong> homepage</a></div>
    </div>
  </div>
</div>
<div id="flash-message-container" class="alert alert-danger" role="alert" style="display: none;">
  <div class="container">
    <div class="row">
      <div class="col-xs-12">
        <div class="alert-content">
          <button type="button" class="close" aria-label="Close"><span aria-hidden="true">×</span></button>
        </div>
      </div>
    </div>
  </div>
</div>

<div class="container">
  <div class="row">
    <div class="col-xs-12">
      <main id="content" class="clearfix openbanner-visible legacy-styles"><div id="note_Hklgis0cF7" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Radial Basis Feature Transformation to Arm CNNs Against Adversarial Attacks</a> <a class="note_content_pdf" href="/pdf?id=Hklgis0cF7" title="Download PDF" target="_blank"><img src="/static/images/pdf_icon_blue.svg" /></a> </h2></div><div class="meta_row"><span class="signatures">Anonymous</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">28 Sep 2018 (modified: 11 Oct 2018)</span><span class="item">ICLR 2019 Conference Blind Submission</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span><span class="item"><a class="action-bibtex-modal" data-bibtex="@inproceedings{    &#10;anonymous2019radial,    &#10;title={Radial Basis Feature Transformation to Arm CNNs Against Adversarial Attacks},    &#10;author={Anonymous},    &#10;booktitle={Submitted to International Conference on Learning Representations},    &#10;year={2019},    &#10;url={https://openreview.net/forum?id=Hklgis0cF7},    &#10;note={under review}    &#10;}">Show Bibtex</a></span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Abstract: </span><span class="note_content_value">The linear and non-flexible nature of deep convolutional models makes them vulnerable to carefully crafted adversarial perturbations. To tackle this problem, in this paper, we propose a nonlinear radial basis convolutional feature transformation by learning the Mahalanobis distance function that maps the input convolutional features from the same class into tight clusters. In such a space, the clusters become compact and well-separated, which prevent small adversarial perturbations from forcing a sample to cross the decision boundary. We test the proposed method on three publicly available image classification and segmentation data-sets namely, MNIST, ISBI ISIC skin lesion, and NIH ChestX-ray14. We evaluate the robustness of our method to different gradient (targeted and untargeted) and non-gradient based attacks and compare it to several non-gradient masking defense strategies. Our results demonstrate that the proposed method can boost the performance of deep convolutional neural networks against adversarial perturbations without accuracy drop on clean data.</span></div><div class="note_contents"><span class="note_content_field">Keywords: </span><span class="note_content_value">Radial basis feature transformation, convolutional neural networks, adversarial defense</span></div><div class="note_contents"><span class="note_content_field">TL;DR: </span><span class="note_content_value">A new nonlinear defense against adversarial attacks.</span></div><div class="reply_row clearfix"><div class="item" id="reply_count">3 Replies</div></div></div><hr class="small" /><div id="note_children"><div class="note_with_children"><div id="note_HygfG3O-TQ" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Interesting idea but unclear evaluation</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=Hklgis0cF7&amp;noteId=HygfG3O-TQ"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper589 AnonReviewer1</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">08 Nov 2018</span><span class="item">ICLR 2019 Conference Paper589 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">The authors propose a new defense against adversarial examples based on radial basis features. Prior work has suggested that the linearity of standard convolutional networks may be a factor contributing to their vulnerability against adversarial examples, and that radial basis functions may help alleviate this weakness. The current paper builds on this idea and proposes a concrete way to add radial basis features to existing convnet architectures.

In the proposed approach, each layer of the network is augmented with a radial basis feature transform of the features in this layer. The output of this feature transform is then concatenated with the features in this layer. The centers of the radial basis features, the bandwidth, and the distance matrix are trained with the other network parameters. The distance matrix in the feature transform is used to compute the Mahalanobis distance between the features and centers in the radial basis functions.

The authors evaluate their defense experimentally on the standard MNIST dataset and two medical image datasets: X-chest14 for classification and a 2D RGB skin lesion dataset from the 2017 IEEE ISBI International Skin Imaging Collaboration (ISIC) Challenge for image segmentation. The experiments show that their method improves over an undefended network on MNIST. On X-chest14, their method improves over features squeezing (input quantization) and Gaussian data augmentation. On the image segmentation dataset, the method improves over these baselines as well as adversarial training.

While I find the overall idea interesting, I have some doubts about the experimental evaluation. For instance, the authors do not compare their MNIST numbers to the robust optimization results reported in Madry et al. (cited in the paper). Robust optimization achieves higher adversarial accuracy than the numbers reported in Table 1.

More importantly, it is unclear to what extent unmodified first-order methods are effective for the proposed defense. While the authors investigate whether their networks exhibit gradient masking / obfuscation, the left plot in Figure 3 still leaves some questions. Based on the curves for FGSM and BIM, the proposed defense would still achieve a high accuracy even against attacks with eps = 0.5. However, this would be a clear failure of the first order attacks (but not a sign of true robustness) because an adversary with eps = 0.5 can trivially defend any network by setting every input pixel to 0.5. Hence the authors should investigate what happens in the regime between eps = 0.4 and eps = 0.5.

While I support the use of non-standard datasets for evaluation, it would still strengthen the paper if the author also reported accuracy numbers on CIFAR-10. The X-chest14 and the segmentation dataset have not been frequently used in the adversarial robustness literature to the best of my knowledge. Hence it is less clear how well the proposed methods perform on these datasets.

While I find the overall idea interesting, with the current experimental evaluation I unfortunately cannot recommend accepting the paper.


Further comments:

- The distinction between "data-level" and "algorithmic-level" approaches in the introduction is unclear to me. Adversarial training can also be seen as robust optimization, which is arguably an algorithmic approach.

- At the beginning of Section 2, it would be helpful if the authors first introduced the meaning of the variables n, m, and k before using them. In general, it would be helpful if the authors described in more detail how the radial basis features are incorporated into the network.

- How is the adversarial training baseline in Section 4.2 implemented? The choice of adversary in adversarial training / robust optimization can be crucial for the robustness of the resulting model.

- Since the authors refer to the linearity of existing model as a potential weakness: there are also alternative explanations, e.g., see <a href="https://arxiv.org/abs/1801.02774" target="_blank" rel="nofollow">https://arxiv.org/abs/1801.02774</a> and https://arxiv.org/abs/1804.11285 .

- The test sets used in the evaluation are fairly small (150 and 200 data points). In this regime, 95% confidence intervals can be as large as +/- 8%. Hence I would recommend increasing the size of the test sets to at least 1,000.</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">4: Ok but not good enough - rejection</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_Hyxghm0t2X" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Not well written</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=Hklgis0cF7&amp;noteId=Hyxghm0t2X"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper589 AnonReviewer3</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">02 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper589 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">This paper realizes the radial basis function in deep CNNs by leveraging the Mahalanobis distance between a convolutional feature vector and the corresponding center. The method is implemented for the image classification and segmentation tasks against several types of attack methods and demonstrates good robustness.

Although the results against adversarial attacks are promising, the paper is not well written. Especially, the notations in Section 2 are not clearly defined which baffled me a lot on how this method functions. For instance, in Equation 4, what does w_k stand for? Why there are K activation functions in a CNN, are they different? What is the meaning of a dot product between a w_k and an activation function?

Additionally, there lacks detail on how to train the transformation matrix (P in Equation 3 or T in Equation 1), and the following sentence confused me a lot: "To enforce T's positive semi-definiteness, using the eigenvalue decomposition, it can be decomposed into T'T". I understand why T needs to be PSD matrix, but how can eigenvalue decomposition decompose T into T'T? And how is this achieved during the training of a CNN? I think the authors should revise this part carefully to demonstrate the proposed methods more clearly.
</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">4: Ok but not good enough - rejection</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">3: The reviewer is fairly confident that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_HJxVHlBNnQ" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>We think that this paper is not of sufficient quality to be accepted in ICLR, for at least the following reasons.</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=Hklgis0cF7&amp;noteId=HJxVHlBNnQ"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper589 AnonReviewer2</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">29 Oct 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper589 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">The proposed method is too simplistic, the model being succinctly described in less than one page with many errors in the given math expressions. Only the model is given. The optimization problem, as given in (1) is not explained. the authors need to stud the optimization problem, to derive its resolution, and to describe the obtained algorithm.

The authors’ main motivation is to “maps the input convolutional features from the same class into tight clusters. In such a space, the clusters become compact and well-separated, …”. However, in the proposed method is operating in this way. The model is a simple transformation, and nothing ensures the compactness of the feature space, neither the separability of the classes.

It is difficult to understand the “arm CNNs with radial basis feature transformation”. There are two figure in the paper that seek to show this modification of CNN, but this is not enough because nothing is said in the text, which makes these images difficult to understand. Moreover, the figures have notations different than those in the  main body, such as F_{l-1} as opposed to F_{i,j,K}.

What is the transformation to be learned ? Is it T as given in the text before (1), or P as given in (3). In (1), it seems that it is a mix of both, namely T* = argmin_P ! Moreover, it is written “To enforce T’s positive semi-definiteness, using the eigenvalue decomposition, it can be decomposed into T ′T”.  Decomposing T as T’T, means that T is very very special.

Equation (4) is not correct. The summation is on i, which is not in the expressions, but in the result with F_{i,j,K}.

With the exception of Tables 3 and 4, most experiments are on comparing the conventional versus the proposed method. The authors need to compare to other methods available in the literature on defense against adversarial attacks. Moreover, it is not clear why the author compare the proposed method to ADVT (adversarial training) in Table 4, and not in Table 3.

Some references are incomplete. For example, the second reference is missing the publication type, volume, … 
</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">3: Clear rejection</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></main></div>
  </div>
</div>


    <!-- Footer -->
    <footer class="sitemap">
      <div class="container">
        <div class="row hidden-xs">
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/venues">All Venues</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="/contact">Contact</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
    
        <div class="row visible-xs-block">
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/contact">Contact</a></li>
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
      </div>
    </footer>
    
    <footer class="sponsor">
      <div class="container">
        <div class="row">
          <div class="col-sm-10 col-sm-offset-1">
            <p class="text-center">
              OpenReview is created by the <a href="http://www.iesl.cs.umass.edu/" target="_blank">Information Extraction and Synthesis Laboratory</a>, College of Information and Computer Science, University of Massachusetts Amherst. We gratefully acknowledge the support of the OpenReview sponsors:  Google,  Facebook, NSF, the University of Massachusetts Amherst Center for Data Science, and Center for Intelligent Information Retrieval, as well as the Google Cloud Platform for donating the computing and networking services on which OpenReview.net runs.
            </p>
          </div>
        </div>
      </div>
    </footer>

  <div id="feedback-modal" class="modal fade" tabindex="-1" role="dialog">
    <div class="modal-dialog">
      <div class="modal-content">
        <div class="modal-header">
          <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button>
          <h3 class="modal-title">Send Feedback</h3>
        </div>
        <div class="modal-body">
          <p>Enter your feedback below and we'll get back to you as soon as possible.</p>
          <form action="/feedback" method="POST">
            <div class="form-group">
              <input type="email" name="from" class="form-control" placeholder="Email" />
            </div>
            <div class="form-group">
              <input type="text" name="subject" class="form-control" placeholder="Subject" />
            </div>
            <div class="form-group">
              <textarea name="message" class="form-control feedback-input" rows="5" placeholder="Message" required=""></textarea>
            </div>
          <ul id="ui-id-2" tabindex="0" class="ui-menu ui-widget ui-widget-content" style="display: none;"></ul></form>
        </div>
        <div class="modal-footer">
          <button type="button" class="btn btn-default" data-dismiss="modal">Cancel</button>
          <button type="button" class="btn btn-primary">Send</button>
        </div>
      </div>
    </div>
  </div>

  <script type="text/javascript" async="" src="https://www.google-analytics.com/analytics.js"></script><script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js"></script>
  <script>window.jQuery || document.write('&lt;script src="/static/js/vendor/jquery-2.2.4.min.js"&gt;&lt;\/script&gt;')</script>

  <script src="/static/dist/vendor.min.js"></script>
  <script src="/static/dist/templates.min.js"></script>
  <script src="/static/dist/openreview.min.js"></script>

    <script>window.legacyScripts = true;</script>


    <script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-108703919-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() { dataLayer.push(arguments); }
      gtag('js', new Date());
      gtag('config', 'UA-108703919-1');
    </script>


<div role="status" aria-live="assertive" aria-relevant="additions" class="ui-helper-hidden-accessible"></div></body></html>
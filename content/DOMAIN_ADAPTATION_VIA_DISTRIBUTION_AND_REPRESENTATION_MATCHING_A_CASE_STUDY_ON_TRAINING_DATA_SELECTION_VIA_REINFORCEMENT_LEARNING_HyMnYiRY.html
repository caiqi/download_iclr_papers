<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" class="no-js"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>DOMAIN ADAPTATION VIA DISTRIBUTION AND REPRESENTATION MATCHING: A CASE STUDY ON TRAINING DATA SELECTION VIA REINFORCEMENT LEARNING | OpenReview</title>
  <meta name="description" content="" />

      <meta name="citation_title" content="DOMAIN ADAPTATION VIA DISTRIBUTION AND REPRESENTATION MATCHING: A CASE STUDY ON TRAINING DATA SELECTION VIA REINFORCEMENT LEARNING" />
        <meta name="citation_author" content="Anonymous" />
      <meta name="citation_publication_date" content="2018/09/27" />
      <meta name="citation_online_date" content="2018/09/27" />
      <meta name="citation_pdf_url" content="https://openreview.net/pdf?id=HyMnYiR9Y7" />
      <meta name="twitter:card" content="summary" />
      <meta name="twitter:site" content="@openreviewnet" />
      <meta name="og:title" content="DOMAIN ADAPTATION VIA DISTRIBUTION AND REPRESENTATION MATCHING: A..." />
      <meta name="og:description" content="Supervised models suffer from domain shifting where distribution mismatch across domains greatly affect model performance. Particularly, noise scattered in each domain has played a crucial role in..." />
      <meta name="og:image" content="https://openreview.net/static/images/openreview_logo_512.png" />

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans:400,400i,700,700i" />

  <link rel="stylesheet" href="/static/css/bootstrap.min.css" />
  <link rel="stylesheet" href="/static/css/jquery-ui.min.css" />
  <link rel="stylesheet" href="/static/css/main.min.css" />
</head>

<body class="forum">
  <nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
  
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand home push-link" href="/"><strong>OpenReview</strong>.net</a>
      </div>
  
      <div id="navbar" class="navbar-collapse collapse">
        <form class="navbar-form navbar-left profile-search" role="search">
          <div class="form-group has-feedback">
            <input id="search_input" type="text" class="form-control ui-autocomplete-input" placeholder="Search ICLR 2019 Conference" autocomplete="off" />
            <span class="glyphicon glyphicon-search form-control-feedback" aria-hidden="true"></span>
          </div>
  
          <input id="search_group" type="hidden" value="ICLR.cc/2019/Conference" />
          <input id="search_content" type="hidden" value="all" />
        <ul id="ui-id-1" tabindex="0" class="ui-menu ui-widget ui-widget-content ui-autocomplete ui-front" style="display: none;"></ul></form>
  
        <ul class="nav navbar-nav navbar-right">
        
            <li id="user-menu"><a href="/login">Login</a></li>
        </ul>
      </div>
  
    </div>
  </nav>

  <div id="or-banner" class="banner" style="">
  <div class="container">
    <div class="row">
      <div class="col-xs-12"><a href="/group?id=ICLR.cc/2019/Conference" title="Venue Homepage"><img class="icon" src="/static/images/arrow_left.svg" /> Go to <strong>ICLR 2019 Conference</strong> homepage</a></div>
    </div>
  </div>
</div>
<div id="flash-message-container" class="alert alert-danger" role="alert" style="display: none;">
  <div class="container">
    <div class="row">
      <div class="col-xs-12">
        <div class="alert-content">
          <button type="button" class="close" aria-label="Close"><span aria-hidden="true">×</span></button>
        </div>
      </div>
    </div>
  </div>
</div>

<div class="container">
  <div class="row">
    <div class="col-xs-12">
      <main id="content" class="clearfix openbanner-visible legacy-styles"><div id="note_HyMnYiR9Y7" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>DOMAIN ADAPTATION VIA DISTRIBUTION AND REPRESENTATION MATCHING: A CASE STUDY ON TRAINING DATA SELECTION VIA REINFORCEMENT LEARNING</a> <a class="note_content_pdf" href="/pdf?id=HyMnYiR9Y7" title="Download PDF" target="_blank"><img src="/static/images/pdf_icon_blue.svg" /></a> </h2></div><div class="meta_row"><span class="signatures">Anonymous</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">28 Sep 2018 (modified: 11 Oct 2018)</span><span class="item">ICLR 2019 Conference Blind Submission</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span><span class="item"><a class="action-bibtex-modal" data-bibtex="@inproceedings{    &#10;anonymous2019domain,    &#10;title={DOMAIN ADAPTATION VIA DISTRIBUTION AND REPRESENTATION MATCHING: A CASE STUDY ON TRAINING DATA SELECTION VIA REINFORCEMENT LEARNING},    &#10;author={Anonymous},    &#10;booktitle={Submitted to International Conference on Learning Representations},    &#10;year={2019},    &#10;url={https://openreview.net/forum?id=HyMnYiR9Y7},    &#10;note={under review}    &#10;}">Show Bibtex</a></span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Abstract: </span><span class="note_content_value">Supervised models suffer from domain shifting where distribution mismatch across domains greatly affect model performance. Particularly, noise scattered in each domain has played a crucial role in representing such distribution, especially in various natural language processing (NLP) tasks. In addressing this issue, training data selection (TDS) has been proven to be a prospective way to train supervised models with higher performance and efficiency. Following the TDS methodology, in this paper, we propose a general data selection framework with representation learning and distribution matching simultaneously for domain adaptation on neural models. In doing so, we formulate TDS as a novel selection process based on a learned distribution from the input data, which is produced by a trainable selection distribution generator (SDG) that is optimized by reinforcement learning (RL). Then, the model trained by the selected data not only predicts the target domain data in a specific task, but also provides input for the value function of the RL. Experiments are conducted on three typical NLP tasks, namely, part-of-speech tagging, dependency parsing, and sentiment analysis. Results demonstrate the validity and effectiveness of our approach.</span></div><div class="note_contents"><span class="note_content_field">Keywords: </span><span class="note_content_value">domain adaptation, training data selection, reinforcement learning, natural language processing</span></div><div class="note_contents"><span class="note_content_field">TL;DR: </span><span class="note_content_value">Training data selection via reinforcement learning</span></div><div class="reply_row clearfix"><div class="item" id="reply_count">3 Replies</div></div></div><hr class="small" /><div id="note_children"><div class="note_with_children"><div id="note_ryxkLEtc2X" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Promising experiments, but I was confused about the method details and motivations</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HyMnYiR9Y7&amp;noteId=ryxkLEtc2X"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper483 AnonReviewer1</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">03 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper483 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">Domain adaptation is an interesting task, and new methods for it would be welcome.  This paper appears to have technical depth and the experimental results are promising.  However, the presented approach is complex, and I found it very hard to understand -- both in terms of how exactly it works, and in terms of why the chosen techniques were chosen.  More detail on my questions and confusions follows.

First, I never understood the motivation for using RL here.  If minimizing the distance between selected data from the source domain and data in the target domain is the objective (equation 1), how does RL help?  The reward seems like it is immediate in each time step.  How does the *order* in which we add source examples to our collection matter?  I never understood the crucial difference that made the RL approach outperform the baselines that just select examples that minimize e.g. JS divergence.  Neither the paper's discussion of motivation nor the experimental analysis clarifies this.

The paper says in Section 2.1 that a formal description of the representations is to follow.  I didn't see this description (I do not see a formal definition of how the feature extractor works, and e.g. how it produces vectors that are *distributions* that can be used within e.g. JS divergence).

The paper also says it follows (Ruder and Plank, 2017) in using JS as a baseline, but as I understand that work the JS baseline is computed over words, not learned representations.  What is done in the submission, is the JS baseline over words in the instances, or the representations from the feature extractor?

What is the reason for partitioning the source data into disjoint "data bags"?  Why not just select the best source domain examples (from among all the source data) using RL?

The experiments are generally over enough tasks and compare against several baselines, and although the empirical wins are not that large I feel that they would be sufficient for publication if not for my other concerns.  The analysis (sec 4) did not make it clear to me why the RL approach works.  The visualization in Figure 3 only contrasts the proposed approach with a weak baseline of selecting all source data -- what we really need to see is an analysis that reveals why the learning of a policy with RL is better than simply greedily minimizing JS for each source data selection, for up to some limit of n selections.

Minor
The paper has a number of typos
The citations in the paper are mis-formatted -- seem to use shortcite where they shouldn't (e.g. "scenarios Akopyan and Khashba (2017)" should be "scenarios (Akopyan and Khashba, 2017)").
When the policy \pi_w(a | s) is introduced at the start of Sec 2.2, it uses symbols (a, s) that have not been defined, also that policy variable is not really utilized in the text so it could be deleted.</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">4: Ok but not good enough - rejection</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_Hye68GV93m" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Interesting approach for learning domain-invariant features + dataset selection</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HyMnYiR9Y7&amp;noteId=Hye68GV93m"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper483 AnonReviewer2</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">03 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper483 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">== Originality ==
The idea of matching features/representations across the source domain and target domain is an old idea, but it is executed in an interesting new way in this paper.

In this approach, feature representations are learned by training a neural classifier on the source domain, and an RL agent influences the feature representation by iteratively adding/removing examples from the source training data. The RL agent receives reward when the resulting feature representation causes the source domain data and target domain data to look more similar in distribution in feature space. To efficiently estimate the improvement in feature matching, a nice data bucketing strategy is used.

The novelty of the approach is the main strength of this paper.

== Quality of results ==
The experimental results seemed overall positive, but I felt that they could have been stronger.

For POS tagging, the authors don't compare against the domain adaptation methods mentioned in their related work section. Instead, they compare against Bayesian optimization using several heuristic criteria, and it was unclear where this baseline comes from. This made it hard to see whether the new approach represents a true improvement over existing techniques.

For dependency parsing, it appears that the proposed approach is outperformed by simply training on all of the source domain data.  It would be interesting to know whether this is because feature-matching is not a good proxy for target domain performance (objective mismatch) or whether the RL system converged to a poor local optima (optimization failure).

== Clarity ==
I felt that the abstract and introduction were vague in describing the main conceptual contribution.

However, Section 2 (The Approach) was clearly written and I came away understanding exactly what the authors are doing.

== Minor comments ==
- Algorithm 1 seems to have a typo: the definition of \nabla \tilde{J}(W) on the second to last line seems to be missing \nabla \log \pi
- Many citations throughout the paper need to be wrapped in parentheses

== Conclusion ==
This paper presents an interesting new approach for dataset selection and learning domain-invariant representations.

Pros:
- originality of the approach

Cons:
- Experiments could have been more convincing:
    - should compare against at least one other state-of-the-art domain adaptation method
    - results on dependency parsing (the most challenging task they consider) were mostly negative
    - evaluation on other more recent multi-domain NLP tasks would have been nice (e.g. MultiNLI)
- Abstract and intro could provide better description of the conceptual contribution, as well as motivation</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">7: Good paper, accept</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">3: The reviewer is fairly confident that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_S1xEN_Sfhm" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>This paper proposes an algorithm that jointly selects training samples for domain adaptation and performs a down stream task such as classification, POS tagging, parsing etc. While the proposed model is interesting and innovative, experimental evaluations are largely lacking and insufficient to establish claims of the authors.</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HyMnYiR9Y7&amp;noteId=S1xEN_Sfhm"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper483 AnonReviewer3</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">28 Oct 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper483 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">The paper aims to address issues with Domain Adaptation by using RL approaches. Domain Adaptation is an actively studied area in NLP research and so this paper is relevant and timely. This paper proposes and algorithm that is in line with work that aims at selecting data smartly when performing Domain Adaptation. The proposed algorithm learns representations for text in the source and target domains jointly. The proposed algorithm has two components i) a selection distribution generator (SDG) and ii) a task specific prediction for tasks being POS tagging, Dependency parsing and Sentiment Analysis.

While the proposed algorithm is interesting from a RL perspective and make sense, there is no explanation provided as to why this algorithm should do better over non RL based approaches for tasks such as Sentiment Analysis.

Domain Adaptation is widely studied for Sentiment Analysis and a lot of current research focuses on the various aspects of domain data, such as word and sentence level semantics, when developing algorithms. For example the following papers all (saving the third) address the problem of Domain Adaptation for Sentiment Analysis through various approaches fairly similar to the authors' algorithm, that provide similar if not better results than those provided in the paper,

[1]Barnes, Jeremy, Roman Klinger, and Sabine Schulte im Walde. "Projecting Embeddings for Domain Adaption: Joint Modeling of Sentiment Analysis in Diverse Domains." arXiv preprint arXiv:1806.04381 (2018).
[2] Ziser, Yftah, and Roi Reichart. "Pivot Based Language Modeling for Improved Neural Domain Adaptation." In Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers), vol. 1, pp. 1241-1251. 2018.
[3]An, Jisun, Haewoon Kwak, and Yong-Yeol Ahn. "SemAxis: A Lightweight Framework to Characterize Domain-Specific Word Semantics Beyond Sentiment." arXiv preprint arXiv:1806.05521 (2018).

Particularly the second paper is a clear improvement over SCL (the earlier pivot based approach), a baseline that is considered by the authors in this work. There are no comparisons against this work in this paper, yet the authors compare against SCL alone.

Due to lack of comparisons against state-of-the-art in Sentiment Analysis/Domain Adaptation for Sentiment Analysis it is hard to accept the claims made by the authors on the superiority of their algorithm. Had their paper aimed at improving over other RL based approaches for Domain Adaptation for Sentiment Analysis, some experiments could be over looked. 

But, when making a claim that addresses the problem of Sentiment Analysis, comparisons against the state-of-the-art non RL based approaches is extremely important. Particularly, given the size of the data sets used, one could use lexical/dictionary based approaches [3] and improve upon the classification accuracies without having to train such an involved algorithm.

Furthermore there is no qualitative analysis provided to gain insights into the behavior of the embeddings spaces of the target and source domains that are learned jointly via the proposed algorithm. At least such an analysis would have provided some insight into why the authors' RL based solution is better than a non RL based solution.

The lack of reference or comparisons against relevant literature is future highlighted by the seemingly relevant, yet largely dated related works section.
</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">5: Marginally below acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></main></div>
  </div>
</div>


    <!-- Footer -->
    <footer class="sitemap">
      <div class="container">
        <div class="row hidden-xs">
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/venues">All Venues</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="/contact">Contact</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
    
        <div class="row visible-xs-block">
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/contact">Contact</a></li>
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
      </div>
    </footer>
    
    <footer class="sponsor">
      <div class="container">
        <div class="row">
          <div class="col-sm-10 col-sm-offset-1">
            <p class="text-center">
              OpenReview is created by the <a href="http://www.iesl.cs.umass.edu/" target="_blank">Information Extraction and Synthesis Laboratory</a>, College of Information and Computer Science, University of Massachusetts Amherst. We gratefully acknowledge the support of the OpenReview sponsors:  Google,  Facebook, NSF, the University of Massachusetts Amherst Center for Data Science, and Center for Intelligent Information Retrieval, as well as the Google Cloud Platform for donating the computing and networking services on which OpenReview.net runs.
            </p>
          </div>
        </div>
      </div>
    </footer>

  <div id="feedback-modal" class="modal fade" tabindex="-1" role="dialog">
    <div class="modal-dialog">
      <div class="modal-content">
        <div class="modal-header">
          <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button>
          <h3 class="modal-title">Send Feedback</h3>
        </div>
        <div class="modal-body">
          <p>Enter your feedback below and we'll get back to you as soon as possible.</p>
          <form action="/feedback" method="POST">
            <div class="form-group">
              <input type="email" name="from" class="form-control" placeholder="Email" />
            </div>
            <div class="form-group">
              <input type="text" name="subject" class="form-control" placeholder="Subject" />
            </div>
            <div class="form-group">
              <textarea name="message" class="form-control feedback-input" rows="5" placeholder="Message" required=""></textarea>
            </div>
          <ul id="ui-id-2" tabindex="0" class="ui-menu ui-widget ui-widget-content" style="display: none;"></ul></form>
        </div>
        <div class="modal-footer">
          <button type="button" class="btn btn-default" data-dismiss="modal">Cancel</button>
          <button type="button" class="btn btn-primary">Send</button>
        </div>
      </div>
    </div>
  </div>

  <script type="text/javascript" async="" src="https://www.google-analytics.com/analytics.js"></script><script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js"></script>
  <script>window.jQuery || document.write('&lt;script src="/static/js/vendor/jquery-2.2.4.min.js"&gt;&lt;\/script&gt;')</script>

  <script src="/static/dist/vendor.min.js"></script>
  <script src="/static/dist/templates.min.js"></script>
  <script src="/static/dist/openreview.min.js"></script>

    <script>window.legacyScripts = true;</script>


    <script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-108703919-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() { dataLayer.push(arguments); }
      gtag('js', new Date());
      gtag('config', 'UA-108703919-1');
    </script>


<div role="status" aria-live="assertive" aria-relevant="additions" class="ui-helper-hidden-accessible"></div></body></html>
<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" class="no-js"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>Rotation Equivariant Networks via Conic Convolution and the DFT | OpenReview</title>
  <meta name="description" content="" />

      <meta name="citation_title" content="Rotation Equivariant Networks via Conic Convolution and the DFT" />
        <meta name="citation_author" content="Anonymous" />
      <meta name="citation_publication_date" content="2018/09/27" />
      <meta name="citation_online_date" content="2018/09/27" />
      <meta name="citation_pdf_url" content="https://openreview.net/pdf?id=BJepX2A9tX" />
      <meta name="twitter:card" content="summary" />
      <meta name="twitter:site" content="@openreviewnet" />
      <meta name="og:title" content="Rotation Equivariant Networks via Conic Convolution and the DFT" />
      <meta name="og:description" content="Performance of neural networks can be significantly improved by encoding known invariance for particular tasks. Many image classification tasks, such as those related to cellular imaging, exhibit..." />
      <meta name="og:image" content="https://openreview.net/static/images/openreview_logo_512.png" />

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans:400,400i,700,700i" />

  <link rel="stylesheet" href="/static/css/bootstrap.min.css" />
  <link rel="stylesheet" href="/static/css/jquery-ui.min.css" />
  <link rel="stylesheet" href="/static/css/main.min.css" />
</head>

<body class="forum">
  <nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
  
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand home push-link" href="/"><strong>OpenReview</strong>.net</a>
      </div>
  
      <div id="navbar" class="navbar-collapse collapse">
        <form class="navbar-form navbar-left profile-search" role="search">
          <div class="form-group has-feedback">
            <input id="search_input" type="text" class="form-control ui-autocomplete-input" placeholder="Search ICLR 2019 Conference" autocomplete="off" />
            <span class="glyphicon glyphicon-search form-control-feedback" aria-hidden="true"></span>
          </div>
  
          <input id="search_group" type="hidden" value="ICLR.cc/2019/Conference" />
          <input id="search_content" type="hidden" value="all" />
        <ul id="ui-id-1" tabindex="0" class="ui-menu ui-widget ui-widget-content ui-autocomplete ui-front" style="display: none;"></ul></form>
  
        <ul class="nav navbar-nav navbar-right">
        
            <li id="user-menu"><a href="/login">Login</a></li>
        </ul>
      </div>
  
    </div>
  </nav>

  <div id="or-banner" class="banner" style="">
  <div class="container">
    <div class="row">
      <div class="col-xs-12"><a href="/group?id=ICLR.cc/2019/Conference" title="Venue Homepage"><img class="icon" src="/static/images/arrow_left.svg" /> Go to <strong>ICLR 2019 Conference</strong> homepage</a></div>
    </div>
  </div>
</div>
<div id="flash-message-container" class="alert alert-danger" role="alert" style="display: none;">
  <div class="container">
    <div class="row">
      <div class="col-xs-12">
        <div class="alert-content">
          <button type="button" class="close" aria-label="Close"><span aria-hidden="true">×</span></button>
        </div>
      </div>
    </div>
  </div>
</div>

<div class="container">
  <div class="row">
    <div class="col-xs-12">
      <main id="content" class="clearfix openbanner-visible legacy-styles"><div id="note_BJepX2A9tX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Rotation Equivariant Networks via Conic Convolution and the DFT</a> <a class="note_content_pdf" href="/pdf?id=BJepX2A9tX" title="Download PDF" target="_blank"><img src="/static/images/pdf_icon_blue.svg" /></a> </h2></div><div class="meta_row"><span class="signatures">Anonymous</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">28 Sep 2018 (modified: 11 Oct 2018)</span><span class="item">ICLR 2019 Conference Blind Submission</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span><span class="item"><a class="action-bibtex-modal" data-bibtex="@inproceedings{    &#10;anonymous2019rotation,    &#10;title={Rotation Equivariant Networks via Conic Convolution and the DFT},    &#10;author={Anonymous},    &#10;booktitle={Submitted to International Conference on Learning Representations},    &#10;year={2019},    &#10;url={https://openreview.net/forum?id=BJepX2A9tX},    &#10;note={under review}    &#10;}">Show Bibtex</a></span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Abstract: </span><span class="note_content_value">Performance of neural networks can be significantly improved by encoding known invariance for particular tasks. Many image classification tasks, such as those related to cellular imaging, exhibit invariance to rotation. In particular, to aid convolutional neural networks in learning rotation invariance, we consider a simple, efficient conic convolutional scheme that encodes rotational equivariance, along with a method for integrating the magnitude response of the 2D-discrete-Fourier transform (2D-DFT) to encode global rotational invariance. We call our new method the Conic Convolution and DFT Network (CFNet). We evaluated the efficacy of CFNet as compared to a standard CNN and group-equivariant CNN (G-CNN) for several different image classification tasks and demonstrated improved performance, including classification accuracy, computational efficiency, and its robustness to hyperparameter selection. Taken together, we believe CFNet represents a new scheme that has the potential to improve many imaging analysis applications.</span></div><div class="note_contents"><span class="note_content_field">Keywords: </span><span class="note_content_value">deep learning, rotation equivariance, bioimaging analysis</span></div><div class="note_contents"><span class="note_content_field">TL;DR: </span><span class="note_content_value">We propose conic convolution and the 2D-DFT to encode rotation equivariance into an neural network.</span></div><div class="reply_row clearfix"><div class="item" id="reply_count">3 Replies</div></div></div><hr class="small" /><div id="note_children"><div class="note_with_children"><div id="note_Hkgm-rB22m" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Okay paper with limited novelty and lacking experimental evidence for main supposed advantages of proposed method</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=BJepX2A9tX&amp;noteId=Hkgm-rB22m"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1399 AnonReviewer3</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">04 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper1399 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">Disclaimer: I've already reviewed an earlier version of this manuscript for NIPS 2018.

# Summary

In the context of image classification, the paper proposes a convolutional neural network architecture with rotation-equivariant feature maps that are eventually made rotation-invariant by using the magnitude of the 2D discrete Fourier transform (DFT). Classification experiments are conducted on three different datasets.

The problem of rotation-invariant image classification addressed by the paper is important, since structures in images may appear at arbitrary orientations in many applications (e.g. microscopy).


# Novelty

The general ideas of the paper are sound, however seem to be of rather minor novelty.
The paper claims two main novelties: (1) conic convolutions and (2) using the DFT magnitude for rotation invariant classification in the context of CNNs.
- While (1) seems novel, the paper doesn't convince me that conic convolutions would be useful in practice. While they are more memory efficient, they achieve this by actually computing fewer features (each conic region is only processed by a particular orientation of a convolution kernel). Hence, they should (theoretically) be less powerful than group convolutions (i.e. G-CNN; the whole image is processed by a particular orientation of a convolution kernel). Furthermore, there are no experiments that demonstrate the advantages of the lower memory footprint of conic convolutions.
- Novelty (2) is only because it hasn't been used in the context of CNNS, but there is no technical novelty here. Using the DFT magnitude for rotational invariance is an orthogonal contribution that can also be applied to G-CNN, which the paper also evaluates (this is good).


# Experiments

- Rotation-equivariant CNNs are expected to perform better than standard CNNs when only limited training data is available. However, this is not thoroughly evaluated in the paper, which only does a very coarse comparison (trained with N=50 or N=100 images). Since this is the main advantage of of CNNs with built-in rotation-equivariance, I expect a more thorough evaluation showing the results for several different training data sizes.
- The savings in terms of computational and especially storage efficiency of CFNet are not really evaluated, only briefly mentioned in the very short section 3.4. Again, this needs to be expanded since computational/memory efficient is a supposed main advantage of conic convolutions over group convolutions.

- In section 4.2: Why are image rotations used for data augmentation? (The whole point of the compared classification methods (expect for "CNN") is to be rotation-invariant.) It would be interesting to show the results with and without image rotation augmentation.
- G-CNN+DFT is missing for the budding yeast cell classification experiment (section 4.3). As mentioned before, I suspect it would perform well or even better than CFNet. Also, why is Worrall et al. (2017) not compared to in sections 4.2 and 4.3.? (It was the best method in for rotation-MNIST.)


# Clarity

Although the writing is grammatically well done, I found it difficult to follow the explanation of the proposed method. In particular, the mathematics often add to my confusion instead of clearing it up. Given that the proposed concepts are not actually that complicated, I feel the paper makes heavy use of *mathiness* ("the use of mathematics that obfuscates or impresses rather than clarifies" [1]).

[1]: Zachary C. Lipton, Jacob Steinhardt. "Troubling Trends in Machine Learning Scholarship.", <a href="https://arxiv.org/abs/1807.03341" target="_blank" rel="nofollow">https://arxiv.org/abs/1807.03341</a>


# Missing explanations

- Standard pooling will not preserve rotation-equivariance (RE). While section 3.2 mentions this, it doesn't really explain how pooling is changed to preserve RE. Furthermore, it is also not explained why a deep network based on conic convolutions remains RE after several downsampling and conic convolution layers. I feel there's a problem when the conic regions become tiny after several downsampling operations. Fig. 2 shows that fewer conic regions are used then, limiting the equivariance to 90 degree rotations. This seems like a conceptual limitation.
- The paper says that the conic convolution layer uses a "filter size of three pixels", but fails to mention that this means there are currently strong interpolation artifacts, especially for finer degrees of rotation (the paper only rotates at most 8 times). Section 4 only briefly mentions that this would be alleviated by using steerable filters.</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">4: Ok but not good enough - rejection</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_HJevN-1FnX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>interesting idea of some novelty, difficult to read if you're not an expert</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=BJepX2A9tX&amp;noteId=HJevN-1FnX"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1399 AnonReviewer2</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">02 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper1399 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">The authors propose (1)  a new method for constructing rotation equivariant networks using 'conic' convolution, and then furthermore propose (2) to integrate the magnitude response of the 2D-discrete Fourier transform into a transition layer between convolutional and fully connected layers to get rotational invariance.  

The conceptual advantage over earlier approaches to (1) such as group convolution is that one operates only over the spatial domain., making it more intuitive (or so the authors claim) and also computationally more efficient.

The advantage of (2) is that invariance is achieved without throwing away useful information (such as earlier approaches did which took e.g. average or maximum. 

The practical advantage of (1) and (2) is that the experiments suggests that it works better than earlier approaches. 

PRO
- Both ideas are reasonable and the experiments suggest that they indeed improve noticeably on state of the art

CON
- Given the earlier work (especially the group convolution CNN) the developments here are not that surprising
- The paper, while well-written in the sense of organization, grammar etc. was still quite a hard read for me; if one is not an expert on invariance/equivariance etc. then one has a hard time. Combining this paper with the Cohen/Welling paper I managed to understand most things in the end, and admittedly I am not an expert (something went wrong with the assignment process here...) but still, I feel things can be improved here. 
</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">7: Good paper, accept</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_rJx7KeaV37" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>A reasonable solution to achieve rotation invariant representation, but experimental and analytic parts should be enhanced. </a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=BJepX2A9tX&amp;noteId=rJx7KeaV37"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1399 AnonReviewer1</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">30 Oct 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper1399 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">Authors provide a rotation invariant neural network via combining conic convolution and 2D-DFT.
The proposed conic convolution is a natural extension of quadrant convolution, which modulates directional convolution results with a direction-related mask. 
The magnitude response of a 2D-DFT is applied to the output of the conic convolution, which further achieves a rotation invariant transformation to the rotation invariant features. 

Comments:
1. Both the conic convolution and 2D-DFT module are rotation invariant transformation, which one is more important for the model? I think the G-CNN + DFT is a good baseline to evaluate the importance of the conic convolution part, and authors should take the variant “the Conic Conv without DFT” into consideration, such that the contribution of the DFT module can be shown quantitatively. 
2. Compared with H-Net, the proposed CFNet is slightly worse on the testing error shown in Table 1. Could authors analyze the potential reason for this phenomenon? Compared with H-net, what is the advantage of the proposed method?
3. In Figure 3(c, d), the learning curves of the proposed CFNet are not as stable as those of its baselines, especially in the initial training phase. What is the reason? And how the configure the hyperparameters of the model?

Minors:
- Section 3.1 is a little redundant in my opinion. Many simple and well-known background/properties are shown, which can be compressed.
- Line 4 of Figure 1’s caption, 90 degrees -&gt; 180 degrees?</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">6: Marginally above acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">3: The reviewer is fairly confident that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></main></div>
  </div>
</div>


    <!-- Footer -->
    <footer class="sitemap">
      <div class="container">
        <div class="row hidden-xs">
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/venues">All Venues</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="/contact">Contact</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
    
        <div class="row visible-xs-block">
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/contact">Contact</a></li>
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
      </div>
    </footer>
    
    <footer class="sponsor">
      <div class="container">
        <div class="row">
          <div class="col-sm-10 col-sm-offset-1">
            <p class="text-center">
              OpenReview is created by the <a href="http://www.iesl.cs.umass.edu/" target="_blank">Information Extraction and Synthesis Laboratory</a>, College of Information and Computer Science, University of Massachusetts Amherst. We gratefully acknowledge the support of the OpenReview sponsors:  Google,  Facebook, NSF, the University of Massachusetts Amherst Center for Data Science, and Center for Intelligent Information Retrieval, as well as the Google Cloud Platform for donating the computing and networking services on which OpenReview.net runs.
            </p>
          </div>
        </div>
      </div>
    </footer>

  <div id="feedback-modal" class="modal fade" tabindex="-1" role="dialog">
    <div class="modal-dialog">
      <div class="modal-content">
        <div class="modal-header">
          <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button>
          <h3 class="modal-title">Send Feedback</h3>
        </div>
        <div class="modal-body">
          <p>Enter your feedback below and we'll get back to you as soon as possible.</p>
          <form action="/feedback" method="POST">
            <div class="form-group">
              <input type="email" name="from" class="form-control" placeholder="Email" />
            </div>
            <div class="form-group">
              <input type="text" name="subject" class="form-control" placeholder="Subject" />
            </div>
            <div class="form-group">
              <textarea name="message" class="form-control feedback-input" rows="5" placeholder="Message" required=""></textarea>
            </div>
          <ul id="ui-id-2" tabindex="0" class="ui-menu ui-widget ui-widget-content" style="display: none;"></ul></form>
        </div>
        <div class="modal-footer">
          <button type="button" class="btn btn-default" data-dismiss="modal">Cancel</button>
          <button type="button" class="btn btn-primary">Send</button>
        </div>
      </div>
    </div>
  </div>

  <script type="text/javascript" async="" src="https://www.google-analytics.com/analytics.js"></script><script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js"></script>
  <script>window.jQuery || document.write('&lt;script src="/static/js/vendor/jquery-2.2.4.min.js"&gt;&lt;\/script&gt;')</script>

  <script src="/static/dist/vendor.min.js"></script>
  <script src="/static/dist/templates.min.js"></script>
  <script src="/static/dist/openreview.min.js"></script>

    <script>window.legacyScripts = true;</script>


    <script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-108703919-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() { dataLayer.push(arguments); }
      gtag('js', new Date());
      gtag('config', 'UA-108703919-1');
    </script>


<div role="status" aria-live="assertive" aria-relevant="additions" class="ui-helper-hidden-accessible"></div></body></html>
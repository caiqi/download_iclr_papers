<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" class="no-js"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>Predicting the Generalization Gap in Deep Networks with Margin Distributions | OpenReview</title>
  <meta name="description" content="" />

      <meta name="citation_title" content="Predicting the Generalization Gap in Deep Networks with Margin Distributions" />
        <meta name="citation_author" content="Anonymous" />
      <meta name="citation_publication_date" content="2018/09/27" />
      <meta name="citation_online_date" content="2018/09/27" />
      <meta name="citation_pdf_url" content="https://openreview.net/pdf?id=HJlQfnCqKX" />
      <meta name="twitter:card" content="summary" />
      <meta name="twitter:site" content="@openreviewnet" />
      <meta name="og:title" content="Predicting the Generalization Gap in Deep Networks with Margin..." />
      <meta name="og:description" content="As shown in recent research, deep neural networks can perfectly fit randomly labeled data, but with very poor accuracy on held out data. This phenomenon indicates that loss functions such as..." />
      <meta name="og:image" content="https://openreview.net/static/images/openreview_logo_512.png" />

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans:400,400i,700,700i" />

  <link rel="stylesheet" href="/static/css/bootstrap.min.css" />
  <link rel="stylesheet" href="/static/css/jquery-ui.min.css" />
  <link rel="stylesheet" href="/static/css/main.min.css" />
</head>

<body class="forum">
  <nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
  
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand home push-link" href="/"><strong>OpenReview</strong>.net</a>
      </div>
  
      <div id="navbar" class="navbar-collapse collapse">
        <form class="navbar-form navbar-left profile-search" role="search">
          <div class="form-group has-feedback">
            <input id="search_input" type="text" class="form-control ui-autocomplete-input" placeholder="Search ICLR 2019 Conference" autocomplete="off" />
            <span class="glyphicon glyphicon-search form-control-feedback" aria-hidden="true"></span>
          </div>
  
          <input id="search_group" type="hidden" value="ICLR.cc/2019/Conference" />
          <input id="search_content" type="hidden" value="all" />
        <ul id="ui-id-1" tabindex="0" class="ui-menu ui-widget ui-widget-content ui-autocomplete ui-front" style="display: none;"></ul></form>
  
        <ul class="nav navbar-nav navbar-right">
        
            <li id="user-menu"><a href="/login">Login</a></li>
        </ul>
      </div>
  
    </div>
  </nav>

  <div id="or-banner" class="banner" style="">
  <div class="container">
    <div class="row">
      <div class="col-xs-12"><a href="/group?id=ICLR.cc/2019/Conference" title="Venue Homepage"><img class="icon" src="/static/images/arrow_left.svg" /> Go to <strong>ICLR 2019 Conference</strong> homepage</a></div>
    </div>
  </div>
</div>
<div id="flash-message-container" class="alert alert-danger" role="alert" style="display: none;">
  <div class="container">
    <div class="row">
      <div class="col-xs-12">
        <div class="alert-content">
          <button type="button" class="close" aria-label="Close"><span aria-hidden="true">×</span></button>
        </div>
      </div>
    </div>
  </div>
</div>

<div class="container">
  <div class="row">
    <div class="col-xs-12">
      <main id="content" class="clearfix openbanner-visible legacy-styles"><div id="note_HJlQfnCqKX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Predicting the Generalization Gap in Deep Networks with Margin Distributions</a> <a class="note_content_pdf" href="/pdf?id=HJlQfnCqKX" title="Download PDF" target="_blank"><img src="/static/images/pdf_icon_blue.svg" /></a> </h2></div><div class="meta_row"><span class="signatures">Anonymous</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">28 Sep 2018 (modified: 11 Oct 2018)</span><span class="item">ICLR 2019 Conference Blind Submission</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span><span class="item"><a class="action-bibtex-modal" data-bibtex="@inproceedings{    &#10;anonymous2019predicting,    &#10;title={Predicting the Generalization Gap in Deep Networks with Margin Distributions},    &#10;author={Anonymous},    &#10;booktitle={Submitted to International Conference on Learning Representations},    &#10;year={2019},    &#10;url={https://openreview.net/forum?id=HJlQfnCqKX},    &#10;note={under review}    &#10;}">Show Bibtex</a></span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Abstract: </span><span class="note_content_value">As shown in recent research, deep neural networks can perfectly fit randomly labeled data, but with very poor accuracy on held out data. This phenomenon indicates that loss functions such as cross-entropy are not a reliable indicator of generalization. This leads to the crucial question of how generalization gap should be predicted from the training data and network parameters. In this paper, we propose such a measure, and conduct extensive empirical studies on how well it can predict the generalization gap. Our measure is based on the concept of margin distribution, which are the distances of training points to the decision boundary. We find that it is necessary to use margin distributions at multiple layers of a deep network. On the CIFAR-10 and the CIFAR-100 datasets, our proposed measure correlates very strongly with the generalization gap. In addition, we find the following other factors to be of importance: normalizing margin values for scale independence, using characterizations of margin distribution rather than just the margin (closest distance to decision boundary), and working in log space instead of linear space (effectively using a product of margins rather than a sum).
Our measure can be easily applied to feedforward deep networks with any architecture and may point towards new training loss functions that could enable better generalization.</span></div><div class="note_contents"><span class="note_content_field">Keywords: </span><span class="note_content_value">Deep learning, large margin, generalization bounds, generalization gap.</span></div><div class="note_contents"><span class="note_content_field">TL;DR: </span><span class="note_content_value">We develop a new scheme to predict the generalization gap in deep networks with high accuracy.</span></div><div class="reply_row clearfix"><div class="item" id="reply_count">7 Replies</div></div></div><hr class="small" /><div id="note_children"><div class="note_with_children"><div id="note_SylJSZ_STX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>An empirical study towards the prediction power based on the margin distribution at each layer.</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HJlQfnCqKX&amp;noteId=SylJSZ_STX"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1249 AnonReviewer4</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">11 Nov 2018</span><span class="item">ICLR 2019 Conference Paper1249 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">The author(s) suggest using geometric margin and layer-wise margin distribution in [Elsayed et al. 2018] for predicting generalization gap.

pros,
a). The author shows large experiments to support their argument.

cons,
a). No theoretical verification (nor convincing intuition) is provided, especially for the following questions,
    i) what benefit can be acquired when using geometric margin defined in the paper.
    ii) why does normalization make sense beyond the simple scaling-free reason. For example, spectral complexity as a normalization factor in [Bartlett et al. 2017] is proposed from the fact, that the Lipschitz constant determines the complexity of network space.
    iii) why does the middle layer margin can help? 
    iv) why a linear (linear log) relation between the statistic and generalization gap.

Further question towards experiment,
i) I don't think your comparison with Bartlett's work is fair. Their bounds suggest the gap is approximately Prob(0&lt;X&lt;\gamma) + Const/\gamma for a chosen \gamma, where X is the normalized margin distribution. I think using the extracted signature from margin distribution and a linear predictor don't make sense here.
ii) If you do regression analysis on a five layers cnn, can you have a good prediction on a nine layers cnn (or even residue cnn)?

Finally, I'm not sure the novelty is strong enough since the margin definition comes from [Elsayed et al. 2018] and the strong linear relationship has been shown in [Bartlett et al. 2017, Liao et al. 2018] though in different settings.</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">5: Marginally below acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_Hkl7VhOqhX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>A nice empirical paper with good intuitions and encouraging results</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HJlQfnCqKX&amp;noteId=Hkl7VhOqhX"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1249 AnonReviewer1</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">03 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper1249 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">This paper does not even try to propose yet another "vacuous" generalization bounds, but instead empirically convincingly shows an interesting connection between the proposed margin statistics and the generalization gap, which could well be used to provide some "prescriptive" insights (per Sanjeev Arora) towards understanding generalization in deep neural nets.

I have no major complaints but for a few questions regarding clarifications,
1. From Eq.(5), such distances are defined for only one out of the many possible pairs of labels. So when forming the so-called "margin signature", how exactly do you compose it from all such pair-wise distances? Do you pool all the distances together before computing the statistics, or do you aggregate individual statistics from pair-wise distances? And how do you select which pairs to include or exclude? Are you assuming "i" is always the ground-truth label class for $x_k$ here?

2. In Eq.(3), the way you define the distance (that flipping i and j would change the sign of the distance) is implying that {i, j} should not be viewed as an unordered pair, in which case a better notation might be (i, j) (i.e. replacing sets "{}" with tuples "()" to signal that order matters).

And why do you "only consider distances with positive sign"? I can understand doing this for when neither i nor j corresponds to the ground-truth label of x, because you really can't tell which score should be higher. But when i happens to be the ground-truth label, wouldn't a positive distance and a negative distance be meaningful different and therefore it should only be beneficial to include both of them in the margin samples?

And a minor typo: In Eq.(4), $\bar{x}_k$ should have been $\bar{x}^l$?</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">9: Top 15% of accepted papers, strong accept</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_S1e5qVsQaQ" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Addressing your comments</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HJlQfnCqKX&amp;noteId=S1e5qVsQaQ"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1249 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">10 Nov 2018</span><span class="item">ICLR 2019 Conference Paper1249 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">We would like to thank you for your review and suggestions. We are very glad that you liked the empirical analysis of generalization gap and margin distribution statistics. On that note, while not mentioned in the paper, we are in preparation to release the  700+ models we used in the paper as a dataset where researchers can easily test theories on generalization. We believe this will be one of the first datasets for studying generalization on realistic and modern network architectures and we hope it will be instrumental in the ongoing generalization research.


## Construction of Signature from Pairwise Distances (i,j) in Eq (5) ##

For computational efficiency, we picked we pick ground truth label as "i" (as you correctly pointed out), and the highest non-ground truth logit as "j", and compute the distance between the two classes. While aggregating all pairwise distance might be more comprehensive, the complexity scales roughly quadratically with the number of classes. As such, we made the design choice to use the top two classes. In cases where the class with the highest logit is not the ground truth (hence misclassification with negative distance), we discard the data point. We will further explain this choice below. We mention this detail in the text but we will make sure it is more clear.


## Notation (i,j) instead of {i,j} to Emphasize Orderedness ##

Thank you for the suggestion. We agree and will incorporate this in the revision to avoid confusion.


## Why Only Positive Distances in Margin Distribution ##

You are right that when “i” is the ground truth label, the sign of the distance indicates whether the point is correctly classifier or is misclassified. 

We indeed investigated using negative distances when computing the margin distribution. We observed that:

1. Modern deep architectures often achieve near perfect classification on training data. Hence, the contribution of negative distances to the full distribution is negligible in most trained models.

2.  A small fraction of models do have notable misclassification (due to data augmentation or heavy regularization). For these models, we found that margin distribution computed with only positive samples predicted the generalization gap better than (or at par with) the full distribution. However, we observed that the latter is indeed a better predictor of test accuracy (just not the gap). Since we focus our narrative on the generalization gap, we decided to omit these results from the main paper; however, we will include these results in the appendix.
We also note that there is no technical problem in using margin distribution with only positive samples, e.g. Bartlett’s work “The Sample Complexity of Pattern Classification with Neural Networks” develops a generalization bound by such samples (paragraph above their Theorem 2).


## Typo ##

Thank you for pointing out the typo. It will be fixed in revision.
</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div><div class="note_with_children"><div id="note_H1xTRJmc3m" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Well written; technically weak</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HJlQfnCqKX&amp;noteId=H1xTRJmc3m"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1249 AnonReviewer2</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">03 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper1249 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">The paper is well written and is mostly clear. (1st line on page 4 has a typo, \bar{x}_k in eq (4) should be \bar{x}^l?)

Novelty: I am not sure whether the paper adds any significant on top of what we know from Bartlett et al., Elsayed et al. since:

(i). The fact that "normalized" margins are strongly correlated with the test set accuracy was shown in Bartlett et al. (figure 1.). A major part of the definition comes from there or from the reference they cite; 
(ii). Taylor approximation to compute the margin distribution is in Elsayed et al.; 
(iii). I think the four points listed in page 2 (which make the distinction between related work) is misleading: the way I see it is that the authors use the margin distribution in Elsayed et al which simply overcomes some of the obstacles that norm based margins may face. The only novelty here seems to be that the authors use the margin distribution at each layer. 

Technical pitfalls: Computing the d_{f,x,i,j} using Equation (3) is missing an absolute value in the numerator as in equation (7) Elsayed et al.. The authors interpret the negative values as misclassification: why is it true? The margin distribution used in Bartlett et al. (below Figure 4 on page 5 in arxiv:1706.08498) uses labeled data and it is obvious in this case to interpreting negative values as misclassification. I don't see how this is true for eq (3) here in this paper. Secondly, why are negative points ignored?? Misclassified points in my opinion are equally important, ignoring the information that a point is misclassified doesn't sound like a great idea. How do the experiments look if we don't ignore them?

Experiments: Good set of experiments. However I find the results to be mildly taking the claims of the authors made in four points listed in page 2 away: Section 4.1, "Empirically, we found constructing this only on four evenly-spaced layers, input, and 3 hidden layers, leads to good predictors.". How can the authors explain this? 

By using linear models, authors implicitly assume that the relationship between generalization gaps and signatures are linear (in Eucledian or log spaces). However, from the experiments (table 1), we see that log models always have better results than linear models. Even assuming linear relationship, I think it is informative to also provide other metrics such as MSE, AIC, BIC etc..</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">5: Marginally below acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_B1gSCYhmTX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Novelty, Experiments, Technical Details</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HJlQfnCqKX&amp;noteId=B1gSCYhmTX"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1249 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">10 Nov 2018</span><span class="item">ICLR 2019 Conference Paper1249 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">
We thank you for your insightful review.

## NOVELTY ##

R2: “The fact that normalized margins are correlated with generalization was shown in Bartlett Fig 1”.

As you pointed out, both works build on the broad notion of “margin distribution” and “normalization”. However, there are significant differences:
1. Margin in Bartlett uses f_i-f_j that can only reflect output margins, as opposed to (f_i-f_j)/||d/dx f_i - d/dx f_j|| that works for any layer.
2. We do not use margin distribution itself to predict the generalization gap, but rather distributional features that involve “nonlinear transform” of the distances (quartiles or moments).
3. Normalization in Bartlett’s uses norm of weight matrices, which is drastically different from geometric spread of activations (variance) we use (Eqs 4 and 5). Also their cannot be used as-is for residual networks, a drawback not present in our normalization. 

These distinctions result in very different predictions of the generalization, as clearly shown in our Fig 2 and Table 1. In fact, the choice of distributional features and normalization are crucial for accurate prediction of the generalization gap.

Finally, we have conducted a far larger scale of experiments, and will be releasing the 700+ realistic models used in the paper so that researchers can easily test generalization theories. This is the first of its kind. 


## TECHNICAL ##

# Missing Absolute Value in Eq (3) #

There is no incorrectness; we deliberately adopt “signed distance”. The polarity reflects which side of the decision boundary the point is. Even Eq (7) of Elsayed that you mentioned quickly evolves to signed distance in their Eq (8).

# Why Negative Distance Implies Misclassification #

It was our oversight not to mention that “i” in our Eq (3) corresponds to the ground truth label. We will clarify this in the final version. In this case, f_i-f_j&gt;0 (i.e. distance is positive) implies correct classification and f_i-f_j&lt;0 implies misclassification. 

# Why Negative Points are Ignored #

We indeed investigated using negative distances. We observed that:

1. Modern deep architectures often achieve near perfect classification on training data. Hence, the contribution of negative distances to the full distribution is negligible in most trained models.

2.  A small fraction of models do have notable misclassification (due to data augmentation or heavy regularization). For these models, we found that margin distribution computed with only positive samples predicted the generalization gap better than (or at par with) the full distribution. However, we observed that the latter is indeed a better predictor of test accuracy (just not the gap). Since we focus our narrative on the generalization gap, we decided to omit these results from the main paper; however, we will include these results in the appendix.
We also note that there is no technical problem in using margin distribution with only positive samples, e.g. Bartlett’s work “The Sample Complexity of Pattern Classification with Neural Networks” develops a generalization bound by such samples (paragraph above their Theorem 2).


## EXPERIMENTS ##

# Why 4 Layers and Why Even Spacing #
1. This leads to a fixed-length signature vector, hence agnostic to the architecture and depth.
2. Computing signature across all layers is expensive for large deep models.
3. Larger signature would require more pre-trained networks to avoid overfitting in regression phase. Given that each pre-trained network is only one sample in the regression task, creating a large pool of models is prohibitively expensive. Our study with 700 realistic sized pre-trained networks is perhaps already beyond the common practice for such empirical analysis. 
4. The even spacing is merely a natural choice of minimal commitment and already achieves near perfect prediction (CoD close to 1) is some scenarios. However, it is possible to examine other configurations.

# Log/Linear #
We are not sure if we understand the question. We provide an answer below, but if this is not what you meant, please let us know. We investigate the use of signature components in two ways: 1. Directly as the input to linear regression, 2. Applying an element-wise log to them before using them as input of the linear regression. In either case, the regression remains linear in optimization variables, but with the log transform we effectively regress the product of signature components to the gap value.

# Other Criteria (MSE, AIC, etc.) #
We have pointed out that the coefficient of determination already captures the MSE along with the scale of the error; however, for completeness, we will include this result in the appendix. We report k-fold cross validation results as well, which is known to be asymptotically equivalent to AIC (Stone M. (1977) An asymptotic equivalence of choice of model by cross-validation and Akaike’s criterion)</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div><div class="note_with_children"><div id="note_SJx6Hx-thX" class="note panel trashed"><div class="title_pdf_row clearfix"><h2 class="note_content_title">  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HJlQfnCqKX&amp;noteId=SJx6Hx-thX"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">[Deleted]</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="item">ICLR 2019 Conference Paper1249 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_BJgDuN3On7" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Some comments</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HJlQfnCqKX&amp;noteId=BJgDuN3On7"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">(anonymous)</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">02 Nov 2018</span><span class="item">ICLR 2019 Conference Paper1249 Public Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Introducing the theory of margin distribution into the framework of deep learning is an interesting idea. And it seems that there is a related work [Optimal margin Distribution Network, Submission to ICLR 2019], which has tried to design a new loss function based on margin distribution and theoretically proved its generalization effect. As I know, the influence of margin distribution has always been a concern for generalization theory. [Schapire, 1998] [Wang, 2011] [Gao, 2013], and there are several new algorithms based on the theory of margin distribution in both SVM [Zhang, 2017] and Clustering [Zhang, 2018] frameworks. I think that authors should read these papers and add references to them.
Regarding the content of the paper, I am confused about the linear (or log() ) estimation of the generalization gap: "$\hat{g} = a^T \phi(\theta) + b$". Does this formula have a theoretical analysis or some statistical models to explain it? It seems unreasonable to directly explain the relationship between margin distribution and generalization with a simple linear relationship. I expect that the authors can theoretically give a formula to explain the relationship between the generalization gap and the margin distribution.


[Optimal margin Distribution Network, Submission to ICLR 2019] Anonymous. “Optimal margin Distribution Network” Submitted to International Conference on Learning Representations 2019
[Schapire, 1998] Schapire, R., Freund, Y., Bartlett, P. L., Lee, W. Boosting the margin: A new explanation for the effectives of voting methods. Annuals of Statistics 26 (5), 1651–1686. 1998
[Wang, 2011] Wang, L. W., Sugiyama, M., Yang, C., Zhou, Z.-H., Feng, J. “A refined margin analysis for boosting algorithms via equilibrium margin.” Journal of Machine Learning Research 12, 1835–1863. 2011
[Gao, 2013] Gao, W., and Zhou, Z.-H. "On the doubt about margin explanation of boosting." Artificial Intelligence 203, 1-18. 2013
[Zhang, 2017] Zhang, T., Zhou, Z.-H. "Multi-Class Optimal Margin Distribution Machine." International Conference on Machine Learning. 2017.
[Zhang, 2018] Zhang, T., Zhou, Z.-H. "Optimal Margin Distribution Clustering." Proceedings of the National Conference on Artificial Intelligence, 2018.
</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_HkgvJXxt2Q" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Thanks for comments</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HJlQfnCqKX&amp;noteId=HkgvJXxt2Q"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1249 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">02 Nov 2018</span><span class="item">ICLR 2019 Conference Paper1249 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Thank you for your helpful comments.

### References ###

1. We agree that the interaction of margin and generalization has been subject to a great amount of research in classical ML literature. This makes it impossible to provide a comprehensive survey in a conference paper. So we had to narrow the scope of related works to recent papers that address generalization/margin in the case of *deep* models. Nonetheless, we will be happy to include the references on SVM and clustering that you suggested.

2. Regarding the other ICLR2019 submission you mentioned, obviously we were not aware of it prior to ICLR submission deadline (and it is not available on arxiv either). We are aware of that submission, but it seems to have some issues (reading the comments for the paper).

### Linear Assumption ###

1. Regarding your suspicion of linear relationship between margin and generalization gap: we are not directly relating the two using a linear map. Note that we are converting the margin distribution to a feature vector via a nonlinear map (quartiles/moments), and it is these features that are regressed to the generalization gap by a linear map. This is a widely used idea for nonlinear regression; e.g. as in kernel SVM for regression (nonlinear feature space followed by linear fitting). One could also train a nonlinear (deep) neural net to predict the gap, but it would need regularization and more data to avoid overfitting while a linear combination of simple distributional features already attains high quality prediction (see next point) across ~700 pretrained models. The latter suggests that a linear relationship is indeed a very close approximation.

2. The point of the paper is not to claim an optimal feature set, but to leverage *simple* and *easy to compute* features that could be extracted from the distribution (like quartiles or moments) can yet give a reasonable prediction of the generalization gap that is much better than recent theoretical upper bounds in the literature. We hope this could be a step toward constructing *practical* algorithms for improving generalization in deep networks. Regarding mathematical proof for why these features should explain the generalization gap: while such results would be very interesting, it is quite ambitious if not impossible. Nevertheless, we assess the quality of the linear fit using one of the standard statistical tools created for this purpose: Coefficient of Determination (CoD).  As mentioned in the paper, in some scenarios we observe CoD=0.97 (max is 1.0) which indicates a reasonably good fit.

</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div></div></main></div>
  </div>
</div>


    <!-- Footer -->
    <footer class="sitemap">
      <div class="container">
        <div class="row hidden-xs">
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/venues">All Venues</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="/contact">Contact</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
    
        <div class="row visible-xs-block">
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/contact">Contact</a></li>
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
      </div>
    </footer>
    
    <footer class="sponsor">
      <div class="container">
        <div class="row">
          <div class="col-sm-10 col-sm-offset-1">
            <p class="text-center">
              OpenReview is created by the <a href="http://www.iesl.cs.umass.edu/" target="_blank">Information Extraction and Synthesis Laboratory</a>, College of Information and Computer Science, University of Massachusetts Amherst. We gratefully acknowledge the support of the OpenReview sponsors:  Google,  Facebook, NSF, the University of Massachusetts Amherst Center for Data Science, and Center for Intelligent Information Retrieval, as well as the Google Cloud Platform for donating the computing and networking services on which OpenReview.net runs.
            </p>
          </div>
        </div>
      </div>
    </footer>

  <div id="feedback-modal" class="modal fade" tabindex="-1" role="dialog">
    <div class="modal-dialog">
      <div class="modal-content">
        <div class="modal-header">
          <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button>
          <h3 class="modal-title">Send Feedback</h3>
        </div>
        <div class="modal-body">
          <p>Enter your feedback below and we'll get back to you as soon as possible.</p>
          <form action="/feedback" method="POST">
            <div class="form-group">
              <input type="email" name="from" class="form-control" placeholder="Email" />
            </div>
            <div class="form-group">
              <input type="text" name="subject" class="form-control" placeholder="Subject" />
            </div>
            <div class="form-group">
              <textarea name="message" class="form-control feedback-input" rows="5" placeholder="Message" required=""></textarea>
            </div>
          <ul id="ui-id-2" tabindex="0" class="ui-menu ui-widget ui-widget-content" style="display: none;"></ul></form>
        </div>
        <div class="modal-footer">
          <button type="button" class="btn btn-default" data-dismiss="modal">Cancel</button>
          <button type="button" class="btn btn-primary">Send</button>
        </div>
      </div>
    </div>
  </div>

  <script type="text/javascript" async="" src="https://www.google-analytics.com/analytics.js"></script><script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js"></script>
  <script>window.jQuery || document.write('&lt;script src="/static/js/vendor/jquery-2.2.4.min.js"&gt;&lt;\/script&gt;')</script>

  <script src="/static/dist/vendor.min.js"></script>
  <script src="/static/dist/templates.min.js"></script>
  <script src="/static/dist/openreview.min.js"></script>

    <script>window.legacyScripts = true;</script>


    <script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-108703919-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() { dataLayer.push(arguments); }
      gtag('js', new Date());
      gtag('config', 'UA-108703919-1');
    </script>


<div role="status" aria-live="assertive" aria-relevant="additions" class="ui-helper-hidden-accessible"></div></body></html>
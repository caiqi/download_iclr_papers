<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" class="no-js"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>Structured Content Preservation for Unsupervised Text Style Transfer | OpenReview</title>
  <meta name="description" content="" />

      <meta name="citation_title" content="Structured Content Preservation for Unsupervised Text Style Transfer" />
        <meta name="citation_author" content="Anonymous" />
      <meta name="citation_publication_date" content="2018/09/27" />
      <meta name="citation_online_date" content="2018/09/27" />
      <meta name="citation_pdf_url" content="https://openreview.net/pdf?id=S1lCbhAqKX" />
      <meta name="twitter:card" content="summary" />
      <meta name="twitter:site" content="@openreviewnet" />
      <meta name="og:title" content="Structured Content Preservation for Unsupervised Text Style Transfer" />
      <meta name="og:description" content="Text style transfer aims to modify the style of a sentence while keeping its content unchanged. Recent style transfer systems often fail to faithfully preserve the content after changing the style...." />
      <meta name="og:image" content="https://openreview.net/static/images/openreview_logo_512.png" />

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans:400,400i,700,700i" />

  <link rel="stylesheet" href="/static/css/bootstrap.min.css" />
  <link rel="stylesheet" href="/static/css/jquery-ui.min.css" />
  <link rel="stylesheet" href="/static/css/main.min.css" />
</head>

<body class="forum">
  <nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
  
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand home push-link" href="/"><strong>OpenReview</strong>.net</a>
      </div>
  
      <div id="navbar" class="navbar-collapse collapse">
        <form class="navbar-form navbar-left profile-search" role="search">
          <div class="form-group has-feedback">
            <input id="search_input" type="text" class="form-control ui-autocomplete-input" placeholder="Search ICLR 2019 Conference" autocomplete="off" />
            <span class="glyphicon glyphicon-search form-control-feedback" aria-hidden="true"></span>
          </div>
  
          <input id="search_group" type="hidden" value="ICLR.cc/2019/Conference" />
          <input id="search_content" type="hidden" value="all" />
        <ul id="ui-id-1" tabindex="0" class="ui-menu ui-widget ui-widget-content ui-autocomplete ui-front" style="display: none;"></ul></form>
  
        <ul class="nav navbar-nav navbar-right">
        
            <li id="user-menu"><a href="/login">Login</a></li>
        </ul>
      </div>
  
    </div>
  </nav>

  <div id="or-banner" class="banner" style="">
  <div class="container">
    <div class="row">
      <div class="col-xs-12"><a href="/group?id=ICLR.cc/2019/Conference" title="Venue Homepage"><img class="icon" src="/static/images/arrow_left.svg" /> Go to <strong>ICLR 2019 Conference</strong> homepage</a></div>
    </div>
  </div>
</div>
<div id="flash-message-container" class="alert alert-danger" role="alert" style="display: none;">
  <div class="container">
    <div class="row">
      <div class="col-xs-12">
        <div class="alert-content">
          <button type="button" class="close" aria-label="Close"><span aria-hidden="true">×</span></button>
        </div>
      </div>
    </div>
  </div>
</div>

<div class="container">
  <div class="row">
    <div class="col-xs-12">
      <main id="content" class="clearfix openbanner-visible legacy-styles"><div id="note_S1lCbhAqKX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Structured Content Preservation for Unsupervised Text Style Transfer</a> <a class="note_content_pdf" href="/pdf?id=S1lCbhAqKX" title="Download PDF" target="_blank"><img src="/static/images/pdf_icon_blue.svg" /></a> </h2></div><div class="meta_row"><span class="signatures">Anonymous</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">28 Sep 2018 (modified: 11 Oct 2018)</span><span class="item">ICLR 2019 Conference Blind Submission</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span><span class="item"><a class="action-bibtex-modal" data-bibtex="@inproceedings{    &#10;anonymous2019structured,    &#10;title={Structured Content Preservation for Unsupervised Text Style Transfer},    &#10;author={Anonymous},    &#10;booktitle={Submitted to International Conference on Learning Representations},    &#10;year={2019},    &#10;url={https://openreview.net/forum?id=S1lCbhAqKX},    &#10;note={under review}    &#10;}">Show Bibtex</a></span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Abstract: </span><span class="note_content_value">Text style transfer aims to modify the style of a sentence while keeping its content unchanged. Recent style transfer systems often fail to faithfully preserve the content after changing the style. This paper proposes a structured content preserving model that leverages linguistic information in the structured fine-grained supervisions to better preserve the style-independent content \footnote{Henceforth, we refer to style-independent content as content, for simplicity.} during style transfer. In particular, we achieve the goal by devising rich model objectives based on both the sentence's lexical information and a language model that conditions on content. The resulting model therefore is encouraged to retain the semantic meaning of the target sentences. We perform extensive experiments that compare our model to other existing approaches in the tasks of sentiment and political slant transfer. Our model achieves significant improvement in terms of both content preservation and style transfer in automatic and human evaluation.</span></div><div class="note_contents"><span class="note_content_field">Keywords: </span><span class="note_content_value">Unsupervised text style transfer</span></div><div class="reply_row clearfix"><div class="item" id="reply_count">3 Replies</div></div></div><hr class="small" /><div id="note_children"><div class="note_with_children"><div id="note_BJlgKEfwpm" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>An approach for content preservation in style transfer</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=S1lCbhAqKX&amp;noteId=BJlgKEfwpm"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1219 AnonReviewer2</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">12 Nov 2018</span><span class="item">ICLR 2019 Conference Paper1219 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">The paper proposes a method to address the issue of content-preservation, which is usually not explicitly handled in approaches for unsupervised style transfer. The presented technique consists of extracting nouns from the input sentence (where the nouns are selected using POS tags), and encouraging the model to include the same nouns in the generated sentence, using two different losses: 1) one that comes from a language model conditioned on the nouns in the input sentence 2) one that combines the cosine distance between the input and the generated nouns embeddings. The model is evaluated on two different datasets: sentiment transfer and political slant transfer.

The use of a language model on the generated sentences was already done in "Unsupervised Text Style Transfer using Language Models as Discriminators" from Yang et al. (2018). The difference is that now the language model is conditioned on the input nouns, but the impact of this conditioning is not studied in the paper. It is also not totally obvious to me that a language model conditioned on the average of nouns embeddings will be able to exploit this information (unless there are only a couple of words?). Did you try to generate random tuples of 4 or 5 nouns and see what the language model samples when it is conditioned on the average of these nouns embeddings?

Although relatively simple, the model combines a lot of different elements (there are 4 different losses), and the impact of each of them is not really clear. It would have been nice to have a more detailed ablation study to see the impact of each loss. In particular, if the language model is conditioned on the content, why is lambda_POS still needed? Similarly, since you also condition the language model on the style, why is the classifier still needed? L_class and L_pos seem redundant with L_lm.

I was initially confused by the title "Structured content preservation" and the section title "POS preservation constraints". As far as I understand, the POS tags are only used to select the nouns in input and generated sentences, and are otherwise ignored. Similarly, the label "POS distance" in Table 1 seems inaccurate, instead I would rather call this "nouns distance". Also, I have a concern about this approach for content preservation. The way the loss works is only a "soft" way to ensure that the generated nouns are the same, in the sense that if 2 words have a very similar embedding, their cosine distances with any other word will also be very similar. As a result, if "orange" and "apple" are very close in the embedding space, and "orange" is the word in the input sentence, the model penalty for generating "apple" as opposed to "orange" will be very small. This is typically what happens for people's names that usually have very similar embeddings, this is why I don't find the explanation in 4.2.2 very satisfying.

Few questions:
1. The equation 8 is very unclear, I cannot understand what d_i is.
2. You set η to 0.5, α to 0.2, and β to 0.1. How did you find these hyper-parameters? Did you try other configurations? Although these losses have a different nature, it gives the feeling that the L_pos loss (which is the main novelty of the paper) with the coefficient β = 0.1 is the least important one.
3. Could you show some examples of Political Slant Transfer in Appendix?
4. In Table 2 you selected 100 random sentences from the test set. The original test set of 500 sentences is already quite small. Could you perform the evaluation on the full 500 sentences? The fact of selecting 100 random sentences will make it difficult for other research groups to reproduce and compare similar experiments.

Overall, I find the overall approach quite incremental. Given the previous studies of Hu et al and Yang et al, the novelty boils down to adding a coefficient L_pos, which I don't find particularly convincing, especially given the absence of ablation study.

Typos:
"Yep review" -&gt; "Yelp reviews" (3.3)
"BLUE score" -&gt; "BLEU score" (4.1.2 and 4.2.2)
"infomration" -&gt; "information" (4.1.2)</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">5: Marginally below acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_SJlT_AOhn7" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>A simple but effective improvement for style transfer</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=S1lCbhAqKX&amp;noteId=SJlT_AOhn7"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1219 AnonReviewer3</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">04 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper1219 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">Structured Content Preservation in Style Transfer

This paper presents a method for style transfer that using an autoencoder. The autoencoder trained to generate a meaning representation of the sentence. A decoder does the style transfer from this meaning representation. The decoder is trained to minimize style transfer loss and content loss. 

The new contribution here is a content loss (referred to as POS loss in the paper), which serves to penalize models that do not retain nouns in the output. 

Strengths:

1. The paper addresses an important problem in style transfer, one of balancing content loss versus changing style. 
2. The experiments include a manual evaluation in addition to automatic evaluation. 
3. The evaluations show that the proposed method is effective compared to style transfer methods that don't include this noun-based content loss.

Issues:

1. The manual evaluation seems to have conflated two dimensions of evaluation into a single rating. Specifically, the evaluation question is:  “Which sentence has an opposite sentiment of the original sentence and at the same time preserves the content of it?” What happens in cases where A preserves the content but does not style transfer and B transfers style but does not preserve content. Which one would the annotators choose? It would be useful to obtain two ratings and combine them instead of using a single one.

2. The idea of enforcing a content loss is well motivated but the approach considered seems rather heuristic. Selecting nouns is a useful start but as the authors point out that not all content words are nouns, and not all nouns are content words always. It would have been useful to consider other categories and quantify their impact in style transfer. 

3. It would have been useful to include an ablation where only the noun lm is used but not the training loss. 

4. The main gains come from using nouns as the set of content to preserve.  I wonder if there is a simpler baseline that uses the noun-based restriction also. A simple baseline for this idea could be to rescore beams using the same loss function (at test time only). 

5. Is there some information on inter-annotator agreement on this task. I suspect the task is straightforward enough that this might not be an issue but it would be useful to know. 

6. The difference in BLEU (Human) between the systems is not that large. However, the difference in terms of the manual evaluation is strikingly large. 
This kind of variance is observed often in language generation tasks. The authors should consider explaining why this difference is so large with a bit more analysis.

7. Why is the paper titled "structured"? It was not obvious to me what kind of structure is being inferred or used in this problem. Also, calling the POS distance is confusing as it seems to indicate that there is some POS tag sequence comparison being done here, which is not the case.

Overall this is a focused contribution that presents a simple yet effective empirical advance on style transfer for two types of tasks. 
</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">6: Marginally above acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">3: The reviewer is fairly confident that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_BJlIWk-UhQ" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>I am skeptical about the need of using POS tags for the text style transfer task.</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=S1lCbhAqKX&amp;noteId=BJlIWk-UhQ"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1219 AnonReviewer1</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">30 Oct 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper1219 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">The paper presents a neural network architecture for unsupervised text style transfer. The key differential of the proposed architecture is the use of part-of-speech tagging (POS) information to enforce  content preservation. The authors limit the use of POS tags to identify nouns, and employ them in the computation of two loss functions: POS loss and language model loss.
The authors present experimental results for two different datasets and show competitive results when compared with other recently proposed neural net architectures.

The paper have some major issues, as listed below, which makes me inclined to vote for rejection:
-	The novelty is very limited. The use of nouns to enforce content preservation was already explored by Melnyk et al. (2017) and the idea of using language models was already proposed by Yang et al (2018). Although the way that the losses are computed in each of these papers are somewhat different from the submitted paper, the key ingredients are the same. Additionally, the authors do not present any comparison with these methods.
-	The proposed strategy goes in a different direction of the current trend in Deep Learning-based NLP approaches. Researchers are trying to move away from classical pipelines that use NLP tools such as POS taggers. Moreover, it is not clear if the POS-based loss is essential for the architecture because there is no ablation experiments showing the importance of each one of the component: attention, POS loss, lm loss. The ablation experiment presented is quite weak and only shows the contribution of the lm loss. Additionally, another recent paper (dos Santos et al.  2018) has shown that just using back-translation or attention is enough to have good content preservation. In summary, I am skeptical about the need of using POS tags for the text style transfer task.

Some minor questions/comments:
(1)	Why do you name your method “structured”? Because of the use of nouns? As far as I understand, a set of nouns do not save the structure of the original sentence where they are employed.
(2)	Model description is not clear. Passages like “After switching the style representation, we can get the generated sentence ~yi” should be improved to include more detail and clarity.
(3)	What exactly is d_i in eq. (8)? Is it the normalized distance between the noun “i” in the input and all nouns in the output ?
(4)	The authors have used the following question for the human evaluators: “Which sentence has an opposite sentiment of the original sentence and at the same time preserves the content of it?”. I am not sure if this is the right question to be asked since it is quite geared towards the type of transfer that their model does. I was expecting a more neutral question.
(5)	The authors do not inform what POS extends for. Please note that ICLR has a diverse audience, NLP researchers are not the majority in this conference.


References:
Yang et al. Unsupervised Text Style Transfer using Language Models as Discriminators. Arxiv 2018
Dos Santos et al.  Fighting Offensive Language on Social Media with Unsupervised Text Style Transfer. ACL 2018.</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">4: Ok but not good enough - rejection</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></main></div>
  </div>
</div>


    <!-- Footer -->
    <footer class="sitemap">
      <div class="container">
        <div class="row hidden-xs">
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/venues">All Venues</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="/contact">Contact</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
    
        <div class="row visible-xs-block">
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/contact">Contact</a></li>
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
      </div>
    </footer>
    
    <footer class="sponsor">
      <div class="container">
        <div class="row">
          <div class="col-sm-10 col-sm-offset-1">
            <p class="text-center">
              OpenReview is created by the <a href="http://www.iesl.cs.umass.edu/" target="_blank">Information Extraction and Synthesis Laboratory</a>, College of Information and Computer Science, University of Massachusetts Amherst. We gratefully acknowledge the support of the OpenReview sponsors:  Google,  Facebook, NSF, the University of Massachusetts Amherst Center for Data Science, and Center for Intelligent Information Retrieval, as well as the Google Cloud Platform for donating the computing and networking services on which OpenReview.net runs.
            </p>
          </div>
        </div>
      </div>
    </footer>

  <div id="feedback-modal" class="modal fade" tabindex="-1" role="dialog">
    <div class="modal-dialog">
      <div class="modal-content">
        <div class="modal-header">
          <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button>
          <h3 class="modal-title">Send Feedback</h3>
        </div>
        <div class="modal-body">
          <p>Enter your feedback below and we'll get back to you as soon as possible.</p>
          <form action="/feedback" method="POST">
            <div class="form-group">
              <input type="email" name="from" class="form-control" placeholder="Email" />
            </div>
            <div class="form-group">
              <input type="text" name="subject" class="form-control" placeholder="Subject" />
            </div>
            <div class="form-group">
              <textarea name="message" class="form-control feedback-input" rows="5" placeholder="Message" required=""></textarea>
            </div>
          <ul id="ui-id-2" tabindex="0" class="ui-menu ui-widget ui-widget-content" style="display: none;"></ul></form>
        </div>
        <div class="modal-footer">
          <button type="button" class="btn btn-default" data-dismiss="modal">Cancel</button>
          <button type="button" class="btn btn-primary">Send</button>
        </div>
      </div>
    </div>
  </div>

  <script type="text/javascript" async="" src="https://www.google-analytics.com/analytics.js"></script><script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js"></script>
  <script>window.jQuery || document.write('&lt;script src="/static/js/vendor/jquery-2.2.4.min.js"&gt;&lt;\/script&gt;')</script>

  <script src="/static/dist/vendor.min.js"></script>
  <script src="/static/dist/templates.min.js"></script>
  <script src="/static/dist/openreview.min.js"></script>

    <script>window.legacyScripts = true;</script>


    <script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-108703919-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() { dataLayer.push(arguments); }
      gtag('js', new Date());
      gtag('config', 'UA-108703919-1');
    </script>


<div role="status" aria-live="assertive" aria-relevant="additions" class="ui-helper-hidden-accessible"></div></body></html>
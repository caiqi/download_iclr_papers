<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" class="no-js"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>Aggregated Momentum: Stability Through Passive Damping | OpenReview</title>
  <meta name="description" content="" />

      <meta name="citation_title" content="Aggregated Momentum: Stability Through Passive Damping" />
        <meta name="citation_author" content="Anonymous" />
      <meta name="citation_publication_date" content="2018/09/27" />
      <meta name="citation_online_date" content="2018/09/27" />
      <meta name="citation_pdf_url" content="https://openreview.net/pdf?id=Syxt5oC5YQ" />
      <meta name="twitter:card" content="summary" />
      <meta name="twitter:site" content="@openreviewnet" />
      <meta name="og:title" content="Aggregated Momentum: Stability Through Passive Damping" />
      <meta name="og:description" content="Momentum is a simple and widely used trick which allows gradient-based optimizers to pick up speed along low curvature directions. Its performance depends crucially on a damping coefficient...." />
      <meta name="og:image" content="https://openreview.net/static/images/openreview_logo_512.png" />

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans:400,400i,700,700i" />

  <link rel="stylesheet" href="/static/css/bootstrap.min.css" />
  <link rel="stylesheet" href="/static/css/jquery-ui.min.css" />
  <link rel="stylesheet" href="/static/css/main.min.css" />
</head>

<body class="forum">
  <nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
  
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand home push-link" href="/"><strong>OpenReview</strong>.net</a>
      </div>
  
      <div id="navbar" class="navbar-collapse collapse">
        <form class="navbar-form navbar-left profile-search" role="search">
          <div class="form-group has-feedback">
            <input id="search_input" type="text" class="form-control ui-autocomplete-input" placeholder="Search ICLR 2019 Conference" autocomplete="off" />
            <span class="glyphicon glyphicon-search form-control-feedback" aria-hidden="true"></span>
          </div>
  
          <input id="search_group" type="hidden" value="ICLR.cc/2019/Conference" />
          <input id="search_content" type="hidden" value="all" />
        <ul id="ui-id-1" tabindex="0" class="ui-menu ui-widget ui-widget-content ui-autocomplete ui-front" style="display: none;"></ul></form>
  
        <ul class="nav navbar-nav navbar-right">
        
            <li id="user-menu"><a href="/login">Login</a></li>
        </ul>
      </div>
  
    </div>
  </nav>

  <div id="or-banner" class="banner" style="">
  <div class="container">
    <div class="row">
      <div class="col-xs-12"><a href="/group?id=ICLR.cc/2019/Conference" title="Venue Homepage"><img class="icon" src="/static/images/arrow_left.svg" /> Go to <strong>ICLR 2019 Conference</strong> homepage</a></div>
    </div>
  </div>
</div>
<div id="flash-message-container" class="alert alert-danger" role="alert" style="display: none;">
  <div class="container">
    <div class="row">
      <div class="col-xs-12">
        <div class="alert-content">
          <button type="button" class="close" aria-label="Close"><span aria-hidden="true">×</span></button>
        </div>
      </div>
    </div>
  </div>
</div>

<div class="container">
  <div class="row">
    <div class="col-xs-12">
      <main id="content" class="clearfix openbanner-visible legacy-styles"><div id="note_Syxt5oC5YQ" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Aggregated Momentum: Stability Through Passive Damping</a> <a class="note_content_pdf" href="/pdf?id=Syxt5oC5YQ" title="Download PDF" target="_blank"><img src="/static/images/pdf_icon_blue.svg" /></a> </h2></div><div class="meta_row"><span class="signatures">Anonymous</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">28 Sep 2018 (modified: 18 Nov 2018)</span><span class="item">ICLR 2019 Conference Blind Submission</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span><span class="item"><a class="action-bibtex-modal" data-bibtex="@inproceedings{    &#10;anonymous2019aggregated,    &#10;title={Aggregated Momentum: Stability Through Passive Damping},    &#10;author={Anonymous},    &#10;booktitle={Submitted to International Conference on Learning Representations},    &#10;year={2019},    &#10;url={https://openreview.net/forum?id=Syxt5oC5YQ},    &#10;note={under review}    &#10;}">Show Bibtex</a></span><a class="note_content_pdf item" href="/revisions?id=Syxt5oC5YQ" target="_blank">Show Revisions</a></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Abstract: </span><span class="note_content_value">Momentum is a simple and widely used trick which allows gradient-based optimizers to pick up speed along low curvature directions. Its performance depends crucially on a damping coefficient. Largecamping  coefficients can potentially deliver much larger speedups, but are prone to oscillations and instability; hence one typically resorts to small values such as 0.5 or 0.9. We propose Aggregated Momentum (AggMo), a variant of momentum which combines multiple velocity vectors with different damping coefficients. AggMo is trivial to implement, but significantly dampens oscillations, enabling it to remain stable even for aggressive damping coefficients such as 0.999. We reinterpret Nesterov's accelerated gradient descent as a special case of AggMo and analyze rates of convergence for quadratic objectives. Empirically, we find that AggMo is a suitable drop-in replacement for other momentum methods, and frequently delivers faster convergence with little to no tuning.</span></div><div class="note_contents"><span class="note_content_field">Keywords: </span><span class="note_content_value">momentum, optimization, deep learning, neural networks</span></div><div class="note_contents"><span class="note_content_field">TL;DR: </span><span class="note_content_value">We introduce a simple variant of momentum optimization which is able to outperform classical momentum, Nesterov, and Adam on deep learning tasks with minimal hyperparameter tuning.</span></div><div class="reply_row clearfix"><div class="item" id="reply_count">7 Replies</div></div></div><hr class="small" /><div id="note_children"><div class="note_with_children"><div id="note_rJlsENApTX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Revision and comments uploaded</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=Syxt5oC5YQ&amp;noteId=rJlsENApTX"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper553 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">18 Nov 2018</span><span class="item">ICLR 2019 Conference Paper553 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Thank you to each reviewer for taking the time to evaluate our work!

We have revised our submission and provided detailed responses to each of you. We hope that these updates address your concerns and look forward to your responses.</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_Skg2m3o92X" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Nice algorithm that is simple yet effective and has good intuition</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=Syxt5oC5YQ&amp;noteId=Skg2m3o92X"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper553 AnonReviewer1</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">03 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper553 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">The paper introduces a variant of momentum that aggregates several velocities with different dampening coefficients. The proposed optimization algorithm can significantly decrease oscillation thus one can use much larger dampening coefficient to achieve faster convergence.

The paper does a good job of motivating the algorithm, both in terms of intuitive reasoning from physics, and some demonstrative examples. The paper also has nice analysis in the simple quadratic case where it tries to make equivalence to the Nesterov's accelerated gradients.

The experiments are also thorough and convincing since it contains various network architectures and different datasets. From the comparison, it seems AggMo consistently achieves the best or comparable performance even in test error/accuracies.

The connection to Nesterov's accelerated gradient and extragradient methods can be discussed in more details. It'll be nice to put the theoretical results in the main text as well.</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">7: Good paper, accept</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">3: The reviewer is fairly confident that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_HkeJFV0TTX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Thank you! Feedback integrated into paper.</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=Syxt5oC5YQ&amp;noteId=HkeJFV0TTX"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper553 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">18 Nov 2018</span><span class="item">ICLR 2019 Conference Paper553 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Thank you for your review!

We are glad that you found the experimental evidence convincing! For transparency, Reviewer 2 pointed out an issue with our reported numbers for the ResNet34 experiments. We have corrected these and provide a detailed response to Reviewer 2 directly. To summarize, AggMo still achieves the fastest overall convergence by a substantial margin but the baseline methods now match in final validation performance. All other empirical results are unaffected.

We have added some further discussion of the connection between AggMo and Nesterov momentum. If there is anything else that you would like to see we would be pleased to be told explicitly. We have also moved the online convex programming theoretical result in the main text. Thank you for the suggestion!</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div><div class="note_with_children"><div id="note_BJlejEkq3m" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Interesting but incremental</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=Syxt5oC5YQ&amp;noteId=BJlejEkq3m"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper553 AnonReviewer3</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">02 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper553 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">This paper proposed an aggregated momentum methods for gradient based optimization. The basic idea is instead of using a single velocity vector, multiple velocity vectors with different damping factors are used in order to improve the stability.

In term of novelty, the proposed method seems quite incremental. Using multiple velocity vectors seems interesting but not surprising, There is no theoretical guideline how to determine the number of velocity vectors and how to choose the damping factors. 

I would also suggest that authors should put some main theoretical results like the convergence analysis to the main paper instead of the appendix. 

In terms of the clarity, I think the paper is well written and the experiments are sufficient and convincing.

One minor question is: what is \lambda in Fig. 1?

 </span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">6: Marginally above acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">3: The reviewer is fairly confident that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_HylZgSRTTX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Thank you!</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=Syxt5oC5YQ&amp;noteId=HylZgSRTTX"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper553 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">18 Nov 2018</span><span class="item">ICLR 2019 Conference Paper553 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Thank you for your feedback!

We appreciate your honest comments on novelty, but respectfully disagree. We have intentionally presented AggMo in a simple form which makes it easily relatable to existing algorithms. However, AggMo realizes complex dynamics which in general escape many theoretical frameworks. In Appendix C.2 we show that AggMo can be written as a (K+1)-th order finite difference equation. We agree that AggMo is a simple extension of classical momentum but emphasize that most successful optimization algorithms are --- the challenge is in finding simple variants which perform well.

While we do not present theoretical guidelines for choosing damping factors, we conduct an extensive empirical study and suggest a range of choices which we found worked well consistently. Choosing optimization hyperparameters is a huge challenge in deep learning, even with well known, extensively explored optimizers. For example, while practitioners typically use a damping coefficient of 0.9 with CM we found that we could achieve better performance with larger coefficients (and carefully tuned learning rates). AggMo is able to use larger damping coefficients without such extensive tuning. Furthermore, AggMo is able to recover CM, NAG, and other algorithms and can make direct use of theoretical convergence results for these.

Per your suggestion, we have moved the online convex programming theoretical results into the main text.



&gt; What is \lambda in Fig. 1?

This indicates the eigenvalue associated with the plotted eigendirection trajectory. This is detailed in the main text but we have added a note to the caption.</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div><div class="note_with_children"><div id="note_rJeNuHAQhm" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Cool Idea but concerns about experiments</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=Syxt5oC5YQ&amp;noteId=rJeNuHAQhm"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper553 AnonReviewer2</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">29 Oct 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper553 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">The authors combined several update steps together to achieve aggregated momentum. They showed that  it is more stable than the other momentum methods. Also, in Auto-encoder and image classification, AggMo outperforms than the other methods. 

Pros:
(+) Theoretical result is shown on the quadratic problem.

(+) Extensive numerical experiments are shown to illustrate the stability of AggMo.

Cons:
(+) The results are not convincing. For example, it said in the default setting (CM \beta=0.9), ResNet34 on CIFAR-10 has accuracy 90.22\%. However, it should be around 93\%.

(+)  This method is similar to multi-step gradient methods.



Comments:
(+) This is no “introduction” in the paper. 

(+) There should be “,” after mathematical equations. 
</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">5: Marginally below acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_Hyxbhr0a6m" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Thank you for pointing out this error. Revised paper has been corrected.</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=Syxt5oC5YQ&amp;noteId=Hyxbhr0a6m"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper553 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">18 Nov 2018</span><span class="item">ICLR 2019 Conference Paper553 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Thank you for your feedback!

#1 Empirical Results

We thank you in particular for pointing out the issues with the ResNet-34 results. After investigating these further we were able to confirm a bug in our implementation, causing batch norm statistics to become fixed after a single epoch of training. We reran the experiments with this bug fixed and have updated the paper to reflect this. Due to computational limitations, we replaced the ResNet-34 architecture with ResNet-32.

To summarize, CM is now able to achieve similar final accuracy to AggMo but AggMo retains faster convergence throughout training. We are confident that the numbers reported are correct and in fact we report almost a full percentage higher accuracy than the original ResNet paper on CIFAR-10 with CM (they reported 92.49%).

The bug also prompted us to rerun these experiments with batch norm completely disabled. We found that AggMo is able to remain stable over a large range of learning rates even without batch normalization. Without batch normalization, AggMo achieves a final test accuracy on CIFAR-100 of 69.32%, more than 2% higher than the best value achieved by CM.

We apologize for the issue with the original results but want to emphasize that this did not affect any other empirical results. We would also like to point out that AggMo performed consistently well across all tasks and is able to do so over a wide range of hyperparameters settings. We believe that the results as a whole clearly show that AggMo is a powerful optimizer that often outperforms well established methods, even on tasks that have been developed with the original methods in mind (e.g. the model hyperparameters we used are chosen to work well with CM). Less formally, in other settings we have applied AggMo to a huge variety of problems and have yet to find a failure case. We would be happy to address any other specific concerns you have about the empirical results.

#2 Similarity to multi-step gradient methods

Could you please clarify what you mean by “multi-step gradient methods”? After looking ourselves, this seemed to be a less common term for multi-state algorithms such as CM or Nesterov. We see this as a pro and not a con of our algorithm. For example, much of the intuition for tuning hyperparameters for Nesterov/CM carries over to AggMo. Reviewer 3 raised a similar concern on the incremental nature of AggMo. We have responded to them but repeat that argument here. We have intentionally presented AggMo in a simple form which makes it easily relatable to existing algorithms. However, AggMo realizes complex dynamics which in general escape many theoretical frameworks. In Appendix C.2 we show that AggMo can be written as a (K+1)th order finite difference equation. We agree that AggMo is a simple extension of classical momentum but emphasize that most successful optimization algorithms are --- the challenge is in finding simple variants which perform well.

#3 Minor comments

We have punctuated the equations and added in the “Introduction” section heading as requested.

Thank you again for your review. We hope that our above comments and new empirical results address your concerns. We are happy to discuss any other concerns raised in your response.</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div></div></main></div>
  </div>
</div>


    <!-- Footer -->
    <footer class="sitemap">
      <div class="container">
        <div class="row hidden-xs">
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/venues">All Venues</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="/contact">Contact</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
    
        <div class="row visible-xs-block">
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/contact">Contact</a></li>
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
      </div>
    </footer>
    
    <footer class="sponsor">
      <div class="container">
        <div class="row">
          <div class="col-sm-10 col-sm-offset-1">
            <p class="text-center">
              OpenReview is created by the <a href="http://www.iesl.cs.umass.edu/" target="_blank">Information Extraction and Synthesis Laboratory</a>, College of Information and Computer Science, University of Massachusetts Amherst. We gratefully acknowledge the support of the OpenReview sponsors:  Google,  Facebook, NSF, the University of Massachusetts Amherst Center for Data Science, and Center for Intelligent Information Retrieval, as well as the Google Cloud Platform for donating the computing and networking services on which OpenReview.net runs.
            </p>
          </div>
        </div>
      </div>
    </footer>

  <div id="feedback-modal" class="modal fade" tabindex="-1" role="dialog">
    <div class="modal-dialog">
      <div class="modal-content">
        <div class="modal-header">
          <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button>
          <h3 class="modal-title">Send Feedback</h3>
        </div>
        <div class="modal-body">
          <p>Enter your feedback below and we'll get back to you as soon as possible.</p>
          <form action="/feedback" method="POST">
            <div class="form-group">
              <input type="email" name="from" class="form-control" placeholder="Email" />
            </div>
            <div class="form-group">
              <input type="text" name="subject" class="form-control" placeholder="Subject" />
            </div>
            <div class="form-group">
              <textarea name="message" class="form-control feedback-input" rows="5" placeholder="Message" required=""></textarea>
            </div>
          <ul id="ui-id-2" tabindex="0" class="ui-menu ui-widget ui-widget-content" style="display: none;"></ul></form>
        </div>
        <div class="modal-footer">
          <button type="button" class="btn btn-default" data-dismiss="modal">Cancel</button>
          <button type="button" class="btn btn-primary">Send</button>
        </div>
      </div>
    </div>
  </div>

  <script type="text/javascript" async="" src="https://www.google-analytics.com/analytics.js"></script><script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js"></script>
  <script>window.jQuery || document.write('&lt;script src="/static/js/vendor/jquery-2.2.4.min.js"&gt;&lt;\/script&gt;')</script>

  <script src="/static/dist/vendor.min.js"></script>
  <script src="/static/dist/templates.min.js"></script>
  <script src="/static/dist/openreview.min.js"></script>

    <script>window.legacyScripts = true;</script>


    <script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-108703919-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() { dataLayer.push(arguments); }
      gtag('js', new Date());
      gtag('config', 'UA-108703919-1');
    </script>


<div role="status" aria-live="assertive" aria-relevant="additions" class="ui-helper-hidden-accessible"></div></body></html>
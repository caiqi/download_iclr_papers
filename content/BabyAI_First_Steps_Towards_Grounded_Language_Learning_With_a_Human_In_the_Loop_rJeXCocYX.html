<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" class="no-js"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>BabyAI: First Steps Towards Grounded Language Learning With a Human In the Loop | OpenReview</title>
  <meta name="description" content="" />

      <meta name="citation_title" content="BabyAI: First Steps Towards Grounded Language Learning With a Human In the Loop" />
        <meta name="citation_author" content="Anonymous" />
      <meta name="citation_publication_date" content="2018/09/27" />
      <meta name="citation_online_date" content="2018/09/27" />
      <meta name="citation_pdf_url" content="https://openreview.net/pdf?id=rJeXCo0cYX" />
      <meta name="twitter:card" content="summary" />
      <meta name="twitter:site" content="@openreviewnet" />
      <meta name="og:title" content="BabyAI: First Steps Towards Grounded Language Learning With a Human..." />
      <meta name="og:description" content="Allowing humans to interactively train artificial agents to understand language instructions is desirable for both practical and scientific reasons, but given the poor data efficiency of the..." />
      <meta name="og:image" content="https://openreview.net/static/images/openreview_logo_512.png" />

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans:400,400i,700,700i" />

  <link rel="stylesheet" href="/static/css/bootstrap.min.css" />
  <link rel="stylesheet" href="/static/css/jquery-ui.min.css" />
  <link rel="stylesheet" href="/static/css/main.min.css" />
</head>

<body class="forum">
  <nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
  
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand home push-link" href="/"><strong>OpenReview</strong>.net</a>
      </div>
  
      <div id="navbar" class="navbar-collapse collapse">
        <form class="navbar-form navbar-left profile-search" role="search">
          <div class="form-group has-feedback">
            <input id="search_input" type="text" class="form-control ui-autocomplete-input" placeholder="Search ICLR 2019 Conference" autocomplete="off" />
            <span class="glyphicon glyphicon-search form-control-feedback" aria-hidden="true"></span>
          </div>
  
          <input id="search_group" type="hidden" value="ICLR.cc/2019/Conference" />
          <input id="search_content" type="hidden" value="all" />
        <ul id="ui-id-1" tabindex="0" class="ui-menu ui-widget ui-widget-content ui-autocomplete ui-front" style="display: none;"></ul></form>
  
        <ul class="nav navbar-nav navbar-right">
        
            <li id="user-menu"><a href="/login">Login</a></li>
        </ul>
      </div>
  
    </div>
  </nav>

  <div id="or-banner" class="banner" style="">
  <div class="container">
    <div class="row">
      <div class="col-xs-12"><a href="/group?id=ICLR.cc/2019/Conference" title="Venue Homepage"><img class="icon" src="/static/images/arrow_left.svg" /> Go to <strong>ICLR 2019 Conference</strong> homepage</a></div>
    </div>
  </div>
</div>
<div id="flash-message-container" class="alert alert-danger" role="alert" style="display: none;">
  <div class="container">
    <div class="row">
      <div class="col-xs-12">
        <div class="alert-content">
          <button type="button" class="close" aria-label="Close"><span aria-hidden="true">×</span></button>
        </div>
      </div>
    </div>
  </div>
</div>

<div class="container">
  <div class="row">
    <div class="col-xs-12">
      <main id="content" class="clearfix openbanner-visible legacy-styles"><div id="note_rJeXCo0cYX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>BabyAI: First Steps Towards Grounded Language Learning With a Human In the Loop</a> <a class="note_content_pdf" href="/pdf?id=rJeXCo0cYX" title="Download PDF" target="_blank"><img src="/static/images/pdf_icon_blue.svg" /></a> </h2></div><div class="meta_row"><span class="signatures">Anonymous</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">28 Sep 2018 (modified: 11 Oct 2018)</span><span class="item">ICLR 2019 Conference Blind Submission</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span><span class="item"><a class="action-bibtex-modal" data-bibtex="@inproceedings{    &#10;anonymous2019babyai:,    &#10;title={BabyAI: First Steps Towards Grounded Language Learning With a Human In the Loop},    &#10;author={Anonymous},    &#10;booktitle={Submitted to International Conference on Learning Representations},    &#10;year={2019},    &#10;url={https://openreview.net/forum?id=rJeXCo0cYX},    &#10;note={under review}    &#10;}">Show Bibtex</a></span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Abstract: </span><span class="note_content_value">Allowing humans to interactively train artificial agents to understand language instructions is desirable for both practical and scientific reasons, but given the poor data efficiency of the current learning methods, this goal may require substantial research efforts. Here, we introduce the BabyAI research platform to support investigations towards including humans in the loop for grounded language learning. The BabyAI platform comprises an extensible suite of 19 levels of increasing difficulty. The levels gradually lead the agent towards acquiring a combinatorially rich synthetic language which is a proper subset of English. The platform also provides a heuristic expert agent for the purpose of simulating a human teacher. We report baseline results and estimate the amount of human involvement that would be required to train a neural network-based agent on some of the BabyAI levels. We put forward strong evidence that current deep learning methods are not yet sufficiently sample efficient when it comes to learning a language with compositional properties.</span></div><div class="note_contents"><span class="note_content_field">Keywords: </span><span class="note_content_value">language, learning, efficiency, imitation learning, reinforcement learning</span></div><div class="note_contents"><span class="note_content_field">TL;DR: </span><span class="note_content_value">We present the BabyAI platform for studying data efficiency of language learning with a human in the loop</span></div><div class="reply_row clearfix"><div class="item" id="reply_count">9 Replies</div></div></div><hr class="small" /><div id="note_children"><div class="note_with_children"><div id="note_BJlsYhEgp7" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Format of the observation</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=rJeXCo0cYX&amp;noteId=BJlsYhEgp7"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">(anonymous)</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">07 Nov 2018</span><span class="item">ICLR 2019 Conference Paper877 Public Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Very interesting work! 

In Appendix A.4, you describe how the observations are encoded: 'Each tile is encoded using 3 integer values: one describing
the type of object contained in the cell, one describing its color, and a flag indicating whether doors
are open or closed.'. I was wondering whether these are given to the agent as actual integers, or they are one-hot encoded first. Could you please comment on this?</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_ByeCy_PDp7" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Clarification on Observation Format</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=rJeXCo0cYX&amp;noteId=ByeCy_PDp7"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper877 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">13 Nov 2018</span><span class="item">ICLR 2019 Conference Paper877 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Thank you for your question. The agent indeed receives 3 integers for each tile. In our preliminary investigations we tried converting these to one-hot embeddings first, but we did not observe a big difference in the results. 

Please let us know if you have any further questions.</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div><div class="note_with_children"><div id="note_SkebaWdinm" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Studies grounded language learning with a human in the loop by removing the human (and natural language)</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=rJeXCo0cYX&amp;noteId=SkebaWdinm"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper877 AnonReviewer1</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">04 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper877 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">This paper focuses on grounded language learning with a human in the loop, in the sense where the language is synthetic, the environment is a 2D grid world, and the human is a simulated human teacher implemented using heuristics. This setup is dubbed the BabyAI platform, and includes curriculum learning over 19 levels of increasing difficulty.  

Overall, the BabyAI platform is conceptually similar to numerous previous works that seek to learn grounded language in simulation environments. These efforts differ along various axes, for example visual realism, 2D vs 3D, partially vs. fully observed, different tasks, world-state manipulation or not, etc. The main original aspect of the BabyAI platform is the simulated human-teacher. 

Strengths
- Learning with a human in the loop is an extremely important problem to study, although currently efforts are hampered by cost, lack or reproducibility, and the sample inefficiency of existing learning methods. This paper addresses all three of these issues, albeit by removing the human and natural language. This is simultaneously the greatest weakness of this approach. The contribution of this paper therefore rests on the quality/interestingness/utility of the provided synthetic language and the synthetic teacher.
- Fortunately, the synthetic language does exhibit interesting compositional properties, it is readily extensible, it has the appealing property that it can be readily interpreted as a subset of english, and it is accompanied by a verifier to check if the specified actions were completed. 

Weaknesses
- If the ultimate goal is learning with a human in the loop, the usefulness of the synthetic teacher is not clear, particularly as it is apparently easier to imitate from an RL trained agent than the teacher. The explanation 'This can explained by the fact that the RL expert has the same neural network architecture as the learner' does no seem obvious to me. 
- Regarding the human in the loop, since this is aspirational and not an aspect of the paper, the title of the paper does not seem reflective of its content (even with the 'First steps' qualifier). 
- If the main unique aspect is the simulated human-teacher, it is not clear why it is necessary to create a new environment, rather than re-using an existing environment. The effect of this is to limit comparisons with recent work and an increasing fragmentation of research across tasks that are related but can’t be compared.

Summary:
This paper represents an important direction, in that it provides a testbed for studying the sample efficiency of grounded language learning in a simplified (yet still challenging and compositional) environment. I believe the environment and the provided synthetic language and verifier will prove useful to the community, and despite some reservations about the title and the simulated human-teacher, I recommend acceptance.</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">6: Marginally above acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_S1gl2Itop7" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Response to Reviewer 1 (part 1 of 2)</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=rJeXCo0cYX&amp;noteId=S1gl2Itop7"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper877 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">16 Nov 2018</span><span class="item">ICLR 2019 Conference Paper877 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">We thank Reviewer 1 (R1) for their careful and detailed review of the paper. In our response we will try to justify the choice of the title, explain why we believe that building a new environment was warranted, and also discuss the difference between imitation learning results obtained with the heuristic expert and an RL-trained agent.

Reviewer 1 has suggested that our aspiration to make progress towards human in the loop training may be insufficient to use the phrase “human in the loop” in the title. With all due respect we would like to argue that the title of a research paper should inform the reader of the high-level goals that are being pursued in the presented research effort. Since the goal of BabyAI platform is to support tangible steps towards human in the loop training, we think that the title “First Steps Towards Grounded Language Learning With a Human In the Loop” is sufficiently accurate. We are open to a continuation of this discussion, but so far our understanding is having “First Steps Towards …” should make it sufficiently clear that training with a human in the loop is something that we aspire to, and not necessarily something that we can already demonstrate.

We thank Reviewer 1 for pointing out that a further discussion of why the synthetic teacher is useful even though an RL-trained agent is easier to imitate may be necessary. The main reason why we chose to build the heuristic expert is that, although RL training did well on some of the simpler levels, it struggled to reach a high success rate on the harder levels. A secondary reason is that, in order to allow further investigations to DAGGER and other more advanced interactive teaching methods, we wanted to have a teacher which could give advice to a learner on which action to take from any state. Unfortunately, RL agents struggle to do this in practice. They generalize poorly to states which they do not normally visit.

As for why RL agents are easier to imitate than the heuristic expert, this is likely because the policy implemented by the RL expert is easier for a neural network to implement. RL is an optimization technique. By design, it attempts to adjust the weights of a neural network so as to maximize the reward obtained on a given problem. In other words, RL will try to find a policy which is the best (in terms of both performance and learnability) for the expert’s neural network. Thus, it may be more natural for a learner that has the same neural network as the  expert to imitate such a policy rather than imitating a computer program, such as our heuristic expert. Informally, we found that the RL-trained policy is more reactive (i.e. based on the current/recent observations), whereas the heuristic expert takes advantage of its perfect memory. In the view of the fact that training RL agents for harder levels is extremely hard, we believe that having a heuristic expert that can solve all levels is highly useful.  

(see part 2 for continuation)
</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_rylPWDFjpQ" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Response to Reviewer 1 (part 2 of 2)</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=rJeXCo0cYX&amp;noteId=rylPWDFjpQ"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper877 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">16 Nov 2018</span><span class="item">ICLR 2019 Conference Paper877 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">(see part 1 for the beginning)

We fully agree with Reviewer 1 that there are a number of existing options in the space of environments for instruction following. We have examined these options before embarking on this project, and determined that none of them provided the specific combination of features that we wanted, along with a systematically designed language. To the best of our knowledge, the environment we have created is unique in a number of important ways.

We chose a gridworld rather than a 3D environment such as in [1, 2] because we wanted an experimental setup that was fast, lightweight, and easy to modify. Using a gridworld means we can run simulations at several thousands of frames per second on a single computer, and train with larger batch sizes. Even so, on some of the more difficult BabyAI levels, training time can take up to a week on a modern GPU. Had we used a 3D environment which was more computationally expensive, the training time requirements would have put this line of research out of our reach.

There are already existing options in terms of gridworld packages, such as MazeBase [3] and PyCoLab [4]. However, we wanted a environments that are partially observable, and feature language. Had we used these packages, we would have had to extensively modify them, thereby making any results incomparable to the existing literature. The closest thing to our setup, that we are aware of, is the Crafting 2D env used in the Policy Sketches paper [5]. This environment is interesting, but a quick inspection of the repository will reveal that it is a bare source code dump, with no documentation whatsoever, no installation script, and no maintenance commits in the last two years. This environment is also not compatible with OpenAI Gym. 

In designing our environment, we wanted a principled approach towards language design, rather than something ad-hoc based on patterns (hence the BNF grammar). We also attempted a principled segmentation of levels in terms of competencies required to solve them. We also believe that ability to scale up/down the difficulty of levels by adjusting various parameters in a fine-grained manner is important to enable curriculum learning, and for research in general, because it can help us establish precisely which aspects of the environment make learning more difficult. Our environment was designed with this in mind.

[1] Grounded Language Learning in a Simulated 3D World (<a href="https://arxiv.org/abs/1706.06551)" target="_blank" rel="nofollow">https://arxiv.org/abs/1706.06551)</a>
[2] Project Malmo (https://github.com/Microsoft/malmo)
[3] MazeBase (https://github.com/facebook/MazeBase)
[4] PyCoLab (https://github.com/deepmind/pycolab)
[5] Policy Sketches implementation (https://github.com/jacobandreas/psketch)
</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div></div></div><div class="note_with_children"><div id="note_HyliNl09h7" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>New platfrom for research</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=rJeXCo0cYX&amp;noteId=HyliNl09h7"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper877 AnonReviewer2</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">03 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper877 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">Summary:
This paper presents a research platform with a simulated human (a.k.a bot) in the loop for learning to execute language instructions in which language has compositional structures. The language introduced in this paper can be used to instruct an agent to go to objects, pick up objects, open doors, and put objects next to other objects. MiniGrid is used to build the environments used for this platform. In addition to introducing the platform, they evaluate the difficulty of each level by training an imitation learning baseline using one million demonstration episodes for each level and report results. Moreover, the reported results contain data efficiencies for imitation learning and reinforcement learning based approaches to solving BabyAI levels. 

A platform like this can be very useful to expedite research in language learning, machine learning, etc. In my view, work like this should be highly encouraged by this conference and alike.  

Comments:
1.  There are following papers should be cited as they are very related to this paper:
    a) Vision-and-Language Navigation: Interpreting visually-grounded navigation instructions in real environments
        <a href="https://arxiv.org/abs/1711.07280" target="_blank" rel="nofollow">https://arxiv.org/abs/1711.07280</a> 
    b) AI2-THOR: An Interactive 3D Environment for Visual AI
         https://arxiv.org/abs/1712.05474 
2. Paper is well-written and easy to follow. The only part which needs an improvement is section 3.4 as the text is a bit confusing.
3. Heuristic expert, simulated human, human, and bot are exchangeably used in the text. It is better to pick one of these to avoid any confusion in the text. In general, it is not clear to why 'a human in the loop' is chosen, isn't just a program/bot that has is engineered using knowledge of the tasks?
4. In Table 5, in GoToObjMaze row, data efficiency for "With Pretraining" is greater than "Without Pretraining", is this a typo? if not, why this is the case?
5. One useful baseline which can be added to this paper is task-oriented language grounding. This task will be a better measure than current baselines, especially for RL case. Authors can check out the following paper:
Gated-Attention Architectures for Task-Oriented Language Grounding
https://arxiv.org/abs/1706.07230
The code is available for this paper. 

Question:
When this platform will be available for public? </span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">6: Marginally above acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_rJgn5DFo6X" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Response to Reviewer 2</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=rJeXCo0cYX&amp;noteId=rJgn5DFo6X"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper877 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">16 Nov 2018</span><span class="item">ICLR 2019 Conference Paper877 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">We are grateful for the detailed review provided by Reviewer 2 (R2), their careful reading of the paper, and their suggestions. We will do our best to incorporate these.

R2 has asked when the platform will be available to the public, and we are happy to announce that that the platform is already available on Github. We will add a link to the repository when the review process is complete in order to preserve anonymity. We have also published a Docker image with the baseline models on Docker Hub so that our results can be easily replicated.

We respond below to the 5 specific comments that R2 made in their review in same order as they were originally presented: 

1) We will cite the two highly relevant papers that R2 suggested in our Related Work section.
2) We will improve the description of the stack-based bot in the text of Section 3.4, and we will furthermore add the complete pseudocode for the bot in an Appendix. 
3) We will follow R2’s suggestion and be more consistent the choice of terms  “simulated human”, “heuristic expert” and “bot”, in particular we will try to use “bot” as often as possible. We would still like to retain occasional references to human in the loop training, since this it is this kind of training that our research aspires to eventually enable. The bot’s role in this context is simulating a hypothetical human teacher, which is why occasionally the paper uses the words “simulated human”.
4) We fully share R2’s concerns with regard to a counterintuitive decrease of data efficiency on GoTo that is observed when the model is first pretrained on GoToObjMaze. We are however confident that this result is correct, and moreover we find it rather interesting. An agent that is pretrained on “GoToObjMaze” level knows how to efficiently navigate a 3x3 maze of 6x6 rooms (Table 1), but somehow this pretraining does not help at all when the same agent is then trained to perform a range of similar tasks (defined by instructions like “go to red ball”) and in the presence of distractor objects. We treat this as an evidence that the current deep learning architectures for language understanding do not lend themselves to curriculum learning, and we hope that BabyAI will support studies on how to improve them in this respect. We believe that such much needed improvements in curriculum learning will play a key role in enabling actual human in the loop training, which is the main aspiration of the paper. 
5) We thank R2 for the pointer to the “Gated-Attention Architectures for Task-Oriented Language Grounding” paper. We have already cited this paper in Introduction and Related Work. We were not sure which of the two ways of understanding  the author’s suggestion that “This task will be a better measure than current baselines, especially for RL case” is right, and below we comment on both. 

If R2’s suggestion was to consider using the VizDoom environment from the aforementioned paper, then we would like to note that we did consider the option of using this environment along with other ones mentioned in our Related Work section. We concluded that in order to have the specific combination of features that we wanted (high speed, interacting with objects in the environment, systematically designed language), we could not use existing environments, such as VizDoom, and had to build a new MiniGrid environment and implement the Baby language in it. 

If instead R2 suggested to use the gated attention approach to combine  representations of images and instructions, then we would like to note that the FiLM [1] layers that we use in our model perform a very similar computation (and in fact FiLM and the “Task-Oriented Language Grounding” were both presented at the same AAAI 2018 conference). We will make this connection more clear in the text of the paper where we describe the model that we use in our experiments. 

We hope that R2 finds our clarifications and comments helpful.

[1] FiLM: Visual Reasoning with a General Conditioning Layer (<a href="https://arxiv.org/abs/1709.07871)" target="_blank" rel="nofollow">https://arxiv.org/abs/1709.07871)</a></span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div><div class="note_with_children"><div id="note_r1eeyarz3m" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Interesting direction and open-source platform, but paper falls short of human evaluation</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=rJeXCo0cYX&amp;noteId=r1eeyarz3m"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper877 AnonReviewer3</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">28 Oct 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper877 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">Summary

The authors introduce BabyAI, a platform with the aim to study grounded language learning with a human in the loop. The platform includes a *simulated* human expert (bot) that teaches a neural learner. The current domain used in a 2D gridworld and the synthetic instructions require the agent to navigate the world (including unlocking doors) and move objects to specified locations. They also introduce "Baby Language" to give instructions to the agent as well as to automatically verify their execution.

The paper includes a detailed description of the minigrid env with the included tasks and instruction language set. 

Authors trained small and large LSTM models on the tasks on a variety of standard learning approaches, using pure exploration (RL) and imitation from a synthetic bot (IL). They show IL is much more data efficient than RL in this domain as well. Also, a curriculum approach is evaluated (pre-train on task 1-N, then train on task N+1).  

Pro
- Human-in-the-loop research is an exciting direction.
- The language instruction set is a starting point for high-level human instructions. 

Con
- It is still unclear how to effectively learn with human-in-the-loop. The authors don't actually evaluate 
1) how well the bot imitates a human, or 
2) how an actual human would interact and speed up learning. 
All experiments are done with standard learning approaches with a synthetic bot. 
- The authors assume that human feedback comes as instructions or demonstrations. These are not the only forms of feedback possible (e.g., preferences). (Does the platform easily support those?)

Reproducibility
- Open-sourcing the platform is a good contribution to the community.
</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">6: Marginally above acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_SJl9AvKsam" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Response to Reviewer 3</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=rJeXCo0cYX&amp;noteId=SJl9AvKsam"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper877 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">16 Nov 2018</span><span class="item">ICLR 2019 Conference Paper877 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">We thank Reviewer 3 (R3) for their review that nicely summarizes our paper. In our response we discuss the two main questions that R3 asked, namely why we have not yet performed experiments with an actual human and how other learning approaches can be studied using the BabyAI platform. 

We completely agree with R3 that “it is still unclear how to effectively learn with a human in the loop.” Our baselines studies on the BabyAI platform have indeed shown that standard approaches for grounded language understanding would need from thousands to hundreds of thousands of demonstrations by the human to learn even the simplest tasks. In order to proceed to studies with actual humans in the loop, the human should be able to see in real time how the agent is progressing, and with the approaches that we evaluated such progress would be unbearably slow. We have postponed studies with actual humans until a sufficient progress is made on BabyAI, that is until we have levels that (at least with pretraining) can be mastered with hundreds of demonstrations. For now, we believe the BabyAI platform is already useful as it supports rigorous studies on data efficiency of grounded language understanding, so that we can measure progress towards the goal of learning with a human in the loop . 

The reviewer correctly pointed out that there are other ways in which a human could teach an agent for which we do not provide baseline results, in particular learning with preferences. To the best of our understanding studies of learning with preferences could be done using the BabyAI platform, since human preferences could be simulated by using the instruction verifier. We would however expect the data efficiency of learning with preferences to be closer to that of RL (i.e. millions of episodes) than that of imitation learning (hundreds of thousand demonstrations).

We hope that R3 finds the clarifications that we present in this response informative and useful.
</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div></div></main></div>
  </div>
</div>


    <!-- Footer -->
    <footer class="sitemap">
      <div class="container">
        <div class="row hidden-xs">
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/venues">All Venues</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="/contact">Contact</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
    
        <div class="row visible-xs-block">
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/contact">Contact</a></li>
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
      </div>
    </footer>
    
    <footer class="sponsor">
      <div class="container">
        <div class="row">
          <div class="col-sm-10 col-sm-offset-1">
            <p class="text-center">
              OpenReview is created by the <a href="http://www.iesl.cs.umass.edu/" target="_blank">Information Extraction and Synthesis Laboratory</a>, College of Information and Computer Science, University of Massachusetts Amherst. We gratefully acknowledge the support of the OpenReview sponsors:  Google,  Facebook, NSF, the University of Massachusetts Amherst Center for Data Science, and Center for Intelligent Information Retrieval, as well as the Google Cloud Platform for donating the computing and networking services on which OpenReview.net runs.
            </p>
          </div>
        </div>
      </div>
    </footer>

  <div id="feedback-modal" class="modal fade" tabindex="-1" role="dialog">
    <div class="modal-dialog">
      <div class="modal-content">
        <div class="modal-header">
          <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button>
          <h3 class="modal-title">Send Feedback</h3>
        </div>
        <div class="modal-body">
          <p>Enter your feedback below and we'll get back to you as soon as possible.</p>
          <form action="/feedback" method="POST">
            <div class="form-group">
              <input type="email" name="from" class="form-control" placeholder="Email" />
            </div>
            <div class="form-group">
              <input type="text" name="subject" class="form-control" placeholder="Subject" />
            </div>
            <div class="form-group">
              <textarea name="message" class="form-control feedback-input" rows="5" placeholder="Message" required=""></textarea>
            </div>
          <ul id="ui-id-2" tabindex="0" class="ui-menu ui-widget ui-widget-content" style="display: none;"></ul></form>
        </div>
        <div class="modal-footer">
          <button type="button" class="btn btn-default" data-dismiss="modal">Cancel</button>
          <button type="button" class="btn btn-primary">Send</button>
        </div>
      </div>
    </div>
  </div>

  <script type="text/javascript" async="" src="https://www.google-analytics.com/analytics.js"></script><script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js"></script>
  <script>window.jQuery || document.write('&lt;script src="/static/js/vendor/jquery-2.2.4.min.js"&gt;&lt;\/script&gt;')</script>

  <script src="/static/dist/vendor.min.js"></script>
  <script src="/static/dist/templates.min.js"></script>
  <script src="/static/dist/openreview.min.js"></script>

    <script>window.legacyScripts = true;</script>


    <script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-108703919-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() { dataLayer.push(arguments); }
      gtag('js', new Date());
      gtag('config', 'UA-108703919-1');
    </script>


<div role="status" aria-live="assertive" aria-relevant="additions" class="ui-helper-hidden-accessible"></div></body></html>
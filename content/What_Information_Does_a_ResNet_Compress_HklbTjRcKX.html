<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" class="no-js"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>What Information Does a ResNet Compress? | OpenReview</title>
  <meta name="description" content="" />

      <meta name="citation_title" content="What Information Does a ResNet Compress?" />
        <meta name="citation_author" content="Anonymous" />
      <meta name="citation_publication_date" content="2018/09/27" />
      <meta name="citation_online_date" content="2018/09/27" />
      <meta name="citation_pdf_url" content="https://openreview.net/pdf?id=HklbTjRcKX" />
      <meta name="twitter:card" content="summary" />
      <meta name="twitter:site" content="@openreviewnet" />
      <meta name="og:title" content="What Information Does a ResNet Compress?" />
      <meta name="og:description" content="The information bottleneck principle (Shwartz-Ziv &amp; Tishby, 2017) suggests that SGD-based training of deep neural networks results in optimally compressed hidden layers, from an information..." />
      <meta name="og:image" content="https://openreview.net/static/images/openreview_logo_512.png" />

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans:400,400i,700,700i" />

  <link rel="stylesheet" href="/static/css/bootstrap.min.css" />
  <link rel="stylesheet" href="/static/css/jquery-ui.min.css" />
  <link rel="stylesheet" href="/static/css/main.min.css" />
</head>

<body class="forum">
  <nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
  
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand home push-link" href="/"><strong>OpenReview</strong>.net</a>
      </div>
  
      <div id="navbar" class="navbar-collapse collapse">
        <form class="navbar-form navbar-left profile-search" role="search">
          <div class="form-group has-feedback">
            <input id="search_input" type="text" class="form-control ui-autocomplete-input" placeholder="Search ICLR 2019 Conference" autocomplete="off" />
            <span class="glyphicon glyphicon-search form-control-feedback" aria-hidden="true"></span>
          </div>
  
          <input id="search_group" type="hidden" value="ICLR.cc/2019/Conference" />
          <input id="search_content" type="hidden" value="all" />
        <ul id="ui-id-1" tabindex="0" class="ui-menu ui-widget ui-widget-content ui-autocomplete ui-front" style="display: none;"></ul></form>
  
        <ul class="nav navbar-nav navbar-right">
        
            <li id="user-menu"><a href="/login">Login</a></li>
        </ul>
      </div>
  
    </div>
  </nav>

  <div id="or-banner" class="banner" style="">
  <div class="container">
    <div class="row">
      <div class="col-xs-12"><a href="/group?id=ICLR.cc/2019/Conference" title="Venue Homepage"><img class="icon" src="/static/images/arrow_left.svg" /> Go to <strong>ICLR 2019 Conference</strong> homepage</a></div>
    </div>
  </div>
</div>
<div id="flash-message-container" class="alert alert-danger" role="alert" style="display: none;">
  <div class="container">
    <div class="row">
      <div class="col-xs-12">
        <div class="alert-content">
          <button type="button" class="close" aria-label="Close"><span aria-hidden="true">×</span></button>
        </div>
      </div>
    </div>
  </div>
</div>

<div class="container">
  <div class="row">
    <div class="col-xs-12">
      <main id="content" class="clearfix openbanner-visible legacy-styles"><div id="note_HklbTjRcKX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>What Information Does a ResNet Compress?</a> <a class="note_content_pdf" href="/pdf?id=HklbTjRcKX" title="Download PDF" target="_blank"><img src="/static/images/pdf_icon_blue.svg" /></a> </h2></div><div class="meta_row"><span class="signatures">Anonymous</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">28 Sep 2018 (modified: 19 Nov 2018)</span><span class="item">ICLR 2019 Conference Blind Submission</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span><span class="item"><a class="action-bibtex-modal" data-bibtex="@inproceedings{    &#10;anonymous2019what,    &#10;title={What Information Does a ResNet Compress?},    &#10;author={Anonymous},    &#10;booktitle={Submitted to International Conference on Learning Representations},    &#10;year={2019},    &#10;url={https://openreview.net/forum?id=HklbTjRcKX},    &#10;note={under review}    &#10;}">Show Bibtex</a></span><a class="note_content_pdf item" href="/revisions?id=HklbTjRcKX" target="_blank">Show Revisions</a></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Abstract: </span><span class="note_content_value">The information bottleneck principle (Shwartz-Ziv &amp; Tishby, 2017) suggests that SGD-based training of deep neural networks results in optimally compressed hidden layers, from an information theoretic perspective. However, this claim was established on toy data. The goal of the work we present here is to test these claims in a realistic setting using a larger and deeper convolutional architecture, a ResNet model. We trained PixelCNN++ models as inverse representation decoders to measure the mutual information between hidden layers of a ResNet and input image data, when trained for (1) classification and (2) autoencoding. We find that two stages of learning happen for both training regimes, and that compression does occur, even for an autoencoder. Sampling images by conditioning on hidden layers’ activations offers an intuitive visualisation to understand what a ResNets learns to forget.</span></div><div class="note_contents"><span class="note_content_field">Keywords: </span><span class="note_content_value">Deep Learning, Information Bottleneck, Residual Neural Networks, Information Theory</span></div><div class="note_contents"><span class="note_content_field">TL;DR: </span><span class="note_content_value">The Information Bottleneck Principle applied to ResNets, using PixelCNN++ models to decode mutual information and conditionally generate images for information illustration</span></div><div class="reply_row clearfix"><div class="item" id="reply_count">6 Replies</div></div></div><hr class="small" /><div id="note_children"><div class="note_with_children"><div id="note_rye2iGUs3m" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Empirical evaluation of information retained across layers of classification ResNets using pixelCNN decoders.</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HklbTjRcKX&amp;noteId=rye2iGUs3m"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper779 AnonReviewer2</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">04 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper779 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">
* Summary: 

This work is an empirical study of the relevance of the Information Bottleneck principle as a way of understanding deep-learning. It is carried out in the setting of realistically sized networks trained on natural images dataset. This is, in spirit, a meaningful and sensible contribution to the ongoing debate. Being a largely empirical contribution, its value hinges on the exhaustivity and clarity of the experiments carried out. As it stands, I believe that these should be, and can be, improved. Details to support this opinion are given below. A summary of my expectations is given at the end.


* Summary of the approach and significance:

The IB principle relies on estimating the mutual information between i) the input and an intermediate layer, I(x,h), and an intermediate layer and the output, I(h, y). Previous work has relied on binning strategies to estimate these quantities. This is not applicable in a real-sized problem such as classification of natural images with deep networks. This paper proposes to invert a first deep model using a second, generative, model which must reconstruct the input of the first given some intermediate layer. The information progressively discarded by the first network should be modelled as uncertainty by the second. This yields a lower bound on the mutual information, with a tightness that depends on the expressivity of the generative model.

I believe the goal to be meaningful and a valuable contribution: going forward, testing this assumption in realistic setting is essential to the debate. The proposed approach to do this seems sensible to me. It is similar to cited work by Nash et al., however both works are concurrent and so far unpublished and should be considered as complementary point of views on the same problem.

Partial conclusion: The goal is meaningful and sensible.

* Quality of writing.

In sections 1, 2 and 3, the motivation is clear and contains relevant information. I feel it could be polished further. In particular, some redundant information could be condensed. The introduction to the IB principle, though understandable, could be improved. Here are some opinions:

&gt;&gt; Paragraphs 3 and 4 of 1.0: A reference to M. Saxe et al. could already be made there: it is a major 'opponent' in the debate to which you are empirically contributing.

&gt;&gt; In paragraph 1.1: Points 1) and 2) are redundant. So are 3) and 4). Paragraph 1.1 as a whole is largely redundant with the previous paragraph, these could be collapsed. 

&gt;&gt; In section 2: I feel that the main intuitions of the encoder / decoder distributions (I(y,h) / I(x,h)), the information plane, and the optimal bottleneck representations (Sections 2.1 to 2.3 of Schwartz-Ziv &amp; Tishby) could be better conveyed in 2, though I understand the need for brevity. 

&gt;&gt; Related works: Descriptions of related works could be condensed. On the other hands, the points of these papers that you contradict in you experiment section could be explicitly mentioned again there.

&gt;&gt; End of section 3, section 4: The fact that estimation of the MI by traditional means is not applicable in your setting is repeated many times throughout the paper, in noticeably rapid succession in that region. Some mentions should be removed.
	
### More minor points:

&gt;&gt; Paragraphs 2 of 1.0:
- 'the extraction of typical abstract properties...' this statement is vague and thus debatable: the channel-wise mean in RGB space, for instance, is not an especially abstract property. 
- Reference is made to Zhang et al. to justify the need for more analysis of generalization in deep-learning. This paper can be considered controversial. Mention could be made of other works, for instance about the inaplicability of traditional generalization bounds and attempts to improve them.

&gt;&gt; Pseudo code algorithm.
- Could be summarized in the main body and pushed to the annex.

&gt;&gt; The choice of pixCNN as a generative model could be discussed more. There are some good reasons to prefer this to L2 regression for instance. 

Partial conclusion: The description of the method contains relevant information and is functional, but the writing could be improved.
	
	
* Experimental results.

&gt; The contribution and novelty of this paper is largely empirical. Therefore the experimental results should be held to a high standard of clarity and exhaustivity.


*** The choice of dataset:
The experimental setup seems to be fair in terms of dataset / split chosen: the abundance of data for the three steps (encoding, decoding, evaluation) is a notable strength.

*** The quality of the lower bound: Uncertainty when reconstructing the image may come from the fact that information has been discarded. Variance may also come from the pixCNN++, which is imperfect. You mention this (paragraph 4.1) but do not take experimental steps to measure it. Please consider reporting the performance of your generative model i) without conditioning, ii) conditioned on one-hot ground truth labels, and optionally iii) on grayscale/downsampled versions of the image without otherwise modifying the training setup. These values will give the reader an idea of the significance of variations in MI measured and give a 'scale' to your figures, strengthening your claims.

*** The evolution of compression *accross iterations* for a fixed layer
I will focus on the classification setting for now.

Qualitatively: Figures 1, 4 and 5 do not convince me that a meaningful evolution in the type of information discarded *across training iterations* can be observed visually. In figures 1 and 4, the network seems to learn invariances to some coloring, and its preferred colours vary across iterations. Beyond that I cannot see much, except maybe for column (f) of figure 4, despite your claim in section 2, paragraph 2.

Quantitatively: Curves in Figure 2 a) are more convincing, though a notion of scale is missing, as already discussed. The evolution of I(y; h) across iterations is very clear, in Figure 2 a) and especially 3 a). The evolution of I(x, h) much less so. h3 and h4 do not seem to show anything meaningful. In h2 the decrease in I(x, h) is supported by only 2 points in the curve (epoch 10 to epoch 100, and epoch 100 to epoch 200, figures 2a and 3c). Epochs displayed are also incoherent from one curve to the next (epoch 15 is missing for h2 in fig 3c) which raises suspicion. It appears important to i) display more points, to show that this is not just noise and ii) track more layers to confirm the trend, supported by a single layer so far (see next paragraph). I understand that each of these points require training of a generative model, but I feel it is necessary to make reliable conclusions.  

Minor: In figure 2, epochs should be added as labels to the colours.  

*** The evolution of compression *across layers* for a fixed iteration
		
Conversely, the evolution of the MI across layers is very convincingly demonstrated, and I feel this is perhaps the main strength of this paper. All curves display consistent trends across layers, and Figure 5 qualitatively displays much more invariance to pose, detail, etc than Figure 4. This is interesting, and could be made more central: i) by making a figure that compares samples across layers, for a fixed iteration, side by side. 

On the downside, I believe it is important to track more layers, as it is to me the main interest of your results. The second paragraph of section 5 does not give a good idea of the spread of these layers to someone not familiar with the resnet architecture used. For example, the penultimate layer of the network could be used (the layer at which the most compression is to be expected).

*** On the auto-encoder experiments.

&gt; Little detail is given about the way the auto-encoder is constructed. In particular, one expects the type of bottleneck used (necessary so that the network does not learn the identity function) to have large impact on the amount of information discarded in the encoding process. This dependency is not discussed. More crucially, experiments with different types / strength of bottleneck are not given, and would, in my opinion, be key to an analysis of this dependency through the IB principle. 

&gt; Furthermore, no qualitative analysis is provided in this setting.

&gt; Without these additions, I find the Auto-encoding setting an unconvincing distraction from the main contribution of this paper. 	

***  main avenues of improvement:
		
&gt; Two kinds of progression in compression are demonstrated in your paper: across layers, and across iterations. 
As it stands, results evidence the former more convincingly than the latter, both qualitatively and quantitatively.
I believe results could be presented in a way that clearly takes better advantage of this, as I will detail further.
More data points (across layer and epochs) would be beneficial. I feel that the auto-encoder setting, as it stands, is a distraction.
I would find this paper more convincing if experiments focused more on showing how layers progressively discard information, and less on the 'training phases' that are so far less clear.

*** Additional comments

The following are a number of points that would be worthwhile to discuss in the paper

&gt; As it stands, it seems the line of reasoning and experimental setup seems to rely on the chain-structured nature of the considered neural net architecture. Can the same line of reasoning be applied to networks with more general computational graphs, such as dense-nets [a], mulit-scale denseness [b], fractal nets [c] etc.

[a] Huang, G.; Liu, Z.; van der Maaten, L. &amp; Weinberger, K. Densely connected convolutional networks CVPR, 2017
[b] Huang, G.; Chen, D.; Li, T.; Wu, F.; van der Maaten, L. &amp; Weinberger, K. Multi-Scale Dense Networks for Resource Efficient Image Classification ICLR, 2018
[c] <a href="https://arxiv.org/abs/1605.07648" target="_blank" rel="nofollow">https://arxiv.org/abs/1605.07648</a>

&gt; Why is it that earlier layers are estimated to have larger MI with the target y than later layers before convergence? Sure, later layers compress certain information about the input x, which could be informative on the response variable y. But since the MI estimate for early layers depends on the same network architecture as the one used to compute the later layers from the early ones, the result seems counter intuitive. See paragraph "forward direction" in section 4.1.

&gt; The orange curve in fig 3a estimating I(x;y) is not commented upon. How was it obtained, what is its relevance to the discussion?


</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">4: Ok but not good enough - rejection</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_rylPxV7xCX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Response to AnonReviewer2</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HklbTjRcKX&amp;noteId=rylPxV7xCX"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">(anonymous)</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">19 Nov 2018</span><span class="item">ICLR 2019 Conference Paper779 Public Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Thank you for your review. Amendments and additions have been made throughout the paper to account for the minor points and suggestions. This will be uploaded as a revision shortly. We will now discuss the major points. 

First, we would like to make apparent the computational burden of in depth analysis in this scenario: each PixelCNN++ model takes approximately two weeks to train on a single Titan 1080ti GPU. This, for example, is the reason there are slightly more data points for h3 in Figure 3c - we determined that this layer was likely to yield interesting results since it is the penultimate layer of the ResNet.

Regarding the quality of the bound on I(x, h). There is no way of theoretically knowing how good the bound is. However, PixelCNN++ is state of the art for extracting useful information in this scenario. 

Regarding the evolution of information across iterations for a fixed layer. First, consider Figure 1:
- at very early stages of training (epochs 0 and 1) the generated samples are noisy and less recognisable as horses when compared to later stages.
- compare the samples at 10 epochs (roughly the peak of ‘fitting’) to those at 200 epochs (end of compression). The background (ground and sky) is less varied earlier on; the colour of the horse is less varied earlier on (notwithstanding noise such as the first row of d); and the positioning of the horses head is less varied earlier on.

Unfortunately these changes are difficult to see unless your PDF viewer does not interpolate pixels and you can zoom sufficiently. It would be ideal to run these experiments on higher resolution images, but simply not computationally feasible at present.
The same sentiments are true for Figure 4 (comparing column (d) and (f), most notably), but owing to the already limited information after average pooling for Figure 5, it is difficult to interpret in the same fashion. Nonetheless, the quality of the images is notably different early and late stage training. 

Regarding the suggestion of more focus on the evolution of information across layers for a fixed iteration. This is largely model specific based on the capacity of each layer and an expected outcome given the structure of this ResNet architecture. Taking an approach of focus on this sort of information evolution is not the direction of this paper, particularly since it was written for comparison with Schwartz-Ziv &amp; Tishby. Future work focusing on this suggested evolution can be undertaken. 

Regarding the spread of h2, h3, and h4 in the ResNet. This is more clear in Figure 6 in the appendix, but we have made it more obvious in the text, too. Specifically, h4 is the penultimate layer and is that layer which should exhibit the most compression. 

Regarding the autoencoder set-up. The decoder of the autoencoder was designed to be as close to an inversion of the encoder structure as possible. Therefore, the bottleneck is defined as the average pooling layer of the ResNet itself. We have made this more clear in the text. Figure 6 in the appendix is an architecture description. Any sort of ablation studies and further hyper-parameter adjustment requires training more PixelCNN++ models for analysis, which is computationally infeasible. Regarding generated images from the h layers for the autoencoder: these almost always look indistinguishable from the input images, so we kept these out for brevity. Finally, since the autoencoder set-up is not comparable to earlier research, we sought to keep these results brief. Nonetheless, the evidence that compression occurs in an autoencoder was an interesting finding and we chose to keep these results in the paper. 

Regarding the reason why earlier layers have higher I(y, h) than later layers before convergence. This is because of the data processing inequality. Specifically, information can only be discarded and never gained. Consider early stage training before convergence. None of the layers are doing a particularly good job of retaining information about y, iteratively throwing information away. Earlier layers will see representations that have a lower level of information degradation and, therefore, always have more information than later layers. As the network learns and approaches convergence, each layer becomes better and better at passing y-relevant information forward and less information gets discarded (they reach a very similar I(y, h) point at 200 epochs). Figure 3a is quite indicative of what you would expect layers to do regarding class-relevant information retention over training.

Regarding the orange curve in Figure 3a. This curve is the original training curve of the network under scrutiny and is directly related to the log-likelihood of the model. We will make this clearer in the caption.
</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div><div class="note_with_children"><div id="note_SJx8hPAq2m" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>An empirical study with specious results</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HklbTjRcKX&amp;noteId=SJx8hPAq2m"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper779 AnonReviewer1</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">03 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper779 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">## Summary

This paper is an empirical study which attempts to test some of the claims regarding the information bottleneck principle applied to deep learning. To estimate the mutual information (I(x; h) and I(y; h)) in neural networks, the authors define a lower bound on the MI. Then a PixelCNN++ model (for I(x; h)) and a partially frozen classifier (for I(y; h)) are used to compute the MI during classifier and autoencoder training. For both tasks, the authors report the mutual information between hidden layers and input training data first increase for a while and then decrease. The generated images conditioned on hidden layers by the PixelCNN++ were shown to demonstrate the fitting and compression of data in a visual and intuitive fashion.

In general, the paper is well-written and organized. The idea behind the paper is not novel. Shwartz-Ziv &amp; Tishby (2017) and Nash et al. (2018) also attempt to test the information bottleneck principle by estimating the mutual information. The results of this paper are specious and hard to be explained. 

## Issues with the tightness of the lower bound
The tightness of the lower bound is dependent on the KL divergence between the true conditional distribution p(x|h) and the approximating distribution q(x|h). Does the adopted PixelCNN++ is good enough to approximate the true conditional distribution? There is not any discussion.

## Issues with the results of autoencoder
The decrease of the mutual information in autoencoder training is very specious. Since the decoder part of autoencoder should generate better and better images during the training process, does it mean that the PixelCNN++ was worse? Does it imply that the optimization of the PixelCNN++ has some unknown problems?

## Issues with the connection between this paper and Nash et al. (2018)
These two paper have used the same lower bound and the same PixelCNN++ for estimating the mutual information. The observations are also similar. Both of these papers found the mutual information between inputs and network layers decreases over the training. The differences of these two papers are the adopted neural networks and the dataset, which are kind of minor.  
</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">4: Ok but not good enough - rejection</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">3: The reviewer is fairly confident that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_BkxPuVQxA7" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Response to AnonReviewer1</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HklbTjRcKX&amp;noteId=BkxPuVQxA7"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">(anonymous)</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">19 Nov 2018</span><span class="item">ICLR 2019 Conference Paper779 Public Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Thank you for your review. Amendments and alterations have been made to the paper to account for minor changes. This will be uploaded as a revision shortly. Regarding the major points of the review, we will address these here. 

It is unclear from this review what about the results are specious and hard to explain. 

Regarding the tightness of the bound. There is no way of theoretically knowing how good the bound is. Another perspective to take is that of USABLE information and the analysis thereof, which is arguably in line with the perspective of Schwartz-Ziv &amp; Tishby. That is, just because information is present, does not mean it is useful or even accessible. As an example of this, consider the process of hashing a password: the information is retained and recoverable but useless without the correct access. A PixelCNN++ is state of the art at extracting usable information as an explicit image distribution estimator. It is unlikely that any other recent models would do better. Therefore, we chose to trade computation for as tight of a bound as we could. In fact, it takes approximately two weeks to train a single PixelCNN++ model (which yields a single data point in Figure 3c and d) to interpret the mutual information here. 

Regarding the autoencoder. We agree that these results can seem counter-intuitive. However, there are a number of possible explanations for these:
1. The autoencoder is learning a representation at the bottleneck for which it is easier for a decoder to learn even at the cost of reducing MI (we mentioned this in the paper already).
2. The mean-squared-error loss criterion is not well suited to preserving information. This issue is similar to the ‘mode averaging’ problem that causes blurry reconstructions in an autoencoder trained with this loss. Essentially, the target and the reconstruction are different owing to an imperfect loss function and therefore information is discarded.
3. Some global components are easier to reconstruct than local features. This is nearly the same as the previous point, but since the MI computation accounts for every pixel in the reconstruction, unless sharp details are being modeled by the autoencoder (which they’re not), information will be lost.

Regarding issues with the connection of this paper with Nash et. al: these were undertaken concurrently and should be consider as such. 
</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div><div class="note_with_children"><div id="note_HJlXGqI53Q" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Interesting empirical work on compression in Resnets with partially inconclusive results</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HklbTjRcKX&amp;noteId=HJlXGqI53Q"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper779 AnonReviewer3</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">03 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper779 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">-&gt; Summary

The authors propose to extend the analysis of Shwartz-Ziv &amp; Tishby on the information bottleneck principle in artificial neural network training to realistic large-scale settings. They do so by replacing otherwise intractable quantities with tractable bounds in forms of classifiers for I(y;h) and Pixel CNNs for I(x;h). In conclusion, they observe two phases during training, one that maximizes mutual information between input and hidden representation and a second one that compresses the representation at the end of training, in line with the predictions from toy tasks of Shwartz-Ziv &amp; Tishby.

-&gt; Quality

The paper is very well written, all concepts are well-motivated and explained.

-&gt; Significance

The main novelty is to replace intractable quantities in the analysis of the information bottleneck with tractable bounds in form of auxiliary models. The idea is neat and makes a lot of sense. On the other hand, some of the results and the bounds themselves are well-known and can thus not be considered novel. The main contribution is thus the empirical analysis itself and given some overly confident claims on qualitative results and missing ablation on the quantitative side, I am not convinced that the overall results are very conclusive.

-&gt; Main Concerns

The authors make a lot of claims about the qualitative diversity of samples from deeper layers h4 of the network as compared to h1 and h2. However, I do not agree with this. When I look at the samples I see a lot of variations early in training and also in layers h1 and h2. The difference to h4 seems marginal at best and not as clear cut as the authors present it. Thus, these claims should be softened.

In figure 1 I tend to say that samples at epoch 1 are more varied than at epoch 200. In figure 5 (b) seems pretty color invariant and not only (f) as claimed. In fact (f) seems pretty stable and consistent to me.

The bound in equation (2) might be quite loose, depending on the quality of the classifier or pixel CNN. Even though there is no way to test this, it should be discussed.

What is the effect of weight decay here? I suspect that weight decay plays a crucial role in the final compression phase observed in e.g. figure 3 (c), but might not be a necessary condition to make the network generalize. An ablation experiment verifying or falsifying this statement would be important to conduct and without it I am not convinced that the shown curves are conclusive.

-&gt; Minor

- You seem to use a weird math font, is this on purpose? It does not seem to be the ICLR standard.
- The bound in equation (2) is a standard variational bound and has been used many times, the authors make it sound like it is their contribution. You should maybe cite basic work and recent work on variational information bottleneck here.</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">6: Marginally above acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_H1lPaVml07" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Response to AnonReviewer3</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HklbTjRcKX&amp;noteId=H1lPaVml07"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">(anonymous)</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">19 Nov 2018</span><span class="item">ICLR 2019 Conference Paper779 Public Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Thank you for your review. Minor comments have been accounted for in the amended script. This will be uploaded as a revision shortly. Major comments will be dealt with here. 

Regarding missing ablation studies. It takes approximately two weeks to train a single PixelCNN++ model for a single data point in Figures 3c and d. We intentionally chose a PixelCNN++ model and the CINIC-10 dataset to ensure the analysis we undertook was as thorough as possible, and that the bounds on the MI were as tight as possible, given current state of the art research and computational feasibilities for this estimation. Ablations studies are simply computationally infeasible for us. 

Regarding the comments on the generated samples. It seems that what is missing from our discussion is the caveat that at convergence the images most resemble the classes they are in. Take Figure 1 for example: you are likely correct that there is more variation at epoch 1 than at epoch 200, but that variation is largely noise related and not necessarily variation in the specific characteristics that would be more natural. At 200 epochs in this figure, consider that the background (both the ground and the sky) are smooth and arguably more realistic looking than at 1 epoch, yet they still vary from sample to sample. A similar argument can be made for the horse itself, in terms of both colour and somewhat in head shape. In the paper itself we said “When inspecting the samples of Figure 4 (b) and (f), we see that even though the information content is higher at network initialisation, the sampled images look like poor renditions of their classes.”

We understand that this is a rather subjective perspective on some generated samples, but we are trying to provide insight based on what is available in this analysis. Attempting to understand information compression in a ResNet on these images is a challenging task, hence we value your perspective and input here.

Regarding the effect of weight decay. We will have to keep this for future work owing to computational constraints. That said, our stance was when where we adopted a modern, well-known, and widely used architecture and training scheme and analysed it as it stood. There are many changes that could be made - removing batch norm, varying the initialisation scheme, weight decay, optimiser preferences, etc. - but these create a scenario where the number of experiments to run becomes combinatorial. Since each PixelCNN++ model takes two weeks to train on a Titan 1080 GPU, compromises were made.
</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div></div></main></div>
  </div>
</div>


    <!-- Footer -->
    <footer class="sitemap">
      <div class="container">
        <div class="row hidden-xs">
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/venues">All Venues</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="/contact">Contact</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
    
        <div class="row visible-xs-block">
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/contact">Contact</a></li>
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
      </div>
    </footer>
    
    <footer class="sponsor">
      <div class="container">
        <div class="row">
          <div class="col-sm-10 col-sm-offset-1">
            <p class="text-center">
              OpenReview is created by the <a href="http://www.iesl.cs.umass.edu/" target="_blank">Information Extraction and Synthesis Laboratory</a>, College of Information and Computer Science, University of Massachusetts Amherst. We gratefully acknowledge the support of the OpenReview sponsors:  Google,  Facebook, NSF, the University of Massachusetts Amherst Center for Data Science, and Center for Intelligent Information Retrieval, as well as the Google Cloud Platform for donating the computing and networking services on which OpenReview.net runs.
            </p>
          </div>
        </div>
      </div>
    </footer>

  <div id="feedback-modal" class="modal fade" tabindex="-1" role="dialog">
    <div class="modal-dialog">
      <div class="modal-content">
        <div class="modal-header">
          <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button>
          <h3 class="modal-title">Send Feedback</h3>
        </div>
        <div class="modal-body">
          <p>Enter your feedback below and we'll get back to you as soon as possible.</p>
          <form action="/feedback" method="POST">
            <div class="form-group">
              <input type="email" name="from" class="form-control" placeholder="Email" />
            </div>
            <div class="form-group">
              <input type="text" name="subject" class="form-control" placeholder="Subject" />
            </div>
            <div class="form-group">
              <textarea name="message" class="form-control feedback-input" rows="5" placeholder="Message" required=""></textarea>
            </div>
          <ul id="ui-id-2" tabindex="0" class="ui-menu ui-widget ui-widget-content" style="display: none;"></ul></form>
        </div>
        <div class="modal-footer">
          <button type="button" class="btn btn-default" data-dismiss="modal">Cancel</button>
          <button type="button" class="btn btn-primary">Send</button>
        </div>
      </div>
    </div>
  </div>

  <script type="text/javascript" async="" src="https://www.google-analytics.com/analytics.js"></script><script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js"></script>
  <script>window.jQuery || document.write('&lt;script src="/static/js/vendor/jquery-2.2.4.min.js"&gt;&lt;\/script&gt;')</script>

  <script src="/static/dist/vendor.min.js"></script>
  <script src="/static/dist/templates.min.js"></script>
  <script src="/static/dist/openreview.min.js"></script>

    <script>window.legacyScripts = true;</script>


    <script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-108703919-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() { dataLayer.push(arguments); }
      gtag('js', new Date());
      gtag('config', 'UA-108703919-1');
    </script>


<div role="status" aria-live="assertive" aria-relevant="additions" class="ui-helper-hidden-accessible"></div></body></html>
<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" class="no-js"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>Structured Neural Summarization | OpenReview</title>
  <meta name="description" content="" />

      <meta name="citation_title" content="Structured Neural Summarization" />
        <meta name="citation_author" content="Anonymous" />
      <meta name="citation_publication_date" content="2018/09/27" />
      <meta name="citation_online_date" content="2018/09/27" />
      <meta name="citation_pdf_url" content="https://openreview.net/pdf?id=H1ersoRqtm" />
      <meta name="twitter:card" content="summary" />
      <meta name="twitter:site" content="@openreviewnet" />
      <meta name="og:title" content="Structured Neural Summarization" />
      <meta name="og:description" content="Summarization of long sequences into a concise statement is a core problem in natural language processing, requiring non-trivial understanding of the input. Based on the promising results of graph..." />
      <meta name="og:image" content="https://openreview.net/static/images/openreview_logo_512.png" />

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans:400,400i,700,700i" />

  <link rel="stylesheet" href="/static/css/bootstrap.min.css" />
  <link rel="stylesheet" href="/static/css/jquery-ui.min.css" />
  <link rel="stylesheet" href="/static/css/main.min.css" />
</head>

<body class="forum">
  <nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
  
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand home push-link" href="/"><strong>OpenReview</strong>.net</a>
      </div>
  
      <div id="navbar" class="navbar-collapse collapse">
        <form class="navbar-form navbar-left profile-search" role="search">
          <div class="form-group has-feedback">
            <input id="search_input" type="text" class="form-control ui-autocomplete-input" placeholder="Search ICLR 2019 Conference" autocomplete="off" />
            <span class="glyphicon glyphicon-search form-control-feedback" aria-hidden="true"></span>
          </div>
  
          <input id="search_group" type="hidden" value="ICLR.cc/2019/Conference" />
          <input id="search_content" type="hidden" value="all" />
        <ul id="ui-id-1" tabindex="0" class="ui-menu ui-widget ui-widget-content ui-autocomplete ui-front" style="display: none;"></ul></form>
  
        <ul class="nav navbar-nav navbar-right">
        
            <li id="user-menu"><a href="/login">Login</a></li>
        </ul>
      </div>
  
    </div>
  </nav>

  <div id="or-banner" class="banner" style="">
  <div class="container">
    <div class="row">
      <div class="col-xs-12"><a href="/group?id=ICLR.cc/2019/Conference" title="Venue Homepage"><img class="icon" src="/static/images/arrow_left.svg" /> Go to <strong>ICLR 2019 Conference</strong> homepage</a></div>
    </div>
  </div>
</div>
<div id="flash-message-container" class="alert alert-danger" role="alert" style="display: none;">
  <div class="container">
    <div class="row">
      <div class="col-xs-12">
        <div class="alert-content">
          <button type="button" class="close" aria-label="Close"><span aria-hidden="true">×</span></button>
        </div>
      </div>
    </div>
  </div>
</div>

<div class="container">
  <div class="row">
    <div class="col-xs-12">
      <main id="content" class="clearfix openbanner-visible legacy-styles"><div id="note_H1ersoRqtm" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Structured Neural Summarization</a> <a class="note_content_pdf" href="/pdf?id=H1ersoRqtm" title="Download PDF" target="_blank"><img src="/static/images/pdf_icon_blue.svg" /></a> </h2></div><div class="meta_row"><span class="signatures">Anonymous</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">28 Sep 2018 (modified: 11 Oct 2018)</span><span class="item">ICLR 2019 Conference Blind Submission</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span><span class="item"><a class="action-bibtex-modal" data-bibtex="@inproceedings{    &#10;anonymous2019structured,    &#10;title={Structured Neural Summarization},    &#10;author={Anonymous},    &#10;booktitle={Submitted to International Conference on Learning Representations},    &#10;year={2019},    &#10;url={https://openreview.net/forum?id=H1ersoRqtm},    &#10;note={under review}    &#10;}">Show Bibtex</a></span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Abstract: </span><span class="note_content_value">Summarization of long sequences into a concise statement is a core problem in natural language processing, requiring non-trivial understanding of the input. Based on the promising results of graph neural networks on highly structured data, we develop a framework to extend existing sequence encoders with a graph component that can reason about long-distance relationships in weakly structured data such as text. In an extensive evaluation, we show that the resulting hybrid sequence-graph models outperform both pure sequence models as well as pure graph models on a range of summarization tasks.</span></div><div class="note_contents"><span class="note_content_field">Keywords: </span><span class="note_content_value">Summarization, Graphs, Source Code</span></div><div class="note_contents"><span class="note_content_field">TL;DR: </span><span class="note_content_value">One simple trick to improve sequence models: Compose them with a graph model</span></div><div class="reply_row clearfix"><div class="item" id="reply_count">10 Replies</div></div></div><hr class="small" /><div id="note_children"><div class="note_with_children"><div id="note_BJgtlQaBTm" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Response Summary</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=H1ersoRqtm&amp;noteId=BJgtlQaBTm"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper621 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">11 Nov 2018</span><span class="item">ICLR 2019 Conference Paper621 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Thank you for all your comments we respond to your comments individually. Below you can find a summary for all the reviewers.

We plan to run the following experiments:
•	[Experiment 1] BiLSTM on natural language inputs using Stanford CoreNLP information. For this, we will extend token embeddings by information from the CoreNLP parser, and introduce special tokens (“&lt;REF1&gt;”, …) to mark co-references.
•	[Experiment 2] BiLSTM+GNN on natural language inputs using only syntactic information. Concretely, each token will be represented by one node and we introduce one node per sentence. The only edges will be “NextToken” and “NextSentence”. This experiment tests the performance of our model using only syntactic information used by other models (e.g., hierarchical representations that split sentences).
•	[Experiment 3] BiLSTM+GNN on natural language input using syntactic and equality information. This is like experiment 2, but will also add edges between non-stopword nodes corresponding to tokens that have identical string representations when stemmed. 
•	[Experiment 4] BilSTM+GNN -&gt; LSTM+Pointer+Coverage. We will extend the full model by See et al. with additional graph information.

Please, do let us know if these sufficiently address the concerns you mention in your review or if you would like to see other experiments.

We also want to emphasize again the broad applicability of our method. While the natural language summarization task is clearly the most interesting one, we do want to remark that our very general model is able to compete with (and beat) specialized approaches on the source code tasks. We have spent very little optimizing our models to the different tasks, and strongly believe that intensive tuning of hyperparameters to each of these tasks could further improve our results.</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_S1xZrF4J6m" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Interesting idea and promising results</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=H1ersoRqtm&amp;noteId=S1xZrF4J6m"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper621 AnonReviewer2</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">06 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper621 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">This paper presents a structural summarization model with a graph-based encoder extended from RNN. Experiments are conducted on three tasks, including generating names for methods, generating descriptions for a function, and generating text summaries for news articles. Experimental results show that the proposed usage of GNN can improve performance by the models without GNN. I think the method is reasonable and results are promising, but I'd like to see more focused evaluation on the semantics captured by the proposed model (compared to the models without GNN).

Here are some questions and suggestions:

- Overall, I think additional evaluation should be done to evaluate on the semantic understanding aspects of the methods. Concretely, the Graph-based encoder has access to semantic information, such as entities. In order to better understand how this helps with the overall improvement, the authors should consider automatic evaluation and human evaluation to measure its contribution. Also from fig. 3, we can see that all methods get the "utf8 string" part right, but it's hard to say the proposed method generates better description. 

- In the last table in Tab. 1, why the authors don't have results for adding GNN for the pointer-generator model with coverage?

</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">6: Marginally above acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_ByxzV76S6X" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Response &amp; Additional Experiments</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=H1ersoRqtm&amp;noteId=ByxzV76S6X"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper621 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">11 Nov 2018</span><span class="item">ICLR 2019 Conference Paper621 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Thanks for your time and helpful comments. As discussed in our reply to all reviews, we will run four additional experiments covering points raised by the different reviewers. However, while we believe that a human evaluation of generated summaries would be helpful, setting this up during the rebuttal period seems to be impossible. Do let us know if you want us to run more experiments / provide more results.</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div><div class="note_with_children"><div id="note_HygI4PN52m" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>A straightforward improvement for abstractive summarization</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=H1ersoRqtm&amp;noteId=HygI4PN52m"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper621 AnonReviewer1</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">03 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper621 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">STRUCTURED NEURAL SUMMARIZATION

Summary:

This work combines Graph Neural Networks with a sequential approach to abstractive summarization across both natural and programming language datasets. The extension of GNNs is simple, but effective across all datasets in comparison to external baselines for CNN/DailyMail, internal baselines for C#, and a combination of both for Java. The idea of applying a more structured approach to summarization is well motivated given that current summarization methods tend to lack the consistency that a structured approach can provide. The chosen examples (which I hope are randomly sampled; are they?) do seem to suggest the efficacy of this approach with that intuition.

Comments:

Should probably cite CNN/DailyMail when it is first introduced as NLSummarization in Section 2 like you do the other datasets.

Can you further elaborate on how your approach is similar to and differs from that in Marcheggiani et al 2017 on Graph CNNs for Semantic Role Labeling, Bastings et al 2017 on Graph Convolutional Encoders for Syntax-aware Machine Translation, and De Cao et al 2018? Why should one elect to go the direction of sequential GNNs over the GCNs of those other works, and how might you compare against them? I would like to see some kind of ablation analysis or direct comparison with similar methods if possible.

Why would GNNs hurt SelfAtt performance on MethodDoc C# SelfAtt+GNN / SelfAtt?

Why not add the coverage mechanism from See et al 2017 in order to demonstrate that the method does in fact surpass that prior work? I'm left wondering whether the proposed method's returns diminish once coverage is added.</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">6: Marginally above acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_SJlxsmaBpm" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Response &amp; Additional Experiments</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=H1ersoRqtm&amp;noteId=SJlxsmaBpm"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper621 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">11 Nov 2018</span><span class="item">ICLR 2019 Conference Paper621 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Thanks for your thoughtful review and your time. As discussed in our reply to all reviews, we will run four additional experiments covering points raised by the different reviewers.


On related work in NLP with graphs:

Thank you for bringing up additional related work. The cited works handle quite different tasks, and so drawing a direct comparison to our work is hard. Marcheggiani et al. (2017) uses their model, with a single GCN propagation, for classification not sequence prediction, whereas Bastings et al. (2017) does sentence-to-sentence translation. Both employ purely syntactic graphs and thus lack the advantages that additional semantic information can provide. Our additional experiments 2 and 3 are designed to show the effect of this. The short paper of De Cao et al. (2018) uses a GCN over entities in multiple documents.  Finally, we want to highlight that we propose to use graphs for longer documents, whereas the approaches above are primarily concerned with single sentences. On average the CNN/DM documents lead to graphs with 900 nodes and 2.5k edges.

Regarding the question of SequentialGNN vs GCN, we believe that there are no substantial differences between the use of GCNs and GGNNs. The core contribution proposed in our paper is the idea to fuse information obtained from state-of-the-art sequence models with a form of structured reasoning that can integrate domain knowledge.
We will clarify the above in the related work section.


On the performance of SelfAtt vs. SelfAtt+GNN on MethodDoc C#:

In the paper, we discuss this result explicitly in the third paragraph of 4.1.4. The core reason for the decrease in ROUGE scores is that the SelfAtt+GNN model produces substantially longer outputs, which tends to impact ROUGE scores. This causes the substantial improvement in the BLEU score. We will extend the appendix to include examples of outputs of the SelfAtt/SelfAtt+GNN models that illustrate how the longer output improves the information content of the results. Overall, we want to note that ROUGE and BLEU are problematic measures for these tasks, but we are not aware of any other metrics that can be computed at scale.


On randomness of shown samples:

The sample in Figure 2 is one appearing in See et al. For Figure 1, we had to pick a sample that would fit within the given space, so it’s not randomly sampled. All other examples are randomly selected. 
</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_rygnAxKlRQ" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Follow up question regarding related work</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=H1ersoRqtm&amp;noteId=rygnAxKlRQ"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper621 Area Chair1</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">20 Nov 2018</span><span class="item">ICLR 2019 Conference Paper621 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Hello!
I had a follow-up question regarding related work: even given the response it still wasn't clear to me the differences and advantages of the proposed method, both theoretically and empirically, compared to previous work incorporating graph structures on the input side of sequence-to-sequence models. Even if the task is different, the methodology seems like it would be largely similar, so these methods would be reasonable baselines. Without a comparison it makes it a bit difficult to tell the merit of this particular work. Would you mind elaborating?</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_BkxA0BqW0m" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Answer regarding related work</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=H1ersoRqtm&amp;noteId=BkxA0BqW0m"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper621 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">20 Nov 2018</span><span class="item">ICLR 2019 Conference Paper621 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">The overall concept in Marcheggiani and Titov's work is similar, but we generalise it in four ways:
 (1) We consider a wider range of sequence encoders.
 (2) We show that the resulting GNN structure is useful for sequence decoding, with attention over the generated inputs.
 (3) We consider a wider range of different tasks, with different graph structures.
 (4) We incorporate semantic and across-sentence relationships, instead of only syntactic relationships.
 
While this work tackles the same problem as we do (namely, modeling long-distance
relationships in NLP) and uses the same fundamental idea (namely, modeling
relationships in graphs), we feel that our work provides the empirical evidence
that the idea is widely applicable, both across diverse modelling choices and
task choices.
 
Bastings et al. provide a follow-up on that work, focusing on aspect (2), adding
a sequence decoder. Similarly, De Cao et al. build on a similar idea, but focus
on aspect (4), but do not introduce intra-document relationships, but instead use
the graph structure to reflect an entity graph. This does not use end-to-end training
for the sequential structure of the natural language (they use pre-trained, fixed
ELMo).
 

Overall, we believe our contribution to generalise in all dimensions (1)-(4), hopefully
providing enough experimental evidence so that all researchers working on sequential
data with some inherent structure will consider mixed sequence/graph models in the
future. This is why we included non-natural language tasks (but with obvious graph
structure), showing the wide applicability of the idea.</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div></div></div></div></div><div class="note_with_children"><div id="note_Sygyxl0IhX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Limited novelty and missing some key experiments</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=H1ersoRqtm&amp;noteId=Sygyxl0IhX"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper621 AnonReviewer3</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">31 Oct 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper621 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value"># Positive aspects of this submission

- The intuition and motivation behind the proposed model are well explained.

- The empirical results on the MethodNaming and MethodDoc tasks are very promising.

# Criticism

- The novelty of the proposed model is limited since it is essentially adding an existing GGNN layer, introduced by Li et al. (2015), on top of an existing LSTM encoder. The most important novelty seems to be the custom graph representation for these sequence inputs to make them compatible with the GGNN, which should then deserve a more in-depth study (i.e. ablation study with different graph representations, etc).

- Since you compare your model performance against Alon et al. on Java-small, it should be fair to report the numbers on Java-med and Java-large as well.

- The "GNN -&gt; LSTM+POINTER" experiment results are reported on the MethodDoc task, but not for MethodNaming. Reporting this number for MethodNaming is essential to show the claimed empirical superiority of the hybrid encoder compared to GNN only.

- I have doubts about the usefulness of the proposed model for natural language summarization, for the following reasons:

    - The comparison of the proposed model for NLSummarization against See et al. is a bit unfair, since it uses additional information through the CoreNLP named entity recognizer and coreference models. With the experiments listed in Table 1, there is no way to know whether the increased performance is due to the hybrid encoder design or due the additional named entity and coreference information. Adding the entity and coreference data in a simpler way (i.e. at the token embedding level with a basic sequence encoder) in the ablation study would very useful to answer that question.

    - In NLSummarization, connecting sentence nodes using a NEXT edge can be analogous to using a hierarchical encoder, as used by Nallapati et al. ("Abstractive Text Summarization using Sequence-to-sequence RNNs and Beyond", 2016). Ignoring the other edges of the GNN graph, what are the theoretical and empirical advantages of your method compared to this sentence-level hierarchical encoder?

    - Adding the coverage decoder introduced by See et al. to your model would have been very useful to prove that the current performance gap is indeed due to the simplistic decoder and not something else.

- How essential is the weighted averaging for graph-level document representation (Gilmer et al. 2017) compared to uniform averaging?

- A few minor comments about writing:
    - In Table 1, please put the highest numbers in bold to improve readability
    - On page 7, the word "summaries" is missing in "the model produces natural-looking with no noticeable negative impact"
    - On page 9, "cove content" should be "core content"
</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">4: Ok but not good enough - rejection</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">3: The reviewer is fairly confident that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_B1g-t4TSTX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Response &amp; Additional Experiments</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=H1ersoRqtm&amp;noteId=B1g-t4TSTX"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper621 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">11 Nov 2018</span><span class="item">ICLR 2019 Conference Paper621 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Thanks for your detailed comments, which we will integrate your comments in the next version of our paper.

On novelty:

We agree that we are not contributing fundamentally new models here – indeed, we refrained from introducing a more complex architecture to make it easy to adopt this modeling approach. We believe that our work introduces a simple way to fuse state-of-the-art sequence (not only LSTMs, but /any/ sequence encoder) learning with reasoning enabled by domain-specific graph constructions. We have not found this idea in prior work, and our experiments show the value across three different tasks from different domains. We hope that other researchers can profit from our work by integrating similar techniques into their own architectures and believe that this deserves publication and wider dissemination.

As discussed in our reply to all reviewers, we will run additional experiments on the CNN/DM to analyze the influence of different graph constructions.


On GNN-&gt;LSTM+pointer on MethodNaming:

We decided to show this ablation experiment only on the MethodDoc task for presentation reasons, but we will rerun the model and provide additional results on the MethodNaming task in our next revision.


On comparison with Alon et al. 2018 on the Java-Large corpus:

We did run these experiments but realized that we could obtain best results by models that “felt” like they had too much capacity. Further analysis of this behavior traced this to a problem with a duplication of samples in the dataset. For example, about 30.7% of files in the Java-Large are near-duplicates of other files in the corpus (across all folds), indicating that results on these datasets primarily measure overfitting to the data. We managed to train competitive models, but only by choosing very large sizes for the hidden dimensions (&gt;1000) and removing dropout. In contrast, Java-Small only has 3.0% duplicates. We will clarify this in the next version of our paper. [This is similar to our experiences with the Barone &amp; Sennrich dataset discussed in Sect. 4.1.2.]


On NL Summarization and additional information:

We agree that our model uses additional information that is not available to the pure sequence models – indeed, we believe that the ability to use this information is the core contribution of our work. Indeed, it is unclear how to add information from the CoreNLP parser to a standard sequence model (how, for example, are coreference connections represented?). As discussed in our reply to all reviews, we will run additional experiments to further elucidate this effect. Primarily, we will run an LSTM baseline that uses additional per-token information in the embedding of words, and additionally will introduce fresh tokens (“&lt;REF1&gt;”, …) to mark points at which references are made. If you had other comparisons in mind, please do react quickly, as these experiments do take a bit of time...


On comparison with Nallapati et al. 2016:

The structure of the “Next” tokens in the graph model resembles that of Nallapati et al. (2016). However, the core difference is in how message-passing GNNs work. In Nallapati et al. (2016) computing the representations this is truly hierarchical, I.e. information flows in one direction: sentence representations are computed, then these are combined into a document representation. In a GNN, messages are passed in both directions, and thus our per-sentence nodes also allow the exchange of information between different tokens in the same sentence. Hence, our model is more comparable to a hierarchical setting in which information can flow both up and down.


On using coverage:

We wanted to avoid the additional work for this experiment, since we believe that the improvements from adding a coverage mechanism are orthogonal to the ones provided by our model but will now run this and provide the results once the experiments have finished.


On weighted averaging:

In past experiments on a variety of datasets and tasks, we have found that weighted averaging helps compared to uniform averaging. We believe that this is due to the fact that weighted averaging acts as an attention-like mechanism that allows the model to pick the salient information from the graph while allowing the message-passing to “freely” transfer information. Since this is also the accepted method in the GNN literature (e.g. Gilmer et al. 2017) we did not further experiment with this design decision. As our compute resources are limited, we want to avoid rerunning this ablation on the CNN/DM dataset, but will provide additional experiments on the two smaller tasks.  


Please, let us know if these do not sufficiently address the concerns you raise in your review and what alternative experiments are missing.</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_BkehgP1qaQ" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>The rebuttal add some useful clarifications and proposed experiments</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=H1ersoRqtm&amp;noteId=BkehgP1qaQ"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper621 AnonReviewer3</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">15 Nov 2018</span><span class="item">ICLR 2019 Conference Paper621 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Thank you for your reply and useful clarifications. The additional experiments you proposed may greatly enhance the quality of your paper indeed. My rating is subject to change depending on the outcome of these experiments.</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div></div></div></div></main></div>
  </div>
</div>


    <!-- Footer -->
    <footer class="sitemap">
      <div class="container">
        <div class="row hidden-xs">
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/venues">All Venues</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="/contact">Contact</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
    
        <div class="row visible-xs-block">
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/contact">Contact</a></li>
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
      </div>
    </footer>
    
    <footer class="sponsor">
      <div class="container">
        <div class="row">
          <div class="col-sm-10 col-sm-offset-1">
            <p class="text-center">
              OpenReview is created by the <a href="http://www.iesl.cs.umass.edu/" target="_blank">Information Extraction and Synthesis Laboratory</a>, College of Information and Computer Science, University of Massachusetts Amherst. We gratefully acknowledge the support of the OpenReview sponsors:  Google,  Facebook, NSF, the University of Massachusetts Amherst Center for Data Science, and Center for Intelligent Information Retrieval, as well as the Google Cloud Platform for donating the computing and networking services on which OpenReview.net runs.
            </p>
          </div>
        </div>
      </div>
    </footer>

  <div id="feedback-modal" class="modal fade" tabindex="-1" role="dialog">
    <div class="modal-dialog">
      <div class="modal-content">
        <div class="modal-header">
          <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button>
          <h3 class="modal-title">Send Feedback</h3>
        </div>
        <div class="modal-body">
          <p>Enter your feedback below and we'll get back to you as soon as possible.</p>
          <form action="/feedback" method="POST">
            <div class="form-group">
              <input type="email" name="from" class="form-control" placeholder="Email" />
            </div>
            <div class="form-group">
              <input type="text" name="subject" class="form-control" placeholder="Subject" />
            </div>
            <div class="form-group">
              <textarea name="message" class="form-control feedback-input" rows="5" placeholder="Message" required=""></textarea>
            </div>
          <ul id="ui-id-2" tabindex="0" class="ui-menu ui-widget ui-widget-content" style="display: none;"></ul></form>
        </div>
        <div class="modal-footer">
          <button type="button" class="btn btn-default" data-dismiss="modal">Cancel</button>
          <button type="button" class="btn btn-primary">Send</button>
        </div>
      </div>
    </div>
  </div>

  <script type="text/javascript" async="" src="https://www.google-analytics.com/analytics.js"></script><script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js"></script>
  <script>window.jQuery || document.write('&lt;script src="/static/js/vendor/jquery-2.2.4.min.js"&gt;&lt;\/script&gt;')</script>

  <script src="/static/dist/vendor.min.js"></script>
  <script src="/static/dist/templates.min.js"></script>
  <script src="/static/dist/openreview.min.js"></script>

    <script>window.legacyScripts = true;</script>


    <script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-108703919-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() { dataLayer.push(arguments); }
      gtag('js', new Date());
      gtag('config', 'UA-108703919-1');
    </script>


<div role="status" aria-live="assertive" aria-relevant="additions" class="ui-helper-hidden-accessible"></div></body></html>
<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" class="no-js"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>Generative Code Modeling with Graphs | OpenReview</title>
  <meta name="description" content="" />

      <meta name="citation_title" content="Generative Code Modeling with Graphs" />
        <meta name="citation_author" content="Anonymous" />
      <meta name="citation_publication_date" content="2018/09/27" />
      <meta name="citation_online_date" content="2018/09/27" />
      <meta name="citation_pdf_url" content="https://openreview.net/pdf?id=Bke4KsA5FX" />
      <meta name="twitter:card" content="summary" />
      <meta name="twitter:site" content="@openreviewnet" />
      <meta name="og:title" content="Generative Code Modeling with Graphs" />
      <meta name="og:description" content="Generative models forsource code are an interesting structured prediction problem, requiring to reason about both hard syntactic and semantic constraints as well as about natural, likely programs...." />
      <meta name="og:image" content="https://openreview.net/static/images/openreview_logo_512.png" />

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans:400,400i,700,700i" />

  <link rel="stylesheet" href="/static/css/bootstrap.min.css" />
  <link rel="stylesheet" href="/static/css/jquery-ui.min.css" />
  <link rel="stylesheet" href="/static/css/main.min.css" />
</head>

<body class="forum">
  <nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
  
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand home push-link" href="/"><strong>OpenReview</strong>.net</a>
      </div>
  
      <div id="navbar" class="navbar-collapse collapse">
        <form class="navbar-form navbar-left profile-search" role="search">
          <div class="form-group has-feedback">
            <input id="search_input" type="text" class="form-control ui-autocomplete-input" placeholder="Search ICLR 2019 Conference" autocomplete="off" />
            <span class="glyphicon glyphicon-search form-control-feedback" aria-hidden="true"></span>
          </div>
  
          <input id="search_group" type="hidden" value="ICLR.cc/2019/Conference" />
          <input id="search_content" type="hidden" value="all" />
        <ul id="ui-id-1" tabindex="0" class="ui-menu ui-widget ui-widget-content ui-autocomplete ui-front" style="display: none;"></ul></form>
  
        <ul class="nav navbar-nav navbar-right">
        
            <li id="user-menu"><a href="/login">Login</a></li>
        </ul>
      </div>
  
    </div>
  </nav>

  <div id="or-banner" class="banner" style="">
  <div class="container">
    <div class="row">
      <div class="col-xs-12"><a href="/group?id=ICLR.cc/2019/Conference" title="Venue Homepage"><img class="icon" src="/static/images/arrow_left.svg" /> Go to <strong>ICLR 2019 Conference</strong> homepage</a></div>
    </div>
  </div>
</div>
<div id="flash-message-container" class="alert alert-danger" role="alert" style="display: none;">
  <div class="container">
    <div class="row">
      <div class="col-xs-12">
        <div class="alert-content">
          <button type="button" class="close" aria-label="Close"><span aria-hidden="true">×</span></button>
        </div>
      </div>
    </div>
  </div>
</div>

<div class="container">
  <div class="row">
    <div class="col-xs-12">
      <main id="content" class="clearfix openbanner-visible legacy-styles"><div id="note_Bke4KsA5FX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Generative Code Modeling with Graphs</a> <a class="note_content_pdf" href="/pdf?id=Bke4KsA5FX" title="Download PDF" target="_blank"><img src="/static/images/pdf_icon_blue.svg" /></a> </h2></div><div class="meta_row"><span class="signatures">Anonymous</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">28 Sep 2018 (modified: 16 Nov 2018)</span><span class="item">ICLR 2019 Conference Blind Submission</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span><span class="item"><a class="action-bibtex-modal" data-bibtex="@inproceedings{    &#10;anonymous2019generative,    &#10;title={Generative Code Modeling with Graphs},    &#10;author={Anonymous},    &#10;booktitle={Submitted to International Conference on Learning Representations},    &#10;year={2019},    &#10;url={https://openreview.net/forum?id=Bke4KsA5FX},    &#10;note={under review}    &#10;}">Show Bibtex</a></span><a class="note_content_pdf item" href="/revisions?id=Bke4KsA5FX" target="_blank">Show Revisions</a></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Abstract: </span><span class="note_content_value">Generative models forsource code are an interesting structured prediction problem, requiring to reason about both hard syntactic and semantic constraints as well as about natural, likely programs. We present a novel model for this problem that uses a graph to represent the intermediate state of the generated output. Our model generates code by interleaving grammar-driven expansion steps with graph augmentation and neural message passing steps. An experimental evaluation shows that our new model can generate semantically meaningful expressions, outperforming a range of strong baselines.</span></div><div class="note_contents"><span class="note_content_field">Keywords: </span><span class="note_content_value">Generative Model, Source Code, Graph Learning</span></div><div class="note_contents"><span class="note_content_field">TL;DR: </span><span class="note_content_value">Representing programs as graphs including semantics helps when generating programs</span></div><div class="reply_row clearfix"><div class="item" id="reply_count">17 Replies</div></div></div><hr class="small" /><div id="note_children"><div class="note_with_children"><div id="note_rygKSlpcp7" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Overview of changes in first revision</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=Bke4KsA5FX&amp;noteId=rygKSlpcp7"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper437 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">15 Nov 2018</span><span class="item">ICLR 2019 Conference Paper437 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">We have updated our submission taking some of the reviewer's feedback into account and hope that this improves its clarity. Primarily, we have made the following changes:
- Experiments: We have included results for the PHOG and seq2seq baselines in the paper.
- Notation: We have slightly improved the notation in Alg. 2 and Eq. (2) and added a paragraph giving an overview of used notation in Sect. 3.
- Visualization of tree expansion: We have replaced Fig. 2 by a step-by-step version that should be easier to follow for the reader.

In the next revision, we plan to reflect the remaining feedback and make the following changes:
- Statistics about dataset and (runtime) performance of decoders.
- Experiments with a graph2seq baseline model.

</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_S1gsoQ69Tm" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Thank you</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=Bke4KsA5FX&amp;noteId=S1gsoQ69Tm"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper437 AnonReviewer3</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">15 Nov 2018</span><span class="item">ICLR 2019 Conference Paper437 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Thank you for the update. Indeed, the explanations and the notations is much better now.</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div><div class="note_with_children"><div id="note_rkeutuqqnm" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Novel Model for Programs and Impressive Results</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=Bke4KsA5FX&amp;noteId=rkeutuqqnm"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper437 AnonReviewer1</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">03 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper437 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">In this paper, authors propose a conditional generative model which predicts the missing expression given the surrounding code snippet. Authors represent programs as graphs and use some off-the-shelf encoder to obtain representations for all nodes. Inspired from the attribute grammar, authors augment every node in AST with two new nodes which contain inherited and synthesized information. Based on GGNN, a grammar-driven decoder is further proposed to sequentially generate the AST and the corresponding program. Authors also propose a large dataset which is built from open sourced projects. Experimental results on this dataset show that the proposed method achieves better predictive performance compared to several recent work. 

Strength:

1, The problem this paper tries to tackle, i.e., building generative models of code, is very challenging and of great significance. 

2, The overall model is a novel and successful attempt to incorporate the structure information of the program into neural networks. I think it will be inspiring for other machine learning based programming applications.

3, The results are very promising and impressive, especially given the large size of the proposed dataset. For example, the top 5 accuracy of predicting correct expression on unseen projects is 57%.

Weakness:

1, I think it would be great to provide more statistics of the proposed dataset, e.g., the average number of tokens, the average size of ASTs. 

2, Given the dynamic nature of the graph generation process, I am curious about the efficiency of the proposed method. It would be great to provide some run time information. Also, since recurrent networks are heavily used throughout the model, I wonder how difficult the training process is. 

3, It would be great to also compare the log likelihood on the test set.

4, It is unclear from the paper that whether authors use a pre-trained GGNN as encoder or train the encoder end-to-end with the decoder from scratch.

5, It would be great to improve figure 2 as it is not easy to read. Maybe draw another graph to illustrate the temporal evolution of AST?

Overall, I think this paper has made a great progress towards neural modelling of programs and recommend it to be accepted for ICLR.
</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">7: Good paper, accept</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_S1gbGzT5aX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Answers to review questions</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=Bke4KsA5FX&amp;noteId=S1gbGzT5aX"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper437 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">15 Nov 2018</span><span class="item">ICLR 2019 Conference Paper437 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Thank you for your careful review and kind comments. We hope that we can further improve our submission with your feedback.

&gt; 1, I think it would be great to provide more statistics of the
&gt; proposed dataset, e.g., the average number of tokens, the average size
&gt; of ASTs. 

As a reminder, there are 344k samples in the dataset overall. There are on average 4.32 (stddev 3.80) tokens per expression to generate [2 tokens: 88k, 3 tokens: 116k, 4 tokens: 38k, 5 tokens: 32k, 6 tokens: 21k, 7 tokens or more: 49k]. The generated trees on average have 3.69 (stddev 3.06) production steps. The dataset is clearly dominated by simple expressions such as “x &gt; y” and “x[y]” (we have filtered out single-variable expressions), but longer expressions are included often as well (cf. Sect. 2 for more details on the selection process). We can also report that we have successfully extended the model to generate whole blocks of statements in a different research project.

&gt; 2, Given the dynamic nature of the graph generation process, I am
&gt; curious about the efficiency of the proposed method. It would be great
&gt; to provide some run time information. Also, since recurrent networks
&gt; are heavily used throughout the model, I wonder how difficult the
&gt; training process is.

Regarding performance: Training is relatively efficient, as we know the target expansion graph and can thus compute the representations of all nodes in the expansion graph in one go. While that computation is relatively easy to parallelize, its length is the length of the longest path in the target expansion graph. We currently cap this at 50 during training (which excludes only few examples in our dataset). Combined with the computationally relatively expensive GGNN-based encoder, training on a K80 processes around ~25 samples/s, compared to about ~60 samples/s just for the encoder. 

As we needed to implement beam search at test time, we have decided to entirely forego batching (and, indeed, GPU usage) at test time, and have essentially implemented Alg. 1 from the paper directly in Python, pruning back the set of beams after each expansion step. For this, “getRepresentation” is a lazy implementation of Eq. (2), computing node representations by message passing “on demand”. We made no efforts to optimize this implementation, instead aiming for simplicity to avoid bugs. An implementation in a dynamic computation graph framework such as TF Eager or PyTorch should be able to significantly outperform our code.

We will report precise runtime statistics in the supplementary material in our next revision. We also plan to release our implementation.

&gt; 3, It would be great to also compare the log likelihood on the test
&gt; set.

The perplexity shown in Table 1 is directly proportional to the log likelihood in the test set, albeit normalized per token. Could you please elaborate on what you had in mind and how this differs from the results in Table 1?

&gt; 4, It is unclear from the paper that whether authors use a pre-trained
&gt; GGNN as encoder or train the encoder end-to-end with the decoder from
&gt; scratch.

The full network is trained end-to-end with no pretraining. We will clarify this in the text.

&gt; 5, It would be great to improve figure 2 as it is not easy to read.
&gt; Maybe draw another graph to illustrate the temporal evolution of AST?

We’re sorry that this figure is not legible. Given the suggested page limit we wanted to make this explanation as concise as possible. In the new version, we redrew this figure as a sequence of multiple minifigures that show the evolution of the propagation.
(This has extended the content length beyond the recommended 8 pages, but we agree with you that clarity of this illustration is more important.)
</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_S1x0nNKgCm" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Thanks for the update</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=Bke4KsA5FX&amp;noteId=S1x0nNKgCm"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper437 AnonReviewer1</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">20 Nov 2018</span><span class="item">ICLR 2019 Conference Paper437 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">The new figure 2 is indeed much clearer. Thanks!</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div></div></div><div class="note_with_children"><div id="note_Hyl3dbvq2X" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Interesting task and dataset.</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=Bke4KsA5FX&amp;noteId=Hyl3dbvq2X"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper437 AnonReviewer2</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">03 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper437 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">The paper introduces a 'code generation as hole completion' task and associated dataset, ExprGen. The authors proposed a novel extension of AST code generation which uses what they call Neural Attribute Grammars. They show the proposed method does well on this task, compared to ablations of their model (which are similar to previous AST approaches).

The task and dataset are interesting, and the comparison of the proposed method to baselines seems thorough. 

*Details to Improve*
The authors have a qualitative evaluation section describing the differences in errors made by various methods. Making this more quantitative by categorizing the errors and computing their frequency would be quite interesting.</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">7: Good paper, accept</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_S1ggSfa567" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Error categorization</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=Bke4KsA5FX&amp;noteId=S1ggSfa567"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper437 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">15 Nov 2018</span><span class="item">ICLR 2019 Conference Paper437 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Thank you for your kind review!

&gt; The authors have a qualitative evaluation section describing the
&gt; differences in errors made by various methods. Making this more
&gt; quantitative by categorizing the errors and computing their frequency
&gt; would be quite interesting.

We thought about this as well, but we found it hard to automatically categorize errors beyond considering syntax, type and non-typing semantic errors. We have not reported the numbers for syntax errors in this paper, as all models produce syntactically valid expressions in over 99% of the cases. If you have ideas for metrics that are effectively computable, we are happy to provide additional experimental data. 
</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div><div class="note_with_children"><div id="note_SJeXntTY37" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>PHOG experimental results</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=Bke4KsA5FX&amp;noteId=SJeXntTY37"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper437 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">02 Nov 2018</span><span class="item">ICLR 2019 Conference Paper437 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">The authors of the non-neural PHOG model have now run additional experiments on the dataset used in our paper. Note that their model is a language model and thus only takes code "left of" the hole to fill into account, and that their framework is fairly generic and does not have special modeling of which variables are in scope etc. Hence, the results of their model are only a lower bound of what their model could achieve on this task with suitable extensions; e.g., it would be possible to extend their formalism to also take code after the hole to fill into account.

Bearing these limitations in mind, their results (i.e., their row in Table 1) are as follows:
On the "Test" dataset:
 Acc@1: 34.8%
 Acc@5: 42.9%
On the "Test-only" dataset:
 Acc@1: 28.0%
 Acc@5: 37.3%</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_SyxeYOdu3Q" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Overall good ideas, but not quite ready</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=Bke4KsA5FX&amp;noteId=SyxeYOdu3Q"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper437 AnonReviewer3</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">01 Nov 2018 (modified: 19 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper437 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span><a class="note_content_pdf item" href="/revisions?id=SyxeYOdu3Q" target="_blank">Show Revisions</a></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">The paper proposes a code completion task that given the rest of a program, predicts the content of an expression. This task has similarity to code completion tasks in the code editor of an IDE. The paper proposes an interesting problem, but the paper would benefit if writing and evaluation are significantly improved.

The work builds on prior research by Allamanis et al. 2018b that performs such completions of single variables by picking from the variables in the scopes. The difference here is that portions of parse trees are predicted as opposed to a single variables, where the algorithm from the prior research is used to predict single variables.

Writing-wise the paper is hard to read on the technical part with many unclear details and this portion needs a good amount of extra explanations. The Epsilon set includes triples which are not described and need understanding equation (2). The first element of this triple is an edge label &lt;edge&gt;($a$, $v$) where $a$ is an AST and $v$ is a node. Thus, edges of the graph end up between entire ASTs and nodes? While I can see how could this make sense, there is certainly lack of explanation going on here. Overall, this part is hard to parse and time-consuming to understand except at high level. Furthermore, the text has many functions without signatures and they seem to be used before they are defined (e.g. getRepresentation).

Technically, the approach also seems very similar to N3NN by Parisotto et al, ICLR 2017. There should be more elaboration on what is new here. Otherwise, the novelty of the paper really is just combining this work with Allamanis et al. 2018b.

In terms of evaluation, the task seems to be on a different set of expressions than the one explained in the exposition. How many expressions where there in the evaluation programs and how many were chosen to evaluate on and based on what criteria. It seems from the exposition that expressions with field accessed and function calls are not possible to be generated, but then some completions show method calls. How much of the full task is actually solved? In particular, several of the cited prior works solve specific problems like constants that are ignored here.

The evaluation is mostly an ablation studies of the proposed approach by removing edges from the final idea. 
Besides this, the paper also introduces a new dataset for showcasing the technique and does not report sizes and running times, essentially not answering basic questions like what is the trade-off between the different techniques. Comparison to actual prior works on similar tasks is also lacking (some TODO is left in the paper), but there is the claim that existing neural techniques such as seq2seq perform "substantially worse". I guess the authors have extra experiments not included for lack of space or that the evaluation was not ready at submission time.
</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">7: Good paper, accept</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_HJl5-iMxAX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Further questions?</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=Bke4KsA5FX&amp;noteId=HJl5-iMxAX"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper437 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">19 Nov 2018</span><span class="item">ICLR 2019 Conference Paper437 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Thank you again for your valuable and detailed feedback. We will add the content of the additional answers we've given in the comments here to the next revision of the paper. Concretely, we will provide more details on (1) the selection of samples in our dataset as well as how we infer the grammar (this will clarify the issue of method calls as well), (2) the exact meaning of lastUse in Alg. 2, with a note on the relationship to Allamanis et al. 2018 (3) the relation to R3NN. Are there any other open questions you had that we overlooked?

Finally, as many of the points you raised in your initial review have been clarified / resolved, would you consider raising your rating for the updated version of our paper?</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_rJgMmnfxC7" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Yes</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=Bke4KsA5FX&amp;noteId=rJgMmnfxC7"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper437 AnonReviewer3</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">19 Nov 2018</span><span class="item">ICLR 2019 Conference Paper437 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Looking forward to revisions</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div><div class="note_with_children"><div id="note_HJeYe4p9p7" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Clarification and answers to review questions (Part 2)</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=Bke4KsA5FX&amp;noteId=HJeYe4p9p7"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper437 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">15 Nov 2018</span><span class="item">ICLR 2019 Conference Paper437 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">[Second part of reply, as we were over 5000 chars]

&gt; In terms of evaluation, the task seems to be on a different set of 
&gt; expressions than the one explained in the exposition. How many 
&gt; expressions where there in the evaluation programs and how many were 
&gt; chosen to evaluate on and based on what criteria.

This is discussed in the first paragraph of Sect. 5:
- "all expressions of the fragment that we are considering (i.e.,
   restricted to numeric, Boolean and string types, or arrays of such
   values; and not using any user-defined functions)"
- "343974 samples overall [...] ~100k samples generated from 114 projects
   into a 'test-only' [...] remaining data we split into
   training-validation-test sets (60-20-20)"

We are not sure what additional information you are asking for here. Could you please elaborate?

&gt; It seems from the exposition that expressions with field accessed and 
&gt; function calls are not possible to be generated, but then some 
&gt; completions show method calls.

We exclude _user-defined_ functions but allow the built-in functions (and fields) of the considered data types, which primarily include string manipulation/tests ("Substring", "IndexOf", etc.) and generic functions such as "Equals" or the "Length" field of arrays. These built-in function calls are added as new productions in the underlying C# expression grammar.

&gt; In particular, several of the cited prior works solve specific 
&gt; problems like constants that are ignored here.

We do handle constants (i) by generation from a vocabulary and (ii) by copying from context (cf. "Choosing Productions, Variables &amp; Literals" and equation (5)); what other problem do you have in mind here?

&gt; The evaluation is mostly an ablation studies of the proposed approach 
&gt; by removing edges from the final idea. Besides this, the paper also 
&gt; introduces a new dataset for showcasing the technique and does not 
&gt; report sizes and running times, essentially not answering basic 
&gt; questions like what is the trade-off between the different techniques.

We will update the paper to include additional statistics about the experiments (for example, how many epochs were needed to train to convergence, how long an epoch takes on our dataset). Are there any specific statistics that you are interested in besides runtime?

&gt; Comparison to actual prior works on similar tasks is also lacking 
&gt; (some TODO is left in the paper), but there is the claim that existing 
&gt; neural techniques such as seq2seq perform "substantially worse".

A seq2seq baseline achieves 21.8% accuracy (28.1% accuracy in the 5 most probable results returned by beam search) on the test dataset. The perplexity is very high 87.5, primarily driven by uncertainty about generating variables in generated expressions. On the test-only dataset, these are 10.8% accuracy (16.8% @5) and perplexity 130.5.
We have also updated the paper with the PHOG results.</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_rkxpzWG36m" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Thanks for the updates. Mostly questions about eval:</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=Bke4KsA5FX&amp;noteId=rkxpzWG36m"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper437 AnonReviewer3</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">16 Nov 2018</span><span class="item">ICLR 2019 Conference Paper437 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">- choosing expressions:

I think part of the question is answered to other reviewers about size of expressions. But for x &gt; y there are 3 expressions that match the description. x, y and x &lt; y. I guess you only take x&lt;y. What is the vocabulary size?

- functions and constants:

Are functions generated with pickLiteral ? There is no special rule for choosing a built-in function in the generation process, yet these functions are in the dataset. Is there a separate vocabulary for functions and other literals? When copying from the context, do you only include functions or all literals? When picking the dataset, how do you decide if a function is user-defined?

Thanks for improving the experiments.</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_Ske3KQBnT7" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>More answers</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=Bke4KsA5FX&amp;noteId=Ske3KQBnT7"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper437 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">16 Nov 2018</span><span class="item">ICLR 2019 Conference Paper437 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">On choosing expressions:

We are greedily picking the largest allowed expression from the ASTs that we consider. So for example, from "if ((boolVar || x &gt; y) &amp;&amp; UserDefinedFoo(x + y + z - 1))", we select "boolVar || x &gt; y" and "x + y + z - 1" and no other subexpressions.


On vocabulary size:
In the graph-expansion setting, there is no classical decoder vocabulary. There is a grammar that we infer from the expressions observed in the training data. This yields rules such as "|Expr| -&gt; ! |Expr|", "|Expr| -&gt; |Expr| + |Expr|", "|Expr| -&gt; |Expr|.Equals(|Expr|", where |Expr| is a non-terminal. That inferred grammar has 222 expressions in total for our dataset, and includes the built-in functions applicable to the datatypes we support.

Some non-terminals are treated specially, as discussed in the paper. Concretely, |Variable| is expanded using pickVariable from Eq. 4, and |${Type}Literal| is expanded using pickLiteral from Eq. 5. The vocabularies used in pickLiteral have size 50, i.e., we pick from the 50 most common integer/character/string literals observed in the training data.
The copying part of the pickLiteral has access to all tokens in the context that are not language keywords ("for", "public", etc). Anecdotally, we can report that this makes no significant difference -- this masking of keywords/nonterminal nodes in the context was disabled by a bug for some experimental runs without negative effects.


On generating functions:
See above - the limited number of functions have dedicated grammar rules, i.e., "|Expr|.Equals(|Expr|)" is treated analogous to generating "|Expr| + |Expr|".


On determining "user-definedness" of methods:
As we only support methods, there is a straightforward check. When we observe "var.Method(${args})", we check if "var" is of an allowed type; this implies that Method is implemented in the type and not by the user. If the arguments ${args} are also in our fragment of the language, we include the full expression in the dataset; the inferrence of grammar rules from the observed ASTs then yields a rule |Expr| -&gt; |Expr|.Method(...)".

This is actually not completely correct, as C# has an extension mechanism by which methods can be added to existing type. However we found this to be seldomly used on the types we are restricting ourselves to, though this leads to a handful of user-defined extension methods occuring in our grammar (e.g., there is "|Expr| -&gt; |Expr|.VirtualPathToDbPath()")</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div></div></div><div class="note_with_children"><div id="note_Skly0QT9pm" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Clarification and answers to review questions</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=Bke4KsA5FX&amp;noteId=Skly0QT9pm"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper437 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">15 Nov 2018</span><span class="item">ICLR 2019 Conference Paper437 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Thanks for the thorough review. We will try to improve the writing to make the parts of the paper you found hard to follow easier to read.

&gt; The work builds on prior research by Allamanis et al. 2018b that 
&gt; performs such completions of single variables by picking from the 
&gt; variables in the scopes. The difference here is that portions of parse 
&gt; trees are predicted as opposed to a single variables, where the 
&gt; algorithm from the prior research is used to predict single variables.

We want to point out that this is not quite precise -- the model from Allamanis et al. 2018b applies a much more complex analysis to identify the correct variable, introducing speculative data flow edges (i.e., "how would the graph look like if a certain variable were used in this location"). Our method is much more simple, and is more akin to using a pointer network to select a variable available in scope.

&gt; Writing-wise the paper is hard to read on the technical part with many 
&gt; unclear details and this portion needs a good amount of extra 
&gt; explanations. The Epsilon set includes triples which are not described 
&gt; and need understanding equation (2). The first element of this triple 
&gt; is an edge label &lt;edge&gt;($a$, $v$) where $a$ is an AST and $v$ is a 
&gt; node.

You seem to be confusing functions $F(a, v)$ and edges $(u, label, v)$, which are not the same thing and should not be used interchangeably. A function like “parent(a, v)” returns a node from the partial AST $a$ (in this case, the parent node of $v$). An edge is a triple of “(node, label, node)”, explicitly defined in the paragraph right above Eq. (2). The edge labels and function names are (generally) not shared.

We apologize for this confusion. We have updated the paper with a new Notation paragraph that formally defines the constituents of edges triples and functions.

&gt; Thus, edges of the graph end up between entire ASTs and nodes?

No, edges are always between nodes. The functions like parent(a, v) return a /node/ from the partial AST $a$ (e.g. in this case, the parent node of $v$), and should not be confused with edge types.

&gt; Furthermore, the text has many functions without signatures and they 
&gt; seem to be used before they are defined (e.g. getRepresentation).

We indeed stripped the text of explicit signatures for space reasons (as we felt they were implicitly defined anyway), but we remedied this somewhat in the new revision. We have added a Notation paragraph to explain the used functions, which we hope is sufficient. If you feel more context is needed, we can also include explicit signatures everywhere.

&gt; Technically, the approach also seems very similar to N3NN by Parisotto 
&gt; et al, ICLR 2017. There should be more elaboration on what is new 
&gt; here.

[We assume this was a typo, and you refer to R3NNs] The core difference is that R3NNs use only the tree structure. While their up-then-down recursion scheme allows information sharing between different sibling subtrees in principle, no explicit domain knowledge is integrated to directly connect relevant parts of the tree. Our core contribution is to show how to integrate richer domain knowledge directly into the model.

Using a R3NNs in a generative procedure also implies a quadratic computational cost, as each partial tree is traversed twice at each expansion step (summing up to roughly \sum_{1 &lt; i &lt; V} 2i = V^2 + V), whereas our sequential graph propagation requires only a linear pass over all nodes in our graph, where each node in the expansion tree is visited at most twice (once for inherited and once for synthesized attributes).

[On a side note, the authors of the R3NN paper have communicated to us privately that training the model was extremely hard, requiring careful tuning of hyperparameters to ensure convergence to a reasonable state.
In contrast, our model required almost no hyperparameter tuning to get good results, and we only did a cursory exploration to create the experiments in the paper]</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_H1eHUfG36m" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Clarifications</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=Bke4KsA5FX&amp;noteId=H1eHUfG36m"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper437 AnonReviewer3</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">16 Nov 2018</span><span class="item">ICLR 2019 Conference Paper437 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">- confusing functions $F(a, v)$ and edges $(u, label, v)$, which are not the same thing

Thank you for the clarification. The problem with $F(a, v)$ being a function is that it is not clear if these functions return a single node (as not all edges have out-degree 1). For example $lastUse(a, v)$ should probably return a set of nodes, because of loops and ifs. However, the new exposition is much better for this.

What does inheritedAttr return?

- R3NNs

Thank you for the clarification. Indeed the proposed idea in this paper is much nicer than R3NN.</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_Byen_drhpX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>More answers</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=Bke4KsA5FX&amp;noteId=Byen_drhpX"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper437 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">16 Nov 2018</span><span class="item">ICLR 2019 Conference Paper437 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">lastToken, lastUse, lastSibling and parent return unique nodes. While you are right that lastUse could be understood to return all locations in which a variable may have been used in an execution (which would indeed require several edges), we mean the lexically last occurrence of the node, which is uniquely determined. This is a simplification of the approach of Allamanis et al. (2018), though we are not stating this explicitly in our submission. We will clarify this in the next revision.

[The actual source code used to compute is posted anonymously on <a href="http://paste.debian.net/hidden/7f6ba717/" target="_blank" rel="nofollow">http://paste.debian.net/hidden/7f6ba717/</a> now]


"inheritedAttr" returns the node corresponding to the inherited attribute of a node, e.g., for node 10 in step 8 of Fig. 2, inheritedAttr(10) would return 0. We will clarify this in the next revision as well.


Thank you for your very detailed questions, they do help as us a lot to identify parts of the paper that are insufficiently precise.</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div></div></div></div></div></div></main></div>
  </div>
</div>


    <!-- Footer -->
    <footer class="sitemap">
      <div class="container">
        <div class="row hidden-xs">
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/venues">All Venues</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="/contact">Contact</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
    
        <div class="row visible-xs-block">
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/contact">Contact</a></li>
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
      </div>
    </footer>
    
    <footer class="sponsor">
      <div class="container">
        <div class="row">
          <div class="col-sm-10 col-sm-offset-1">
            <p class="text-center">
              OpenReview is created by the <a href="http://www.iesl.cs.umass.edu/" target="_blank">Information Extraction and Synthesis Laboratory</a>, College of Information and Computer Science, University of Massachusetts Amherst. We gratefully acknowledge the support of the OpenReview sponsors:  Google,  Facebook, NSF, the University of Massachusetts Amherst Center for Data Science, and Center for Intelligent Information Retrieval, as well as the Google Cloud Platform for donating the computing and networking services on which OpenReview.net runs.
            </p>
          </div>
        </div>
      </div>
    </footer>

  <div id="feedback-modal" class="modal fade" tabindex="-1" role="dialog">
    <div class="modal-dialog">
      <div class="modal-content">
        <div class="modal-header">
          <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button>
          <h3 class="modal-title">Send Feedback</h3>
        </div>
        <div class="modal-body">
          <p>Enter your feedback below and we'll get back to you as soon as possible.</p>
          <form action="/feedback" method="POST">
            <div class="form-group">
              <input type="email" name="from" class="form-control" placeholder="Email" />
            </div>
            <div class="form-group">
              <input type="text" name="subject" class="form-control" placeholder="Subject" />
            </div>
            <div class="form-group">
              <textarea name="message" class="form-control feedback-input" rows="5" placeholder="Message" required=""></textarea>
            </div>
          <ul id="ui-id-2" tabindex="0" class="ui-menu ui-widget ui-widget-content" style="display: none;"></ul></form>
        </div>
        <div class="modal-footer">
          <button type="button" class="btn btn-default" data-dismiss="modal">Cancel</button>
          <button type="button" class="btn btn-primary">Send</button>
        </div>
      </div>
    </div>
  </div>

  <script type="text/javascript" async="" src="https://www.google-analytics.com/analytics.js"></script><script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js"></script>
  <script>window.jQuery || document.write('&lt;script src="/static/js/vendor/jquery-2.2.4.min.js"&gt;&lt;\/script&gt;')</script>

  <script src="/static/dist/vendor.min.js"></script>
  <script src="/static/dist/templates.min.js"></script>
  <script src="/static/dist/openreview.min.js"></script>

    <script>window.legacyScripts = true;</script>


    <script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-108703919-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() { dataLayer.push(arguments); }
      gtag('js', new Date());
      gtag('config', 'UA-108703919-1');
    </script>


<div role="status" aria-live="assertive" aria-relevant="additions" class="ui-helper-hidden-accessible"></div></body></html>
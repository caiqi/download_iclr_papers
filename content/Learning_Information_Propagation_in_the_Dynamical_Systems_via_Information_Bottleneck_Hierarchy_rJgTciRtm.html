<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" class="no-js"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>Learning Information Propagation in the Dynamical Systems via Information Bottleneck Hierarchy | OpenReview</title>
  <meta name="description" content="" />

      <meta name="citation_title" content="Learning Information Propagation in the Dynamical Systems via Information Bottleneck Hierarchy" />
        <meta name="citation_author" content="Anonymous" />
      <meta name="citation_publication_date" content="2018/09/27" />
      <meta name="citation_online_date" content="2018/09/27" />
      <meta name="citation_pdf_url" content="https://openreview.net/pdf?id=rJgTciR9tm" />
      <meta name="twitter:card" content="summary" />
      <meta name="twitter:site" content="@openreviewnet" />
      <meta name="og:title" content="Learning Information Propagation in the Dynamical Systems via..." />
      <meta name="og:description" content="Extracting relevant information, causally inferring and predicting the future states with high accuracy is a crucial task for modeling complex systems. The endeavor to address these tasks is made..." />
      <meta name="og:image" content="https://openreview.net/static/images/openreview_logo_512.png" />

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans:400,400i,700,700i" />

  <link rel="stylesheet" href="/static/css/bootstrap.min.css" />
  <link rel="stylesheet" href="/static/css/jquery-ui.min.css" />
  <link rel="stylesheet" href="/static/css/main.min.css" />
</head>

<body class="forum">
  <nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
  
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand home push-link" href="/"><strong>OpenReview</strong>.net</a>
      </div>
  
      <div id="navbar" class="navbar-collapse collapse">
        <form class="navbar-form navbar-left profile-search" role="search">
          <div class="form-group has-feedback">
            <input id="search_input" type="text" class="form-control ui-autocomplete-input" placeholder="Search ICLR 2019 Conference" autocomplete="off" />
            <span class="glyphicon glyphicon-search form-control-feedback" aria-hidden="true"></span>
          </div>
  
          <input id="search_group" type="hidden" value="ICLR.cc/2019/Conference" />
          <input id="search_content" type="hidden" value="all" />
        <ul id="ui-id-1" tabindex="0" class="ui-menu ui-widget ui-widget-content ui-autocomplete ui-front" style="display: none;"></ul></form>
  
        <ul class="nav navbar-nav navbar-right">
        
            <li id="user-menu"><a href="/login">Login</a></li>
        </ul>
      </div>
  
    </div>
  </nav>

  <div id="or-banner" class="banner" style="">
  <div class="container">
    <div class="row">
      <div class="col-xs-12"><a href="/group?id=ICLR.cc/2019/Conference" title="Venue Homepage"><img class="icon" src="/static/images/arrow_left.svg" /> Go to <strong>ICLR 2019 Conference</strong> homepage</a></div>
    </div>
  </div>
</div>
<div id="flash-message-container" class="alert alert-danger" role="alert" style="display: none;">
  <div class="container">
    <div class="row">
      <div class="col-xs-12">
        <div class="alert-content">
          <button type="button" class="close" aria-label="Close"><span aria-hidden="true">×</span></button>
        </div>
      </div>
    </div>
  </div>
</div>

<div class="container">
  <div class="row">
    <div class="col-xs-12">
      <main id="content" class="clearfix openbanner-visible legacy-styles"><div id="note_rJgTciR9tm" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Learning Information Propagation in the Dynamical Systems via Information Bottleneck Hierarchy</a> <a class="note_content_pdf" href="/pdf?id=rJgTciR9tm" title="Download PDF" target="_blank"><img src="/static/images/pdf_icon_blue.svg" /></a> </h2></div><div class="meta_row"><span class="signatures">Anonymous</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">28 Sep 2018 (modified: 16 Nov 2018)</span><span class="item">ICLR 2019 Conference Blind Submission</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span><span class="item"><a class="action-bibtex-modal" data-bibtex="@inproceedings{    &#10;anonymous2019learning,    &#10;title={Learning Information Propagation in the Dynamical Systems via Information Bottleneck Hierarchy},    &#10;author={Anonymous},    &#10;booktitle={Submitted to International Conference on Learning Representations},    &#10;year={2019},    &#10;url={https://openreview.net/forum?id=rJgTciR9tm},    &#10;note={under review}    &#10;}">Show Bibtex</a></span><a class="note_content_pdf item" href="/revisions?id=rJgTciR9tm" target="_blank">Show Revisions</a></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Abstract: </span><span class="note_content_value">Extracting relevant information, causally inferring and predicting the future states with high accuracy is a crucial task for modeling complex systems. The endeavor to address these tasks is made even more challenging when we have to deal with high-dimensional heterogeneous data streams. Such data streams often have higher-order inter-dependencies across spatial and temporal dimensions. We propose to perform a soft-clustering of the data and learn its dynamics to produce a compact dynamical model while still ensuring the original objectives of causal inference and accurate predictions. To efficiently and rigorously process the dynamics of soft-clustering, we advocate for an information theory inspired approach that incorporates stochastic calculus and seeks to determine a trade-off between the predictive accuracy and compactness of the mathematical representation. We cast the model construction as a maximization of the compression of the state variables such that the predictive ability and causal interdependence (relatedness) constraints between the original data streams and the compact model are closely bounded. We provide theoretical guarantees concerning the convergence of the proposed learning algorithm. To further test the proposed framework, we consider a high-dimensional Gaussian case study and describe an iterative scheme for updating the new model parameters. Using numerical experiments, we demonstrate the benefits on compression and prediction accuracy for a class of dynamical systems. Finally, we apply the proposed algorithm to the real-world dataset of multimodal sentiment intensity and show improvements in prediction with reduced dimensions.</span></div><div class="note_contents"><span class="note_content_field">Keywords: </span><span class="note_content_value">compact representation, perception, dynamical systems, information bottleneck</span></div><div class="note_contents"><span class="note_content_field">TL;DR: </span><span class="note_content_value">Compact perception of dynamical process</span></div><div class="reply_row clearfix"><div class="item" id="reply_count">7 Replies</div></div></div><hr class="small" /><div id="note_children"><div class="note_with_children"><div id="note_r1eaEaAeAX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Changes Summary </a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=rJgTciR9tm&amp;noteId=r1eaEaAeAX"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper576 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">20 Nov 2018</span><span class="item">ICLR 2019 Conference Paper576 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">We address the reviewers comments, in detail, individually in the responses, and a brief overview of the changes in the revised version are as follows:

1. The abstract and introduction are modified to reflect the problem setup and our proposed novel ideas better.

2. We further elaborate the Figure 1, thanks to the suggestions of the Reviewer-3

3. The constraints are further elaborated for the optimization problem in (3)

4. The proof of the Theorem 1 has been moved to the Appendix

5. The proposed iterative solution (initially present in the Appendix) is now termed as Corollary 1 for a better connection with the text of Section 3.1

6. The real-world experiment of sentiment prediction in Section 5 is further elaborated in terms of the problem setup, prior works. Further, we add more explanation of the applied techniques of the proposed work</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_B1lW4mEC2X" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>review</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=rJgTciR9tm&amp;noteId=B1lW4mEC2X"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper576 AnonReviewer1</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">06 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper576 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">This paper studies the problem of compactly represent the model of a complex dynamic system while preserving information. The method is based on the information bottleneck method. Basically, for a dynamic system whose states changing from X_{k-1}, X_k to X_{k+1}, the "information bottleneck hierarchy" method learns a variable B_k and B_{k+1} such that B_k predicts B_{k+1} well, B_k predicts X_k well, and B_{k+1} predicts X_{k+1} well, while minimizing the information of X_{k-1} contained in B_k. 

In my opinion, this is a very interesting framework for representing and learning a dynamic system. The paper then considers simple examples on a linear model with Gaussian noise and show that the IBH method performs better than the one-BN method. The simulation and the experiments on real data all show very good performance (even with the simple linear Gaussian estimator).

The reason that I give such a rating is that of the confusing writing.
* In the abstract, it is unclear what the goal is. For example, the second and third sentence do not explain the first sentence: "the task is a crucial task".
* Introduction is also very confusing. It seems there is not a good logic connecting each sentence.
* The paper does not give a good survey of other methods performing similar tasks, e.g., the ones the paper are comparing to in the experiment section. Therefore, it is hard to compare or to understand why the previous methods are worse.
* Figure 2: one-BN is not well defined. How do you design the IB locally? 
</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">5: Marginally below acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">3: The reviewer is fairly confident that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_S1gJpd59pQ" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Response to Reviewer-1</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=rJgTciR9tm&amp;noteId=S1gJpd59pQ"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper576 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">15 Nov 2018</span><span class="item">ICLR 2019 Conference Paper576 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">We appreciate the reviewers' views on the novelty and usefulness of the proposed results. We are also thankful for the careful reading of the manuscript, and comments which have led us to improve the presentation of the results further. We provide clarifications as follows, and would like to emphasize that the raised concerns can be addressed by taking advantage of the discussion period.

1. The abstract and introduction were modified to present the original ideas and the problem statement better.
2. The experiments section is further elaborated to have prior works and further intuition of the developed approach. We wish to claim that the proposed approach (by design) can identify complex inter- and intra- dependencies across spatio-temporal states of the dynamical system. Hence, representing the modalities as a linear dynamical system, then allow us to come up with an alternate compact dynamical system which can be used to perform discriminative learning of the speaker sentiment using machine learning classifiers like SVM.
3. By one-BN, we mean designing an Information bottleneck between any consecutive pair of RVs in the given Markov Chain. The IBH designs series of bottlenecks jointly across the entire given dynamical system. In Figure 2, we try to emphasize that the joint design performs better than the local (or individually/independently designed) bottlenecks across the hops of the dynamical system. We elaborate this further in the simulation results section of the revised manuscript.
4. Also, we have made a small cosmetic change of moving the Theorem 1 proof to the appendix.
</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div><div class="note_with_children"><div id="note_BkebP2PthQ" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Preliminary, with 1 promising experiment, but unclear and vague</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=rJgTciR9tm&amp;noteId=BkebP2PthQ"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper576 AnonReviewer2</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">02 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper576 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">The paper proposes a method to learn the conditional distribution of a random variable in order to minimize and maximize certain mutual information terms.  Interestingly, the proposed method can be applied to sentiment prediction and outperforms a 2018 method based on SVM.

Overall, the ideas seem intriguing, and the results seem promising, but I really cannot understand what the paper is saying, and I think the paper would be much stronger if it was written more clearly (to make individual sentences more clear, but also to make the broader picture more clear). Not only is the writing hard to understand (some sentences lack a verb!), but it is vague, and the notion of a "complex system" is never defined.  It seems that the technique can be applied to any (potentially non-stationary) Markov process?

Additionally, due to the lack of clarity in the writing and lack of mathematical rigor, Theorem 1 does not seem to be true as stated. I think this is an issue of stating the assumptions, and not due to a mistake in the derivation.  Right now, the actual conclusion of theorem 1 is not even clear to me.

Quality: poor/unclear
Clarity: very poor
Originality: unclear, perhaps high? Not clear how related it is to the methods of Tishby et al.
Significance: unclear, as clarity was poor, and there was minimal discussion of alternative methods.

Specific points:

- Eq (2), the first term is included because it is for the "information compression task", but I do not understand that. Where is the actual compression?  This is not traditional compression (turning a large vector into a smaller vector), but more like turning one PDF into a PDF with lower entropy?

- This paper seems to fall into the subfield of system identification (at which I am not an expert), so I'd expect to see some related literature in the field. The only compared method was the IF method of Tishby et al. from 18 years ago (and the current work seems to be a generalization of that).

- Equation (4): what exactly is the object being minimized? Is it a PDF/probability measure? Is it an *instance* of a random variable?  If it is a PDF, is it the PDF of B_k | X_{k-1} ?

- The statement of Theorem 1 is either too vague or wrong. To say "The solution... is given by" makes it sound like you are giving equations that define a unique solution. Perhaps you mean, "Any solution ... must necessarily satisfy..." ? And that is not clearly true without more work. You are basically saying that any minimizer must be a stationary point of the objective (since you are not assuming convexity). It seems everything is differentiable?  How do you know solutions even exist -- what if it is unbounded? In that case, these are not necessary conditions.

- Lemma 1: "The iterative procedure... is convergent."  The iterative procedure was never defined, so I don't even know what to make of this.

- Section 3.2: "As proved by prior work, the optimum solution obtained by a stochastic transformation that is jointly Gaussian with bottleneck's input."  I do not know what you are trying to say here. There's no predicate.

- Section 4 wasn't that interesting to me yet, since it was abstract and it seemed possible that you make a model to fit your framework well. But section 5 is much better, since you apply it to a real problem. However, what you are actually solving in section 5 is unclear. The entire setup is poorly described, so I am very confused.

</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">4: Ok but not good enough - rejection</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_SkeHfY9qaQ" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Response to Reviewer-2</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=rJgTciR9tm&amp;noteId=SkeHfY9qaQ"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper576 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">15 Nov 2018</span><span class="item">ICLR 2019 Conference Paper576 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">We want to thank the reviewer for the detailed reading of the manuscript. We agree with the reviewer that the presentation of the novel results can be improved with further clarifications/modification of the text. With the unique opportunity provided by open-review and the discussion period, we are positive that all the raised comments and concerns can be addressed to further strengthen the manuscript. We have revised the paper, and now we further elaborate the comments as follows.

1. The details of the used compression term were first provided in the original IB paper (Tishby et a. 2000), where the authors have explained that the bottleneck variable (B) is determined via a stochastic mapping p(B|X) such that it produces a soft-clustering of the input variable (X). It has been realized that we are not looking at minimization of the entropy of the bottleneck variable (which is the lower bound on the number of bits needed to specify B in a codebook). Instead, we look for the expected number of bits needed to specify the new variable (B) in a codebook without confusion, i.e., a mapping from X to B, such that X's can be clustered to B (hence compression), and the clusters are distinguishable. In other words, this is equivalent to the number of B's in the codebook such that they represent distinguishable clustering of X, which is equal to vol(X)/vol(X mapped to the same B) = 2^I(X; B) using standard asymptotic equipartition property arguments.

It can be noted that such compression can lead to spurious results, as we can very well choose to throw away all the details and reduce the required bits to zero (by mapping all of the input to a single cluster). So, the compression has to be done with some constraints of prediction (correlation) accuracies which appear through the second term in equation (2). The combined tradeoff is now a variational problem which is what is known as Information bottleneck problem, or equation (2). Further details are provided in the original IB paper.

2. The objective in equation (4) is a functional (function of functions), and the arguments are the associated probability distributions in the optimization problem (3). We have further clarified by explicitly writing the variables in the equation (4) in the revised manuscript.

3. In Theorem 1 what we meant to say is the conditions for the optimal solution (now revised). However, since we noted that the functional (4) might not be convex in the product space of the probabilities, we can only come up with a locally optimal solution.

We have made some cosmetic changes in this section, by moving the Theorem 1 proof to the appendix (to get more space for explanation). We also specified clearly the iterative solution (which previously was a section in the Appendix) as Corollary 1. We also emphasize that in the proof of the Lemma 1 we have already proved that the functional is lower bounded. We also show that each iteration monotonically reduces the functional, hence we are guaranteed to find a solution since convergence is guaranteed.

4. The experimental section is clarified further in the revision. The goal of the multimodal sentiment intensity dataset is to predict the sentiment of the speaker using the three available modalities (text, audio and visual). We have mapped the modalities into a dynamical system and then used IBH to compress the high-dimensional data and identify the complex correlations across the modalities using the \Delta matrix.

5. The manuscript is revised to take care of the presentation of the paper, especially Introduction, Sec-3.1, Sec-3.2.
</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div><div class="note_with_children"><div id="note_B1gi5FcQsX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a> ICLR 2019 Conference Paper576 AnonReviewer3</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=rJgTciR9tm&amp;noteId=B1gi5FcQsX"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper576 AnonReviewer3</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">17 Oct 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper576 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">This paper studied an extension of the Information Bottleneck Principle called Information Bottleneck Hierarchy (IBH).  The goal of IBH is to extract meaningful information from a Markov Chain. Then the authors studied case of the Gaussian linear dynamic and proposed an algorithm for computing the IBH. Then an experiment was conducted to show the usage of IBH to practical problems.

Generally I like the idea of extending Information Bottleneck to dynamic systems and I think the experiment is interesting. But I have some major questions to the paper and these questions are important about the principle you are proposing.

1. About Figure 1, there is a link between X_{k-1} and B_k, but there are no link between X_k and B_{k+1}. I understand what you said --- B_k needs to compress X_{k-1} and delivers information to B_{k+1}. My question is ---- Figure 1 can not be generated to a longer Markov Chain. It seems that the principle you proposed only works for 3 random variables X_{k-1}-X_k-X_{k+1}, which weaken the principle a lot. Please draw a longer Markov Chain like Figure 1 to illustrate your principle.

2.  About the \epsilon_{1,2,3} in formula (3). \epsilon_1 is claimed to bound the accuracy of the prediction of X_k by B_{k-1}, but where not B_{k-1} appear in the formula (actually B_{k-1} is not even in Figure 1)? \epsilon_3 is claimed to define the closeness of prediction of X_{k+1} by B_{k+1}, but why does I(X_{k-1},X_{k+1}) need to be small? In the "Markov chains are considered" before formula (3), there are some typos, for example, X_{k+1}-B_k-B_{k+1} seems not a Markov Chain. Also why you are bounding the difference of two mutual informations, but not take the absolute value (I think the difference you are considered are not guaranteed to be non-negative)? I think formula (3) is the key to understand the IBH principle, but it is not well illustrated for the readers to understand.

3. I understand that you can only derive an algorithm for Gaussian linear dynamic, since non-Gaussian case might be difficult and Gaussian linear dynamic might be good enough for modeling real random processes. But I wonder what is the physical or practical meaning for the matrices \Psi and \Delta? Why \Delta can be used to predict sentiment intensity in your experiment? It seems that \Delta carries the information from B_k to B_{k+1}, so it is only one-hop information and the sentiment intensity involves multi-hop information. How do you combine the different \Delta for different hops to predict sentiment intensity? These questions are not well illustrated in the paper.

So I think the paper can be accepted if the author can provide some more insightful illustrations, especially for Figure 1, formula (3) and the experiment. But overall I think the idea in this paper is interesting, if well illustrated.</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">5: Marginally below acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_S1gaSt9caQ" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Response to Reviewer-3</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=rJgTciR9tm&amp;noteId=S1gaSt9caQ"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper576 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">15 Nov 2018</span><span class="item">ICLR 2019 Conference Paper576 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">We are extremely grateful for the careful reading of the manuscript and would like to thank the reviewer for appreciating the novelty of the proposed results. We also would like to clarify the concerns raised by the reviewer regarding the technical contribution and hope that we would converge by utilizing this discussion period. We now address the comments point-wise as follows.

1. We thank the reviewer for the suggestion of drawing the complete Markov Chain, and to explain the part of the problem that we are solving. We have modified the Figure 1 in the revised manuscript. We now like to mention that one of the main contributions of the paper is to write the IBH as an optimization problem. An advantage of such formulation is that it can be very well generalized to any number of hops (as mentioned in the manuscript, ending of Sec-3.1). In this work, we have introduced all these concepts and solved the problem for three variable case i.e. X_{k-1}-X_{k}-X_{k+1}. The IBH solution can be derived for the general case, by appropriately differentiating the information terms. For example, a generalized differentiation can be written as 
\begin{equation}
\frac{\delta I({\bf B}_{k};{\bf B}_{k+1})}{\delta p({\bf B}_{j+1}\vert {\bf B}_{j})} = p({\bf B}_{j})(\mathbb{E}_{{\bf B}_{j+2}\vert {\bf B}_{j+1}}\ldots\mathbb{E}_{{\bf B}_{k}\vert {\bf B}_{k-1}}[D_{KL}(p({\bf B}_{k+1}\vert {\bf B}_{k})\vert\vert p({\bf B}_{k+1}))]-1),\quad\forall 1\leq j &lt; k.
\end{equation}

The mathematical generalization of the IBH is already derived, and now we are looking for some interesting datasets which can benefit from larger than three hop dynamical systems. The generalization with new real-world datasets will be presented in the future as the full version.

2. We agree with the reviewer that the optimization problem (3) is critical to understand the IBH principle. Towards that, we would like to mention the following.
a) There is a typo in the manuscript, what we meant to say is "\epsilon_1 bounds the accuracy of the prediction of X_k by B_k", since B_k is is the bottleneck corresponding to the first hop (X_{k-1}-X_k), therefore it is designed such that it better predict the X_k by compressing the information from X_{k-1}.

b) The Markov chains are correct in the sense that, we design B_{k+1} such that all the information that B_{k+1} received is only through B_{k}, to construct an alternate dynamical process of B_{k}'s. In other words, this means that B_{k} is the parent of B_{k+1} (from a Bayesian network perspective) and hence B_{k+1} is independent of all other RV in consideration given B_{k}.

c) The primary purpose of the constraints in the optimization problem (3) is to lower bound the prediction accuracies (to guarantee accurate predictions) and upper bound the compression at each hop of the alternate dynamical system (IBH). We note that only signs of the associated terms matter in this respect (as far as writing the Lagrangian is concerned), however, the mutual information constants in the constraints are carefully chosen by reverse-engineering from the proof of the Lemma 1. It has been shown in equation (21)-(22) that these differences are actually KL-divergence terms and hence guaranteed to be positive. This formulation also guarantees the lower boundedness of the functional in (4). Therefore, there is no need for the absolute difference in our framework as we only need the inequalities in one appropriate direction.

3. The reviewer is right in saying that \Phi matrix captures information flow from X_{k-1} to B_{k}, and \Delta is from B_{k} to B_{k+1}. We now note that B_{k} is designed to tap the information flow from X_{k-1} to X_{k} (here, from text to audio), and B_{k+1} wish to receive information from B_{k} to explain X_{k+1} (visual). Hence, \Delta has correlations from all three modalities because it receives correlations from text-audio and uses them to explain the visual modality. This is why \Delta is used for the sentiment prediction. A further explanation is added in the revised manuscript in the experiments sections.

4. Also, we have made a small cosmetic change of moving the Theorem 1 proof to the appendix.</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div></div></main></div>
  </div>
</div>


    <!-- Footer -->
    <footer class="sitemap">
      <div class="container">
        <div class="row hidden-xs">
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/venues">All Venues</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="/contact">Contact</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
    
        <div class="row visible-xs-block">
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/contact">Contact</a></li>
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
      </div>
    </footer>
    
    <footer class="sponsor">
      <div class="container">
        <div class="row">
          <div class="col-sm-10 col-sm-offset-1">
            <p class="text-center">
              OpenReview is created by the <a href="http://www.iesl.cs.umass.edu/" target="_blank">Information Extraction and Synthesis Laboratory</a>, College of Information and Computer Science, University of Massachusetts Amherst. We gratefully acknowledge the support of the OpenReview sponsors:  Google,  Facebook, NSF, the University of Massachusetts Amherst Center for Data Science, and Center for Intelligent Information Retrieval, as well as the Google Cloud Platform for donating the computing and networking services on which OpenReview.net runs.
            </p>
          </div>
        </div>
      </div>
    </footer>

  <div id="feedback-modal" class="modal fade" tabindex="-1" role="dialog">
    <div class="modal-dialog">
      <div class="modal-content">
        <div class="modal-header">
          <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button>
          <h3 class="modal-title">Send Feedback</h3>
        </div>
        <div class="modal-body">
          <p>Enter your feedback below and we'll get back to you as soon as possible.</p>
          <form action="/feedback" method="POST">
            <div class="form-group">
              <input type="email" name="from" class="form-control" placeholder="Email" />
            </div>
            <div class="form-group">
              <input type="text" name="subject" class="form-control" placeholder="Subject" />
            </div>
            <div class="form-group">
              <textarea name="message" class="form-control feedback-input" rows="5" placeholder="Message" required=""></textarea>
            </div>
          <ul id="ui-id-2" tabindex="0" class="ui-menu ui-widget ui-widget-content" style="display: none;"></ul></form>
        </div>
        <div class="modal-footer">
          <button type="button" class="btn btn-default" data-dismiss="modal">Cancel</button>
          <button type="button" class="btn btn-primary">Send</button>
        </div>
      </div>
    </div>
  </div>

  <script type="text/javascript" async="" src="https://www.google-analytics.com/analytics.js"></script><script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js"></script>
  <script>window.jQuery || document.write('&lt;script src="/static/js/vendor/jquery-2.2.4.min.js"&gt;&lt;\/script&gt;')</script>

  <script src="/static/dist/vendor.min.js"></script>
  <script src="/static/dist/templates.min.js"></script>
  <script src="/static/dist/openreview.min.js"></script>

    <script>window.legacyScripts = true;</script>


    <script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-108703919-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() { dataLayer.push(arguments); }
      gtag('js', new Date());
      gtag('config', 'UA-108703919-1');
    </script>


<div role="status" aria-live="assertive" aria-relevant="additions" class="ui-helper-hidden-accessible"></div></body></html>
<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" class="no-js"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>The effectiveness of layer-by-layer training using the information bottleneck principle | OpenReview</title>
  <meta name="description" content="" />

      <meta name="citation_title" content="The effectiveness of layer-by-layer training using the information bottleneck principle" />
        <meta name="citation_author" content="Anonymous" />
      <meta name="citation_publication_date" content="2018/09/27" />
      <meta name="citation_online_date" content="2018/09/27" />
      <meta name="citation_pdf_url" content="https://openreview.net/pdf?id=r1Nb5i05tX" />
      <meta name="twitter:card" content="summary" />
      <meta name="twitter:site" content="@openreviewnet" />
      <meta name="og:title" content="The effectiveness of layer-by-layer training using the information..." />
      <meta name="og:description" content="The recently proposed information bottleneck (IB) theory of deep nets suggests that during training, each layer attempts to maximize its mutual information (MI) with the target labels (so as to..." />
      <meta name="og:image" content="https://openreview.net/static/images/openreview_logo_512.png" />

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans:400,400i,700,700i" />

  <link rel="stylesheet" href="/static/css/bootstrap.min.css" />
  <link rel="stylesheet" href="/static/css/jquery-ui.min.css" />
  <link rel="stylesheet" href="/static/css/main.min.css" />
</head>

<body class="forum">
  <nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
  
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand home push-link" href="/"><strong>OpenReview</strong>.net</a>
      </div>
  
      <div id="navbar" class="navbar-collapse collapse">
        <form class="navbar-form navbar-left profile-search" role="search">
          <div class="form-group has-feedback">
            <input id="search_input" type="text" class="form-control ui-autocomplete-input" placeholder="Search ICLR 2019 Conference" autocomplete="off" />
            <span class="glyphicon glyphicon-search form-control-feedback" aria-hidden="true"></span>
          </div>
  
          <input id="search_group" type="hidden" value="ICLR.cc/2019/Conference" />
          <input id="search_content" type="hidden" value="all" />
        <ul id="ui-id-1" tabindex="0" class="ui-menu ui-widget ui-widget-content ui-autocomplete ui-front" style="display: none;"></ul></form>
  
        <ul class="nav navbar-nav navbar-right">
        
            <li id="user-menu"><a href="/login">Login</a></li>
        </ul>
      </div>
  
    </div>
  </nav>

  <div id="or-banner" class="banner" style="">
  <div class="container">
    <div class="row">
      <div class="col-xs-12"><a href="/group?id=ICLR.cc/2019/Conference" title="Venue Homepage"><img class="icon" src="/static/images/arrow_left.svg" /> Go to <strong>ICLR 2019 Conference</strong> homepage</a></div>
    </div>
  </div>
</div>
<div id="flash-message-container" class="alert alert-danger" role="alert" style="display: none;">
  <div class="container">
    <div class="row">
      <div class="col-xs-12">
        <div class="alert-content">
          <button type="button" class="close" aria-label="Close"><span aria-hidden="true">×</span></button>
        </div>
      </div>
    </div>
  </div>
</div>

<div class="container">
  <div class="row">
    <div class="col-xs-12">
      <main id="content" class="clearfix openbanner-visible legacy-styles"><div id="note_r1Nb5i05tX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>The effectiveness of layer-by-layer training using the information bottleneck principle</a> <a class="note_content_pdf" href="/pdf?id=r1Nb5i05tX" title="Download PDF" target="_blank"><img src="/static/images/pdf_icon_blue.svg" /></a> </h2></div><div class="meta_row"><span class="signatures">Anonymous</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">28 Sep 2018 (modified: 10 Nov 2018)</span><span class="item">ICLR 2019 Conference Blind Submission</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span><span class="item"><a class="action-bibtex-modal" data-bibtex="@inproceedings{    &#10;anonymous2019the,    &#10;title={The effectiveness of layer-by-layer training using the information bottleneck principle},    &#10;author={Anonymous},    &#10;booktitle={Submitted to International Conference on Learning Representations},    &#10;year={2019},    &#10;url={https://openreview.net/forum?id=r1Nb5i05tX},    &#10;note={under review}    &#10;}">Show Bibtex</a></span><a class="note_content_pdf item" href="/revisions?id=r1Nb5i05tX" target="_blank">Show Revisions</a></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Abstract: </span><span class="note_content_value">The recently proposed information bottleneck (IB) theory of deep nets suggests that during training, each layer attempts to maximize its mutual information (MI) with the target labels (so as to allow good prediction accuracy), while minimizing its MI with the input (leading to effective compression and thus good generalization). To date, evidence of this phenomenon has been indirect and aroused controversy due to theoretical and practical complications. In particular, it has been pointed out that the MI with the input is theoretically inﬁnite in many cases of interest, and that the MI with the target is fundamentally difﬁcult to estimate in high dimensions. As a consequence, the validity of this theory has been questioned. In this paper, we overcome these obstacles by two means. First, as previously suggested, we replace the MI with the input by a noise-regularized version, which ensures it is ﬁnite. As we show, this modiﬁed penalty in fact acts as a form of weight decay regularization. Second, to obtain accurate (noise regularized) MI estimates between an intermediate representation and the input, we incorporate the strong prior-knowledge we have about their relation, into the recently proposed MI estimator of Belghazi et al. (2018). With this scheme, we are able to stably train each layer independently to explicitly optimize the IB functional. Surprisingly, this leads to enhanced prediction accuracy, thus directly validating the IB theory of deep nets for the ﬁrst time.</span></div><div class="reply_row clearfix"><div class="item" id="reply_count">8 Replies</div></div></div><hr class="small" /><div id="note_children"><div class="note_with_children"><div id="note_rJe0qyKXpX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>New revision</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=r1Nb5i05tX&amp;noteId=rJe0qyKXpX"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper511 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">10 Nov 2018</span><span class="item">ICLR 2019 Conference Paper511 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">A revision of our paper has been uploaded, after incorporating the reviewers comments and suggestions.</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_HJg9b0Xxpm" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>The effectiveness of layer-by-layer training using the information bottleneck principle</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=r1Nb5i05tX&amp;noteId=HJg9b0Xxpm"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper511 AnonReviewer3</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">07 Nov 2018</span><span class="item">ICLR 2019 Conference Paper511 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">
This work is about layer-wise training of networks by way of optimizing the IB cost function, which basically measures the compression of the inputs under the constraint that some degree of information with respect to the targets must be preserved. Both terms of the IB cost function are formalized as mutual informations, but since in neural nets, the latent "compression" is a deterministic function of the inputs, a severe technical problems arises: the joint distribution between p-dimensional inputs X and the q-dimensional latent compression L is degenerate in that  its support lies in a space of dimension p (and not p+q as it would be in the non-degenerate case). As a consequence, no p.d.f. exists (with respect to the Lebesgue measure of R^{p+q}). Thus, defining mutual information is cumbersome. The paper attempts to overcome this problem by using a noisy version of the latent compression, i.e. L' = L + \epsilon, which can be seen as an "ad hoc" fix of this problem. Not too surprising, this additive noise works as a ridge-type (or weight-decay) regularizer, just as a Gaussian prior in regression.

On one hand, I find this paper interesting, because it aims at carefully studying the proposed link between DNN training and IB optimization, thereby showing that layer-wise IB training indeed seems to work very well in practice. Such results are certainly interesting, both from a theoretical and from a practical point of view. On the other hand, I honestly think that on the conceptual side, this work does not make that many really interesting contributions. The observation that additive noise works as a weight-decay regularizer is in my opinion almost trivial, and any claims about experimental results "validating(!) the IB theory" seem to contain some degree of over-selling. In summary, I think that this is a paper that certainly contains some interesting ideas, but on the other hand I am not fully convinced about the significance and relevance of the findings.       </span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">5: Marginally below acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_rye9H9_Qa7" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Response</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=r1Nb5i05tX&amp;noteId=rye9H9_Qa7"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper511 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">10 Nov 2018</span><span class="item">ICLR 2019 Conference Paper511 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Thank you for your review, we are happy you found our work interesting. The IB theory of deep learning by Tishby and Zaslavsky (2015) has attracted much interest, and increasing controversy is arising regarding some of the provided insights, such as the existence of a compression phase in training with the cross-entropy loss. However, the very basic claim of this theory, that each layer should ideally optimize the IB functional, was never verified. A direct way to validate the correctness of this claim, is to explicitly optimize the IB functional of each layer, as we did. We believe that this key element of the theory is very important to validate experimentally, perhaps even more than understanding the exact information dynamics during training with the cross-entropy loss.
</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div><div class="note_with_children"><div id="note_r1ehpIDThX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Confused discussion, lacking experiments, strong reject.</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=r1Nb5i05tX&amp;noteId=r1ehpIDThX"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper511 AnonReviewer1</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">05 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper511 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">While overall the writing quality of the paper is high, the paper itself is a strong rejection.  I believe the analysis of the paper is at points flawed, and the experiments are minimal.  

This work attempts to study the degree to which a layer by layer information bottleneck inspired objective can improve performance, as well as generally attempt to clarify some of the discussion surrounding Shwartz-Ziv &amp; Tishby 2017.  Here, the authors study a deterministic neural network, for which the mutual information estimation is difficult (I(X,L)) and error prone.  To combat this they use the noise-regularized mutual information estimator (I(X; L+eps)).  To actually estimate the mutual information the authors use the MINE estimator of Belghazi (2018).  Here they suggest using the neural network itself as a structural element in the form of the discriminator to take advantage of the specific circumstances in this case.  Doing this ensured that their estimator diverged in the zero noise limit as expected.  From here they show some experimental results of the effect of their objective on an MNIST / CIFAR10 classification task.

This paper fits into what is an increasingly large discussion in the literature, surrounding Information Bottleneck.  The paper itself does a very good job of citing recent relevant work.  Technically however I take issue with the framing of previous work in the last paragraph of the "Deep neural nets" subsection of Section 2.  Technically Achille &amp; Soatto explicitly formed a variational approximation to the posterior over the weights of the neural network and so was not a "single bottleneck layer" as stated in the paper.  More generally at the end of that paragraph it is implied that the single bottleneck layer scheme "deviates from the original theory".  This is a misleading characterization of the original information bottleneck (Tishby et al 1999) in which there was a single random variable, a representation of the data (Z) satisfying the Markov conditions Z &lt;- X -&gt; Y.   I believe the authors instead meant to say that the cited works deviate from the information bottleneck theory of learning suggested in (Shwartz-Ziv &amp; Tishby 2017).  In general the paper does a poor job of distinguishing between the Shwartz-Ziv &amp; Tishby paper and the rest, but this is a distinction that should be maintained.  The original information bottleneck may and has demonstrated utility regardless of whether the information bottleneck generally can help explain why ordinary deterministic feed forward networks trained with cross entropy and sgd generalize well.  

This also raises one of the main problems with the current work. The title, abstract and especially the conclusion ("This provides, for the first time, strong and direct emperical evidence for the validity of the IB theory of deep learning") seem to present the paper as somehow offering some clarity and further support for the assertions of the Shwartz-Ziv &amp; Tishby 2017 paper, but that paper hoped to establish that information bottleneck can explain the workings of ordinary networks.  Here the authors modify the ordinary cross entropy objective, and so their networks are necessarily not ordinary and so they cannot claim they have helped clarify our understanding of the vast majority of neural networks currently being trained.  Again, this is distinct and should be kept distinct from the utility of their proposed objective, itself inspired by the information bottleneck.  Here too the paper falls flat.  If instead of attempting to comment on networks as they are designed today they aim to proposed a new information bottleneck inspired objective they really ought to directly compare other attempts along those lines (such as the ones they themselves cite  Alemi et al. 2018, Kolchinsky et al. 2017, Chalk et al. 2016, Achile &amp; Soatto 2018, Belghazi et al. 2018) but there are no comparative studies.

The experiments are extremely lacking, not only are any of their cited alternatives compared, they don't compare to what would be an equivalent network to their but where they did utilize the noise at every layer and actually made the network stochastic.  Their reported numbers are not very impressive with their top MNIST number at 98.09 and their baseline at 97.73. These numbers are worse than many of the papers they themselves cite.  Only a single comparative results for both a limited training set run and the full one are shown, as well as only a single choice of beta.  The CIFAR10 numbers are not very good either.  There is some discussion of the text suggesting they believe their method acts like an approximate weight decay, but there are no results showing the effect of weight decay just on the baseline classification accuracies they compare against.

Technically a deterministic function need not have infinite mutual information, if it is non-invertible, i.e. the sign function, or just floating point discretization. 

Their own results in Figure 2 and the main body of the text highlight that the authors believe the true mutual information between the activations of the intermediate layers and the input is infinite.  If the true mutual information is infinite and the noise regularized estimator is only meant for comparative purposes, why then are the results of the training trajectories interpreted so literally as estimates of the true mutual information?

Just plugging in the Discriminator for the objective (equation (7)) is flawed.  The discriminator, if optimal would learn to approximate the density ratio 1 + log p(x,y)/(p(x) p(y)) .   ( see f-GAN, Norowin et al. 2016).  How does this justify using the individual elements of the discriminator in the functional form of the IB objective?  

At the bottom of page 6 they rightfully say that mutual information is invariant to reparameterizations, but their noise regularized mutual information estimator is not (by their own reference (Saxe et al 2017).

The discussion at the center of page 8 is confusing.   They claim that Figure 5 (a) is more 'quantized' than (b) and "has reduced entropy".  I think it should be the other way.  More clusters should translate to a higher KL divergence, or higher entropy.  If you need only identify which cluster an activation is in, that should require log K nats where K is the number of clusters.  (a) shows more clusters and so seems like it should cost more and have a higher entropy not a lower one.

Despite a recurring focus of the text that this paper applies and information theoretic objective at each layer of the network, and hence is novel, the final sentence of the paper suggests it might not actually be needed and single layer IB objectives can work as well.</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">2: Strong rejection</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_B1xgjhOmT7" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Response - part II</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=r1Nb5i05tX&amp;noteId=B1xgjhOmT7"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper511 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">10 Nov 2018</span><span class="item">ICLR 2019 Conference Paper511 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">- Eq. (7) is indeed a typo, thank you for pointing this out. We certainly don’t maximize the objective in (7) where the discriminator output replaces the mutual information, but the Donsker-Varadhan dual representation (6) substituted into the IB functional (5). We fixed this in our revised paper.

- Our noise regularized mutual information is not meant only for comparative purposes. We claim that this quantity is in fact a more appropriate measure for “compactness” or “complexity” than the mutual information itself (which is infinite). As such, we propose to replace the horizontal axis in the original “information-plane” of Tishby’s papers by the noise-regularized mutual information when it comes to analyzing deterministic DNNs.

- Regarding Fig. 5, we understand the confusion, thanks for pointing this out. Note that this is a continuous representation, therefore we are talking about differential entropy and not (discrete) entropy. Now, differential entropy depends not only on the number of clusters, but also on their sizes. Even a single cluster can have a very large entropy, if its size is large. For example, the entropy of a Gaussian is 0.5 ln(|2 \pi \Sigma|), which can be arbitrarily large if we take the determinant of \Sigma to be large. The point is that the entropy of a continuous distribution becomes smaller as its (effective) support becomes smaller, eventually tending to minus infinity for a distribution that is supported on a finite discrete set of points. This is exactly what’s seen in Fig. 5. In (b) the clusters are very large and the effective support of the distribution is large, whereas in (a) the clusters are very small and the effective support of the distribution is small. Therefore the differential entropy of (b) is larger than that of (a). We have clarified this point in the paper.</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_rJgqHhOX6m" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Response - part I</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=r1Nb5i05tX&amp;noteId=rJgqHhOX6m"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper511 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">10 Nov 2018</span><span class="item">ICLR 2019 Conference Paper511 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Thanks for the comments. We may have not clarified the scope and goals of our paper well enough, as well as the sense in which the effectiveness of layer-by-layer training via the IB objective helps explain the theory of (Tishby &amp; Zaslavsky, 2015) (not that of their 2017 paper, which specifically focused on nets trained with the cross-entropy objective). Let us try to clarify these points below:

- First, we do not attempt to suggest a novel IB-based objective for enhancing DNN accuracy. Also, we do not attempt to validate whether DNNs trained with the cross-entropy loss do or do not optimize the IB objective, as in (Shwartz-Ziv &amp; Tishby 2017). Our sole goal is to examine the original IB theory of DNNs suggested by Tishby and Zaslavsky (2015), and to do so for deterministic DNNs (which are more popular than stochastic ones). The principal claim in this theory is that ideally each layer should optimize the IB objective. This has not yet been directly validated to date. What has been observed empirically in (Shwartz-Ziv &amp; Tishby 2017) and in later works, is that when training nets with the cross-entropy loss, the IB objective tends to improve along the iterations. Combining this with the fact that training with the cross-entropy loss leads to good performance, one could claim that this indicates that a good IB loss in each layer leads to good performance. However, due to the difficulties in measuring MI (and the fact that I(X,L) is theoretically infinite in most interesting cases) these experiments do not give a good indication of whether the IB objective has indeed reached an optimal value  in each layer. Therefore, to directly examine the hypothesis of Tishby and Zaslavsky (2015) that optimizing the IB objective in each layer is the “ideal” thing to do in some sense, here we take “ordinary” DNNs and optimize each layer using the IB objective, with no cross-entropy term. Surprisingly, we find that this leads to competitive (and even enhanced) accuracy and generalization, and therefore constitutes a direct validation of the theory by Tishby and Zaslavsky (2015). We hope this clarifies the scope and logic behind our arguments. We have modified the introduction to make the scope and goal of our paper more clear.

- Regarding comparisons, we don’t compare the accuracy of our scheme to other IB-based methods or regularization techniques, because our paper does not propose a novel training algorithm or regularization term. We do not claim that our IB-based layer-by-layer training scheme is practical for large-scale problems, or better than other schemes of similar flavor, and do not advocate its use in applications. As mentioned above, our experiments are only meant to explicitly validate the IB theory of deep learning for deterministic DNNs. The fact that this scheme leads to performance which is on par with end-to-end cross entropy training is the key point in the experiments. Note that the accuracy achieved in our experiments doesn’t compare to other works as they used DNNs with greater capacity, thus comparing these numbers is beside the point. 

- The paper by Achille &amp; Soatto (2018) indeed does not fall into the category of “single bottleneck layer”, as you rightfully indicate. It is in the category of stochastic DNNs. This was a phrasing mistake. We have rephrased that sentence. In any case, as mentioned above, the scope of our paper is to study deterministic DNNs.

- Regarding use of the term “original theory”, please note that by that we refer to the theory of Tishby and Zaslavsky (2015) which connects the IB principle to DNN training and not to the original IB principle (Tishby et al., 1999), which of course was not presented specifically in the context of DNNs. We have attempted to clarify this in the introduction, although we originally never referred to the 1999 paper in the context of DNNs within the text (it was cited only twice very briefly in the intro and related work sections).

- If X is a continuous RV and f is a deterministic function, then it is a known fact that the mutual information between X and f(X) is always infinite. This is true regardless of whether f is invertible or not (even in the extreme case where f(X)=0). Please see Eq. (2) and the sentences below. Specifically, I(X,f(X)) = h(f(X)) - h(f(X)|X), where the conditional differential entropy (the second term) becomes minus infinity when f(X) is a deterministic function of X. This happens since the conditional density function becomes a delta function, which is true for invertible and non-invertible functions alike. This is as opposed to the discrete case, in which H(f(X)|X)=0 and there is no problem of this sort. Therefore, it is meaningless to study the original IB principle for deterministic DNNs with a continuous input, which is why we propose to study a noise-regularized version of the IB principle for DNNs.</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div><div class="note_with_children"><div id="note_Bkgj99ssnX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Layer-wise explicit IB functional training in DNNs</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=r1Nb5i05tX&amp;noteId=Bkgj99ssnX"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper511 AnonReviewer2</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">04 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper511 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">This paper provides a method to do explicit IB functional estimation for deep neural networks inspired from the recent mutual information estimation method (MINE).  By using the method, the authors 1) validate the IB theory of deep nets using weight decay, and 2) provides a layer-wise explicit IB functional training for DNN which is shown to have better prediction accuracy.

Pros:
- The paper carefully constructs a method to estimate the mutual information between high dimensional variables and address the infinite mutual information issue by adding noise to the output. This is novel and theoretical sounding. 
- The paper connects the IB theory of DNN with weight decay, which is a novel founding.

Cons:
- The paper claims no literature has been doing IB functional on a layer-by-layer objective, however, see [1, 2] for the total correlation explanation work which is closely related to IB functional and they have also verified the effectiveness of layer-by-layer objective. 
- The scope of the paper is unclear. It seems that the paper is trying to convince two things to the readers: 1) The compression phase in DNN does exist 2) Layer-wise training helps to improve the accuracy. Although these two things are close related to each other (because they all requires to estimate the IB functional), it seems that neither these two conclusions are convincing. First, the compression phase is achieved only through weight decay; without weight decay, as shown in the paper, the compression phase is gone. Does that verify the incorrectness of IB theory of deep nets? Second, for the layer-wise training, the paper only compares the layer-wise IB objective with the cross entropy loss. But if we really want to show the `effectiveness` of `layer-wise` training, one should compare the `layer-wise` training with `end-to-end` training while keeping the objective itself fixed. Otherwise, it is really difficult to draw conclusions about why the accuracy is improving, it is because of the objective changes or because of the `layer-wise` training.
- How does the beta (in IB objective) selected in the experiments for comparison? Do you use a validation dataset, and what is the final beta? If the paper fine-tune beta on the validation dateset, then the comparison of "IB functional, only the first term" and "IB functional" is unfair. 

[1]  Ver Steeg et al. Maximally Informative Hierarchical Representations of High-Dimensional Data. AISTATS 2015
[2]  Gao et al. Auto-Encoding Total Correlation Explanation. Arxiv 1802.05822.

 </span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">5: Marginally below acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_rygrGiumpX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Response</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=r1Nb5i05tX&amp;noteId=rygrGiumpX"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper511 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">10 Nov 2018</span><span class="item">ICLR 2019 Conference Paper511 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Thank you for the review. The points raised will help us clarify and improve our paper. Specifically:

- Works [1], [2], which we weren’t aware of, are indeed related to layer-wise training with a closely-related unsupervised variant of the information bottleneck. We have now added a brief discussion on these works. Thank you for pointing this out. Please note that these works do not validate the IB theory, though, because their objective is unsupervised.

- Regarding the scope of our paper, let us try to clarify. The goal of our paper is to validate the theory proposed by Tishby and Zaslavsky (2015). This theory suggests that each DNN layer should ideally optimize the IB functional to reach good performance. This theory was only partially and implicitly validated beforehand. For the purpose of testing this theory directly, we adopt a layer-wise training scheme which shows that the theory is indeed sound. We agree that it is interesting to independently study the effect of the two factors: the objective modification and the shift to a layer-wise training scheme. However we believe this is out of the scope of this paper and leave this for future work. Our paper does not attempt to conclude that layer-wise training is advantageous in this scenario, although this certainly might be the case. We have now stated the paper scope more clearly in the introduction.

- During our attempts to validate the original theory of Tishby and Zaslavsky (2015), we observed an interesting behavior regarding the controversial argument of (Shwartz-Ziv &amp; Tishby 2017) regarding the existence of a “compression phase” when training with the cross-entropy loss. Particularly, this phase didn’t appear for “vanilla” cross-entropy training, but did appear for cross-entropy training with weight decay regularization. We therefore briefly reported this, and tried to provide some insight in continuation to previous works discussing this. This observation does not contradict the original theory of Tishby and Zaslavsky (2015), which only claimed that the IB loss should ideally be optimized in each layer, but it does contribute to the discussion on the observations in (Shwartz-Ziv &amp; Tishby 2017). In any case, this is not the main focus of our paper. Our main goal is to explicitly validate the theory of Tishby and Zaslavsky (2015), and this we do by layer-wise training with the IB loss.

- For the case of “IB functional, only first term”, beta is zero (beta multiplies the second term). For the “IB functional” case, beta was chosen from {10^-4, 10^-3, 10^-2, 10^-1} on a validation set. The chosen beta for each experiment appears in Appendix C. We do not see why this is unfair.
</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div></div></main></div>
  </div>
</div>


    <!-- Footer -->
    <footer class="sitemap">
      <div class="container">
        <div class="row hidden-xs">
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/venues">All Venues</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="/contact">Contact</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
    
        <div class="row visible-xs-block">
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/contact">Contact</a></li>
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
      </div>
    </footer>
    
    <footer class="sponsor">
      <div class="container">
        <div class="row">
          <div class="col-sm-10 col-sm-offset-1">
            <p class="text-center">
              OpenReview is created by the <a href="http://www.iesl.cs.umass.edu/" target="_blank">Information Extraction and Synthesis Laboratory</a>, College of Information and Computer Science, University of Massachusetts Amherst. We gratefully acknowledge the support of the OpenReview sponsors:  Google,  Facebook, NSF, the University of Massachusetts Amherst Center for Data Science, and Center for Intelligent Information Retrieval, as well as the Google Cloud Platform for donating the computing and networking services on which OpenReview.net runs.
            </p>
          </div>
        </div>
      </div>
    </footer>

  <div id="feedback-modal" class="modal fade" tabindex="-1" role="dialog">
    <div class="modal-dialog">
      <div class="modal-content">
        <div class="modal-header">
          <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button>
          <h3 class="modal-title">Send Feedback</h3>
        </div>
        <div class="modal-body">
          <p>Enter your feedback below and we'll get back to you as soon as possible.</p>
          <form action="/feedback" method="POST">
            <div class="form-group">
              <input type="email" name="from" class="form-control" placeholder="Email" />
            </div>
            <div class="form-group">
              <input type="text" name="subject" class="form-control" placeholder="Subject" />
            </div>
            <div class="form-group">
              <textarea name="message" class="form-control feedback-input" rows="5" placeholder="Message" required=""></textarea>
            </div>
          <ul id="ui-id-2" tabindex="0" class="ui-menu ui-widget ui-widget-content" style="display: none;"></ul></form>
        </div>
        <div class="modal-footer">
          <button type="button" class="btn btn-default" data-dismiss="modal">Cancel</button>
          <button type="button" class="btn btn-primary">Send</button>
        </div>
      </div>
    </div>
  </div>

  <script type="text/javascript" async="" src="https://www.google-analytics.com/analytics.js"></script><script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js"></script>
  <script>window.jQuery || document.write('&lt;script src="/static/js/vendor/jquery-2.2.4.min.js"&gt;&lt;\/script&gt;')</script>

  <script src="/static/dist/vendor.min.js"></script>
  <script src="/static/dist/templates.min.js"></script>
  <script src="/static/dist/openreview.min.js"></script>

    <script>window.legacyScripts = true;</script>


    <script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-108703919-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() { dataLayer.push(arguments); }
      gtag('js', new Date());
      gtag('config', 'UA-108703919-1');
    </script>


<div role="status" aria-live="assertive" aria-relevant="additions" class="ui-helper-hidden-accessible"></div></body></html>
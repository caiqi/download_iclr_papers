<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" class="no-js"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>Online Bellman Residue Minimization via Saddle Point Optimization | OpenReview</title>
  <meta name="description" content="" />

      <meta name="citation_title" content="Online Bellman Residue Minimization via Saddle Point Optimization" />
        <meta name="citation_author" content="Anonymous" />
      <meta name="citation_publication_date" content="2018/09/27" />
      <meta name="citation_online_date" content="2018/09/27" />
      <meta name="citation_pdf_url" content="https://openreview.net/pdf?id=Skxqni09KX" />
      <meta name="twitter:card" content="summary" />
      <meta name="twitter:site" content="@openreviewnet" />
      <meta name="og:title" content="Online Bellman Residue Minimization via Saddle Point Optimization" />
      <meta name="og:description" content="We study the problem of Bellman residual minimization with nonlinear function approximation in general.  &#10;     Based on a nonconvex saddle point formulation of Bellman residual minimization via..." />
      <meta name="og:image" content="https://openreview.net/static/images/openreview_logo_512.png" />

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans:400,400i,700,700i" />

  <link rel="stylesheet" href="/static/css/bootstrap.min.css" />
  <link rel="stylesheet" href="/static/css/jquery-ui.min.css" />
  <link rel="stylesheet" href="/static/css/main.min.css" />
</head>

<body class="forum">
  <nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
  
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand home push-link" href="/"><strong>OpenReview</strong>.net</a>
      </div>
  
      <div id="navbar" class="navbar-collapse collapse">
        <form class="navbar-form navbar-left profile-search" role="search">
          <div class="form-group has-feedback">
            <input id="search_input" type="text" class="form-control ui-autocomplete-input" placeholder="Search ICLR 2019 Conference" autocomplete="off" />
            <span class="glyphicon glyphicon-search form-control-feedback" aria-hidden="true"></span>
          </div>
  
          <input id="search_group" type="hidden" value="ICLR.cc/2019/Conference" />
          <input id="search_content" type="hidden" value="all" />
        <ul id="ui-id-1" tabindex="0" class="ui-menu ui-widget ui-widget-content ui-autocomplete ui-front" style="display: none;"></ul></form>
  
        <ul class="nav navbar-nav navbar-right">
        
            <li id="user-menu"><a href="/login">Login</a></li>
        </ul>
      </div>
  
    </div>
  </nav>

  <div id="or-banner" class="banner" style="">
  <div class="container">
    <div class="row">
      <div class="col-xs-12"><a href="/group?id=ICLR.cc/2019/Conference" title="Venue Homepage"><img class="icon" src="/static/images/arrow_left.svg" /> Go to <strong>ICLR 2019 Conference</strong> homepage</a></div>
    </div>
  </div>
</div>
<div id="flash-message-container" class="alert alert-danger" role="alert" style="display: none;">
  <div class="container">
    <div class="row">
      <div class="col-xs-12">
        <div class="alert-content">
          <button type="button" class="close" aria-label="Close"><span aria-hidden="true">×</span></button>
        </div>
      </div>
    </div>
  </div>
</div>

<div class="container">
  <div class="row">
    <div class="col-xs-12">
      <main id="content" class="clearfix openbanner-visible legacy-styles"><div id="note_Skxqni09KX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Online Bellman Residue Minimization via Saddle Point Optimization</a> <a class="note_content_pdf" href="/pdf?id=Skxqni09KX" title="Download PDF" target="_blank"><img src="/static/images/pdf_icon_blue.svg" /></a> </h2></div><div class="meta_row"><span class="signatures">Anonymous</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">28 Sep 2018 (modified: 11 Oct 2018)</span><span class="item">ICLR 2019 Conference Blind Submission</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span><span class="item"><a class="action-bibtex-modal" data-bibtex="@inproceedings{    &#10;anonymous2019online,    &#10;title={Online Bellman Residue Minimization via Saddle Point Optimization},    &#10;author={Anonymous},    &#10;booktitle={Submitted to International Conference on Learning Representations},    &#10;year={2019},    &#10;url={https://openreview.net/forum?id=Skxqni09KX},    &#10;note={under review}    &#10;}">Show Bibtex</a></span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Abstract: </span><span class="note_content_value">We study the problem of Bellman residual minimization with nonlinear function approximation in general.  
   Based on a nonconvex saddle point formulation of Bellman residual minimization via Fenchel duality, we propose an online first-order algorithm with two-timescale learning rates.  Using tools from stochastic approximation, we establish the convergence of our problem by approximating the dynamics of the iterates using two ordinary differential equations. Moreover, as a byproduct, we establish a finite-time convergence result under the assumption that the dual problem can be solved up to some error. Finally, numerical experiments are provided to back up our theory.</span></div><div class="reply_row clearfix"><div class="item" id="reply_count">3 Replies</div></div></div><hr class="small" /><div id="note_children"><div class="note_with_children"><div id="note_HylcndNkam" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>2 time scales stochastic approximation for approximately minimizing the Bellman residual</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=Skxqni09KX&amp;noteId=HylcndNkam"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper736 AnonReviewer3</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">06 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper736 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">The paper analyzes a 2 time scales stochastic approximation algorithm for approximately solving a minmax formulation of a Bellman residual minimization problem. The minmax approach is used as a way to avoid the bias introduced when directly trying to minimize the squared norm of the Bellman residual from transition samples. As acknowledged by the authors this formulation is not new and has been described in [Dai et al. 2017] and can be traced back to [Antos et al. 2008]. Now the way to solve it using a 2 timescale SA constitutes the main contribution of the paper. 

However, I am surprised by the requirement of Assumption 4.2 (that the class of functions under which we project the Bellman residual is linear). Indeed, under this assumption, the inner maximization problem could be solved by least squares instead of gradient ascent, which could be much faster. So my question is why do you think a 2 time scales SA algorithm is better than a single time scale SA using as inner loop the LS solution? 

I would think the main merit of the 2 scales SA algo would be to get rid of this assumption of linear function space for the inner loop (in order to reduce the bias as much as possible by optimizing over a larger class of functions), so I find that the need for Assumption 4.2 reduces considerably the motivation for a 2 time scales algo, which is your main contribution.

Other comments:
- You should provide arguments for why minimizing the Bellman residual (eq. (3.1)) is a good things for approximating the optimal value function or the optimal policy. This is not clear, specially in the control case when the behavior policy is fixed.
- Minimizing (3.10) (using approximate function spaces) may not give you a solution close to that of the (3.5) problem. It would be interesting to analyse how far the solution to those two problems are as a function of the capacity of the spaces.
- Also the local minimum reached by the algorithm may be far away from the solution to (3.10). So in the end, it's not clear if we can say anything about the Bellman residual of the solution found by the algorithm.
- It’s not clear how to implement the projection onto a compact set of parameters (in Algorithm 1), specially using neural nets.
- Finally the experiments are not very convincing. The proposed algorithm does not seem to do better than a 5 years old DQN algorithm… I know this was not the main contribution of the paper, which is theoretical, but then it’s not clear to see the added value of the experiments.


</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">5: Marginally below acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_BylmQwu2hm" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>promising approach, but the problem formulation has some flaws</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=Skxqni09KX&amp;noteId=BylmQwu2hm"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper736 AnonReviewer1</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">04 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper736 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">The paper studies the behavior of two-timescale stochastic approximation methods in the two fundamental approximate dynamic programming problems of policy evaluation and optimal control. Specifically, the authors pose the problem of Bellman residual minimization as a saddle-point problem and apply stochastic gradient updates for the primal and dual variables, and show that this procedure converges to a certain fixed point under rather general conditions. Notably, the results are claimed to hold even when the objective function is not convex-concave. The authors also highlight that the eventual solution may not necessarily be sensible in general, and also analyze a variant in which the dual variables can be optimized with bounded error in each iteration. In this setup, the main result is showing that the proposed algorithm converges to a neighborhood of the optimal solution of the original problem, and the size of the neighborhood is controlled by the optimization error in the dual objective.

I enjoyed reading the paper for the most part: the proposed approach is simple and natural (closely resembling GTD algorithms), and the core technical results seem plausible (although I didn't have the capacity to check the details this time). I appreciated the openness of the authors to discuss the limitations of their result in Theorem 4.3. The writing is generally good, up to some minor typos.

That said, I do have some relatively serious concerns about the nature of some of the results. Specifically, the objective function considered for optimal control seems fundamentally flawed and can be shown to lead to meaningless results even when optimized to zero error. To see this, observe that the objective (3.1) involves an expectation taken under the behavior policy \pi_b which may be arbitrarily far away from the optimal policy. This can lead to easily-seen problems in extreme cases, e.g., when pi_b only visits a recurrent class of states that are not visited at all by the optimal policy, and all rewards are zero in this recurrent class and its neighboring states. Under these conditions, the constant zero function trivially minimizes the Bellman error, even though being a potentially terrible solution. This is a well-known issue with this objective, and it can be solved by making some stronger assumptions on the behavior policy and using importance weighting (as done by, e.g., Antos et al. 2008). Incorporating these elements in the present analysis seems nontrivial, although certainly not impossible.

Another concern is that the optimization oracle required for Theorem 4.5 is unrealistically strong, and not just due to computational issues. The problem is that the optimization target for the oracle considered in this theorem is not an observable quantity, but rather an expectation over random variables with unknown distribution (that can only be estimated with an infinite sample size). Making such an assumption effectively eliminates the main technical challenges related to the double sampling issue, so it feels a bit like cheating. In fact, one can use such an assumption to completely circumvent the need for a saddle-point formulation and prove convergence results for Q-learning-style methods directly in a single-timescale SA framework. Right now, this aspect remains hidden due to the writing---the authors should discuss this assumption more honestly in the paper.

In order to resolve the above issues, I suggest that the authors limit their presentation to policy evaluation problems where at least some of these technical problems are not present. I believe that a paper focusing only on policy evaluation should have sufficient merit for publication---but then again, rewriting the paper accordingly should be a bit too much to ask for in a conference revision. In either case, I am looking forward to hearing the opinion of the authors on the issues raised above.

Detailed comments
=================
- pp.1, intro: "the statistical and computational properties of the RL algorithms are well-understood under these settings"---well, let's just say that *some* of these properties are well understood. E.g., I don't think that many people would consider "concentrability coefficients" to be really well-understood :)
- pp.2, top: "Bellman residue" -&gt; "Bellman residual" (many times in the paper)
- pp.2, related work: "our study" -&gt; "we study"
- pp.2, bottom: "could stringent" -&gt; "could be stringent"
- pp.3, below (2.2): "applying the Bellman optimality operator repeatedly gives the classical Q-learning algorithm"---this is actually value iteration, Q-learning also uses other ideas related to stochastic approximation. Please clarify a bit.
- pp.3, above Sec 3: "saddle framework" -&gt; "saddle-point framework"
- pp.4, 2nd paragraph: "when the capacity of S is large"---what does this mean?
- pp.4, Eq.(3.3): extra \cdot
- pp.5, below (3.7): "since the saddle point problem is nonconvex, we project the iterates"---can you explain what this projection has to do with nonconvexity?
- pp.5, below (3.7): "such a condition on the learning rates ensures that the dual iterates asymptotically track the sequence [...]"---this is technically only true if the faster-timescale can be first shown to converge at all, which is not trivial!
- pp.6, Assumption 4.1: missing comma between Q_max and \|\nabla_\theta...\|. It would also be worth noting that this assumption technically excludes neural nets with RELU activations, so I'm not sure if your theory actually applies to the setup in the experiments.
- pp.6, below (4.1): "most online TD-learning algorithms uses [sic] linear function approximation"---this is a quite weak argument given that the main contribution of the paper is precisely going beyond these settings; this claim suggests that linear FA methods are OK after all.</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">5: Marginally below acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_B1eE1CI527" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Solving the Saddle-Point objective of Dai et al. by two-timescale SA</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=Skxqni09KX&amp;noteId=B1eE1CI527"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper736 AnonReviewer2</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">03 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper736 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">The contribution of this paper is to solve the optimization problem from the problem "Smoothed dual embedding control" by Dai et al. (2017) using two-timescale stochastic approximation. The inner "max" problem is optimized by stochastic gradient ascent at a higher learning rate, in parallel with the outer "min" so that the inner problem appears quasi-stationary to the outer one. In my understanding, the analysis follows the usual template per Borkar or Konda in actor-critic methods and is not new. The proposed method is demonstrated in Cartpole and Mountain car and against a DQN baseline.  It is not clear why the author chose the heavy-duty DQN as a baseline in such simple environments when they could have compared directly against Dai et al. (2017) using the same architecture. While the idea of using two-timescale stochastic approximation to solve the saddle point formulation of Dai &amp; al. (2017) is sound, the contribution of this paper is insufficient for the main conference.  The saddle-point formulation in the title really comes from Dai: the title should rather include "two-timescale" somewhere because this is main contribution.

I would suggest enriching the experiments section by including an empirical study of the effect of the ratio of the learning rates on the stability and convergence rate. You should also really compare against Dai et al. (2017) and highlight why your method would be preferable (potentially computationally cheaper and more scalable than other alternatives). 

# Typos 

&gt; an stochasitc 
&gt; the iterates onto [the] compact sets
&gt; in (3.5) for [a] fixed θ
&gt; in different [s]paces</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">4: Ok but not good enough - rejection</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></main></div>
  </div>
</div>


    <!-- Footer -->
    <footer class="sitemap">
      <div class="container">
        <div class="row hidden-xs">
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/venues">All Venues</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="/contact">Contact</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
    
        <div class="row visible-xs-block">
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/contact">Contact</a></li>
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
      </div>
    </footer>
    
    <footer class="sponsor">
      <div class="container">
        <div class="row">
          <div class="col-sm-10 col-sm-offset-1">
            <p class="text-center">
              OpenReview is created by the <a href="http://www.iesl.cs.umass.edu/" target="_blank">Information Extraction and Synthesis Laboratory</a>, College of Information and Computer Science, University of Massachusetts Amherst. We gratefully acknowledge the support of the OpenReview sponsors:  Google,  Facebook, NSF, the University of Massachusetts Amherst Center for Data Science, and Center for Intelligent Information Retrieval, as well as the Google Cloud Platform for donating the computing and networking services on which OpenReview.net runs.
            </p>
          </div>
        </div>
      </div>
    </footer>

  <div id="feedback-modal" class="modal fade" tabindex="-1" role="dialog">
    <div class="modal-dialog">
      <div class="modal-content">
        <div class="modal-header">
          <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button>
          <h3 class="modal-title">Send Feedback</h3>
        </div>
        <div class="modal-body">
          <p>Enter your feedback below and we'll get back to you as soon as possible.</p>
          <form action="/feedback" method="POST">
            <div class="form-group">
              <input type="email" name="from" class="form-control" placeholder="Email" />
            </div>
            <div class="form-group">
              <input type="text" name="subject" class="form-control" placeholder="Subject" />
            </div>
            <div class="form-group">
              <textarea name="message" class="form-control feedback-input" rows="5" placeholder="Message" required=""></textarea>
            </div>
          <ul id="ui-id-2" tabindex="0" class="ui-menu ui-widget ui-widget-content" style="display: none;"></ul></form>
        </div>
        <div class="modal-footer">
          <button type="button" class="btn btn-default" data-dismiss="modal">Cancel</button>
          <button type="button" class="btn btn-primary">Send</button>
        </div>
      </div>
    </div>
  </div>

  <script type="text/javascript" async="" src="https://www.google-analytics.com/analytics.js"></script><script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js"></script>
  <script>window.jQuery || document.write('&lt;script src="/static/js/vendor/jquery-2.2.4.min.js"&gt;&lt;\/script&gt;')</script>

  <script src="/static/dist/vendor.min.js"></script>
  <script src="/static/dist/templates.min.js"></script>
  <script src="/static/dist/openreview.min.js"></script>

    <script>window.legacyScripts = true;</script>


    <script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-108703919-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() { dataLayer.push(arguments); }
      gtag('js', new Date());
      gtag('config', 'UA-108703919-1');
    </script>


<div role="status" aria-live="assertive" aria-relevant="additions" class="ui-helper-hidden-accessible"></div></body></html>
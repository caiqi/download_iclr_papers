<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" class="no-js"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>PCNN: Environment Adaptive Model Without Finetuning | OpenReview</title>
  <meta name="description" content="" />

      <meta name="citation_title" content="PCNN: Environment Adaptive Model Without Finetuning" />
        <meta name="citation_author" content="Anonymous" />
      <meta name="citation_publication_date" content="2018/09/27" />
      <meta name="citation_online_date" content="2018/09/27" />
      <meta name="citation_pdf_url" content="https://openreview.net/pdf?id=S1eVe2AqKX" />
      <meta name="twitter:card" content="summary" />
      <meta name="twitter:site" content="@openreviewnet" />
      <meta name="og:title" content="PCNN: Environment Adaptive Model Without Finetuning" />
      <meta name="og:description" content="Convolutional Neural Networks (CNNs) have achieved tremendous success for many computer vision tasks, which shows a promising perspective of deploying CNNs on mobile platforms. An obstacle to this..." />
      <meta name="og:image" content="https://openreview.net/static/images/openreview_logo_512.png" />

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans:400,400i,700,700i" />

  <link rel="stylesheet" href="/static/css/bootstrap.min.css" />
  <link rel="stylesheet" href="/static/css/jquery-ui.min.css" />
  <link rel="stylesheet" href="/static/css/main.min.css" />
</head>

<body class="forum">
  <nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
  
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand home push-link" href="/"><strong>OpenReview</strong>.net</a>
      </div>
  
      <div id="navbar" class="navbar-collapse collapse">
        <form class="navbar-form navbar-left profile-search" role="search">
          <div class="form-group has-feedback">
            <input id="search_input" type="text" class="form-control ui-autocomplete-input" placeholder="Search ICLR 2019 Conference" autocomplete="off" />
            <span class="glyphicon glyphicon-search form-control-feedback" aria-hidden="true"></span>
          </div>
  
          <input id="search_group" type="hidden" value="ICLR.cc/2019/Conference" />
          <input id="search_content" type="hidden" value="all" />
        <ul id="ui-id-1" tabindex="0" class="ui-menu ui-widget ui-widget-content ui-autocomplete ui-front" style="display: none;"></ul></form>
  
        <ul class="nav navbar-nav navbar-right">
        
            <li id="user-menu"><a href="/login">Login</a></li>
        </ul>
      </div>
  
    </div>
  </nav>

  <div id="or-banner" class="banner" style="">
  <div class="container">
    <div class="row">
      <div class="col-xs-12"><a href="/group?id=ICLR.cc/2019/Conference" title="Venue Homepage"><img class="icon" src="/static/images/arrow_left.svg" /> Go to <strong>ICLR 2019 Conference</strong> homepage</a></div>
    </div>
  </div>
</div>
<div id="flash-message-container" class="alert alert-danger" role="alert" style="display: none;">
  <div class="container">
    <div class="row">
      <div class="col-xs-12">
        <div class="alert-content">
          <button type="button" class="close" aria-label="Close"><span aria-hidden="true">Ã—</span></button>
        </div>
      </div>
    </div>
  </div>
</div>

<div class="container">
  <div class="row">
    <div class="col-xs-12">
      <main id="content" class="clearfix openbanner-visible legacy-styles"><div id="note_S1eVe2AqKX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>PCNN: Environment Adaptive Model Without Finetuning</a> <a class="note_content_pdf" href="/pdf?id=S1eVe2AqKX" title="Download PDF" target="_blank"><img src="/static/images/pdf_icon_blue.svg" /></a> </h2></div><div class="meta_row"><span class="signatures">Anonymous</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">28 Sep 2018 (modified: 11 Oct 2018)</span><span class="item">ICLR 2019 Conference Blind Submission</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span><span class="item"><a class="action-bibtex-modal" data-bibtex="@inproceedings{    &#10;anonymous2019pcnn:,    &#10;title={PCNN: Environment Adaptive Model Without Finetuning},    &#10;author={Anonymous},    &#10;booktitle={Submitted to International Conference on Learning Representations},    &#10;year={2019},    &#10;url={https://openreview.net/forum?id=S1eVe2AqKX},    &#10;note={under review}    &#10;}">Show Bibtex</a></span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Abstract: </span><span class="note_content_value">Convolutional Neural Networks (CNNs) have achieved tremendous success for many computer vision tasks, which shows a promising perspective of deploying CNNs on mobile platforms. An obstacle to this promising perspective is the tension between intensive resource consumption of CNNs and limited resource budget on mobile platforms. Existing works generally utilize a simpler architecture with lower accuracy for a higher energy-efficiency, \textit{i.e.}, trading accuracy for resource consumption. An emerging opportunity to both increasing accuracy and decreasing resource consumption is \textbf{class skew}, \textit{i.e.}, the strong temporal and spatial locality of the appearance of classes. However, it is challenging to efficiently utilize the class skew due to both the frequent switches and the huge number of class skews. Existing works use transfer learning to adapt the model towards the class skew during runtime, which consumes resource intensively. In this paper, we propose \textbf{probability layer}, an \textit{easily-implemented and highly flexible add-on module} to adapt the model efficiently during runtime \textit{without any fine-tuning} and achieving an \textit{equivalent or better} performance than transfer learning. Further, both \textit{increasing accuracy} and \textit{decreasing resource consumption} can be achieved during runtime through the combination of probability layer and pruning methods.</span></div><div class="note_contents"><span class="note_content_field">Keywords: </span><span class="note_content_value">Class skew, Runtime adaption</span></div><div class="reply_row clearfix"><div class="item" id="reply_count">7 Replies</div></div></div><hr class="small" /><div id="note_children"><div class="note_with_children"><div id="note_HylkPTJ0hX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Simple Idea, Good Results But Novelty? Detailed Analysis?</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=S1eVe2AqKX&amp;noteId=HylkPTJ0hX"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1069 AnonReviewer1</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">06 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper1069 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">The paper proposes a simple idea to calibrate probabilities outputted by a CNN model to adapt easily to environments where class distributions change with space and time (and are often skewed). The paper shows that such a simple approach is sufficient to get good accuracies without requiring any costly retraining or transfer learning. Thereby proving to give benefits in terms of resource consumption and at the same time giving better results than the state of the art.

However, 
A] The proposed calibration doesn't take any CNN specific details into consideration, rather it is a general calibration method which was also proposed in Saerens et. al, 2002 (cited in the paper). It is unclear why the paper specifically talks about CNN.
B] The proposed Class Skew Detector is a simple method. Change-point detection is a well-studied area. The paper lacks a literature review in this area and a reasoning of why the proposed approach is preferred. Also, an independent analysis of how the class skew detector behaves in the face of rapidly changing class skews versus slow changing class skews is warranted here. Particularly, given that the paper proposes to use this approaches in mobile which may work in both rapid and slow changing class skews.
C] The Class Skew Detector is dependent on the base model. Thus, it is also likely that the empirical distribution estimated is biased and yet the final accuracies reported are much higher than the base model accuracies. There is something interesting happening here. An analysis of the robustness of the proposed approach in the face of noisy class skew detection could potentially make this paper a stronger work.
D] The analysis in the paper has largely focused on pre-trained models. However, another analysis that could have been useful here is, varying the quality of the classifier (e.g. classifier trained on skewed training data vs. balanced training data) and measuring how the quality of the classifier correlates with the final performance. Maybe even attempt to answer the question "which classifiers are likely to work with this approach?" In fact, this analysis can be either done in a general context of any classifier or just CNN's and identifying whether certain properties of CNN help in getting better performance.

The paper lacks novelty and at the same time, it is not quite compensating that with a detailed analysis of the work. The problem is interesting and I like the work because the approach is simple and the results look good. I think with a stronger focus on more detailed analysis, this can be a good submission to an applied conference like MobiCom etc.

By the way, the paper is riddled with several spelling errors - 
"filed" -&gt; "field", page 1, second paragraph, last line
"complimentary" -&gt; "complementary", page 2, section 2, paragraph 1, last line
"epoches" -&gt; "epochs", page 2, section 2, transfer learning, second paragraph, second last line
"CNNs does not use" -&gt; "CNNs do not use", page 3, section 3, intuition, first paragraph, first line
"formular" -&gt; "formula", page 4, above equation 4
Equation 4 has a typo in the denominator, P_t(i) should be P_t(j), same with Equation 5
"obstained" -&gt; "obtained", page 7, second paragraph, first line
"adaptation" is almost everywhere spelled as "adaption"</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">4: Ok but not good enough - rejection</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_S1glW4P5hX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>No technical contribution, Heuristic solution</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=S1eVe2AqKX&amp;noteId=S1glW4P5hX"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1069 AnonReviewer2</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">03 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper1069 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">This paper proposed a way to detect a skew in the distribution of classes in a stream of images and reweight the class priors accordingly, to estimate the final posterior probabilities of present classes. This probability re-calibration is referred to as the probability layer. A simple algorithm is proposed to detect the class distribution skew. The proposed benefit of this method is that they do not require fine-tuning any network parameters using newly skewed data. 

Overall the method is quite simple and heuristic. The technical contribution - i) updating class priors online ii) detecting class skews, is marginal. 

The evaluation is performed on a contrived setting of skewed imagenet images. I would have liked to see some evaluation on video stream data where the skews are more natural. 

In real scenarios, the class specific appearances P_{X|Y}(x|i) as well as class distributions P_Y(i) change online. The method seems incapable to handle such problems.  In these situations, there is no simple fix, and one needs to resort to transfer.
 </span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">3: Clear rejection</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_SkgZr2nwh7" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Review</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=S1eVe2AqKX&amp;noteId=SkgZr2nwh7"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1069 AnonReviewer3</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">01 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper1069 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">The idea proposed in this paper is to improve classification accuracy by making use of the context.
E.g. on the north pole we will see polar bears but no penguins, on Antartica we have no polar bears but many penguins.
Hence, if we apply our imagenet-like classifier in the wild, we can improve accuracy by taking into account changes in the prior distribution.

The paper proposes a way to rescale the probabilities to do exactly this and reports improved results on modified versions of 
 CIFAR 10 and imagenet with artificial class skew. To achieve this, an additional trick is introduced where the re-scaling is only used when the model is not very certain of its prediction. And additional motivation for this work is that less compute resources are needed if the problem is simplified by utilizing class skew. 

The core idea of the paper is interesting. However, I am not able to understand what exactly is done and I am 100% confident I cannot re-implement it. The authors already improved upon this in our interactions prior to the review deadline. 
An additional issue is that the paper does not have a good baseline. 
I would not like to dismiss the approach based on its simplicity. An elegant solution is always preferred. However, all the tasks are quite artificial and this limits the "impact" of this work. If an "natural" application/evaluation where this approach would be possible, it would strengthen the paper greatly. 

For the reasons above I recommend rejection of the manuscript in the current state but I am confident that many of these issues can be resolved easily and if this is done I will update the review.

Missing information
----------------------------
- The original manuscript had a lot of information missing, but much of it has since been provided by the authors.
- In the static class skew experiment, were two passes over the data needed? Or was the Pt(i) pre-set? Would it also be possible to give details about LR, optimizer, LR schedule, batch size, .... for the transfer learning experiments. This would enhance reproducibility. 
- For the imagenet experiments how was Pt(i) set in the if I assume correctly, static setting.

Possible additional baselines:
-----------------------------------------

We could make a simpler rescaling by changing the prior distribution and assuming everything else remains constant.
While this is a simplifying assumption, it is very easy to implement and should take only a couple of minutes to run. 
P(i|x)=1/P(X)*P(X|i)*P(i)
Pt(i|x)=P(i|x)*Pt(i)/P(i)

One could also introduce another baseline where only the most probably classes are considered. Since this approach is clearly sub-optimal since it guarantees some mis-predictions it should serve as a lower bound on the performance that is to be expected. 
</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">4: Ok but not good enough - rejection</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_SkgDx7nD3X" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Request for clarification</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=S1eVe2AqKX&amp;noteId=SkgDx7nD3X"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1069 AnonReviewer3</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">01 Nov 2018</span><span class="item">ICLR 2019 Conference Paper1069 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Dear Authors,

Could you please clarify the transition from equation 3 to equation 4. I do not understand how this step is made.

It would be helpful if you could clarify this before I submit the official review.

</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_Syen8Xawn7" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Clarification on the transition from euqation 3 to equation 4</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=S1eVe2AqKX&amp;noteId=Syen8Xawn7"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1069 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">01 Nov 2018</span><span class="item">ICLR 2019 Conference Paper1069 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Dear reviewer,

Thanks for your comment! There is a small typo in equation 4, which has no influence over other parts in our paper. (This clarification could be better read in pdf version (<a href="https://drive.google.com/file/d/1M1t0CjZWmcolfELb-kkqKVWtcqR9A6mg/view?usp=sharing)" target="_blank" rel="nofollow">https://drive.google.com/file/d/1M1t0CjZWmcolfELb-kkqKVWtcqR9A6mg/view?usp=sharing)</a> due to latex equations.)

Instead of 
\begin{equation*}
    P_t(i|X) = \frac{\frac{P_t(i)}{P(i)} \cdot P(i|X)}{\sum_{j=1}^n \frac{P_t(i)}{P(j)} \cdot P(j|X)}
\end{equation*},
it should be 
\begin{align*}
     P_t(i|X)  = \frac{\frac{P_t(i)}{P(i)} \cdot P(i|X)}{\sum_{j=1}^n \frac{P_t(j)}{P(j)} \cdot P(j|X)}
\end{align*}.
Note the single $i$ in the denominator has been replaced by $j$.

The following is the detailed proof on the transition from equation 3 to equation 4.

In equation 3, we have $P_t(i|X) = \frac{P_t(i)}{P(i)} \cdot \frac{P(X)}{P_t(X)} \cdot P(i|X)$. We also have $\sum_{i=1}^n P_t(i|X) = 1$, based on the property of probability. Together, we can find that 
\begin{align*}
    1 &amp; = \sum_{i=1}^n P_t(i|X) \\
      &amp; = \sum_{i=1}^n\frac{P_t(i)}{P(i)} \cdot \frac{P(X)}{P_t(X)} \cdot P(i|X) \\
      &amp; = \frac{P(X)}{P_t(X)} \cdot \sum_{i=1}^n \frac{P_t(i)}{P(i)} \cdot P(i|X)
\end{align*}
The second equality holds by using equation 3. The third equality holds since $\frac{P(X)}{P_t(X)}$ does not change over $i$.

Thus, we can have
\begin{align*}
    \frac{P(X)}{P_t(X)} &amp; = \frac{1}{\sum_{i=1}^n \frac{P_t(i)}{P(i)} \cdot P(i|X)}   \\ 
                        &amp; = \frac{1}{\sum_{j=1}^n \frac{P_t(j)}{P(j)} \cdot P(j|X)}
\end{align*}
The second equality holds since every $i$ has been replaced with $j$. We conduct this replacement to avoid confusement with $i$ used in equation 3 and equation 4.

Use this equation to replace $\frac{P(X)}{P_t(X)}$ in equation 3, we can get
\begin{align*}
    P_t(i|X) &amp; =  \frac{P_t(i)}{P(i)} \cdot P(i|X) \cdot \frac{P(X)}{P_t(X)} \\
             &amp; = \frac{P_t(i)}{P(i)} \cdot P(i|X) \cdot \frac{1}{\sum_{j=1}^n \frac{P_t(j)}{P(j)} \cdot P(j|X)} \\
             &amp; = \frac{\frac{P_t(i)}{P(i)} \cdot P(i|X)}{\sum_{j=1}^n \frac{P_t(j)}{P(j)} \cdot P(j|X)}
\end{align*}
</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_r1eLxATDhm" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Thanks for this response</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=S1eVe2AqKX&amp;noteId=r1eLxATDhm"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1069 AnonReviewer3</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">01 Nov 2018</span><span class="item">ICLR 2019 Conference Paper1069 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Thanks for this response, 

Can you also expand on section 4. The notation used in algorithm 1 is not detailed. 
What is of particular interest is how Pt(i) is computed.</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_HJl1rrQdnX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Clarification on section 4.</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=S1eVe2AqKX&amp;noteId=HJl1rrQdnX"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1069 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">01 Nov 2018</span><span class="item">ICLR 2019 Conference Paper1069 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Dear reviewer:

Thanks for your comment!  (This clarification could be better read in pdf version (<a href="https://drive.google.com/file/d/17wFjCrhnNjcoIeV5v537gvcw9bH3KekX/view?usp=sharing)" target="_blank" rel="nofollow">https://drive.google.com/file/d/17wFjCrhnNjcoIeV5v537gvcw9bH3KekX/view?usp=sharing)</a> due to latex equations.)


We estimate $P_t(i)$ with the \textit{empirical class distribution} [1] in a short time window (every $\omega_{min}$). In algorithm 1, $y_t$ indicates the prediction result for the $t$-th input frame classified by the model $h(\cdot)$. $S_j$ indicates the empirical distribution in the $j$-th time window (the utilization of time window will be justified in \textbf{Assumption} paragraph) and $\oplus$ indicates the concatenation of two distributions. $S_j \leftarrow S_j \oplus [y_t]$ means that every new prediction result $y_t$ will be incorporated into the \textit{empirical class distribution} $S_j$ composed by all $\omega_{min}$ predictions, which will be computed as following:
\begin{equation}
  S_j(i) = \frac{1}{\omega_{min}} \sum_{t=1}^{\omega_{min}}\mathbbm{1}_{y_t \leq i}    
\end{equation}
. The $P_t(i)$ can be derived from empirical class distribution $S_j(i)$ by 
\begin{equation}
    P_t(i) = S_j(i) - S_j(i-1)
\end{equation}


The if statement of $|| S_{j-1}, S_j|| \leq \pi_r$ is proposed for detecting the switch of class skew, as detailed in the following.


\paragraph{Assumption.}As described in the first paragraph of section 4, the only assumption we hold is that the class skew in a scenario remains unchanged. Formally, let assume the existence of a partition (scenario for a class skew) $\pi: N^+ \rightarrow N^+$ over the input stream, where $\pi(t)$ refers to the class skew that $t$-th image belongs to. Here, each partition maintains a distribution $T_{\pi(t)}$ and the image $(x_t, y_t)$ is drawn randomly (\textit{i.i.d.}) from distribution $T_{\pi(t)}$. Here, the overall series is composed by a sequence of abruptly-changing partitions and the distribution within each partition remains same. This is a very weak but realistic assumption, since we do not have any other assumptions on how long a stationary distribution exists. Thus our proposed algorithm needs to not only detect the underlying distribution $T_{\pi(t)}$ ($P_t(i)$ is the probability of each class $i$ in the distribution $T_{\pi(t)}$), but also recognize the start time and end time for each partition $\pi(t)$ (class skew) in an untrimmed streams of data.

\paragraph{Proposed approach.}As described in the second paragraph of section 4, we propose a windowed class skew detector to approximate the underlying distribution, as well as the start time and end time for each partition $\pi(t)$ (class skew). Here, the empirical distribution $S_j$ in each window $j$ can be obtained to estimate the $P_t(i)$. Furher, the start time and end time of each partition $\pi(t)$ (class skew) can be decided when there is a dramatic change in empirical class distributions $S_{j-1}$ and $S_{j}$ from adjacent windows $j-1$ and $j$. A dramatic change is decided when
\begin{equation}
  \underset{i}{\text{sup}} | S_{j}(i) - S_{j-1}(i) | \geq \frac{\pi_r}{\omega_{min}}
\end{equation}
, where $\omega_{min} = 30$ and $\pi_r = 2$ in our evaluations.

\paragraph{Edge case when class skew switches.}Our proposed probability layer can handle the edge case, \textit{i.e.}, a small turbulence to class skew has happened. For example, $10$ people stays in a lab and a stranger suddenly visits. This edge case is handled by the weak class skew (p&lt;1) in our evaluation section.

We apologize for not providing enough detail for the Algorithm 1. We will revise it in our final version.

\begin{wrapfigure}{R}{0.35\textwidth}
    \begin{minipage}{0.35\textwidth}
      \begin{algorithm}[H]
        \caption{CSD algorithm}
        \begin{algorithmic}
            \Function{CSD}{$ $} \label{alg: WEG}
                \For{$t$ in $1, ..., w_{min}$}
                    \State $y_t \leftarrow h(t)$
                    \State $S_j \leftarrow S_j \oplus [y_t]$
                \EndFor
                \If{$|| S_{j-1}, S_j|| \leq \pi_r$}
                    \State $S_j \leftarrow S_{j-1} \oplus S_j$
                \EndIf
                \State \Return $S_j$
            \EndFunction
        \end{algorithmic}
         \label{alg: algorithm}
      \end{algorithm}
    \end{minipage}
\end{wrapfigure}

[1]  J. Shao.Mathematical Statistics. Springer Texts in Statistics. Springer, 2003.
</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div></div></div></div></div></div></main></div>
  </div>
</div>


    <!-- Footer -->
    <footer class="sitemap">
      <div class="container">
        <div class="row hidden-xs">
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/venues">All Venues</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="/contact">Contact</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
    
        <div class="row visible-xs-block">
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/contact">Contact</a></li>
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
      </div>
    </footer>
    
    <footer class="sponsor">
      <div class="container">
        <div class="row">
          <div class="col-sm-10 col-sm-offset-1">
            <p class="text-center">
              OpenReview is created by the <a href="http://www.iesl.cs.umass.edu/" target="_blank">Information Extraction and Synthesis Laboratory</a>, College of Information and Computer Science, University of Massachusetts Amherst. We gratefully acknowledge the support of the OpenReview sponsors:  Google,  Facebook, NSF, the University of Massachusetts Amherst Center for Data Science, and Center for Intelligent Information Retrieval, as well as the Google Cloud Platform for donating the computing and networking services on which OpenReview.net runs.
            </p>
          </div>
        </div>
      </div>
    </footer>

  <div id="feedback-modal" class="modal fade" tabindex="-1" role="dialog">
    <div class="modal-dialog">
      <div class="modal-content">
        <div class="modal-header">
          <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">Ã—</span></button>
          <h3 class="modal-title">Send Feedback</h3>
        </div>
        <div class="modal-body">
          <p>Enter your feedback below and we'll get back to you as soon as possible.</p>
          <form action="/feedback" method="POST">
            <div class="form-group">
              <input type="email" name="from" class="form-control" placeholder="Email" />
            </div>
            <div class="form-group">
              <input type="text" name="subject" class="form-control" placeholder="Subject" />
            </div>
            <div class="form-group">
              <textarea name="message" class="form-control feedback-input" rows="5" placeholder="Message" required=""></textarea>
            </div>
          <ul id="ui-id-2" tabindex="0" class="ui-menu ui-widget ui-widget-content" style="display: none;"></ul></form>
        </div>
        <div class="modal-footer">
          <button type="button" class="btn btn-default" data-dismiss="modal">Cancel</button>
          <button type="button" class="btn btn-primary">Send</button>
        </div>
      </div>
    </div>
  </div>

  <script type="text/javascript" async="" src="https://www.google-analytics.com/analytics.js"></script><script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js"></script>
  <script>window.jQuery || document.write('&lt;script src="/static/js/vendor/jquery-2.2.4.min.js"&gt;&lt;\/script&gt;')</script>

  <script src="/static/dist/vendor.min.js"></script>
  <script src="/static/dist/templates.min.js"></script>
  <script src="/static/dist/openreview.min.js"></script>

    <script>window.legacyScripts = true;</script>


    <script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-108703919-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() { dataLayer.push(arguments); }
      gtag('js', new Date());
      gtag('config', 'UA-108703919-1');
    </script>


<div role="status" aria-live="assertive" aria-relevant="additions" class="ui-helper-hidden-accessible"></div></body></html>
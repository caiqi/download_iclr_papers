<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" class="no-js"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>Tangent-Normal Adversarial Regularization for Semi-supervised Learning | OpenReview</title>
  <meta name="description" content="" />

      <meta name="citation_title" content="Tangent-Normal Adversarial Regularization for Semi-supervised Learning" />
        <meta name="citation_author" content="Bing Yu" />
        <meta name="citation_author" content="Jingfeng Wu" />
        <meta name="citation_author" content="Jinwen Ma" />
        <meta name="citation_author" content="Zhanxing Zhu" />
      <meta name="citation_publication_date" content="2018/09/27" />
      <meta name="citation_online_date" content="2018/09/27" />
      <meta name="citation_pdf_url" content="https://openreview.net/pdf?id=BJxz5jRcFm" />
      <meta name="twitter:card" content="summary" />
      <meta name="twitter:site" content="@openreviewnet" />
      <meta name="og:title" content="Tangent-Normal Adversarial Regularization for Semi-supervised Learning" />
      <meta name="og:description" content="The ever-increasing size of modern datasets combined with the difficulty of obtaining label information has made semi-supervised learning of significant practical importance in modern machine..." />
      <meta name="og:image" content="https://openreview.net/static/images/openreview_logo_512.png" />

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans:400,400i,700,700i" />

  <link rel="stylesheet" href="/static/css/bootstrap.min.css" />
  <link rel="stylesheet" href="/static/css/jquery-ui.min.css" />
  <link rel="stylesheet" href="/static/css/main.min.css" />
</head>

<body class="forum">
  <nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
  
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand home push-link" href="/"><strong>OpenReview</strong>.net</a>
      </div>
  
      <div id="navbar" class="navbar-collapse collapse">
        <form class="navbar-form navbar-left profile-search" role="search">
          <div class="form-group has-feedback">
            <input id="search_input" type="text" class="form-control ui-autocomplete-input" placeholder="Search ICLR 2019 Conference" autocomplete="off" />
            <span class="glyphicon glyphicon-search form-control-feedback" aria-hidden="true"></span>
          </div>
  
          <input id="search_group" type="hidden" value="ICLR.cc/2019/Conference" />
          <input id="search_content" type="hidden" value="all" />
        <ul id="ui-id-1" tabindex="0" class="ui-menu ui-widget ui-widget-content ui-autocomplete ui-front" style="display: none;"></ul></form>
  
        <ul class="nav navbar-nav navbar-right">
        
            <li id="user-menu"><a href="/login">Login</a></li>
        </ul>
      </div>
  
    </div>
  </nav>

  <div id="or-banner" class="banner" style="">
  <div class="container">
    <div class="row">
      <div class="col-xs-12"><a href="/group?id=ICLR.cc/2019/Conference" title="Venue Homepage"><img class="icon" src="/static/images/arrow_left.svg" /> Go to <strong>ICLR 2019 Conference</strong> homepage</a></div>
    </div>
  </div>
</div>
<div id="flash-message-container" class="alert alert-danger" role="alert" style="display: none;">
  <div class="container">
    <div class="row">
      <div class="col-xs-12">
        <div class="alert-content">
          <button type="button" class="close" aria-label="Close"><span aria-hidden="true">×</span></button>
        </div>
      </div>
    </div>
  </div>
</div>

<div class="container">
  <div class="row">
    <div class="col-xs-12">
      <main id="content" class="clearfix openbanner-visible legacy-styles"><div id="note_BJxz5jRcFm" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Tangent-Normal Adversarial Regularization for Semi-supervised Learning</a> <a class="note_content_pdf" href="/pdf?id=BJxz5jRcFm" title="Download PDF" target="_blank"><img src="/static/images/pdf_icon_blue.svg" /></a> </h2></div><div class="meta_row"><span class="signatures"><a href="/profile?email=byu%40pku.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="bottom" title="" data-original-title="byu@pku.edu.cn">Bing Yu</a>, <a href="/profile?email=pkuwjf%40pku.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="bottom" title="" data-original-title="pkuwjf@pku.edu.cn">Jingfeng Wu</a>, <a href="/profile?email=jwma%40math.pku.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="bottom" title="" data-original-title="jwma@math.pku.edu.cn">Jinwen Ma</a>, <a href="/profile?email=zhanxing.zhu%40pku.edu.cn" class="profile-link" data-toggle="tooltip" data-placement="bottom" title="" data-original-title="zhanxing.zhu@pku.edu.cn">Zhanxing Zhu</a></span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">28 Sep 2018 (modified: 17 Nov 2018)</span><span class="item">ICLR 2019 Conference Withdrawn Submission</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Abstract: </span><span class="note_content_value">The ever-increasing size of modern datasets combined with the difficulty of obtaining label information has made semi-supervised learning of significant practical importance in modern machine learning applications. In comparison to supervised learning, the key difficulty in semi-supervised learning is how to make full use of the unlabeled data. In order to utilize manifold information provided by unlabeled data, we propose a novel regularization called the tangent-normal adversarial regularization, which is composed by two parts. The two parts complement with each other and jointly enforce the smoothness along two different directions that are crucial for semi-supervised learning. One is applied along the tangent space of the data manifold, aiming to enforce local invariance of the classifier on the manifold, while the other is performed on the normal space orthogonal to the tangent space, intending to impose robustness on the classifier against the noise causing the observed data deviating from the underlying data manifold.  Both of the two regularizers are achieved by the strategy of virtual adversarial training. Our method has achieved state-of-the-art performance on semi-supervised learning tasks on both artificial dataset and practical datasets.</span></div><div class="note_contents"><span class="note_content_field">Keywords: </span><span class="note_content_value">semi-supervised learning, manifold regularization, adversarial training</span></div><div class="note_contents"><span class="note_content_field">TL;DR: </span><span class="note_content_value">We propose a novel manifold regularization strategy based on adversarial training, which can significantly improve the performance of semi-supervised learning.</span></div><div class="reply_row clearfix"><div class="item" id="reply_count">5 Replies</div></div></div><hr class="small" /><div id="note_children"><div class="note_with_children"><div id="note_rklhCKMBaQ" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Submission Withdrawn by the Authors</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=BJxz5jRcFm&amp;noteId=rklhCKMBaQ"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper516 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">11 Nov 2018</span><span class="item">ICLR 2019 Conference Paper516 Withdraw Submission</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Withdrawal confirmation: </span><span class="note_content_value">I have read and agree with the withdrawal statement on behalf of myself and my co-authors.</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_Hyer92qEaX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Limited novelty and not fully convince by the improvement in empirical evaluation</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=BJxz5jRcFm&amp;noteId=Hyer92qEaX"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper516 AnonReviewer2</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">11 Nov 2018</span><span class="item">ICLR 2019 Conference Paper516 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">As I was asked for an emergency reviewer for this paper rather late, I refrain myself from reading at other reviewers comment when writing this review for an unbiased judgment. Please forgive me if the concerns or issues I raise here already been asked by other reviewers.

- summary
This paper proposes to improve semi-supervised learning with two manifold regularizations: the tangent adversarial regularization (TAR) and normal adversarial regularization (NAR), hence naming their method Tangent-Normal Adversarial Regularization (TNAR). The author implements the TAR and NAR by applying virtual adversarial training (VAT) techniques on the manifold space, which is trained separately by either variational autoencoder (VAE) or localized GAN (LGAN) to obtain the encoder and decoder mapping between data space and manifold space. The proposed TNAR shows improvement on the controlled synthetic dataset; demonstrates the effectiveness of both TAR and NAR via the ablation study on the FashionMNIST dataset; claims to outperform state-of-the-art SSL methods on both SVHN and CIFAR-10 datasets. 

Evaluation
- The writing of the paper is in general ok, but reading the introduction that categorizes the SSL by three streams seem somehow unnatural to me. Perhaps it would be more clear to directly start from manifold space assumption and add more details or connection to other manifold space regularization related works.  

-The technical derivation in section 3 is sound as far as I can tell because it mainly involves existing techniques that have been studied in VAT [7]. This also makes me feel the contribution in terms of novelty is rather limited, since the tangent space regularization is not new [4]. The only novel part seems to add an additional normal adversarial regularization that is perpendicular to the tangent noise.

- My biggest concern is in the empirical evaluation. The experiment setup closely follows [7], using the model architecture Conv-small appeared in [1,3,4,5,6,7] and Conv-large appeared in [2,6,7], while not applying ZCA whitening as data preprocessing. This possibly leads to an inconsistency between the results in Table 3 of this paper and table 4 of [7] for both Conv-small and Conv-large setting. Also, it would also be an unfair comparison that only TNAR and VAT include entropy regularization while other SOTA methods [1,3,4,5,6] did not. As shown in Table 4 of [7], entropy-regularization significantly improve accuracy. I suggest the author include results of TNAR w/o entropy-regularization;  results of ZCA preprocessed data;  setting alpha_2 and alpha_3 as zero to see the difference between TNAR and FM-GAN [5].

Minor questions:
- What is the difference between TNAR and [5]? Is it that TNAR finding the tangent vector r where TNAR applies power methods as like VAT while [5] find the tangent vector r differently?

- How important is the GAN/VAE training for good semi-supervised learning task? Do you also find the bad generator leading to better SSL task as shown in [8]? I am also curious that how different encoder/decoding mapping would affect the SSL downstream task, as different prior works adopt different settings.

- TNAR is claimed to be computational efficient compared other manifold regularization based on tangent propagation or manifold Laplacian norm. Do you have empirical evidence?

- I also suggest reporting the mean/std of the experiment results by running like five different random seed, as most of the works did.

[1] T. Salimans et al., Improved techniques for training gans. NIPS 2016
[2] S. Laine and T. Aila. Temporal Ensembling for Semi-supervised Learning. ICLR 2017
[3] V. Dumoulin et al., Adversarial Learned Inference. ICLR 2017
[4] A. Kumar et al, Semi-supervised Learning with GANs: Manifold Invariance with Improved Inference, NIPS 2017
[5] B. Lecouat et al., Semi-supervised Learning with GANs: Revisiting Manifold Regularization. ICLR 2018 Workshop
[6] Guo-Jun Qi et al, Global versus Localized Generative Adversarial Nets. CVPR 2018
[7] T. Miyato et al., Virtual Adversarial Training: A Regularization Method for Supervised and Semi-Supervised Learning, PAMI 2018
[8] Z. Dai etal ., Good Semi-supervised Learning That Requires a Bad GAN, NIPS 2017
</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">5: Marginally below acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">3: The reviewer is fairly confident that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_SyxLlrsVT7" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Correction on the paper citing in previous post</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=BJxz5jRcFm&amp;noteId=SyxLlrsVT7"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper516 AnonReviewer2</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">11 Nov 2018</span><span class="item">ICLR 2019 Conference Paper516 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">I found my citing of FM-GAN should be [4], instead of [5].  This applies to the third bullet point in the Evaluation part, and the first bullet point in the Minor question part. Sorry for the typo.
</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div><div class="note_with_children"><div id="note_BygKO27dnQ" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Poor novelty, clarity and significance</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=BJxz5jRcFm&amp;noteId=BygKO27dnQ"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper516 AnonReviewer1</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">01 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper516 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">This paper proposed a new regularization for semi-supervised learning called tangent-normal adversarial regularization. It can be decomposed into two parts, namely the tangent adversarial regularization and the normal adversarial regularization. Both of them are related to the smoothness assumption in a more general form.

The novelty seems really incremental as a combination of two existing concepts and thus there is no clear conceptual improvement. The two parts as the building blocks are even already included in the deep learning book.

The clarity is OK but not so good. The introduction is very long but not so informative. In fact, the description and discussion are even misleading. The first paragraph gives the background information of SSL in 12 lines without a single citation. I think a minimal background is necessary, while this paragraph is too much in such a way that it gives something every body knows and is a waste of the most precious space.

The 3 streams of SSL are misleading: the 1st and 3rd are traditional generative methods and GANs which overlap a lot, and some important streams such as co-training are completely ignored. Even though the paper is claimed to focus on the 2nd stream, i.e., regularization, it focused only on the geometric regularization and ignored any other regularization for instance entropy regularization (by Prof. Bengio!) and expectation regularization (by Prof. McCallum!) that belong to information-theoretic regularization.

The 3 assumptions are also strange. To me, there is 1 assumption and 2 implementations of that assumption. As far as I know, the basic assumptions in SSL are all based on 3 concepts of consistency originated from LGC and VAT. Since SSL has a long history and is/was a very hot topic, the authors should survey the literature more carefully.

The significance is even not OK. As claimed in the paper it focuses on the 2nd stream, the proposed method should mainly be compared with similar regularization approaches. VAT is the origin of perturbation consistency but no longer SOTA. There are many following methods, temporal ensembling from ICLR 2017, mean teacher from NIPS 2017, smooth neighbor teacher graph from CVPR 2018, and compact clustering via label propagation from ICML 2018, just to name a few. Again, the authors should survey the literature more carefully and then consider how to revise their paper.</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">4: Ok but not good enough - rejection</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_B1eVYG9whX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>review</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=BJxz5jRcFm&amp;noteId=B1eVYG9whX"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper516 AnonReviewer3</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">01 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper516 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">The paper proposes to extend VAT by decomposing the regularization term into two spaces, the tangent space and the normal space. The tangent space is spanned over the columns of the Jacobian matrix of a function that maps latent (manifold) variables to data, and the normal space is defined as orthogonal to the tangent space. Power iteration was employed to optimize the inner-loop function.

Pros
1. Positive signals have been shown on multiple datasets.
2. The proposed regularization terms seem to be novel and technically sound.

Cons and questions
1. How did you obtain the results of VAT in the experiments? It seems the results in Table 3 could not be found in Miyato et al. It is important to obtain a proper baseline to substantiate the main claim of the paper. Moreover, it might not be appropriate to claim the proposed method is state-of-the-art (SoTA) on SVHN and CIFAR-10 given that the numbers in Table 3 are different from Miyato et al. To claim SoTA, you would need to at least implement your model in a setting that is comparable to the numbers in Miyato et al (e.g. using ZCA), rather than running your model in a setting that was not considered in Miyato et al (e.g. removing ZCA).
2. It seems that the proposed method introduces a bunch of additional hyper-parameters, including lambda, two epsilons, and the alphas that weigh different terms. Is it difficult to tune these hyper-parameters in practice? What values did you actually use for these hyper-parameters?
3. The paper would be further improved if an ablation study could be performed on SVHN and/or CIFAR-10, since these are more popular datasets for semi-supervised learning. It would become clearer how the proposed method is better than the previous ones.
4. The paper claimed that "TAR inherits the computational efficiency from VAT". Does power iteration bring additional computation costs? What is the actual computational time, compared to VAT?</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">7: Good paper, accept</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></main></div>
  </div>
</div>


    <!-- Footer -->
    <footer class="sitemap">
      <div class="container">
        <div class="row hidden-xs">
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/venues">All Venues</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="/contact">Contact</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
    
        <div class="row visible-xs-block">
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/contact">Contact</a></li>
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
      </div>
    </footer>
    
    <footer class="sponsor">
      <div class="container">
        <div class="row">
          <div class="col-sm-10 col-sm-offset-1">
            <p class="text-center">
              OpenReview is created by the <a href="http://www.iesl.cs.umass.edu/" target="_blank">Information Extraction and Synthesis Laboratory</a>, College of Information and Computer Science, University of Massachusetts Amherst. We gratefully acknowledge the support of the OpenReview sponsors:  Google,  Facebook, NSF, the University of Massachusetts Amherst Center for Data Science, and Center for Intelligent Information Retrieval, as well as the Google Cloud Platform for donating the computing and networking services on which OpenReview.net runs.
            </p>
          </div>
        </div>
      </div>
    </footer>

  <div id="feedback-modal" class="modal fade" tabindex="-1" role="dialog">
    <div class="modal-dialog">
      <div class="modal-content">
        <div class="modal-header">
          <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button>
          <h3 class="modal-title">Send Feedback</h3>
        </div>
        <div class="modal-body">
          <p>Enter your feedback below and we'll get back to you as soon as possible.</p>
          <form action="/feedback" method="POST">
            <div class="form-group">
              <input type="email" name="from" class="form-control" placeholder="Email" />
            </div>
            <div class="form-group">
              <input type="text" name="subject" class="form-control" placeholder="Subject" />
            </div>
            <div class="form-group">
              <textarea name="message" class="form-control feedback-input" rows="5" placeholder="Message" required=""></textarea>
            </div>
          <ul id="ui-id-2" tabindex="0" class="ui-menu ui-widget ui-widget-content" style="display: none;"></ul></form>
        </div>
        <div class="modal-footer">
          <button type="button" class="btn btn-default" data-dismiss="modal">Cancel</button>
          <button type="button" class="btn btn-primary">Send</button>
        </div>
      </div>
    </div>
  </div>

  <script type="text/javascript" async="" src="https://www.google-analytics.com/analytics.js"></script><script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js"></script>
  <script>window.jQuery || document.write('&lt;script src="/static/js/vendor/jquery-2.2.4.min.js"&gt;&lt;\/script&gt;')</script>

  <script src="/static/dist/vendor.min.js"></script>
  <script src="/static/dist/templates.min.js"></script>
  <script src="/static/dist/openreview.min.js"></script>

    <script>window.legacyScripts = true;</script>


    <script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-108703919-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() { dataLayer.push(arguments); }
      gtag('js', new Date());
      gtag('config', 'UA-108703919-1');
    </script>


<div role="status" aria-live="assertive" aria-relevant="additions" class="ui-helper-hidden-accessible"></div></body></html>
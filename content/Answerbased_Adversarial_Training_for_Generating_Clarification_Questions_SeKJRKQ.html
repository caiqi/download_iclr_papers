<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" class="no-js"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>Answer-based Adversarial Training for Generating Clarification Questions | OpenReview</title>
  <meta name="description" content="" />

      <meta name="citation_title" content="Answer-based Adversarial Training for Generating Clarification Questions" />
        <meta name="citation_author" content="Sudha Rao" />
        <meta name="citation_author" content="Hal Daumé III" />
      <meta name="citation_publication_date" content="2018/09/27" />
      <meta name="citation_online_date" content="2018/09/27" />
      <meta name="citation_pdf_url" content="https://openreview.net/pdf?id=S1eKJ3R5KQ" />
      <meta name="twitter:card" content="summary" />
      <meta name="twitter:site" content="@openreviewnet" />
      <meta name="og:title" content="Answer-based Adversarial Training for Generating Clarification..." />
      <meta name="og:description" content="We propose a generative adversarial training approach for the problem of clarification question generation. Our approach generates clarification questions with the goal of eliciting new information..." />
      <meta name="og:image" content="https://openreview.net/static/images/openreview_logo_512.png" />

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans:400,400i,700,700i" />

  <link rel="stylesheet" href="/static/css/bootstrap.min.css" />
  <link rel="stylesheet" href="/static/css/jquery-ui.min.css" />
  <link rel="stylesheet" href="/static/css/main.min.css" />
</head>

<body class="forum">
  <nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
  
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand home push-link" href="/"><strong>OpenReview</strong>.net</a>
      </div>
  
      <div id="navbar" class="navbar-collapse collapse">
        <form class="navbar-form navbar-left profile-search" role="search">
          <div class="form-group has-feedback">
            <input id="search_input" type="text" class="form-control ui-autocomplete-input" placeholder="Search ICLR 2019 Conference" autocomplete="off" />
            <span class="glyphicon glyphicon-search form-control-feedback" aria-hidden="true"></span>
          </div>
  
          <input id="search_group" type="hidden" value="ICLR.cc/2019/Conference" />
          <input id="search_content" type="hidden" value="all" />
        <ul id="ui-id-1" tabindex="0" class="ui-menu ui-widget ui-widget-content ui-autocomplete ui-front" style="display: none;"></ul></form>
  
        <ul class="nav navbar-nav navbar-right">
        
            <li id="user-menu"><a href="/login">Login</a></li>
        </ul>
      </div>
  
    </div>
  </nav>

  <div id="or-banner" class="banner" style="">
  <div class="container">
    <div class="row">
      <div class="col-xs-12"><a href="/group?id=ICLR.cc/2019/Conference" title="Venue Homepage"><img class="icon" src="/static/images/arrow_left.svg" /> Go to <strong>ICLR 2019 Conference</strong> homepage</a></div>
    </div>
  </div>
</div>
<div id="flash-message-container" class="alert alert-danger" role="alert" style="display: none;">
  <div class="container">
    <div class="row">
      <div class="col-xs-12">
        <div class="alert-content">
          <button type="button" class="close" aria-label="Close"><span aria-hidden="true">×</span></button>
        </div>
      </div>
    </div>
  </div>
</div>

<div class="container">
  <div class="row">
    <div class="col-xs-12">
      <main id="content" class="clearfix openbanner-visible legacy-styles"><div id="note_S1eKJ3R5KQ" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Answer-based Adversarial Training for Generating Clarification Questions</a> <a class="note_content_pdf" href="/pdf?id=S1eKJ3R5KQ" title="Download PDF" target="_blank"><img src="/static/images/pdf_icon_blue.svg" /></a> </h2></div><div class="meta_row"><span class="signatures"><a href="/profile?email=raosudha%40cs.umd.edu" class="profile-link" data-toggle="tooltip" data-placement="bottom" title="" data-original-title="raosudha@cs.umd.edu">Sudha Rao</a>, <a href="/profile?email=hal%40umiacs.umd.edu" class="profile-link" data-toggle="tooltip" data-placement="bottom" title="" data-original-title="hal@umiacs.umd.edu">Hal Daumé III</a></span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">28 Sep 2018 (modified: 17 Nov 2018)</span><span class="item">ICLR 2019 Conference Withdrawn Submission</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Abstract: </span><span class="note_content_value">We propose a generative adversarial training approach for the problem of clarification question generation. Our approach generates clarification questions with the goal of eliciting new information that would make the given context more complete. We develop a Generative Adversarial Network (GAN) where the generator is a sequence-to-sequence model and the discriminator is a utility function that models the value of updating the context with the answer to the clarification question. We evaluate on two datasets, using both automatic metrics and human judgments of usefulness, specificity and relevance, showing that our approach outperforms both a retrieval-based model and ablations that exclude the utility model and the adversarial training.
</span></div><div class="note_contents"><span class="note_content_field">Keywords: </span><span class="note_content_value">natural language processing, text generation, generative adversarial network</span></div><div class="note_contents"><span class="note_content_field">TL;DR: </span><span class="note_content_value">We propose an adversarial training approach to the problem of clarification question generation which uses the answer to the question to model the reward. </span></div><div class="reply_row clearfix"><div class="item" id="reply_count">4 Replies</div></div></div><hr class="small" /><div id="note_children"><div class="note_with_children"><div id="note_HkxfA5GHTQ" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Submission Withdrawn by the Authors</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=S1eKJ3R5KQ&amp;noteId=HkxfA5GHTQ"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1002 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">11 Nov 2018</span><span class="item">ICLR 2019 Conference Paper1002 Withdraw Submission</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Withdrawal confirmation: </span><span class="note_content_value">I have read and agree with the withdrawal statement on behalf of myself and my co-authors.</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_HJgCH8Nc37" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Needs more work and clarity</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=S1eKJ3R5KQ&amp;noteId=HJgCH8Nc37"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1002 AnonReviewer3</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">03 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper1002 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">This paper addresses an interesting task of clarification question generation by proposing a GAN-based approach. It mainly builds on the ideas of Rao &amp; Daum´e III (2018) to understand the usefulness of generated questions via a utility function that acts as the discriminator while a simple seq-to-seq model is used to generate questions in the generator module. The proposed GAN model is inspired by the sequence GAN model of Yu et al. (2017) with simple variations such as using MIXER (Ranzato et al., 2015) as the generator and not using a CNN-based discriminator. Experiments were conducted on two datasets, and the obtained results were mixed and not conclusive. Overall, due to the lack of novelty and unconvincing results, I feel the paper needs more work before it is ready for publication. My detailed comments are below:

- "As a running example, we will use the Amazon setting: ..." --&gt; The example in Figure 1 is only referred once and not even in Table 3 to show the related model predictions. I would suggest to truly consider it as a running example to clarify the training and testing procedure better. Also, an example of the StackExchange dataset would be helpful.

- The utility function (Section 2.3) seems to be simple. Did you evaluate the effectiveness of this function solely in predicting the usefulness of a question? How would a binary classifier work instead? I also wonder why simple seq-to-seq models were used as question/answer generators while there exist a lot of work that already outperform these models for similar text generation tasks. 

- "In our model, the answer is an latent variable: we do not actually use it anywhere except to train the discriminator. Because of this, we train our discriminator using (context, true question, generated answer) triples as positive instances and (context, generated question, generated answer) triples as the negative instances." --&gt; This part is not clear. Did you use generated answers or the true answers as part of the positive instances? Please clarify across the paper when you used generated answer/question and when you used true answer/question.

- "Unlike the question generator, the parameters of the answer generator are kept fixed during the adversarial training" --&gt; please explain why.

- I like that the experiments were carried out on multiple datasets. What are the lengths of the contexts, questions, and answers for both datasets on average number of words? What are the impacts of the length restrictions of 100, 20, and 20 you set for context, question, answer on the evaluation results? How did you come up with these numbers? I would suggest to include an analysis of impacts of variable lengths of context, question, answer on the model performance.  

- It's not clear how the Lucene system was built with human generated questions. Please clarify.

- Table 2 shows mixed results, what should we conclude from this? 

- How many crowdworkers were used for human judgements? What was the inter-annotator agreement? How did you convert the human answers into the numeric scores of Table 2? Without these information, it is not possible to judge the utility of the human evaluation. StackExchange results could have been annotated via other crowdsourcing venues e.g. upwork.   

- The related work should be better compared and contrasted with the proposed work, especially the main contributions of the paper should be clearly highlighted. 

- Table 3 is not referred in text. I would suggest to include the name of the products also for better context. The human evaluation scores look very subjective, hence, the inter-annotator agreement is an essential factor. 

- There are a lot of grammatical mistakes and inconsistencies across the paper that need to be corrected.</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">4: Ok but not good enough - rejection</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_SyxbIyNq3m" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Very interesting idea with weak evaluation</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=S1eKJ3R5KQ&amp;noteId=SyxbIyNq3m"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1002 AnonReviewer2</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">03 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper1002 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">In the paper, the authors try to improve the generation of clarification questions using reinforcement learning against a discriminator, creating a GAN-like setting. They train two sequence-to-sequence models that i) generate questions from context, and ii) answers from (context, question) pairs. They also train a discriminator model on (question, answer, context) triples.

I believe the task, and the setup created by the authors is very interesting and novel, and the paper is very well written. They show that the additional training against the discriminator leads to a (very small) increase in diversity and question specificity.

On the negative side:
  - It is not clear to me that the discriminator acts as a utility function as they claim, at least in the way they define utility. It is only trained to distinguish real questions about a context from random ones.
  - The results presented in Table 1 and 2 show only very small differences to the other approaches. I wonder why that is, and how much the model actually changes in the reinforcement learning tuning step.
  - The automated metrics do not seem suitable for the task, since they can only measure how close a generated example is to some gold example. 
  - The only significant improvement is on specificity, with the much more important goal of creating useful questions not achieved. I am actually not sure if increased utility (i.e. identifying missing information and asking about it) can be achieved with a setup like this.

But despite these weaknesses I still think this is a very interesting contribution.</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">6: Marginally above acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_H1eVqQ-CoX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Interesting approach with bad evaluation setup</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=S1eKJ3R5KQ&amp;noteId=H1eVqQ-CoX"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1002 AnonReviewer1</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">24 Oct 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper1002 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span><a class="note_content_pdf item" href="/revisions?id=H1eVqQ-CoX" target="_blank">Show Revisions</a></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">The paper proposes a new approach for the problem of clarification question generation. It is based on training question-answer generator model jointly with a utility function (or discriminator) using a GAN-like objective. The system is compared to a variety of baselines and shows to generate slightly more diverse answers than competing baselines, but is otherwise quite comparable. 

The paper is overall well presented and introduces an interesting approach that combines SeqGANs with MIXER training and a self critical baseline. The authors also took care to establish reasonable baselines given the novelty of the task. The evaluations are carried out on a very artificial task setup, however, that is overall not very usefull for evaluating clarification questions. Therefore, I believe that this paper needs a completely different evaluation setup and I can unfortunately not recommend it for acceptance without that.

Detailed comments:
It is unclear to me whether it is really possible to evaluate a model trained in such a setup, because it is impossible to say what is a useful clarification question without establishing an information need first. Just asking random questions about a product, which is the best we can hope to learn, is not a very interesting task. Clarification is usually a means to an end goal, but in this paper it is established as the final goal, which doesn't make too much sense to me. This leads to the rather artificial treatment of "Utility", which is impossible to define without a clear down-stream task. The paper relabels generating human-like questions as the utility to optimize towards in order to ultimately fool a discriminator. I don't see how this can be viewed as defining utility. So I strongly suggest to evaluate the approach on a task that might actually require asking clarification questions, in which case utility is naturally defined. GAN training could still be used to make the generated questions more diverse.


Strengths:
- clearly written and well presented
- learning to generate clarification questions is an important topic
- interesting combination of SeqGANs, MIXER and self-critical baseline for policy gradient updates
- a range of good baselines for this novel task setup


Weaknesses:
- minor: automatic evaluations are kind of useless here and the datasets are rather artificial for this task
- major: generating clarification questions cannot be the end goal in and of itself (see above explanation)


Other comments:
- section pretraining, paragraph question generator: I do not understand the reference to answer generator in this paragraph. I think something got mixed up in this section.
- needs some proof reading: some spelling mistakes (eg: p3 thier-&gt;their), missing spaces (e.g., p.4 "model§2.1"), 


Questions:
Why is specificity such an important aspect if we mainly care about usefulness? In other words, is usefulness not capturing specificity to a certain degree?

The goal of this paper is to train clarification questions, so I do not really understand why also synthetic answers are being generated? Why not just training the system on (context, question) tuples? </span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">4: Ok but not good enough - rejection</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></main></div>
  </div>
</div>


    <!-- Footer -->
    <footer class="sitemap">
      <div class="container">
        <div class="row hidden-xs">
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/venues">All Venues</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="/contact">Contact</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
    
        <div class="row visible-xs-block">
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/contact">Contact</a></li>
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
      </div>
    </footer>
    
    <footer class="sponsor">
      <div class="container">
        <div class="row">
          <div class="col-sm-10 col-sm-offset-1">
            <p class="text-center">
              OpenReview is created by the <a href="http://www.iesl.cs.umass.edu/" target="_blank">Information Extraction and Synthesis Laboratory</a>, College of Information and Computer Science, University of Massachusetts Amherst. We gratefully acknowledge the support of the OpenReview sponsors:  Google,  Facebook, NSF, the University of Massachusetts Amherst Center for Data Science, and Center for Intelligent Information Retrieval, as well as the Google Cloud Platform for donating the computing and networking services on which OpenReview.net runs.
            </p>
          </div>
        </div>
      </div>
    </footer>

  <div id="feedback-modal" class="modal fade" tabindex="-1" role="dialog">
    <div class="modal-dialog">
      <div class="modal-content">
        <div class="modal-header">
          <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button>
          <h3 class="modal-title">Send Feedback</h3>
        </div>
        <div class="modal-body">
          <p>Enter your feedback below and we'll get back to you as soon as possible.</p>
          <form action="/feedback" method="POST">
            <div class="form-group">
              <input type="email" name="from" class="form-control" placeholder="Email" />
            </div>
            <div class="form-group">
              <input type="text" name="subject" class="form-control" placeholder="Subject" />
            </div>
            <div class="form-group">
              <textarea name="message" class="form-control feedback-input" rows="5" placeholder="Message" required=""></textarea>
            </div>
          <ul id="ui-id-2" tabindex="0" class="ui-menu ui-widget ui-widget-content" style="display: none;"></ul></form>
        </div>
        <div class="modal-footer">
          <button type="button" class="btn btn-default" data-dismiss="modal">Cancel</button>
          <button type="button" class="btn btn-primary">Send</button>
        </div>
      </div>
    </div>
  </div>

  <script type="text/javascript" async="" src="https://www.google-analytics.com/analytics.js"></script><script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js"></script>
  <script>window.jQuery || document.write('&lt;script src="/static/js/vendor/jquery-2.2.4.min.js"&gt;&lt;\/script&gt;')</script>

  <script src="/static/dist/vendor.min.js"></script>
  <script src="/static/dist/templates.min.js"></script>
  <script src="/static/dist/openreview.min.js"></script>

    <script>window.legacyScripts = true;</script>


    <script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-108703919-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() { dataLayer.push(arguments); }
      gtag('js', new Date());
      gtag('config', 'UA-108703919-1');
    </script>


<div role="status" aria-live="assertive" aria-relevant="additions" class="ui-helper-hidden-accessible"></div></body></html>
<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" class="no-js"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>Learning Diverse Generations using Determinantal Point Processes | OpenReview</title>
  <meta name="description" content="" />

      <meta name="citation_title" content="Learning Diverse Generations using Determinantal Point Processes" />
        <meta name="citation_author" content="Anonymous" />
      <meta name="citation_publication_date" content="2018/09/27" />
      <meta name="citation_online_date" content="2018/09/27" />
      <meta name="citation_pdf_url" content="https://openreview.net/pdf?id=S1x8WnA5Ym" />
      <meta name="twitter:card" content="summary" />
      <meta name="twitter:site" content="@openreviewnet" />
      <meta name="og:title" content="Learning Diverse Generations using Determinantal Point Processes" />
      <meta name="og:description" content="Generative models have proven to be an outstanding tool for representing high-&#10;  dimensional probability distributions and generating realistic looking images. A&#10;  fundamental characteristic of..." />
      <meta name="og:image" content="https://openreview.net/static/images/openreview_logo_512.png" />

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans:400,400i,700,700i" />

  <link rel="stylesheet" href="/static/css/bootstrap.min.css" />
  <link rel="stylesheet" href="/static/css/jquery-ui.min.css" />
  <link rel="stylesheet" href="/static/css/main.min.css" />
</head>

<body class="forum">
  <nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
  
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand home push-link" href="/"><strong>OpenReview</strong>.net</a>
      </div>
  
      <div id="navbar" class="navbar-collapse collapse">
        <form class="navbar-form navbar-left profile-search" role="search">
          <div class="form-group has-feedback">
            <input id="search_input" type="text" class="form-control ui-autocomplete-input" placeholder="Search ICLR 2019 Conference" autocomplete="off" />
            <span class="glyphicon glyphicon-search form-control-feedback" aria-hidden="true"></span>
          </div>
  
          <input id="search_group" type="hidden" value="ICLR.cc/2019/Conference" />
          <input id="search_content" type="hidden" value="all" />
        <ul id="ui-id-1" tabindex="0" class="ui-menu ui-widget ui-widget-content ui-autocomplete ui-front" style="display: none;"></ul></form>
  
        <ul class="nav navbar-nav navbar-right">
        
            <li id="user-menu"><a href="/login">Login</a></li>
        </ul>
      </div>
  
    </div>
  </nav>

  <div id="or-banner" class="banner" style="">
  <div class="container">
    <div class="row">
      <div class="col-xs-12"><a href="/group?id=ICLR.cc/2019/Conference" title="Venue Homepage"><img class="icon" src="/static/images/arrow_left.svg" /> Go to <strong>ICLR 2019 Conference</strong> homepage</a></div>
    </div>
  </div>
</div>
<div id="flash-message-container" class="alert alert-danger" role="alert" style="display: none;">
  <div class="container">
    <div class="row">
      <div class="col-xs-12">
        <div class="alert-content">
          <button type="button" class="close" aria-label="Close"><span aria-hidden="true">×</span></button>
        </div>
      </div>
    </div>
  </div>
</div>

<div class="container">
  <div class="row">
    <div class="col-xs-12">
      <main id="content" class="clearfix openbanner-visible legacy-styles"><div id="note_S1x8WnA5Ym" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Learning Diverse Generations using Determinantal Point Processes</a> <a class="note_content_pdf" href="/pdf?id=S1x8WnA5Ym" title="Download PDF" target="_blank"><img src="/static/images/pdf_icon_blue.svg" /></a> </h2></div><div class="meta_row"><span class="signatures">Anonymous</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">28 Sep 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Blind Submission</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span><span class="item"><a class="action-bibtex-modal" data-bibtex="@inproceedings{    &#10;anonymous2019learning,    &#10;title={Learning Diverse Generations using Determinantal Point Processes},    &#10;author={Anonymous},    &#10;booktitle={Submitted to International Conference on Learning Representations},    &#10;year={2019},    &#10;url={https://openreview.net/forum?id=S1x8WnA5Ym},    &#10;note={under review}    &#10;}">Show Bibtex</a></span><a class="note_content_pdf item" href="/revisions?id=S1x8WnA5Ym" target="_blank">Show Revisions</a></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Abstract: </span><span class="note_content_value">Generative models have proven to be an outstanding tool for representing high-
dimensional probability distributions and generating realistic looking images. A
fundamental characteristic of generative models is their ability to produce multi-
modal outputs. However while training, they are often susceptible to mode col-
lapse, which means that the model is limited in mapping the input noise to only
a few modes of the true data distribution. In this paper, we draw inspiration from
Determinantal Point Process (DPP) to devise a generative model that alleviates
mode collapse problem while producing higher quality samples. DPP is an ele-
gant probabilistic measure used to model negative correlations within a subset, and
hence quantify its diversity. We propose a generation penalty term that encourages
the generator to behave as a Determinantal Point Process sampler and hence learns
to generates diverse data. In contrast to previous state-of-the-art generative mod-
els that tend to use additional trainable parameters or complex training paradigms,
our method does not change the original training scheme. Embedded in an ad-
versarial strategy, our Generative DPP approach shows a consistent resistance to
mode-collapse on a wide-variety of synthetic data and natural image datasets in-
cluding MNIST and CIFAR10, while outperforming state-of-the-art methods for
data-efficiency, convergence-time, and generation quality. Our code will be made
publicly available.</span></div><div class="note_contents"><span class="note_content_field">Keywords: </span><span class="note_content_value">Generative Adversarial Networks</span></div><div class="note_contents"><span class="note_content_field">TL;DR: </span><span class="note_content_value">The addition of a diversity criterion inspired from DPP in the GAN objective avoids mode collapse and leads to better generations. </span></div><div class="reply_row clearfix"><div class="item" id="reply_count">4 Replies</div></div></div><hr class="small" /><div id="note_children"><div class="note_with_children"><div id="note_rkgO-i9H6Q" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>The authors’ motivation from DPP is arguable</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=S1x8WnA5Ym&amp;noteId=rkgO-i9H6Q"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1173 AnonReviewer1</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">11 Nov 2018</span><span class="item">ICLR 2019 Conference Paper1173 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">This paper proposes generative adversarial networks regularized by Determinantal Point Process (DPP) to learn diverse data space. DPP is a probabilistic model that encourages the diversity between the dataset. Authors observe that previous generative models have a mode-collapse problem, and they add generative DPP (GDPP) loss (eq (5)) as a diversity regularizer. Experiments show the GDPP loss is practically helpful to learn under synthetic multi-modal data and real-world image generation.

The paper is well written and easy to comprehend the motivations and main contributions. And the experimental results seem to be interesting. However, there are some arguable issues:

- The main contribution is adding GDPP loss to the original generative models. The authors claim that the GDPP loss (eq (5)) is motivated by the DPP, but I think it does not utilize DPP characteristics at all. The proposed loss is rather close to eigenvalues/vectors matching rather than DPP. It does not seem to be capture DPP properties even assuming the training is perfect. In particular, DPP measures the similarity as the volume of spanned space, while the GDPP loss uses the cosine similarity.

- The GDPP loss is a function of eigenvalues/vectors of kernels, which is generated by internal features of the discriminator. I am curious how to compute the eigenvalues/vectors. Also, the gradient of functions of eigenvalues/vectors is not straightforward as it takes at least a cubic time-complexity with a dimension. It is better to clarify the time complexity for computing the loss and its gradients.

- In addition, if the feature kernel is not a full rank, it is deficient, i.e., some eigenvalues can be zeros. Do you compute the loss all eigenvalues? or compute only some eigenvectors?

- In section 5, the analysis of time-efficiency is not sufficient. Authors report the performance varying the number of iterations. However, since the loss computes eigenvectors/values, the cost per iteration should be larger than other competitors. It is natural to compare the elapsed time or number of FLOPS.

- Although the proposed method shows the best results for the experiments, it is desirable to compare to more diversity encouraging generative models, e.g., DeLiGAN [1]. In addition, I could not recognize the effectiveness of proposals in the experiments of image dataset.

In overall, I think the proposed idea is interesting, but the authors’ motivation from DPP is arguable. In addition, I do not find enough novelty.

Minor issues:
- What is cos(v,w)? Please specify the definition of this.
- Where is Fig. 2k ? Please add the sub-index in Figure 2.

[1] Gurumurthy, Swaminathan, Ravi Kiran Sarvadevabhatla, and R. Venkatesh Babu. “DeLiGAN: Generative Adversarial Networks for Diverse and Limited Data.” CVPR. 2017</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">5: Marginally below acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_Skx_mWw7TX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>The connection between the propsoed regularizer and the DPP is not precise.</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=S1x8WnA5Ym&amp;noteId=Skx_mWw7TX"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1173 AnonReviewer3</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">10 Nov 2018</span><span class="item">ICLR 2019 Conference Paper1173 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">For training GANs, the authors propose a regularizer that is inspired by DPP, which encourage diversity. This new regularizer is tested on several benchmark datasets and compared against other mode-collapse mitigating approaches. 

   
In section 2, important references to recent techniques to mitigate mode collapse are missing, e.g.
BourGAN (<a href="https://arxiv.org/abs/1805.07674)" target="_blank" rel="nofollow">https://arxiv.org/abs/1805.07674)</a>
PacGAN (https://arxiv.org/abs/1712.04086)
D2GAN (https://arxiv.org/abs/1709.03831)

Also related is evaluation of mode collapse as in 
On GANs and GMMs (https://arxiv.org/abs/1805.12462) 

The actual loss that is proposed as in (5) and (6), seems far from the motivation that is explained as in Eq (3), using generator as a point process that resembles DPP. This conceptual gap makes the proposed explanation w.r.t DPP unsatisfactory. A more natural approach would be simply add $det(L_{S_B})$ itself as a regularizer. Extensive experimental comparisons with this straightforward regularizer is in order. 

It is not immediate if the proposed diversity regularizer $L_g^{DPP}$ in (5) is differentiable in general, as it involves computing the eigen-vectors. Elaborate on the implementation of the gradient update with respect to this new regularizer. 
 

Experiments: 

1. The results in Table 3 for stacked-MNIST are very different from VEEGAN paper. Explain why a different setting was used compared to VEEGAN experiments. 

2. Similar experiments have been done in Unrolled-GAN paper. Add the experiment from that setting also. 

3. In general, split the experiments to two parts: one where the same setting is used as in the literature (e.g. VEEGAN, Unrolled GAN) and the results are compared against those reported in those papers. Another where new settings are studied, and the experiments of the baseline methods are also run by the authors. This is critical to differentiate such cases, as hyper parameters of competing algorithms could have not been tuned as rigorously as the proposed method. This improves the credibility of the experimental results, eventually leading to reproducibility. 

</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">5: Marginally below acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_SyxGMY50h7" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>This paper integrates DPP with GAN and promotes diversity in learning generator distribution</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=S1x8WnA5Ym&amp;noteId=SyxGMY50h7"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1173 AnonReviewer2</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">06 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper1173 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">The paper proposes to introduce DPP into the vanilla GAN loss and uses it as a way to regularize the generator to produce more diverse outputs, in order to combat the mode-collapse problem. Since the proposed method is added as a simple loss regularizer, the approach does not introduce additional parameters, therefore, less training difficulties. The results on synthetic data seems promising, but there is insufficient evaluation being performed on real and larger dataset where the mode collapse problems are more likely to happen.

- Method
The proposed methods seem sensible. But there are some critical details missing from the current text that prevents me from assessing this paper clearly. 

* How are the \lambda and v in Eq.6 calculated? It seems to me that you need to estimate the eigenvalues and eigenvectors at every iteration of your training. I am aware of that many DPP-based models suffer from scalability issues. Could you discuss the potential overhead of this procedure? Also in experiments, you claim "DPP-GAN is cost-free, we observe that the training of GDPP-GAN has an indistinguishable running time than the DCGAN, which are the fastest models to finish training“, which is hard to believe.. could you give more details and analysis on the overhead here?

* In Eq.6 why there are both  "a diversity magnitude loss L_m", and "diversity structure loss L_s". What do they specifically try to capture respectively? Could you give a geometric interpretation on this part?

* what is the batch size used in your experiments on MNIST and CIFAR-10. It seems to me that the effectiveness of GDPP would rely on batch size used as per my understanding you will estimate the DPP kernel using the current batch of samples (generated or real)? 

* Despite the fact that GDPP wants to reduce parameters introduced, it is not very intuitive to understand how it would work to use the features outputted by D as the DPP features as well. As D, as the discriminator itself, is trained to distinguish real from fake, while mimicking the eigenvalues/vectors of real data. How would these two goals be reconciled by the same set of parameters?

- Experiments
The results on the synthetic data seem promising, but the results on MNIST and CIFAR-10 are not impressive enough:
* The visual quality of Figure.9 does not look very appealing. I believe many simple variants DCGAN can produce better quality of images
* Why your DCGAN baseline on CIFAR-10 only reports inception score around 5 (with high variance, see Figure.5 and Table 3)? I believe vanilla DCGANs can easily attain an IS at 5.5 to 6, as reported in most recent GAN literature.
* More visual results on CIFAR10 should have been presented in order to demonstrate DPP does generate images with as many classes as existed in CIFAR-10 (which is 10)
* The results could be much more convincing if the authors could show the generation results and evaluation metrics on larger/more real datasets other than CIFAR-10 and MNIST. See GAN literature in 2018 about what dataset to use.


- Presentation
Most parts of this paper are well written. There are few typos and grammatical errors across the text which I believe are easily fixable. There are some missing details that hinder the understanding of some technical parts of the paper. See above for detailed comments.

- Other
Promoting diversity in (deep) generative models isn't a new topic. It would be good if the authors could established connections/differences between this work and this line of relevant  works. 

</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">5: Marginally below acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_S1lVMpOypX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Addressing the comments and describing our additional experiments</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=S1x8WnA5Ym&amp;noteId=S1lVMpOypX"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1173 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">07 Nov 2018</span><span class="item">ICLR 2019 Conference Paper1173 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Thanks a lot for your constructive comments. We reply to each of the aforementioned points separately. Additionally, we updated our manuscript with new results of applying GDPP on Variational AutoEncoder and progressive-growing GANs on the CelebA dataset.

[Eigen values and vector computation] Correct, we perform an eigen decomposition to obtain the eigenvalues and eigenvectors.
In general, there are two factors that contribute to a potential overhead for the eigen decomposition: the batch size and the extracted features dimensionality. The larger the batch size or features dimensionality, the larger the kernel to be decomposed, which constitutes a computational overhead. However, if the data is too complex and large, it would not fit a large batch size in the memory but will need a larger feature representation. And, if the data is too simple and small, can fit larger batch sizes in the memory, and will need a smaller feature representation. Therefore, the computational overhead should be similar across variable types of data.
In practice, we computed the average ratio of GDPP computation with respect to the total iteration time. We obtained 11.61% for Synthetic data, 9.36% for Stacked-MNIST data and 8.27% for CIFAR-10.

[Interpreting GDPP loss (Eq. 6)] Intuitively, for a positive semidefinite matrix, eigenvectors represent the orientation of distortion within data, and eigenvalues represent the magnitude of distortion of each eigenvector. That's why we have an L2 magnitude loss that favors a matching of the magnitudes of eigenvalues (Magnitude loss), and a Cosine-similarity loss that aims to match the orientations of the eigenvectors (Structure loss).

[Batch size effect] Increasing the batch size is a subject of memory constraints, but theoretically, it should improve the performance up to a limit. In synthetic data, we used a batch size of 512. For stacked-MNIST and CIFAR-10, we used a batch size of 64. In CelebA, we used a batch size of 16, and plan to present results with a larger batch size.

[Quality of the discriminator features] In order for the adversarial network to distinguish real from fake, it learns to extract discriminative features of each data sample. When training with GDPP loss, we use those features to compute the GDPP. Specifically, we compute eigen vectors and values of the DPP kernel constructed using those features. However, we only backpropagate this loss to the generator but not the discriminator.

[Quality on CIFAR10] It is true that DCGANs reach an Inception score greater than 6 in a conditioned setting, whereas we applied GDPP to the more challenging setup of unsupervised adversarial training.  Using the same architecture of WGAN-GP(Gulrajani et al., 2017), with only half the number of training iterations and the standard adversarial training paradigm, our method generates similar qualitative results to the unsupervised WGAN-GP with a higher Inception-Score and a lower Inference-Via-Optimization. We also note that the inception score values greatly depend on the used architecture: using deeper networks would probably improve the performances, but the rank should be the same. 

[Diversity in GANs] Unrolled-GAN, VEEGAN, ALI are methods that were explicitly introduced to address mode collapse. We presented these methods in the related work section and compared to them in the experiments section.

[More datasets &amp; VAE] We now present additional results with the state-of-the-art progressive growing architecture on CelebA, demonstrating that our loss scales across deeper networks and more complex datasets. We also show that it performs similarly in Variational Autoencoder, deeming GDPP to be a model and architecture invariant loss.
</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div></div></main></div>
  </div>
</div>


    <!-- Footer -->
    <footer class="sitemap">
      <div class="container">
        <div class="row hidden-xs">
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/venues">All Venues</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="/contact">Contact</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
    
        <div class="row visible-xs-block">
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/contact">Contact</a></li>
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
      </div>
    </footer>
    
    <footer class="sponsor">
      <div class="container">
        <div class="row">
          <div class="col-sm-10 col-sm-offset-1">
            <p class="text-center">
              OpenReview is created by the <a href="http://www.iesl.cs.umass.edu/" target="_blank">Information Extraction and Synthesis Laboratory</a>, College of Information and Computer Science, University of Massachusetts Amherst. We gratefully acknowledge the support of the OpenReview sponsors:  Google,  Facebook, NSF, the University of Massachusetts Amherst Center for Data Science, and Center for Intelligent Information Retrieval, as well as the Google Cloud Platform for donating the computing and networking services on which OpenReview.net runs.
            </p>
          </div>
        </div>
      </div>
    </footer>

  <div id="feedback-modal" class="modal fade" tabindex="-1" role="dialog">
    <div class="modal-dialog">
      <div class="modal-content">
        <div class="modal-header">
          <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button>
          <h3 class="modal-title">Send Feedback</h3>
        </div>
        <div class="modal-body">
          <p>Enter your feedback below and we'll get back to you as soon as possible.</p>
          <form action="/feedback" method="POST">
            <div class="form-group">
              <input type="email" name="from" class="form-control" placeholder="Email" />
            </div>
            <div class="form-group">
              <input type="text" name="subject" class="form-control" placeholder="Subject" />
            </div>
            <div class="form-group">
              <textarea name="message" class="form-control feedback-input" rows="5" placeholder="Message" required=""></textarea>
            </div>
          <ul id="ui-id-2" tabindex="0" class="ui-menu ui-widget ui-widget-content" style="display: none;"></ul></form>
        </div>
        <div class="modal-footer">
          <button type="button" class="btn btn-default" data-dismiss="modal">Cancel</button>
          <button type="button" class="btn btn-primary">Send</button>
        </div>
      </div>
    </div>
  </div>

  <script type="text/javascript" async="" src="https://www.google-analytics.com/analytics.js"></script><script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js"></script>
  <script>window.jQuery || document.write('&lt;script src="/static/js/vendor/jquery-2.2.4.min.js"&gt;&lt;\/script&gt;')</script>

  <script src="/static/dist/vendor.min.js"></script>
  <script src="/static/dist/templates.min.js"></script>
  <script src="/static/dist/openreview.min.js"></script>

    <script>window.legacyScripts = true;</script>


    <script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-108703919-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() { dataLayer.push(arguments); }
      gtag('js', new Date());
      gtag('config', 'UA-108703919-1');
    </script>


<div role="status" aria-live="assertive" aria-relevant="additions" class="ui-helper-hidden-accessible"></div></body></html>
<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" class="no-js"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>I Know the Feeling: Learning to Converse with Empathy | OpenReview</title>
  <meta name="description" content="" />

      <meta name="citation_title" content="I Know the Feeling: Learning to Converse with Empathy" />
        <meta name="citation_author" content="Anonymous" />
      <meta name="citation_publication_date" content="2018/09/27" />
      <meta name="citation_online_date" content="2018/09/27" />
      <meta name="citation_pdf_url" content="https://openreview.net/pdf?id=HyesW2C9YQ" />
      <meta name="twitter:card" content="summary" />
      <meta name="twitter:site" content="@openreviewnet" />
      <meta name="og:title" content="I Know the Feeling: Learning to Converse with Empathy" />
      <meta name="og:description" content="Beyond understanding what is being discussed, human communication requires an awareness of what someone is feeling. One challenge for dialogue agents is being able to recognize feelings in the..." />
      <meta name="og:image" content="https://openreview.net/static/images/openreview_logo_512.png" />

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans:400,400i,700,700i" />

  <link rel="stylesheet" href="/static/css/bootstrap.min.css" />
  <link rel="stylesheet" href="/static/css/jquery-ui.min.css" />
  <link rel="stylesheet" href="/static/css/main.min.css" />
</head>

<body class="forum">
  <nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
  
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand home push-link" href="/"><strong>OpenReview</strong>.net</a>
      </div>
  
      <div id="navbar" class="navbar-collapse collapse">
        <form class="navbar-form navbar-left profile-search" role="search">
          <div class="form-group has-feedback">
            <input id="search_input" type="text" class="form-control ui-autocomplete-input" placeholder="Search ICLR 2019 Conference" autocomplete="off" />
            <span class="glyphicon glyphicon-search form-control-feedback" aria-hidden="true"></span>
          </div>
  
          <input id="search_group" type="hidden" value="ICLR.cc/2019/Conference" />
          <input id="search_content" type="hidden" value="all" />
        <ul id="ui-id-1" tabindex="0" class="ui-menu ui-widget ui-widget-content ui-autocomplete ui-front" style="display: none;"></ul></form>
  
        <ul class="nav navbar-nav navbar-right">
        
            <li id="user-menu"><a href="/login">Login</a></li>
        </ul>
      </div>
  
    </div>
  </nav>

  <div id="or-banner" class="banner" style="">
  <div class="container">
    <div class="row">
      <div class="col-xs-12"><a href="/group?id=ICLR.cc/2019/Conference" title="Venue Homepage"><img class="icon" src="/static/images/arrow_left.svg" /> Go to <strong>ICLR 2019 Conference</strong> homepage</a></div>
    </div>
  </div>
</div>
<div id="flash-message-container" class="alert alert-danger" role="alert" style="display: none;">
  <div class="container">
    <div class="row">
      <div class="col-xs-12">
        <div class="alert-content">
          <button type="button" class="close" aria-label="Close"><span aria-hidden="true">×</span></button>
        </div>
      </div>
    </div>
  </div>
</div>

<div class="container">
  <div class="row">
    <div class="col-xs-12">
      <main id="content" class="clearfix openbanner-visible legacy-styles"><div id="note_HyesW2C9YQ" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>I Know the Feeling: Learning to Converse with Empathy</a> <a class="note_content_pdf" href="/pdf?id=HyesW2C9YQ" title="Download PDF" target="_blank"><img src="/static/images/pdf_icon_blue.svg" /></a> </h2></div><div class="meta_row"><span class="signatures">Anonymous</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">28 Sep 2018 (modified: 11 Oct 2018)</span><span class="item">ICLR 2019 Conference Blind Submission</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span><span class="item"><a class="action-bibtex-modal" data-bibtex="@inproceedings{    &#10;anonymous2019i,    &#10;title={I Know the Feeling: Learning to Converse with Empathy},    &#10;author={Anonymous},    &#10;booktitle={Submitted to International Conference on Learning Representations},    &#10;year={2019},    &#10;url={https://openreview.net/forum?id=HyesW2C9YQ},    &#10;note={under review}    &#10;}">Show Bibtex</a></span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Abstract: </span><span class="note_content_value">Beyond understanding what is being discussed, human communication requires an awareness of what someone is feeling. One challenge for dialogue agents is being able to recognize feelings in the conversation partner and reply accordingly, a key communicative skill that is trivial for humans. Research in this area is made difficult by the paucity of large-scale publicly available datasets both for emotion and relevant dialogues. This work proposes a new task for empathetic dialogue generation and EmpatheticDialogues, a dataset of 25k conversations grounded in emotional contexts to facilitate training and evaluating dialogue systems. Our experiments indicate that models explicitly leveraging emotion predictions from previous utterances are perceived to be more empathetic by human evaluators, while improving on other metrics as well (e.g. perceived relevance of responses, BLEU scores).</span></div><div class="note_contents"><span class="note_content_field">Keywords: </span><span class="note_content_value">dialogue generation, nlp applications, grounded text  generation, contextual representation learning</span></div><div class="note_contents"><span class="note_content_field">TL;DR: </span><span class="note_content_value">We improve existing dialogue systems for responding to people sharing personal stories, incorporating emotion prediction representations and also release a new benchmark and dataset of empathetic dialogues.</span></div><div class="reply_row clearfix"><div class="item" id="reply_count">3 Replies</div></div></div><hr class="small" /><div id="note_children"><div class="note_with_children"><div id="note_Hklbe_U027" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Doubts about the two main contributions</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HyesW2C9YQ&amp;noteId=Hklbe_U027"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1202 AnonReviewer2</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">06 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper1202 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">The overall goal of the paper is to make end-to-end dialogue systems more empathetic, so that they can respond more appropriately and in ways that acknowledge how the users are feeling. The authors make two contributions towards that goal: (1) they introduce a crowdsourced dataset (EmpatheticDialogue) annotated with fine-grained emotion labels. (2) They show improvements on dialogue generation (in terms of empathy, but also relevance and fluency) using a multi-task objective, ensemble of encoders, and a more ad-hoc technique that consists of prepending inferred emotion labels to the input.

In terms of technical novelty, the work is relatively incremental: (A) The use of multi-task objectives in sequence models [1] is relatively common nowadays (there is little mathematical details in the paper, so it’s hard to see how the approach of the paper really differs from extensive related work.). (B) Prepending predictions: prepending class labels to the input is also relatively common (e.g., in multilingual NMT to select a language). [2] presents a similar approach for polite response generation, where they prepend a label using a politeness classifier.

I also have some doubts about the two claimed contributions of the paper (the authors actually list 3 contributions in the introduction, but for convenience I lump the 2 non-data ones together):

(1) Dataset: The dataset was crowdsourced by giving workers an emotion label (e.g., afraid) and asking them to define a situation in which that emotion might occur and inviting them to have a conversation on that situation. The problem with prompting workers for specific emotions is that this assumes they are good actors and this is likely to produce exchanges that are rather cliché and overdone (e.g., Table 1: the label “afraid” yields a situation that is rather spooky and unlikely in the real world, and the conversations themselves are rather cliché and incorporate little details that would make them sound real).  The authors justify this dataset by pointing out that existing real-world datasets underrepresent rare emotions (e.g., afraid), but that’s just a reflection of how these emotions are distributed in the real world. Better subsampling strategies would enable a better balance in the distribution without having to give up on real-world data (filtering using emojis, hashtags, etc.).  As the paper shows quantitative gains using this dataset, it is probably ok to use but, qualitatively, this dataset is probably not for everyone working on emotion in NLP. 

(2) Improvement in empathetic dialogue generation: The paper shows improvements across the board compared to a Transformer baseline, but the question the authors do not satisfactorily address is whether their explicit (and I would say sometimes ad-hoc) treatment of empathy (e.g., using emotion classifier, etc.) is crucially needed to get better empathetic dialogues, since the authors did not control for training data size and model capacity. Indeed, the authors exploited different amounts of data (out of-domain, or both in- and out-of-domain), different model capacities (going from baseline Transformer to model ensembles), and sometimes richer input (e.g., pre-trained emotion classifier). The results might only be showing that more data or more model capacity helps, which would of course not be surprising at all. The fact that generated outputs improve in all aspects (not only empathy, but in attributes completely unrelated to empathy such as fluency and relevance) suggests that the improvement is due to more data or capacity (e.g., perhaps yielding better encoder).  More statistics in the table in terms of number of parameters and amount of in- and out-of-domain data used for each experiment would help draw a clearer picture.

About the use of Reddit: this might not be the best background dataset, as it’s mostly strangers talking to other strangers, presumably causing the baseline to be weak on empathy. Twitter or other social-network type datasets (letting you follow people rather topics) *might* be better suited as it comparatively involves more exchanges between people who actually know each other and who are thus more likely to behave empathetically.

Overall, the paper doesn’t really attempt to make major technical contribution, and instead (1) introduces a dataset and (2) makes empirical contributions, but I think there are problems with both.

Typos:

Introduction: “fro”
References: Elizaa 

[1] Minh-Thang Luong, Quoc V. Le, Ilya Sutskever, Oriol Vinyals, Lukasz Kaiser  
Multi-task Sequence to Sequence Learning
<a href="https://arxiv.org/abs/1511.06114" target="_blank" rel="nofollow">https://arxiv.org/abs/1511.06114</a>

[2] Tong Niu and Mohit Bansal
Polite Dialogue Generation Without Parallel Data
https://arxiv.org/pdf/1805.03162.pdf</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">4: Ok but not good enough - rejection</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_S1eSaJc53Q" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>A renewed attempt for adapting dialog responses to emotional context</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HyesW2C9YQ&amp;noteId=S1eSaJc53Q"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1202 AnonReviewer3</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">03 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper1202 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">The paper describes a new study about how to make dialogs more empathetic.
The work introduced a new dataset of 25k dialogs designed to evaluate the
role that empathy recognition may play in generating better responses 
tuned to the feeling of the conversation partner.  Several model
set-ups, and many secondary options of the set-ups are evaluated.

Pros:

A lot of good thoughts were put into the work, and even though the techniques
tried are relatively unsophisticated, the work represents a serious attempt
on the subject and is of good reference value.

The linkage between the use of emotion supervision and better relevancy is interesting.

The dataset by itself is a good contribution to the community conducting studies in this area.

Cons:

The conclusions are somewhat fuzzy as there are too many effects
interacting, and as a result no clear cut recommendations can be made
(perhaps with the exception that ensembling a classifier model trained
for emotion recognition together with the response selector is seen
as having advantages).

There are some detailed questions that are unaddressed or unclear from
the writing.  See the Misc. items below.

Misc.

P.1, 6th line from bottom: "fro" -&gt; "from"

Table 1:  How is the "situation description" supposed to be related to the
opening sentence of the speaker?  In the examples there seems to be substantial
overlap.

Figure 2, distribution of the 32 emotion labels used:
this is a very refined set that could get blurred at the boundaries between similar emotions.
As for the creators of those dialogs,  does everyone interpret the same emotion label the same way?
e.g. angry, furious; confident, prepared; ...; will such potential ambiguities impact the work?
One way to learn more about this is to aggregate related emotions to make a coarser set,
and compare the results.

Also, often an event may trigger multiple emotions, which one the speaker chooses to focus on
may vary from person to person.  How may ignoring the secondary emotions impact the results?
To some extent this is leveraged by the prepending method (with top-K emotion predictions).
What about the other two methods?

P. 6, on using an existing emotion predictor:  does it predict the same set of emotions
that you are using in this work?

</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">7: Good paper, accept</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_B1xDLFJTiQ" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Attempting to improve chatbot responses with empathy - contributed dataset</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HyesW2C9YQ&amp;noteId=B1xDLFJTiQ"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1202 AnonReviewer1</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">24 Oct 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper1202 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">Overall this paper contributes many interesting insights into the specific application of empathetic dialog into chatbot responses.  The paper in particular is contributing its collected set of 25k empathetic dialogs, short semi-staged conversations around a particular seeded emotion and the results of various ways of incorporating this training set into a generative chatbot.

While the results clearly do not solve the problem of automating emapthy, the paper does give insights into which methods perform better than others (Generation vs Retrieval) and explicitly adding emotion predictions vs using an ensemble of encoders.

There is a lot in this paper, and I think it could have been better organized.
I am more familiar with emotion related research and not language to language translation, so I would have appreciated a better explanation of the rationale for using BLEU scores.  I did some online research to understand these Bilingual Evaluation Understudy Scores and while it seems like they measure sentence similarity, it is unclear how they capture ”relevance” at least according to the brief tutorial that I read (<a href="https://machinelearningmastery.com/calculate-bleu-score-for-text-python/)." target="_blank" rel="nofollow">https://machinelearningmastery.com/calculate-bleu-score-for-text-python/).</a>  I did not see the paper describing the use of this score in the references but perhaps I missed it – could you please clarify why this is a good metric for relevance?  It seems that these scores are very sensitive to sentence variation.  I am not sure if you can measure empathy or appropriateness of a response using this metric.
For your data collection you have 810 participants and 24,850 conversations.  Are the 810 participants all speakers or speakers and listeners combined?  How many conversations did each speaker/listener pair perform 32?  (one for each emotion) or 64? (two for each emotion) Was the number variable?  If so what is the distribution of the contribution – e.g. did one worker generate 10,000 while several hundred workers did only three of four?  Was it about even?  Just for clarity – how did you enroll participants?  Was it through AMT?  What were the criteria for the workers?  E.g. Native English speaker, etc.

In your supplemental material, I found the interchanging of the words “context” and “emotion” confusing.  The word context is used frequently throughout your manuscript: “dialog context,” “situational context” - emotions are different from situations, the situational utterance is the first utterance describing the emotion if I read your manuscript correctly.  Table 6 should use “Label” or “Emotion” instead of the more ambiguous “Context.”  

My understanding is that speakers were asked to write about a time when they experienced a particular feeling and they were given a choice of three feelings that they could write about.  You then say that workers are forced to select from contexts they had not chosen before to ensure that all of the categories were used.  From this I am assuming that each speaker/listener worker pair had to write about all 32 emotions – is this correct?  Another interpretation of this is that you asked new workers to describe situations involving feelings that had not been chosen by other workers as data collection progressed to ensure that you had a balanced data set.  This would imply that some emotional situations were less preferred and potentially more difficult to write about.  It would be interesting if this data was presented.  It might imply that some emotion labels are not as strong if people were forced to write about them rather than being able to choose to write about them.  
Were these dialogs ever actually annotated?  You state in section 2, Related Work “we train models for emotion detection on conversation data that has been explicitly labeled by annotators” – please describe how this was done.  Did independent third party annotators review the dialogs for label correctness?  Was a single rater or a majority vote used to decide the final label.  For example, in Table 1, the label “Afraid” is given to a conversation that could also have reasonable been generated by the label “Anxious” a word explicitly used in the dialog.  I am guessing that the dialogs are just labeled according to the label / provocation word and that they were not annotated beyond that, but please make this clear.  
In the last paragraph you state “A few works focus..” and then list 5.  This should rather be “several other works have focused on “ …  
Conversely, you later state in section 3 “Speaker and Listener”, “We include a few example conversations from the training data in Table 1,” this should more explicitly be “two.”
Also in section 3 when you describe your cross validation process, you state “We split the conversations into approximately 80/10/10 partitions.  To prevent overlap of &lt;&lt;discussed topics&gt;&gt; we split the data so that all the sets of conversations with the same speaker providing the prompt would be in the same partition.  
In your supplemental material you state that workers were paired.  Each worker is asked to write a prompt, which also seems to be the first utterance in the dialog they will start.  You state each worker selects one emotion word from a list of three which is somehow generated (randomly?) form your list of 32 .  I am assuming each worker in the pair does this, then the pair has a two “conversations” one where the first worker is the speaker and another where the second worker is the speaker – is this correct?  It is not entirely clear from the description. Given that you have 810 workers and 24,850 conversations, I am assuming that each worker had more than one conversation.  My question is  - did they generate a new prompt / first utterance for each conversations.  I am assuming yes since you say there are 24,850 prompts/conversations.  For each user are all of the situation/prompts they generate  describing the same emotion context?  E.g. would one worker write ~30 conversations on the same emotion.  This seems unlikely, and it seems more likely that given the number of conversations ~30 per participant is similar to the number of emotion words that you asked each worker to cycle through nearly all of the emotions or that given they were able to select, they might describe the same emotion, e.g. “fear” several times.  If the same worker was allowed to select the same emotion context multiple times was it found that they re-used the same prompt several times?  I am assuming that this is the case and that this is what you mean when you say that you “prevent overlap of discussed topics” between sets when you exclude particular workers.  Is this correct?  Or did you actually look and code the discussed topics to ensure no overlap even across workers (e.g. several people might have expressed fear of heights or fear of the dark).

In section 4, Empathetic dialog generator, you state that the dialog model has access to the situation description given by the speaker (also later called the situational prompt) but not the emotion word prompt.  Calling these both prompts makes the statement about 24,850 prompts/conversations a bit ambiguous.  A better statement would be 24,850 conversations based on unique situational prompts/descriptions (if they are in fact unique situational prompts.  I am assuming they are not if you are worried about overlapping “discussed topics” which I am assuming are the situational prompts since the dialogs are very short and heavily keyed off these initial situational prompts)

In your evaluation of the models with Human ratings you describe two sets of tests.  In one test you say you collect 100 annotations per model.  More explicitly, did you select 100 situational prompts and then ask workers to rate the response of each model?  Was how many responses was each worker shown?  How many workers were used?  Are the highlighted numbers the only significant findings or just the max scores?  Annotations is probably not the correct word here.

Please also describe your process for assigning workers to the second human ratings task.     

Since the two novel aspects of your paper are the new dataset and the use of this dataset to create more empathetic chatbot responses ("I know the feeling") I have focused on these aspects of the paper in my review.

I found the inclusion of Table 7 underexplained in the text.  The emotion labels for all these datasets are not directly comparable so I would have liked to have seen more explanation around how these classifications were compared.  It would also be helpful to know how more similar emotions such as "afraid" and "anxious" were scored vs "happy" and "sad" confusions 
</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">5: Marginally below acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">3: The reviewer is fairly confident that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></main></div>
  </div>
</div>


    <!-- Footer -->
    <footer class="sitemap">
      <div class="container">
        <div class="row hidden-xs">
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/venues">All Venues</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="/contact">Contact</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
    
        <div class="row visible-xs-block">
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/contact">Contact</a></li>
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
      </div>
    </footer>
    
    <footer class="sponsor">
      <div class="container">
        <div class="row">
          <div class="col-sm-10 col-sm-offset-1">
            <p class="text-center">
              OpenReview is created by the <a href="http://www.iesl.cs.umass.edu/" target="_blank">Information Extraction and Synthesis Laboratory</a>, College of Information and Computer Science, University of Massachusetts Amherst. We gratefully acknowledge the support of the OpenReview sponsors:  Google,  Facebook, NSF, the University of Massachusetts Amherst Center for Data Science, and Center for Intelligent Information Retrieval, as well as the Google Cloud Platform for donating the computing and networking services on which OpenReview.net runs.
            </p>
          </div>
        </div>
      </div>
    </footer>

  <div id="feedback-modal" class="modal fade" tabindex="-1" role="dialog">
    <div class="modal-dialog">
      <div class="modal-content">
        <div class="modal-header">
          <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button>
          <h3 class="modal-title">Send Feedback</h3>
        </div>
        <div class="modal-body">
          <p>Enter your feedback below and we'll get back to you as soon as possible.</p>
          <form action="/feedback" method="POST">
            <div class="form-group">
              <input type="email" name="from" class="form-control" placeholder="Email" />
            </div>
            <div class="form-group">
              <input type="text" name="subject" class="form-control" placeholder="Subject" />
            </div>
            <div class="form-group">
              <textarea name="message" class="form-control feedback-input" rows="5" placeholder="Message" required=""></textarea>
            </div>
          <ul id="ui-id-2" tabindex="0" class="ui-menu ui-widget ui-widget-content" style="display: none;"></ul></form>
        </div>
        <div class="modal-footer">
          <button type="button" class="btn btn-default" data-dismiss="modal">Cancel</button>
          <button type="button" class="btn btn-primary">Send</button>
        </div>
      </div>
    </div>
  </div>

  <script type="text/javascript" async="" src="https://www.google-analytics.com/analytics.js"></script><script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js"></script>
  <script>window.jQuery || document.write('&lt;script src="/static/js/vendor/jquery-2.2.4.min.js"&gt;&lt;\/script&gt;')</script>

  <script src="/static/dist/vendor.min.js"></script>
  <script src="/static/dist/templates.min.js"></script>
  <script src="/static/dist/openreview.min.js"></script>

    <script>window.legacyScripts = true;</script>


    <script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-108703919-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() { dataLayer.push(arguments); }
      gtag('js', new Date());
      gtag('config', 'UA-108703919-1');
    </script>


<div role="status" aria-live="assertive" aria-relevant="additions" class="ui-helper-hidden-accessible"></div></body></html>
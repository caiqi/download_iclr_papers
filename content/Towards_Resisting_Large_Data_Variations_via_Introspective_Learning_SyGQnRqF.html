<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" class="no-js"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>Towards Resisting Large Data Variations via Introspective Learning | OpenReview</title>
  <meta name="description" content="" />

      <meta name="citation_title" content="Towards Resisting Large Data Variations via Introspective Learning" />
        <meta name="citation_author" content="Yunhan Zhao" />
        <meta name="citation_author" content="Ye Tian" />
        <meta name="citation_author" content="Wei Shen" />
        <meta name="citation_author" content="Alan Yuille" />
      <meta name="citation_publication_date" content="2018/09/27" />
      <meta name="citation_online_date" content="2018/09/27" />
      <meta name="citation_pdf_url" content="https://openreview.net/pdf?id=SyG1QnRqF7" />
      <meta name="twitter:card" content="summary" />
      <meta name="twitter:site" content="@openreviewnet" />
      <meta name="og:title" content="Towards Resisting Large Data Variations via Introspective Learning" />
      <meta name="og:description" content="Learning deep networks which can resist large variations between training andtesting data is essential to build accurate and robust image classifiers.  Towardsthis end, a typical strategy is to..." />
      <meta name="og:image" content="https://openreview.net/static/images/openreview_logo_512.png" />

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans:400,400i,700,700i" />

  <link rel="stylesheet" href="/static/css/bootstrap.min.css" />
  <link rel="stylesheet" href="/static/css/jquery-ui.min.css" />
  <link rel="stylesheet" href="/static/css/main.min.css" />
</head>

<body class="forum">
  <nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
  
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand home push-link" href="/"><strong>OpenReview</strong>.net</a>
      </div>
  
      <div id="navbar" class="navbar-collapse collapse">
        <form class="navbar-form navbar-left profile-search" role="search">
          <div class="form-group has-feedback">
            <input id="search_input" type="text" class="form-control ui-autocomplete-input" placeholder="Search ICLR 2019 Conference" autocomplete="off" />
            <span class="glyphicon glyphicon-search form-control-feedback" aria-hidden="true"></span>
          </div>
  
          <input id="search_group" type="hidden" value="ICLR.cc/2019/Conference" />
          <input id="search_content" type="hidden" value="all" />
        <ul id="ui-id-1" tabindex="0" class="ui-menu ui-widget ui-widget-content ui-autocomplete ui-front" style="display: none;"></ul></form>
  
        <ul class="nav navbar-nav navbar-right">
        
            <li id="user-menu"><a href="/login">Login</a></li>
        </ul>
      </div>
  
    </div>
  </nav>

  <div id="or-banner" class="banner" style="">
  <div class="container">
    <div class="row">
      <div class="col-xs-12"><a href="/group?id=ICLR.cc/2019/Conference" title="Venue Homepage"><img class="icon" src="/static/images/arrow_left.svg" /> Go to <strong>ICLR 2019 Conference</strong> homepage</a></div>
    </div>
  </div>
</div>
<div id="flash-message-container" class="alert alert-danger" role="alert" style="display: none;">
  <div class="container">
    <div class="row">
      <div class="col-xs-12">
        <div class="alert-content">
          <button type="button" class="close" aria-label="Close"><span aria-hidden="true">×</span></button>
        </div>
      </div>
    </div>
  </div>
</div>

<div class="container">
  <div class="row">
    <div class="col-xs-12">
      <main id="content" class="clearfix openbanner-visible legacy-styles"><div id="note_SyG1QnRqF7" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Towards Resisting Large Data Variations via Introspective Learning</a> <a class="note_content_pdf" href="/pdf?id=SyG1QnRqF7" title="Download PDF" target="_blank"><img src="/static/images/pdf_icon_blue.svg" /></a> </h2></div><div class="meta_row"><span class="signatures"><a href="/profile?email=yzhao83%40jhu.edu" class="profile-link" data-toggle="tooltip" data-placement="bottom" title="" data-original-title="yzhao83@jhu.edu">Yunhan Zhao</a>, <a href="/profile?email=tytian%40outlook.com" class="profile-link" data-toggle="tooltip" data-placement="bottom" title="" data-original-title="tytian@outlook.com">Ye Tian</a>, <a href="/profile?email=shenwei1231%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="bottom" title="" data-original-title="shenwei1231@gmail.com">Wei Shen</a>, <a href="/profile?email=alan.l.yuille%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="bottom" title="" data-original-title="alan.l.yuille@gmail.com">Alan Yuille</a></span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">28 Sep 2018 (modified: 20 Nov 2018)</span><span class="item">ICLR 2019 Conference Withdrawn Submission</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Abstract: </span><span class="note_content_value">Learning deep networks which can resist large variations between training andtesting data is essential to build accurate and robust image classifiers.  Towardsthis end, a typical strategy is to apply data augmentation to enlarge the trainingset.   However,  standard  data  augmentation  is  essentially  a  brute-force  strategywhich is inefficient,  as it performs all the pre-defined transformations  to everytraining sample. In this paper, we propose a principled approach to train networkswith  significantly  improved  resistance  to  large  variations  between  training  andtesting data.  This is achieved by embedding a learnable transformation moduleinto the introspective networks (Jin et al., 2017; Lazarow et al., 2017; Lee et al.,2018), which is a convolutional neural network (CNN) classifier empowered withgenerative capabilities.  Our approach alternatively synthesizes pseudo-negativesamples with learned transformations and enhances the classifier by retraining itwith synthesized samples.  Experimental results verify that our approach signif-icantly improves the ability of deep networks to resist large variations betweentraining and testing data and achieves classification accuracy improvements onseveral benchmark datasets, including MNIST, affNIST, SVHN and CIFAR-10.</span></div><div class="note_contents"><span class="note_content_field">Keywords: </span><span class="note_content_value">Introspective learning, Large variations resistance, Image classification, Generative models</span></div><div class="note_contents"><span class="note_content_field">TL;DR: </span><span class="note_content_value">We propose a principled approach that endows classifiers with the ability to resist larger variations between training and testing data in an intelligent and efficient manner.</span></div><div class="reply_row clearfix"><div class="item" id="reply_count">11 Replies</div></div></div><hr class="small" /><div id="note_children"><div class="note_with_children"><div id="note_Byea_J-aT7" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Submission Withdrawn by the Authors</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=SyG1QnRqF7&amp;noteId=Byea_J-aT7"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1321 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">17 Nov 2018</span><span class="item">ICLR 2019 Conference Paper1321 Withdraw Submission</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Withdrawal confirmation: </span><span class="note_content_value">I have read and agree with the withdrawal statement on behalf of myself and my co-authors.</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_HkeEoT3fTm" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Interesting idea, but the novel contributions are unclear and experimental results don't seem to match earlier published results</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=SyG1QnRqF7&amp;noteId=HkeEoT3fTm"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1321 AnonReviewer4</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">09 Nov 2018</span><span class="item">ICLR 2019 Conference Paper1321 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">This paper proposes a way to use generative modeling (specifically, introspective learning) to handle data variations at test time. 

While the proposed idea is interesting, many of the core ideas seem to have been proposed in earlier work (Jin et al., 2017; Lazarow et al., 2017; Lee et al., 2018) and the novel contributions of this work are not clearly explained. It would be useful to split Section 3 into background section which reviews prior work and a section which describes the proposed idea and how it differs from prior work. 

Experiments: 
- The performance numbers in Table 1 seem quite far from the earlier published results. For instance, the ICN paper reports 6.5% test error on CIFAR and 1.9% test error on SVHN, which are much lower than the results reported in this paper 
<a href="https://papers.nips.cc/paper/6684-introspective-classification-with-convolutional-nets.pdf." target="_blank" rel="nofollow">https://papers.nips.cc/paper/6684-introspective-classification-with-convolutional-nets.pdf.</a> It would be better to similar architectures as the original paper for a fair comparison.


Other comments:
- Section 3: it might be worth making a distinction between the two notions in which generative versus discriminative methods are discussed (i) using a discriminative binary classifier within a generative model and (ii) using the classifier that predicts class labels (e.g. the 10 classes in MNIST). 
- The extension to multi-class problems is only briefly discussed in page 4. Which version (series of one-vs-all or a single CNN classifier) is used in the experiments?  What's the computational complexity and how would it scale with the number of classes?
- The semi-supervised learning results only discuss GAN-based methods, but there are a lot of VAE-based methods (cf. https://arxiv.org/abs/1406.5298) that would be worth discussing too
- I think it’s a bit confusing to label the methods "WGAN-GP", "DCGAN" as these methods uses both CNN for classifier in addition to the generative part.
</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">4: Ok but not good enough - rejection</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_SklcaEjnp7" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Response to AnonReviewer4 (Part 1/2)</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=SyG1QnRqF7&amp;noteId=SklcaEjnp7"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1321 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">17 Nov 2018</span><span class="item">ICLR 2019 Conference Paper1321 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">We thank the AnonReviewer4 for the feedback, however, we respectfully disagree with the comments about our novelty. Detailed responses to each specific concerns are enclosed below. We use &gt; to denote each questions/concerns.

&gt; Core ideas seem to have been proposed in earlier work (Jin et al., 2017; Lazarow et al., 2017; Lee et al., 2018) and the novelty is not clear

There are clear differences between introspective papers and ITN. ITN is built upon any generative models with discriminative abilities. We adopt introspective learning only for the purpose of generating samples in our work. Therefore, we disagree with the opinion that the core ideas are similar between ITN and other introspective papers. 

Our contribution is clear since ITN focuses on addressing the large variations between training and testing data. ITN works in a similar way as data augmentation, however, data augmentation is an exhaustively searching method. ITN forms a natural min-max problem that searches samples more efficiently and effectively than standard data augmentation. 

&gt; Experiment performance is lower than reported in the ICN paper

The purpose of this work is not to beat STOA performance. Our goal is to show that ICN has the ability to resist large variations between training and testing data. We test ICN and ITN with the same shallow network to evaluate the ability of ITN, which we believe is absolutely a fair comparison.

We replicated the experiment in table 1 with ResNet 32 to align with the settings in ICN as AnonReviewer4 requested. 

				                w/o DA	                           | | 		   w/ DA	
                       | MNIST | affNIST | SVHN | CIFAR-10 | | MNIST | affNIST | SVHN | CIFAR-10 |

ResNet-32        0.45%   |  1.16% | 4.64% | 12.38%  | |   0.36%  |  0.75%  |  4.03% |  7.51%  |

DCGAN +         0.43%   |  1.08% | 4.63% | 11.97%  | |   0.33%  |  0.71%  |  3.87% |  7.17%  |
ResNet 32

WGAN-GP +     0.41%   |  1.02% | 4.61% | 11.83%  | |   0.31%  |  0.67%  |  3.81% |  7.05%  |
ResNet 32

ICN +                0.44%   |  0.98% | 4.57% | 11.46%  | |   0.32%  |  0.56%  |  3.76% |  6.70%  |
ResNet 32

WINN +             0.48%   |  0.93% | 4.50% | 10.54%  | |   0.29%  |  0.53%  |  3.68% |  6.43%  |
ResNet 32

ITN +                 0.27%  |  0.44% | 3.54%  |  7.38%  | |  0.24%  |  0.42%  |  3.40% |  5.94%  |
ResNet 32

As shown in the table above, ITN has constantly better performance than other methods. We hope this results can address the concern of fair comparisons.</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_H1eAZSs3a7" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Response to AnonReviewer4 (Part 2/2)</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=SyG1QnRqF7&amp;noteId=H1eAZSs3a7"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1321 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">17 Nov 2018</span><span class="item">ICLR 2019 Conference Paper1321 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">&gt; Section 3: it might be worth making a distinction between the two notions in which generative versus discriminative methods are discussed (i) using a discriminative binary classifier within a generative model and (ii) using the classifier that predicts class labels (e.g. the 10 classes in MNIST).

We're not quite clear what’s the meaning of this question but we assume that the reviewer suggests us to also have a separate mathematical formula for the case of multi-class setting. 

Since we adopt the introspective learning, the ways to expand this work from binary to multi-class follows the same strategy as ICN. We thank the reviewer for this suggestion but we think it’s not necessary to repeat the same strategy demonstrated in ICN. 

&gt; The extension to multi-class problems is only briefly discussed in page 4. Which version (series of one-vs-all or a single CNN classifier) is used in the experiments?  What's the computational complexity and how would it scale with the number of classes?

All the experiments are using the single CNN classifiers setting, which adopts a softmax layer at the end. The computational complexity of ITN is O(nm), where n is the number of classes and m is the number of samples within each class. The computational complexity scales up linearly when the number of classes increases. 

&gt; Semi-supervised learning results only discuss GAN-based methods

We emphasize that there are no semi-supervised experiments in our paper! We are not sure what causes Reviewer 4 has the same misunderstanding as Reviewer 3 but we will try to revise the paper to make it more clear. As Reviewer 4 didn’t point out which results are semi-supervised learning results, we assume that Reviewer 4 also refers to the experiments in Table 3 as Reviewer 3. 

As we clearly described in the paper, the experiments in Table 3 are conducted with reduced training samples and full testing data. In other words, the 0.1%(M) means the training data is 0.1% of the entire training data of MNIST and the testing data set is the whole MNIST testing data. The purpose of this experiment is to implicitly increase the variations between the training and testing data by reducing the number of samples in the training data. We are not sure why Reviewer 4 suggested comparing with VAE-based semi-supervised methods.

&gt; label the methods "WGAN-GP", "DCGAN" as these methods uses both CNN for classifier in addition to the generative part.

We will revise the method names in the table accordingly to make them more clear, Thanks for the suggestions.
</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div></div></div><div class="note_with_children"><div id="note_SJlQKiZGT7" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Good discussion, improved comparisons needed</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=SyG1QnRqF7&amp;noteId=SJlQKiZGT7"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1321 AnonReviewer2</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">09 Nov 2018</span><span class="item">ICLR 2019 Conference Paper1321 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">This paper suggests the use of learned transformation networks, embedded within introspective networks to improve classification performance with synthesized examples.

The authors cite a number of related works, and give a good introduction to both introspective learning, as well as the particular usage for large variation resistance. This discussion forms the majority of the paper, and while the explanation seems clear it would be nice to have a stronger dedicated section on exact relations to both GAN and potentially VAE mathematically. Any kind of discussion which could tie the thorough derivation to some of the contemporaries in generative modeling would help the accessibility of the paper.

My primary concerns are from the experimental sections of the paper. The setup of the problem seems such that any strong baseline could be directly tested, since the final CNN is ultimately trained in a two stage setup on the aggregated dataset (as per subsection Baselines). Here it is also worth mentioning DAgger <a href="https://ri.cmu.edu/pub_files/2010/5/Ross-AIStats10-paper.pdf" target="_blank" rel="nofollow">https://ri.cmu.edu/pub_files/2010/5/Ross-AIStats10-paper.pdf</a> / https://www.cs.cmu.edu/~sross1/publications/Ross-AIStats11-NoRegret.pdf which is used in another context but in a similar way for improving imitation and online learning. 

Many of the baseline methods for table 1 seem far from what I would consider "strong" baselines. Given that the core proposal of the paper is improving classifiers, the importance of having high quality baselines cannot be overstated. Particularly, baseline CNN numbers for MNIST, SVHN, and CIFAR-10 are far from what has been seen in simple papers such as Wide ResNet https://arxiv.org/abs/1605.07146, ResNet https://arxiv.org/abs/1512.03385, Universum Perscription (which bears some resemblence to this work in high level concept) https://arxiv.org/abs/1511.03719, or even older work such as Maxout Networks http://proceedings.mlr.press/v28/goodfellow13.pdf . Particularly, these papers show examples of simple CNNs which outscore the best values reported in this table, on the same datasets. Running the same setup but with these improved classifiers as baselines would make a much stronger support for the core hypothesis that ITN can be used to improve strong classifiers.

Table 2 seems to me an improper comparison. Methods such as zero-shot or meta-learning type approaches seem much more appropriate for testing cross-generalization improvement. In some sense, none of the tested methods besides ITN should even be able to cross-generalize well, so the fact that ITN does better here is not surprising to me. While this is a benefit of ITN as stated, seeing a comparison to methods deisgned for cross-generalization as well would make the results of Table 2 much stronger.

Table 3 also seems have improper comparisons, in that there are a large number of works using semi-supervised generative models (Improved Techniques for Training GANS, which is already cited, SS-VAE https://arxiv.org/abs/1406.5298, Temporal Ensembling https://arxiv.org/abs/1610.02242, VAT https://ieeexplore.ieee.org/abstract/document/8417973/, Ladder Networks http://papers.nips.cc/paper/5947-semi-supervised-learning-with-ladder-networks, Auxiliary Deep Generative Models https://arxiv.org/abs/1602.05473, Manifold Tangent Classifier https://papers.nips.cc/paper/4409-the-manifold-tangent-classifier) for improved classification in low data domains. Adopting the same settings and comparing directly to these methods would greatly strengthen this section as well, as simple classifiers (as shown in many of these previous papers) are not generally great baselines for semi-supervised modeling.

In addition, there should be a direct case where becoming robust to these kinds of transformations fails. For example, if my classification task is the rotation/position of a repositioned MNIST digit, becoming robust to these types of transformations may be harmful. An experiment or discussion about when robustness to large data variation might be harmful would be a good inclusion as well. As a more general comment, this method seems applicable outside of image domains, and it would be interesting to see it applied in other settings though it is likely outside the scope of this particular paper.

Formatting of the paper (specifically spacing between sections and subsections) seems a bit off in general. If the authors are applying /vspace tricks to shrink spaces in the format, I would recommend taking a closer look at how and where, to make spacing more consistent over the whole document. Comparing to past ICLR papers (best papers, or high rated from past conferences) to see how they approach formatting could improve the visual appeal of this paper.

Overall, this paper has a lot in its favor. The experimental section is thorough, if not as strong as I would like. The derivation of the method and motivation is clear, and there are a lot of avenues explored. However, as it currently stands the experimental sections should be stronger to really prove out the core claim "Our method, ITN strengthens the classifiers by generating unseen variations with various learned transformations." compared to other methods using generative and semi-supervised methods in a similar vein. In addition, the clarity and approachability of the paper could be improved by drawing a relation to parallel related work such as GAN or VAE in more detail.</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">5: Marginally below acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_Hygb9xiha7" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Response to AnonReviewer2 (Part 1/2)</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=SyG1QnRqF7&amp;noteId=Hygb9xiha7"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1321 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">17 Nov 2018</span><span class="item">ICLR 2019 Conference Paper1321 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">We thank the AnonReviewer2 for the feedback, however, we respectfully disagree with the comments about our experiment section. We believe the AnonReviewer2 misunderstands the purpose and the motivation of our experiment section. Our experiment sections are carefully organized as the following:

We first demonstrate the performance of our method on benchmark dataset under standard setup, which shows our method has good classification ability. 

Then, we show that our method works well when the variations between training and testing data are significantly large from two prospective. First, we increase the variations in the testing data to create large variations between training and testing data, i.e., using different datasets for training and testing (Table 2). Second, we decrease the number of training samples, which implicitly decreases the existing variations in the training data to create large variations between training and testing data (Table 3). 

Lastly, we show the flexibility of our approach by substituting the spatial transformation with other transformation functions. More importantly, we demonstrate that our approach works well when the variations in testing data are unknown and ITN won’t cause any harmful effect to the classifiers. (see ITN(DDT + ST) + MNIST(DDT) and ITN(DDT) + MNIST(DDT) results.)

Detailed responses to each specific concerns are enclosed below. We use &gt; to denote each questions/concerns.

&gt; Mathematical connection to GAN and potential VAE

A: As stated in our paper, our approach can work with any models that have generative and discriminative abilities. GANs can be integrated into our framework since GANs have distinct generators and discriminators. VAEs do not have the discriminative ability, therefore we don’t think VAE match with our settings. 

Applying GANs to our approach follows the same intuition as the introspective learning. The generators are trying to capture the transformed true samples while the discriminators are supposed to correctly classify the true samples, generated samples and transformed true samples. We’ll add the details of the mathematical formula of applying GANs to our approach in the appendix. 

&gt; Here it is also worth mentioning DAgger, which is used in another context but in a similar way for improving imitation and online learning

A: Imitation learning, which aims at addressing sequential decision making problems, such as self-driving, is closely related to reinforcement learning, We do not think there is a connection between the problem setup of imitation learning and ours.

&gt; The baseline methods in Table 1 are not strong enough.

A: The purpose of this paper is not to pursue the STOA classification results on these benchmark dataset. Our goal is to address the larger variations between training and testing data and make the classifiers robust to the unseen variations with the generated samples. Therefore, our comparisons are always between the same classifiers with and without ITN, regardless of the depth of the networks.

Even though completely unnecessary, we still respect the concerns from the reviewer. Therefore, we replicate the experiments in Table 1 with ResNet to address this concern. Our results are shown below:

				 w/o DA	                                           | | 		   w/ DA	
                       | MNIST | affNIST | SVHN | CIFAR-10 | | MNIST | affNIST | SVHN | CIFAR-10 |

ResNet-32        0.45%   |  1.16% | 4.64% | 12.38%  | |   0.36%  |  0.75%  |  4.03% |  7.51%  |

DCGAN +         0.43%   |  1.08% | 4.63% | 11.97%  | |   0.33%  |  0.71%  |  3.87% |  7.17%  |
ResNet 32

WGAN-GP +     0.41%   |  1.02% | 4.61% | 11.83%  | |   0.31%  |  0.67%  |  3.81% |  7.05%  |
ResNet 32

ICN +                0.44%   |  0.98% | 4.57% | 11.46%  | |   0.32%  |  0.56%  |  3.76% |  6.70%  |
ResNet 32

WINN +             0.48%   |  0.93% | 4.50% | 10.54%  | |   0.29%  |  0.53%  |  3.68% |  6.43%  |
ResNet 32

ITN +                 0.27%  |  0.44% | 3.54%  |  7.38%  | |  0.24%  |  0.42%  |  3.40% |  5.94%  |
ResNet 32

As shown in this table, our method has no trouble deploying to deep networks. We hope this table is sufficient to address this concern. 

</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_HylUvbj2p7" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Response to AnonReviewer2 (Part 2/2) </a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=SyG1QnRqF7&amp;noteId=HylUvbj2p7"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1321 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">17 Nov 2018</span><span class="item">ICLR 2019 Conference Paper1321 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">&gt; The comparisons in Table 2 are improper since “other methods in Table 2 can’t handle cross dataset generalization”

A: The reviewer suggests to compare to meta-learning and zero-shot approaches, which are not quite appropriate from our perspective. We believe the reviewer might misunderstand the purpose of the experiment in Table 2.

First of all, we believe other methods in Table 2 are very fair comparisons considering the training and testing data that we carefully chose. The training data in Table 2 is MNIST and the testing data is affNIST. Based on the affNIST website [1], this dataset is produced by applying various data augmentation to the MNIST dataset. Even though the training and testing samples are from “different dataset”, we believe it’s reasonable to consider the training and testing samples are from the same underlying distribution, just like other datasets. From this perspective, the only difference between the MNIST experiments in Table 1 and the experiments in Table 2 is that the testing data of the latter one contains more variations. 

Besides, note that we also introduce data augmentation to other methods in Table 2. Under data augmentation, the gap between training and testing data is significantly reduced (consider how affNIST is built), thus we believe the claim from the reviewer that other methods in Table 2 have no ability to cross-generalize well doesn’t hold. 

Second, comparing to meta learning and zero-shot learning is also infeasible with given dataset and experiment settings. Meta-learning is also known as learning to learn, which learns the model through a sequence of tasks. Meta learning is normally tested on the dataset with large number of classes (Omniglot and mini-ImageNet) to prove the ability to adapt to new classes.  Zero-shot learning also has distinct settings compared to ours. Zero-shot learning transfers the semantic knowledge to the unknown classes, which always involves text in their dataset. Therefore, based our knowledge, comparing against meta-learning and zero-shot learning is far from the purpose of our experiment.

&gt; The reviewer suggests adopting settings of semi-supervised generative models and compare against them.

A: We are not quite sure why this reviewer wants us to do comparison under semi-supervised learning settings. The purpose of Table 3 is to show the ability of ITN in resisting variations between training and testing data. The experiments in Table 3 are conducted with reduced training data and the whole testing data. In other words, the 0.1%(M) means the training data is 0.1% of the entire training data of MNIST and the testing data set is the whole MNIST testing data. It is not a semi-supervised learning setting at all.

The purpose of this experiment is to implicitly increase the variations between the training and testing data by reducing the number of samples in the training data. We do not think introducing unlabeled data can achieve this purpose. Thus, we are not quite clear why the reviewer suggests comparing against semi-supervised methods, even though our motivation for Table 3 is already clearly demonstrated in our paper.

&gt; The reviewer thought there should be a direct case where becoming robust to these kinds of transformations fails.

A: We respectfully disagree with this opinion. Since ITN generates different transformations in every iteration, it avoids over-reliance of a particular transformation. Moreover, according to the result in Table 4, it is unlikely to have such a case. We have experimental results that our transformation function contains more types of transformations than transformations in the test data, e.g. ITN (DDT + ST) on MNIST (DDT) dataset. In this case, the performance of ITN (DDT + ST) should drop compared with ITN (DDT) on MNIST(DDT) if the reviewer’s opinion were correct, because there are extra type of transformations that might be “harmful” to the classifiers. To the contrary,  the performance of ITN (DDT + ST) is better than ITN (DDT) on  MNIST (DDT). 

&gt; Formatting of the paper should be more clear
We’ll revise the format of the paper accordingly and we thank the reviewer for the kindly reminder.

[1] <a href="https://www.cs.toronto.edu/~tijmen/affNIST/" target="_blank" rel="nofollow">https://www.cs.toronto.edu/~tijmen/affNIST/</a>
</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_r1xcQNj2TX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>It's not about SOTA</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=SyG1QnRqF7&amp;noteId=r1xcQNj2TX"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1321 AnonReviewer2</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">17 Nov 2018</span><span class="item">ICLR 2019 Conference Paper1321 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">I will reply in more detail later, but wanted to be crystal clear about something.

It's not about SOTA.

The fundamental claim from your abstract is "Experimental results verify that our approach significantly improves the ability of deep networks [...] achieves classification accuracy improvements onseveral benchmark datasets, including MNIST, affNIST, SVHN and CIFAR-10." . Without moderately strong benchmarks and comparisons, it is not possible to evaluate that portion of your methodology.

SOTA is *not necessary*, but to evaluate a claim of fundamental improvement, it should start from somewhere reasonably high-performing, using the best known "communal knowledge" for such networks. Showing an improvement  then *clearly* demonstrates the claim as stated in the abstract (and not just hyperparameter tuning or other practical matters about training these networks).</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_r1gpPshn67" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Thanks for your clarification</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=SyG1QnRqF7&amp;noteId=r1gpPshn67"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1321 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">17 Nov 2018</span><span class="item">ICLR 2019 Conference Paper1321 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">We thank the AnonReviewer2 for the quick response and clarification.

We agree with the Reviewer to evaluate the methodology based on reasonable high performance on the benchmark datasets. As we initially design this experiment, we consider our method as a general model that integrates with any classifiers, regardless of the depth. Therefore, our concern is whether we can outperform other methods under the same networks, instead of how much we outperform.

That's the fundamental motivation why we use the shallow network in Table 1 and evaluate the performance of each method. Another reason is that we still have datasets like MNIST, affNIST that already saturates even under shallow networks. To keep it consistent, we just adopt a shallow network for the purpose of computational efficiency. If this is really a significant concern for the Reviewer, we respect this concern and replicate our experiment with ResNet-32. The results are shown in the previous response. </span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div></div></div></div></div></div></div><div class="note_with_children"><div id="note_BJllpCBA2m" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>This paper builds on top introspective learning to bridge the gap between training and test set distributions. Overall, it is an interesting paper showing significant better performance results with and without existing data augmentation.</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=SyG1QnRqF7&amp;noteId=BJllpCBA2m"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1321 AnonReviewer3</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">06 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper1321 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">This paper proposes to combine the generative capabilities of introspection networks with geometric transformations in order to augment the dataset for training image based classifiers.  The paper is well written and shows promising results on standard datasets, (albeit the SVHN and cifar-10 results are not near STOA).

- There are a few areas where the writing could be more clear: \omega_t is introduced right after equation 5, but it is unclear what is that parameter. Is it the parameter of a separate f_t(x;\omega_t) function used to generate the pseudo-negative examples?  Equation 5 is also confusion with f_t conditioned on both \theta_t and \omega_t.

- How does the data-argumentation's parameter range compare to the learned \sigma and g(.), does g(.) learn significantly different/bigger transformations?

- Regarding computation time, how long does it takes to generate the augmented data set using the proposed method? Do you have to keep a series of f_t in-order to transform the pseudo-negative points (equation 12)?


</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">6: Marginally above acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">3: The reviewer is fairly confident that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_B1xcMyo3TX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Response to AnonReviewer3</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=SyG1QnRqF7&amp;noteId=B1xcMyo3TX"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1321 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">17 Nov 2018</span><span class="item">ICLR 2019 Conference Paper1321 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">We thank the reviewers and the commentators for their feedback, clarifications of your comments are enclosed below. We use &gt; to denote each questions/concerns.

&gt; The experiment results are not near STOA

A: The purpose of our paper is not to pursue STOA performance on these benchmark dataset, such as SVHN and CIFAR-10. Our purpose is to improve the resistance of deep networks to large variations between training and testing data. Therefore, we only use 5 layers shallow network to demonstrate the effectiveness of our method. The performance of ITN will increase when we adopt deeper network architectures.

&gt; There are a few areas where the writing could be more clear: \omega_t is introduced right after equation 5, but it is unclear what is that parameter. Is it the parameter of a separate f_t(x;\omega_t) function used to generate the pseudo-negative examples?  Equation 5 is also confusion with f_t conditioned on both \theta_t and \omega_t.

A: The \omega_t in the Equation 5 is not the parameter of a separate f_t(x;\omega_t) function used to generate the pseudo-negative examples, but the parameter to compute the Wasserstein distance based on the output of function f_t(x; \theta_t). We will revise the paper to make this part more clear.

&gt; How does the data-augmentation’s parameter range compare to the learned \sigma and g(.), does g(.) learn significantly different/bigger transformations?

A: Since we performed standard data augmentation in experiments, theoretically, the range of data augmentation parameters is equivalent to the learned \sigma. The function g(.) not necessarily finds the significantly different/bigger transformation, however, g(.) finds the transformation parameters which make transformed sample hard to recognize by the current classifier to recognize (shown in Eqn. 8). 

&gt; How long it takes to generate the augmented data set using the proposed method? Do you have to keep a series of f_t to transform pseudo-negative points?

A: The computational time of ITN is slightly longer than the pure discriminative methods due to the searching and generation. For ITN, on MNIST dataset, each epoch takes about 35s using single NVIDIA TITAN V. Inside each epoch, it takes 15s to generate all the pseudo-negative points. In comparison, the pure discriminative method takes about 10s for each epoch.

As we stated in the paper, there is no need to store a series of f_t to generate pseudo-negative points in practice. For the purpose of memory efficiency, we generate pseudo-negative points at iteration t, S_t with pseudo-negative points at iteration t-1, S_{t-1} and f_t.
</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div></div></main></div>
  </div>
</div>


    <!-- Footer -->
    <footer class="sitemap">
      <div class="container">
        <div class="row hidden-xs">
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/venues">All Venues</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="/contact">Contact</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
    
        <div class="row visible-xs-block">
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/contact">Contact</a></li>
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
      </div>
    </footer>
    
    <footer class="sponsor">
      <div class="container">
        <div class="row">
          <div class="col-sm-10 col-sm-offset-1">
            <p class="text-center">
              OpenReview is created by the <a href="http://www.iesl.cs.umass.edu/" target="_blank">Information Extraction and Synthesis Laboratory</a>, College of Information and Computer Science, University of Massachusetts Amherst. We gratefully acknowledge the support of the OpenReview sponsors:  Google,  Facebook, NSF, the University of Massachusetts Amherst Center for Data Science, and Center for Intelligent Information Retrieval, as well as the Google Cloud Platform for donating the computing and networking services on which OpenReview.net runs.
            </p>
          </div>
        </div>
      </div>
    </footer>

  <div id="feedback-modal" class="modal fade" tabindex="-1" role="dialog">
    <div class="modal-dialog">
      <div class="modal-content">
        <div class="modal-header">
          <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button>
          <h3 class="modal-title">Send Feedback</h3>
        </div>
        <div class="modal-body">
          <p>Enter your feedback below and we'll get back to you as soon as possible.</p>
          <form action="/feedback" method="POST">
            <div class="form-group">
              <input type="email" name="from" class="form-control" placeholder="Email" />
            </div>
            <div class="form-group">
              <input type="text" name="subject" class="form-control" placeholder="Subject" />
            </div>
            <div class="form-group">
              <textarea name="message" class="form-control feedback-input" rows="5" placeholder="Message" required=""></textarea>
            </div>
          <ul id="ui-id-2" tabindex="0" class="ui-menu ui-widget ui-widget-content" style="display: none;"></ul></form>
        </div>
        <div class="modal-footer">
          <button type="button" class="btn btn-default" data-dismiss="modal">Cancel</button>
          <button type="button" class="btn btn-primary">Send</button>
        </div>
      </div>
    </div>
  </div>

  <script type="text/javascript" async="" src="https://www.google-analytics.com/analytics.js"></script><script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js"></script>
  <script>window.jQuery || document.write('&lt;script src="/static/js/vendor/jquery-2.2.4.min.js"&gt;&lt;\/script&gt;')</script>

  <script src="/static/dist/vendor.min.js"></script>
  <script src="/static/dist/templates.min.js"></script>
  <script src="/static/dist/openreview.min.js"></script>

    <script>window.legacyScripts = true;</script>


    <script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-108703919-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() { dataLayer.push(arguments); }
      gtag('js', new Date());
      gtag('config', 'UA-108703919-1');
    </script>


<div role="status" aria-live="assertive" aria-relevant="additions" class="ui-helper-hidden-accessible"></div></body></html>
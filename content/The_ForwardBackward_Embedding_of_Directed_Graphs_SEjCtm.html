<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" class="no-js"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>The Forward-Backward Embedding of Directed Graphs | OpenReview</title>
  <meta name="description" content="" />

      <meta name="citation_title" content="The Forward-Backward Embedding of Directed Graphs" />
        <meta name="citation_author" content="Anonymous" />
      <meta name="citation_publication_date" content="2018/09/27" />
      <meta name="citation_online_date" content="2018/09/27" />
      <meta name="citation_pdf_url" content="https://openreview.net/pdf?id=S1E64jC5tm" />
      <meta name="twitter:card" content="summary" />
      <meta name="twitter:site" content="@openreviewnet" />
      <meta name="og:title" content="The Forward-Backward Embedding of Directed Graphs" />
      <meta name="og:description" content="We introduce a novel embedding of directed graphs derived from the singular value decomposition (SVD) of the  normalized adjacency matrix. Specifically, we show that, after proper normalization of..." />
      <meta name="og:image" content="https://openreview.net/static/images/openreview_logo_512.png" />

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans:400,400i,700,700i" />

  <link rel="stylesheet" href="/static/css/bootstrap.min.css" />
  <link rel="stylesheet" href="/static/css/jquery-ui.min.css" />
  <link rel="stylesheet" href="/static/css/main.min.css" />
</head>

<body class="forum">
  <nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
  
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand home push-link" href="/"><strong>OpenReview</strong>.net</a>
      </div>
  
      <div id="navbar" class="navbar-collapse collapse">
        <form class="navbar-form navbar-left profile-search" role="search">
          <div class="form-group has-feedback">
            <input id="search_input" type="text" class="form-control ui-autocomplete-input" placeholder="Search ICLR 2019 Conference" autocomplete="off" />
            <span class="glyphicon glyphicon-search form-control-feedback" aria-hidden="true"></span>
          </div>
  
          <input id="search_group" type="hidden" value="ICLR.cc/2019/Conference" />
          <input id="search_content" type="hidden" value="all" />
        <ul id="ui-id-1" tabindex="0" class="ui-menu ui-widget ui-widget-content ui-autocomplete ui-front" style="display: none;"></ul></form>
  
        <ul class="nav navbar-nav navbar-right">
        
            <li id="user-menu"><a href="/login">Login</a></li>
        </ul>
      </div>
  
    </div>
  </nav>

  <div id="or-banner" class="banner" style="">
  <div class="container">
    <div class="row">
      <div class="col-xs-12"><a href="/group?id=ICLR.cc/2019/Conference" title="Venue Homepage"><img class="icon" src="/static/images/arrow_left.svg" /> Go to <strong>ICLR 2019 Conference</strong> homepage</a></div>
    </div>
  </div>
</div>
<div id="flash-message-container" class="alert alert-danger" role="alert" style="display: none;">
  <div class="container">
    <div class="row">
      <div class="col-xs-12">
        <div class="alert-content">
          <button type="button" class="close" aria-label="Close"><span aria-hidden="true">×</span></button>
        </div>
      </div>
    </div>
  </div>
</div>

<div class="container">
  <div class="row">
    <div class="col-xs-12">
      <main id="content" class="clearfix openbanner-visible legacy-styles"><div id="note_S1E64jC5tm" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>The Forward-Backward Embedding of Directed Graphs</a> <a class="note_content_pdf" href="/pdf?id=S1E64jC5tm" title="Download PDF" target="_blank"><img src="/static/images/pdf_icon_blue.svg" /></a> </h2></div><div class="meta_row"><span class="signatures">Anonymous</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">28 Sep 2018 (modified: 11 Oct 2018)</span><span class="item">ICLR 2019 Conference Blind Submission</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span><span class="item"><a class="action-bibtex-modal" data-bibtex="@inproceedings{    &#10;anonymous2019the,    &#10;title={The Forward-Backward Embedding of Directed Graphs},    &#10;author={Anonymous},    &#10;booktitle={Submitted to International Conference on Learning Representations},    &#10;year={2019},    &#10;url={https://openreview.net/forum?id=S1E64jC5tm},    &#10;note={under review}    &#10;}">Show Bibtex</a></span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Abstract: </span><span class="note_content_value">We introduce a novel embedding of directed graphs derived from the singular value decomposition (SVD) of the  normalized adjacency matrix. Specifically, we show that, after proper normalization of the singular vectors,  
 the  distances between vectors in  the embedding space are proportional to the mean commute times between the corresponding  nodes by a  forward-backward random walk in the graph, which follows the edges  alternately in forward and backward directions.  In particular, two nodes having many common successors in the graph tend to be represented by close vectors in the embedding space. More formally, we prove that our representation of the graph is  equivalent to the spectral embedding of some co-citation graph, where  nodes are linked with respect to their common set of successors in the original graph. The interest of our approach is that it does not require to build this co-citation graph, which is typically much denser than the original graph. Experiments  on  real datasets show the efficiency of the approach. 
</span></div><div class="note_contents"><span class="note_content_field">Keywords: </span><span class="note_content_value">Graph embedding, SVD, random walk, co-clustering</span></div><div class="reply_row clearfix"><div class="item" id="reply_count">6 Replies</div></div></div><hr class="small" /><div id="note_children"><div class="note_with_children"><div id="note_SkxVfLSzaX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>well written - standard / light content  </a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=S1E64jC5tm&amp;noteId=SkxVfLSzaX"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper43 AnonReviewer2</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">09 Nov 2018</span><span class="item">ICLR 2019 Conference Paper43 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">The paper discusses how to embed nodes of a graph to a vector space using singular value decomposition of the normalized adjacency matrix. The material in this paper are standard literature in graph theory and spectral analysis. The paper contains a well-written literature review. The contributions and not new enough for a publication.</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">5: Marginally below acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_r1e5PpwR37" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Incremental and trivial observations</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=S1E64jC5tm&amp;noteId=r1e5PpwR37"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper43 AnonReviewer3</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">06 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper43 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">The paper studies embeddings of directed graphs based on SVD. It proposes an interpretation of the embedding obtained from the normalized adjacency matrix in terms of the forward-backward random walk on the graph. In such random walk odd steps are taken using the edges of the graph while even steps are taken using reverse edges. Such an interpretation seems to be a trivial extension of the work for undirected graphs. 

For example, consider bipartite graphs, in such graphs the forward-backward random walk can be seen as a standard random walk on the graph with directions removed. Indeed, if the walk starts in part A then remove all edges from B to A and make A to B edges undirected.

</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">3: Clear rejection</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_BJxPZpNJpX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Reply to the reviewer</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=S1E64jC5tm&amp;noteId=BJxPZpNJpX"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">(anonymous)</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">07 Nov 2018</span><span class="item">ICLR 2019 Conference Paper43 Public Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Our paper is not a trivial extension of the work for undirected graphs. In particular, for bipartite graphs, the considered random walk is *not* a regular random walk as claimed in the review, but a two-hop random walk. To our knowledge, this has never been observed before. More generally, our paper is the first to relate SVD to random walks in directed graphs. This is very well known for spectral embedding, *not* for the SVD. </span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div><div class="note_with_children"><div id="note_BkeLffqx3Q" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>An interesting and valuable idea, but flawed in terms of execution and distinction/difference to previous works</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=S1E64jC5tm&amp;noteId=BkeLffqx3Q"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper43 AnonReviewer1</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">26 Oct 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper43 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value"># Summary of the paper

This paper proposes an embedding of directed graphs based on the SVD of a normalized adjacency matrix. This embedding is shown to be equivalent to the spectral embedding of a co-citation graph, which is more complex to calculate. Interestingly, the proposed approach does not require the *explicit* representation of this graph. Moreover, the paper also shows that distances of the embedded vectors are proportional to mean commute times of a forward--backward random walk in the original graph. A suite of experiments is run on graphs from KONECT.

# Review

This is a well-written paper, which I enjoyed reading. The extension of embeddings to the case of directed graphs is significant and warrants a detailed exploration.

The principal issues I see with this paper are as follows:

- The originality or scope of the contribution is not clear
- The experimental section is uncompelling
- Several relevant works appear to have been ignored

Overall, I like the way the paper treats the subject. In particular, I appreciate the fact that proofs are explained well; additionally, code is provided, which will increase reproducibility. This is uncommon and praiseworthy!

As for the originality of the paper, I find it hard to judge the scope of the contribution. The paper is extremely well written and employs a very pedagogical treatment of the subject, which I appreciate. Yet, it is hard for me to judge the utility and novelty of the proposed method in light of Section 8, where the paper shows that a spectral embedding of the undirected variant of the graph leads to essentially the *same* eigenvectors (up to renormalization and permutations). To prove that a new method is more effective, this point should be emphasized more:

1. In a sense, I would see the results from Section 8 as the equal to what 'Laplacian Eigenmaps' (LE) yields. This needs to be stressed, and analysed in an experimental section.

2. I understand that the order of the singular vectors is different, so embeddings that use only parts of them will be different. However, a convincing experiment should assess the differences. For example, in which regime for $d$ (number of used vectors) will the new method be surpassed by the old one? Is there such a regime? Ideally, this will be answered in the form of an asymptotic theorem; it could also be a larger experiment, though (to simulate the conditions in practice).

3. I understand that the new approach has a lower run-time, because the SVD is more efficient than eigendecomposition. However, what about a simple baseline algorithm that uses SVD for the *undirected* graph of the input data? This should be simple to accomplish, and would be a way to ascertain the benefit of using edge directions.

  To my understanding, LE should be this embedding, but from the table, I can see that its runtime is a lot worse than the novel method. What causes this? The fact that eigendecomposition is used instead of SVD?  If so, an additional SVD-based approach should be implemented.

This brings me to the experimental section. Here, the paper demonstrates the superiority of the new embedding based on evaluating modularity of a set of different clusterings of larger graphs, obtained using $k$-means. I have several concerns about this:

1. Modularity has problems with larger networks because only a small part of the network will be used in its configuration.

2. Since the embeddings cannot be easily compared due to missing ground truth information, other metrics should be employed. Here are a few, which are often used  by the community. See 'Is there a best quality metric for graph clusters?' by Almeida et al. for more details and a description of their shortcomings:
    - Silhouette coefficient
    - Coverage
    - Conductance

  Different ones should be evaluated here in order to show the behaviour of the new embedding. Do the embeddings differ if the modularities are similar?

3. How do the results change for different values of $d$? I find it hard to disentangle such a discussion from instabilities in $k$-means, but to my understanding of the method, tuning $d$ means that more or less information is used from the singular vectors.

   This could also be quantified in a proof (about asymptotic behaviour) but an experiment would be equally fine.

Concerning the bibliography, or the treatment of prior works, there are some issues:

- There appear to be some missing references of earlier works that used SVD or variants in order to cluster graphs or embed them:

  - Drineas et al.: 'Clustering Large Graphs via the Singular Value Decomposition'
  - Malliaros and Vazirgiannis: 'Clustering and Community Detection in Directed Networks: A Survey'

- Likewise, the use of pseudo-inverse Laplacians has a lot more papers attached to it (these are only a few that are relevant):

  - Ho and Dooren: 'On the pseudo-inverse of the Laplacian of a bipartite graph'
  - Gutman and Xia: 'Generalized inverse of the Laplacian matrix and some applications'

# Suggestions for improvement

- In some sense, this work can be seen as an extension of Laplacian eigenmaps to the directed case. The paper needs to be more clear about these extensions with respect to prior work. In Section 2, it is claimed that 'our main contribution is a proper normalization'. This strikes me as a rather small contribution in light of the experimental section, as outlined above.

- I am also hesitant to speak about a better interpretability of the mean commute time. I agree that it is nice to know that the distance permits such an interpretation in terms of random walks, but what is the impact of knowing the MCT? It is not only used in the embedding insofar as one obtains a vector representation.

- Section 5 is then the standard way of defining random walks based on a Laplacian matrix, and the correspondence to the pseudo-inverse of the Laplacian is shown. This is mathematically interesting, but appears to me to be in line with previous research.

- The section about co-citation graphs should make it more clear that 'successors' are to be taken in terms of the original graph and the directionality of edges. Since this is a standard definition in the domain of network analysis I would suggest citing a textbook here.

- In Section 6, the paper could give more details about random walk concepts such as 'stochastic', 'stationary distribution' etc., as it would make the paper more accessible (I am familiar with these concepts but since the writing of the paper is of high quality in the other sections, I am convinced this would improve its impact, and attract more readers).

Typos &amp; grammar issues:

- 'in terms of random walk' --&gt; 'in terms of random walks'
- 'equivalent to build' --&gt; 'equivalent to building'
- 'with corresponding unitary matrix' --&gt; 'with a corresponding unitary
  matrix'
- 'square Euclidean distance' --&gt; 'squared Euclidean distance'
- 'equivalent to consider' --&gt; 'equivalent to considering'
- 'irreductible' --&gt; 'irreducible'
- 'and provide generally' --&gt; 'and provides generally'
- 'in low dimension' --&gt; 'in a lower dimension'

Furthermore, the bibliography should employ consistent capitalization and journal names for articles.</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">4: Ok but not good enough - rejection</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_B1lFP1IPqX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>related methods?</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=S1E64jC5tm&amp;noteId=B1lFP1IPqX"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures"><a href="/profile?id=~Michael_Bronstein1" class="profile-link">Michael Bronstein</a></span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">07 Oct 2018</span><span class="item">ICLR 2019 Conference Paper43 Public Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Interesting work - one of a few to explicitly address directed graphs. I wonder if and how your approach related to the following two recent works: 

1. MotifNet: a motif-based Graph Convolutional Network for directed graphs, arXiv:1802.01572 - using sub-graph structures (motifs) to convert directed graphs into (re)-weighted undirected graphs. This is the closest analogy of anisotropic diffusion on graphs. 

2. Dual-Primal Graph Convolutional Networks, arXiv:1806.00770 - using convolutions on the line graph to update the edge weights; also can be considered as a generalization of the graph attention (GAT) approach. 

</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_r1l2PlkY57" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Reply about related methods</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=S1E64jC5tm&amp;noteId=r1l2PlkY57"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">(anonymous)</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">08 Oct 2018</span><span class="item">ICLR 2019 Conference Paper43 Public Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Thank you for the interest in our work and for the references.

&gt; I wonder if and how your approach related to the following two recent works: 
&gt; 1. MotifNet: a motif-based Graph Convolutional Network for directed graphs, arXiv:1802.01572 - using sub-graph structures (motifs) to convert directed graphs into (re)-weighted undirected graphs. This is the closest analogy of anisotropic diffusion on graphs. 

Our approach also relies on the conversion of a directed graph into a weighted undirected graph (the normalized co-citation graph). The key point is that this conversion is implicit, i.e., we do not need to actually construct this graph. The diffusion in the directed graph occurs through a forward-backward random walk. 

As far as we understand, the conversion we use is not in the class of motif-based graph conversions. The appropriate motif would be motif 10 of Fig. 2, with nodes i,j pointing to k, but we would need to:
* count each such motif whenever it corresponds to a subset of the edges (not necessaritly a subgraph)
* normalize this count by the degree of k.

So we believe our work is only loosely related to this paper.

&gt; 2. Dual-Primal Graph Convolutional Networks, arXiv:1806.00770 - using convolutions on the line graph to update the edge weights; also can be considered as a generalization of the graph attention (GAT) approach. 

We do not see any direct link with this work. The considered normalized co-citation graph is not a line graph. In particular, the set of vertices of the normalized  co-citation graph is that of the original graph, without the sinks. It is not the set of edges.

The authors</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div></div></main></div>
  </div>
</div>


    <!-- Footer -->
    <footer class="sitemap">
      <div class="container">
        <div class="row hidden-xs">
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/venues">All Venues</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="/contact">Contact</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
    
        <div class="row visible-xs-block">
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/contact">Contact</a></li>
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
      </div>
    </footer>
    
    <footer class="sponsor">
      <div class="container">
        <div class="row">
          <div class="col-sm-10 col-sm-offset-1">
            <p class="text-center">
              OpenReview is created by the <a href="http://www.iesl.cs.umass.edu/" target="_blank">Information Extraction and Synthesis Laboratory</a>, College of Information and Computer Science, University of Massachusetts Amherst. We gratefully acknowledge the support of the OpenReview sponsors:  Google,  Facebook, NSF, the University of Massachusetts Amherst Center for Data Science, and Center for Intelligent Information Retrieval, as well as the Google Cloud Platform for donating the computing and networking services on which OpenReview.net runs.
            </p>
          </div>
        </div>
      </div>
    </footer>

  <div id="feedback-modal" class="modal fade" tabindex="-1" role="dialog">
    <div class="modal-dialog">
      <div class="modal-content">
        <div class="modal-header">
          <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button>
          <h3 class="modal-title">Send Feedback</h3>
        </div>
        <div class="modal-body">
          <p>Enter your feedback below and we'll get back to you as soon as possible.</p>
          <form action="/feedback" method="POST">
            <div class="form-group">
              <input type="email" name="from" class="form-control" placeholder="Email" />
            </div>
            <div class="form-group">
              <input type="text" name="subject" class="form-control" placeholder="Subject" />
            </div>
            <div class="form-group">
              <textarea name="message" class="form-control feedback-input" rows="5" placeholder="Message" required=""></textarea>
            </div>
          <ul id="ui-id-2" tabindex="0" class="ui-menu ui-widget ui-widget-content" style="display: none;"></ul></form>
        </div>
        <div class="modal-footer">
          <button type="button" class="btn btn-default" data-dismiss="modal">Cancel</button>
          <button type="button" class="btn btn-primary">Send</button>
        </div>
      </div>
    </div>
  </div>

  <script type="text/javascript" async="" src="https://www.google-analytics.com/analytics.js"></script><script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js"></script>
  <script>window.jQuery || document.write('&lt;script src="/static/js/vendor/jquery-2.2.4.min.js"&gt;&lt;\/script&gt;')</script>

  <script src="/static/dist/vendor.min.js"></script>
  <script src="/static/dist/templates.min.js"></script>
  <script src="/static/dist/openreview.min.js"></script>

    <script>window.legacyScripts = true;</script>


    <script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-108703919-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() { dataLayer.push(arguments); }
      gtag('js', new Date());
      gtag('config', 'UA-108703919-1');
    </script>


<div role="status" aria-live="assertive" aria-relevant="additions" class="ui-helper-hidden-accessible"></div></body></html>
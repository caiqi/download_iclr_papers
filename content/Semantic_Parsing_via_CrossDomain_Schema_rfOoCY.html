<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" class="no-js"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>Semantic Parsing via Cross-Domain Schema | OpenReview</title>
  <meta name="description" content="" />

      <meta name="citation_title" content="Semantic Parsing via Cross-Domain Schema" />
        <meta name="citation_author" content="Anonymous" />
      <meta name="citation_publication_date" content="2018/09/27" />
      <meta name="citation_online_date" content="2018/09/27" />
      <meta name="citation_pdf_url" content="https://openreview.net/pdf?id=r1fO8oC9Y7" />
      <meta name="twitter:card" content="summary" />
      <meta name="twitter:site" content="@openreviewnet" />
      <meta name="og:title" content="Semantic Parsing via Cross-Domain Schema" />
      <meta name="og:description" content="Semantic parsing which maps a natural language sentence into a formal machine-readable representation of its meaning, is highly constrained by the limited annotated training data. Inspired by the..." />
      <meta name="og:image" content="https://openreview.net/static/images/openreview_logo_512.png" />

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans:400,400i,700,700i" />

  <link rel="stylesheet" href="/static/css/bootstrap.min.css" />
  <link rel="stylesheet" href="/static/css/jquery-ui.min.css" />
  <link rel="stylesheet" href="/static/css/main.min.css" />
</head>

<body class="forum">
  <nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
  
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand home push-link" href="/"><strong>OpenReview</strong>.net</a>
      </div>
  
      <div id="navbar" class="navbar-collapse collapse">
        <form class="navbar-form navbar-left profile-search" role="search">
          <div class="form-group has-feedback">
            <input id="search_input" type="text" class="form-control ui-autocomplete-input" placeholder="Search ICLR 2019 Conference" autocomplete="off" />
            <span class="glyphicon glyphicon-search form-control-feedback" aria-hidden="true"></span>
          </div>
  
          <input id="search_group" type="hidden" value="ICLR.cc/2019/Conference" />
          <input id="search_content" type="hidden" value="all" />
        <ul id="ui-id-1" tabindex="0" class="ui-menu ui-widget ui-widget-content ui-autocomplete ui-front" style="display: none;"></ul></form>
  
        <ul class="nav navbar-nav navbar-right">
        
            <li id="user-menu"><a href="/login">Login</a></li>
        </ul>
      </div>
  
    </div>
  </nav>

  <div id="or-banner" class="banner" style="">
  <div class="container">
    <div class="row">
      <div class="col-xs-12"><a href="/group?id=ICLR.cc/2019/Conference" title="Venue Homepage"><img class="icon" src="/static/images/arrow_left.svg" /> Go to <strong>ICLR 2019 Conference</strong> homepage</a></div>
    </div>
  </div>
</div>
<div id="flash-message-container" class="alert alert-danger" role="alert" style="display: none;">
  <div class="container">
    <div class="row">
      <div class="col-xs-12">
        <div class="alert-content">
          <button type="button" class="close" aria-label="Close"><span aria-hidden="true">×</span></button>
        </div>
      </div>
    </div>
  </div>
</div>

<div class="container">
  <div class="row">
    <div class="col-xs-12">
      <main id="content" class="clearfix openbanner-visible legacy-styles"><div id="note_r1fO8oC9Y7" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Semantic Parsing via Cross-Domain Schema</a> <a class="note_content_pdf" href="/pdf?id=r1fO8oC9Y7" title="Download PDF" target="_blank"><img src="/static/images/pdf_icon_blue.svg" /></a> </h2></div><div class="meta_row"><span class="signatures">Anonymous</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">28 Sep 2018 (modified: 11 Oct 2018)</span><span class="item">ICLR 2019 Conference Blind Submission</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span><span class="item"><a class="action-bibtex-modal" data-bibtex="@inproceedings{    &#10;anonymous2019semantic,    &#10;title={Semantic Parsing via Cross-Domain Schema},    &#10;author={Anonymous},    &#10;booktitle={Submitted to International Conference on Learning Representations},    &#10;year={2019},    &#10;url={https://openreview.net/forum?id=r1fO8oC9Y7},    &#10;note={under review}    &#10;}">Show Bibtex</a></span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Abstract: </span><span class="note_content_value">Semantic parsing which maps a natural language sentence into a formal machine-readable representation of its meaning, is highly constrained by the limited annotated training data. Inspired by the idea of coarse-to-fine, we propose a general-to-detailed neural network(GDNN) by incorporating cross-domain schema(CDS) among utterances and their logic forms. For utterances in different domains, the General Network will extract CDS using an encoder-decoder model in a multi-task learning setup. Then for some utterances in a specific domain, the Detailed Network will generate the detailed target parts using sequence-to-sequence architecture with advanced attention to both utterance and generated CDS. Our experiments show that compared to direct multi-task learning, CDS has improved the performance in semantic parsing task which converts users' requests into meaning representation language(MRL). We also use experiments to illustrate that CDS works by adding some constraints to the target decoding process, which further proves the effectiveness and rationality of CDS.</span></div><div class="note_contents"><span class="note_content_field">Keywords: </span><span class="note_content_value">semantic parsing, natural language understanding, machine learning</span></div><div class="note_contents"><span class="note_content_field">TL;DR: </span><span class="note_content_value">General-to-detailed neural network(GDNN) by incorporating cross-domain schema(CDS) for semantic parsing</span></div><div class="reply_row clearfix"><div class="item" id="reply_count">3 Replies</div></div></div><hr class="small" /><div id="note_children"><div class="note_with_children"><div id="note_HJeYN9r63Q" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Overall score 3</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=r1fO8oC9Y7&amp;noteId=HJeYN9r63Q"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper191 AnonReviewer2</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">05 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper191 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">Overall Score 3

This paper introduces “Cross domain schemas” (CDS) for semantic parsing of utterances made to a virtual assistant. CDS captures similarities in requests according to the underlying actions or attributes being discussed, regardless of the user’s high-level intent. Also introduced is a model which leverages CDS to improve semantic parsing of utterances to a meaning representation language (MRL). This model first parses an utterance to CDS, then uses an encoding of the CDS jointly with the utterance encoding to decode a meaning representation. By treating different intents as separate domains, the authors construct a multi-task learning setup for CDS and MRL parsing. Results are provided for the Snips dataset of virtual assistant queries. 

Unfortunately, this paper fails to sufficiently explain its main proposal, the CDS. The stated goal is to explicitly define the cross-domain features that would otherwise be implicitly learned by the parameters of a neural network, yet no explicit definition is given. No rough quantification of how many or what percent of features appear across domains is provided. Rather, significant time and space is given to describing a fairly unsophisticated two-decoder model for inserting the mysterious CDS representation into the final decoding task. 

The paper ignores standard semantic parsing datasets (GeoQuery and ATIS) due to their size and scope. However, comparable models (Goo et al. 2018) are trained and tested on ATIS. Moreover, an evaluation on a small, unseen target domain would be the perfect justification for the kind of cross-domain learning proposed here. 

Instead, this paper opts only to evaluate on the recent Snips dataset. This dataset seems to be best suited to evaluating intent classification and slot filling (intent-slot), but the current work fails to improve over what Goo et al. 2018 report on this data. In the current work, the Snips dataset is used to evaluate MRL parsing, where the CDS model shows improvements over other seq2seq models. However, since MRL can be parsed from intent-slot format by predefined rules, it is uncertain whether the CDS model outperforms the Goo et al. model at even the task of MRL parsing (no such comparison is provided). 

Overall, the paper suffers from some clarity issues especially regarding the definition and value of CDS. The model provided may be slightly original but is quite similar to the model of Dong and Lapata 2018. The significance of this work is questionable due to the poor comparison with recently released baseline models for the more common intent-slot task. 

Pros

Introduces “Cross Domain Schemas” (CDS) for semantic parsing, which help improve robustness of semantic parsers by allowing models to learn patterns in one domain for use in another. 

Through the use of CDS, train semantic parsers in a multi-task learning setup

Cons

CDS is not described in sufficient detail. In particular, the possible actions and attributes are not defined. 

The model is described as “multi-task learning”, however all tasks are parsing requests made of a virtual assistant. 

Results on standard data for semantic parsing such as GEO or ATIS are not reported.

The model does not appear to improve the results on the Snips dataset compared to the paper that introduces this dataset. Thus, the value of CDS is difficult to judge. 

No per-domain analysis of the impact of CDS is provided.</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">3: Clear rejection</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_BklT1yJs27" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Where's SRL?</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=r1fO8oC9Y7&amp;noteId=BklT1yJs27"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper191 AnonReviewer1</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">03 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper191 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">This is a wonderful paper as it seems to have brougth Semantic Role Labelling (SRL) in the context of DL and in the context of voice search. 
Results are interesting but the paper has some major limitations. In fact, the paper totally disregard the work on Semantic Role Labelling and on languages for expressing the general meaning of language in terms of relations and in terms of concepts. 

The first limitation is on the key idea. The key idea of the paper seems to be the existence of an intermediate representation language to encode meaning for utterances. Yet, this intermediate language seems to be the final language with the same relation types (for example, SearchAction) and without representations for the involved concepts (Type that becomes alternatively Film or Weather according to the target final language). This seems to be SRL where the first step is to recognize the relation and, then, the second step is to recognize the roles even if roles are slot filler types in the case of this papers.

The second limitation is on how the intermediate language has been choosen. What is the relation with FrameNet or VerbNet? Why the authors have not choosen something similar? What are the limitations of these two resources that have forced the authors to disregard them?

Minor problems
====
- Why there are not spaces between characters and opening brackets?
- "compositional graph based .... language" is a really large noun compound
</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">4: Ok but not good enough - rejection</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_rke8DKIKhm" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Semantic parsing model with a domain-agnostic intermediate decoding step</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=r1fO8oC9Y7&amp;noteId=rke8DKIKhm"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper191 AnonReviewer3</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">02 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper191 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">This paper describes a two-stage encoder-decoder model for semantic parsing. The model first decodes a cross-domain schema (CDS) representation from the input utterance, then decodes the final logial form from both the utterance and CDS. The model outperforms other multitask Seq2Seq models on the Snips (Goo et al., 2018) dataset, but is still behind the traditional slot-filling models (Goo et al., 2018).

My main concern is that it is unclear to me how CDS (cross-domain schema) can be generalized to the other semantic parsing datasets, e.g., the Overnight dataset (Wang et al., 2015), which also contains multiple domains. 

I think it would be nice to have some details about the CDS in the paper. For example, I’m wondering 1) how is this CDS designed? 2) how are the CDS annotations derived from the target output? 

There are other details missing regarding the comparisons and the evaluation metrics. In 4.2, the authors mentioned “We use accuracy as the evaluation metric’’, does “accuracy” mean full logical form accuracy or accuracy on execution results?

* More minor comments:
In the first paragraph of Section 3, “irrelevant to domain’’ -&gt; “domain-general’’ or “domain-agnostic’’?

It will be nice to write something more specific than “explore more ways to make it work better” in the future work.

This paper has some grammatical errors and formatting issues (e.g. missing space before punctuations).

* Missing references:
Neural semantic parsing over multiple knowledge-bases, Herzig and Berant, ACL 2017 &lt;- This paper explores shared encoder/decoder for multi-domain semantic parsing, which is very related.

(Concurrent) Decoupling Structure and Lexicon for Zero-Shot Semantic Parsing, Herzig and Berant, EMNLP 2018 
</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">5: Marginally below acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></main></div>
  </div>
</div>


    <!-- Footer -->
    <footer class="sitemap">
      <div class="container">
        <div class="row hidden-xs">
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/venues">All Venues</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="/contact">Contact</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
    
        <div class="row visible-xs-block">
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/contact">Contact</a></li>
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
      </div>
    </footer>
    
    <footer class="sponsor">
      <div class="container">
        <div class="row">
          <div class="col-sm-10 col-sm-offset-1">
            <p class="text-center">
              OpenReview is created by the <a href="http://www.iesl.cs.umass.edu/" target="_blank">Information Extraction and Synthesis Laboratory</a>, College of Information and Computer Science, University of Massachusetts Amherst. We gratefully acknowledge the support of the OpenReview sponsors:  Google,  Facebook, NSF, the University of Massachusetts Amherst Center for Data Science, and Center for Intelligent Information Retrieval, as well as the Google Cloud Platform for donating the computing and networking services on which OpenReview.net runs.
            </p>
          </div>
        </div>
      </div>
    </footer>

  <div id="feedback-modal" class="modal fade" tabindex="-1" role="dialog">
    <div class="modal-dialog">
      <div class="modal-content">
        <div class="modal-header">
          <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button>
          <h3 class="modal-title">Send Feedback</h3>
        </div>
        <div class="modal-body">
          <p>Enter your feedback below and we'll get back to you as soon as possible.</p>
          <form action="/feedback" method="POST">
            <div class="form-group">
              <input type="email" name="from" class="form-control" placeholder="Email" />
            </div>
            <div class="form-group">
              <input type="text" name="subject" class="form-control" placeholder="Subject" />
            </div>
            <div class="form-group">
              <textarea name="message" class="form-control feedback-input" rows="5" placeholder="Message" required=""></textarea>
            </div>
          <ul id="ui-id-2" tabindex="0" class="ui-menu ui-widget ui-widget-content" style="display: none;"></ul></form>
        </div>
        <div class="modal-footer">
          <button type="button" class="btn btn-default" data-dismiss="modal">Cancel</button>
          <button type="button" class="btn btn-primary">Send</button>
        </div>
      </div>
    </div>
  </div>

  <script type="text/javascript" async="" src="https://www.google-analytics.com/analytics.js"></script><script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js"></script>
  <script>window.jQuery || document.write('&lt;script src="/static/js/vendor/jquery-2.2.4.min.js"&gt;&lt;\/script&gt;')</script>

  <script src="/static/dist/vendor.min.js"></script>
  <script src="/static/dist/templates.min.js"></script>
  <script src="/static/dist/openreview.min.js"></script>

    <script>window.legacyScripts = true;</script>


    <script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-108703919-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() { dataLayer.push(arguments); }
      gtag('js', new Date());
      gtag('config', 'UA-108703919-1');
    </script>


<div role="status" aria-live="assertive" aria-relevant="additions" class="ui-helper-hidden-accessible"></div></body></html>
<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" class="no-js"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>Incremental Few-Shot Learning with Attention Attractor Networks | OpenReview</title>
  <meta name="description" content="" />

      <meta name="citation_title" content="Incremental Few-Shot Learning with Attention Attractor Networks" />
        <meta name="citation_author" content="Anonymous" />
      <meta name="citation_publication_date" content="2018/09/27" />
      <meta name="citation_online_date" content="2018/09/27" />
      <meta name="citation_pdf_url" content="https://openreview.net/pdf?id=rkxn7nR5KX" />
      <meta name="twitter:card" content="summary" />
      <meta name="twitter:site" content="@openreviewnet" />
      <meta name="og:title" content="Incremental Few-Shot Learning with Attention Attractor Networks" />
      <meta name="og:description" content="Machine learning classifiers are often trained to recognize a set of pre-defined classes. However,&#10;  in many real applications, it is often desirable to have the flexibility of learning..." />
      <meta name="og:image" content="https://openreview.net/static/images/openreview_logo_512.png" />

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans:400,400i,700,700i" />

  <link rel="stylesheet" href="/static/css/bootstrap.min.css" />
  <link rel="stylesheet" href="/static/css/jquery-ui.min.css" />
  <link rel="stylesheet" href="/static/css/main.min.css" />
</head>

<body class="forum">
  <nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
  
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand home push-link" href="/"><strong>OpenReview</strong>.net</a>
      </div>
  
      <div id="navbar" class="navbar-collapse collapse">
        <form class="navbar-form navbar-left profile-search" role="search">
          <div class="form-group has-feedback">
            <input id="search_input" type="text" class="form-control ui-autocomplete-input" placeholder="Search ICLR 2019 Conference" autocomplete="off" />
            <span class="glyphicon glyphicon-search form-control-feedback" aria-hidden="true"></span>
          </div>
  
          <input id="search_group" type="hidden" value="ICLR.cc/2019/Conference" />
          <input id="search_content" type="hidden" value="all" />
        <ul id="ui-id-1" tabindex="0" class="ui-menu ui-widget ui-widget-content ui-autocomplete ui-front" style="display: none;"></ul></form>
  
        <ul class="nav navbar-nav navbar-right">
        
            <li id="user-menu"><a href="/login">Login</a></li>
        </ul>
      </div>
  
    </div>
  </nav>

  <div id="or-banner" class="banner" style="">
  <div class="container">
    <div class="row">
      <div class="col-xs-12"><a href="/group?id=ICLR.cc/2019/Conference" title="Venue Homepage"><img class="icon" src="/static/images/arrow_left.svg" /> Go to <strong>ICLR 2019 Conference</strong> homepage</a></div>
    </div>
  </div>
</div>
<div id="flash-message-container" class="alert alert-danger" role="alert" style="display: none;">
  <div class="container">
    <div class="row">
      <div class="col-xs-12">
        <div class="alert-content">
          <button type="button" class="close" aria-label="Close"><span aria-hidden="true">×</span></button>
        </div>
      </div>
    </div>
  </div>
</div>

<div class="container">
  <div class="row">
    <div class="col-xs-12">
      <main id="content" class="clearfix openbanner-visible legacy-styles"><div id="note_rkxn7nR5KX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Incremental Few-Shot Learning with Attention Attractor Networks</a> <a class="note_content_pdf" href="/pdf?id=rkxn7nR5KX" title="Download PDF" target="_blank"><img src="/static/images/pdf_icon_blue.svg" /></a> </h2></div><div class="meta_row"><span class="signatures">Anonymous</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">28 Sep 2018 (modified: 11 Oct 2018)</span><span class="item">ICLR 2019 Conference Blind Submission</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span><span class="item"><a class="action-bibtex-modal" data-bibtex="@inproceedings{    &#10;anonymous2019incremental,    &#10;title={Incremental Few-Shot Learning with Attention Attractor Networks},    &#10;author={Anonymous},    &#10;booktitle={Submitted to International Conference on Learning Representations},    &#10;year={2019},    &#10;url={https://openreview.net/forum?id=rkxn7nR5KX},    &#10;note={under review}    &#10;}">Show Bibtex</a></span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Abstract: </span><span class="note_content_value">Machine learning classifiers are often trained to recognize a set of pre-defined classes. However,
in many real applications, it is often desirable to have the flexibility of learning additional
concepts, without re-training on the full training set. This paper addresses this problem,
incremental few-shot learning, where a regular classification network has already been trained to
recognize a set of base classes; and several extra novel classes are being considered, each with
only a few labeled examples. After learning the novel classes, the model is then evaluated on the
overall performance of both base and novel classes. To this end, we propose a meta-learning model,
the Attention Attractor Network, which regularizes the learning of novel classes. In each episode,
we train a set of new weights to recognize novel classes until they converge, and we show that the
technique of recurrent back-propagation can back-propagate through the optimization process and
facilitate the learning of the attractor network regularizer. We demonstrate that the learned
attractor network can recognize novel classes while remembering old classes without the need to
review the original training set, outperforming baselines that do not rely on an iterative
optimization process.</span></div><div class="note_contents"><span class="note_content_field">Keywords: </span><span class="note_content_value">meta-learning, few-shot learning, incremental learning</span></div><div class="reply_row clearfix"><div class="item" id="reply_count">12 Replies</div></div></div><hr class="small" /><div id="note_children"><div class="note_with_children"><div id="note_Sye3gf7ahX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Question about the details</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=rkxn7nR5KX&amp;noteId=Sye3gf7ahX"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">(anonymous)</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">05 Nov 2018</span><span class="item">ICLR 2019 Conference Paper1396 Public Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Hi, I have the following confusion: How is the attractor $U_k$ for the base class which is stored in the knowledge base generated? Apologies if I missed something important.

Looking forward to your reply. Thank you.</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_BJxKuIEahm" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Response</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=rkxn7nR5KX&amp;noteId=BJxKuIEahm"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1396 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">05 Nov 2018</span><span class="item">ICLR 2019 Conference Paper1396 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Hi, $U_k$ are learned as slow weights in the meta-training. Thanks!</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div><div class="note_with_children"><div id="note_B1lJPA1hhQ" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>The problem of incremental few-shot learning is interesting and the presented meta-learning method seems to be effective, but the novelty is limited.  </a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=rkxn7nR5KX&amp;noteId=B1lJPA1hhQ"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1396 AnonReviewer3</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">04 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper1396 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">This work addresses incremental few-shot learning that learns novel classes without forgetting old classes, which is interesting and different from conventional few-shot learning that considers only the few-shot learning task of interest. This problem is also related closely to the important problem of life-long learning. 

This work presents an interesting framework based on meta-learning by learning to learn how to attend to the old classes using an attention mechanism. Experimental results also show improvement over two related works on incremental few-shot learning. The writing is quite clear. Some concerns, especially its novelty, are listed below.  

1. The novelty appears to be limited. The presented framework looks quite similar to the recent work 

Spyros Gidaris and Nikos Komodakis. Dynamic few-shot visual learning without forgetting. CVPR'18

that addresses the same problem in a similar manner: 1) learn a base feature extractor and classifier; and then 2) attend to old classes also via meta-learning and attention mechanism.  
As mentioned by the authors, "The main difference to this work is that we use an iterative optimization to compute W_b". More discussions on the iterative optimization and why it matters may be helpful.

Another related work is "Deep Meta-Learning: Learning to Learn in the Concept Space", Arxiv'18, that also relies on an external base classes for few-shot learning. Similar to the proposed research, it also learns a feature extractor and a classifier from the base classes, which are used to regularize the learning of novel classes, in an end-to-end meta-learning manner. Extending it for the incremental setting seems natural. 

2. To learn a few novel classes, all U_k on old classes are relearned, which seems quite time-consuming with a large vocabulary of base classes.

3. To learn a few novel classes, old data on base classes are still required, which seems different from how humans learn -- humans learn novel concepts solely from a few examples without forgetting old concepts, without requiring examples on old concepts.  </span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">5: Marginally below acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_SJe0IAYmTX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Author Response</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=rkxn7nR5KX&amp;noteId=SJe0IAYmTX"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1396 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">10 Nov 2018</span><span class="item">ICLR 2019 Conference Paper1396 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Thank you for the review. We would like first explain the novelty aspect of our paper.

- Novelty: Although both our work and the CVPR paper use an attention mechanism, the two methods are actually very different. The new weights in their method are based on Prototypical Nets, i.e. simply averaging the embedding. We however optimize the weights on the new task and backprop through the optimization, which is a challenging step in learning our model. The attention mechanism is also formulated differently. Whereas the attended content is used as multiplicative gating in their work, we used it as an additive energy term in the overall objective function to optimize. 

Secondly, there seem to be a couple crucial misunderstandings in the review. We will revise our paper to make sure that our points are clearly stated.

- Learning of novel classes needs old data: We are afraid that there might be a big misunderstanding. The whole incremental few-shot learning problem is set up so that reviewing old data is *not* allowed. Otherwise the problem can be very trivial to solve: just sample some old data and new data and train jointly. We believe that learning novel classes *without* reviewing old data is an important and challenging problem, especially learning it iteratively, since many models will run into catastrophic forgetting. We have shown that while BPTT does not perform well in this scenario, the proposed meta-learning algorithm can solve it.

- Learning of novel classes involves relearning U_k. During learning of novel classes, U_k is fixed and *not* re-learned. U_k is learned during the meta-learning stage, where the novel classes are subsampled from the training set classes (Train_B set). Also the size of U_k is the same as a fully connected softmax layer, which is quite small compared to all the parameters of a deep CNN model. </span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div><div class="note_with_children"><div id="note_BJlnllqsn7" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Import discussions missing</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=rkxn7nR5KX&amp;noteId=BJlnllqsn7"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1396 AnonReviewer2</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">04 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper1396 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">This paper proposes a novel few-shot learning method that achieves better overall accuracies on base and novel classes. The key idea is to regularize the learning of novel classes such that base classes are not forgotten. 

I mainly have the following two concerns. 

-In Table 2, I observe that performance on novel classess is actually not improved. The main improvement lies in overall accuracy. As numbers of training samples between base and novel classes are not balanced, there must be some trade-off between  obtaining better performance on base or novel classes. For instance, stopping early when training on novel classes would result in high base accuracy but low novel accuracy. Fine-tuning on novel classes for more iterations would lead to high novel accuracy but  low base accuracy. Such trade-off can be also controlled by simply over-sampling novel or base classes.  I would suggest the authors to study more on understanding this trade-off. In addition, another naive baseline is to train a softmax classifier at the second stage on both base and novel class training samples and sample mini-batch by uniformly sampling over novel and base classes.  

-The following two papers extensively studied the problem of achieving better overall accuracies on base and novel classes. Including comparison and discussion with those two papers will enhance this paper further. 
Low-Shot Learning from Imaginary Data
low-shot visual recognition by shrinking and hallucinating features</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">5: Marginally below acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">3: The reviewer is fairly confident that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_S1xaiCK76X" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Author Response</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=rkxn7nR5KX&amp;noteId=S1xaiCK76X"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1396 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">10 Nov 2018</span><span class="item">ICLR 2019 Conference Paper1396 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">We thank the reviewer for the comments and pointing out related work. We are revising our paper and adding the discussion of these and other relevant papers. In response to one of the public comments, we have compared our approach to these two papers:

The ICCV 2017 paper proposes the SGM loss, which makes the learned classifier from the few-shot examples have a smaller gradient value when learning on all examples. The CVPR 2018 paper proposes the prototypical matching networks, a combination of prototypical network and matching network. The paper also adds hallucination, which generates new examples.

In contrast to these approaches, we directly learn a logistic regression classifier during the few-shot episode, which is very simple and straightforward. Although vanilla logistic regression has been shown to be worse in these prior work (since the logistic regression cannot see old data), we found that it can be improved significantly by differentiating through the few-shot learning iterations, taking into account the additional regularizer..

- Uniform samples: We also would like to emphasize that, in the learning of novel classes, the base class data is *not* available, thus making the problem very challenging. Therefore, the proposed “naive baseline” which samples a mini-batch uniformly over novel and base classes, will not be comparable to the new approach introduced in the paper, which does not rely on reviewing the old data.

- Early stopping: Since we are learning an objective function that needs to be solved until convergence. Stopping early is possible but that relies on an external validation set, which might not be available since we do not have access to the old data when learning the novel classes.

Lastly, the reviewer is right that there is a trade-off between learning novel and remembering old classes. Getting better results on the novel class is is indeed possible but has the undesired effect, of catastrophic forgetting. In our setting of incremental few-shot learning the goal is to have the best performance on *both base and novel classes*. Hence we focus on the \delta bar metric, and our method has a clear win on this crucial metric.</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div><div class="note_with_children"><div id="note_Hyeike3c3X" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>review</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=rkxn7nR5KX&amp;noteId=Hyeike3c3X"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1396 AnonReviewer1</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">03 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper1396 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">The paper addresses the incremental few-shot learning problem where a model starts with base network and then introduces the novel classes, building a connection between novel and base classes via an attention module.

Strengths:
+ clear writing. 
+ the experiments are compared with related work and the ablation studies can verify the effectiveness of the proposed (or "introduced" would be a precise term) recurrent BP.

Weakness:

- [Novelty]
The paper title is called attention attractor network, which shares very relevance to previous CVPR work (Gidaris &amp; Komodakis, 2018). So the first thing I was looking for is the clear description of the difference between these two. Unfortunately, in related work, authors mention the CVPR work without stating the difference (last few lines in Section 2). As such, I don't see much novelty in the paper compared with previous work. Eqn. (7)-(10) explicitly describes the attention formula. What's the distinction from the CVPR work?

- [Motivation of the regularizer using Recurrent BP is not clear]
The use of recurrent BP is probably the most distinction from previous work. However, I don't see a clear description on why such a technique is necessary.

Starting from the first line in Section 3.3, "since there is no closed-form of the regularizer in Eqn (13)", E needs BPTT or the introduced recurrent BP. This part is simply a re-adaption of other algorithms. A very simple question is, how about use other regularizers to replace Eqn (13)? 

- [Some experiments missing]
The experiments section 4.6 uses a case of None and "best WD" to address some of my concerns. This is good. Does the "gamma random" indicates only E is used without the ||W||^2? why the best WD for one-shot is zero? This implies the model is best for applying no weight decay?

What's the effect of using the recurrent BP technique to the CVPR work? Is there some similar improvement? If yes, then the paper makes some contribution by the regularization. If not, what's the reason?

How about using the truncated BPTT with a larger T?

In general, I think the recurrent BP part should be the highlight of the paper and yet authors fail to spread such a spirit in the abstract or title. And there are some experiments missed as I mentioned above.
</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">5: Marginally below acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_rkgRfJ576X" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Author Response</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=rkxn7nR5KX&amp;noteId=rkgRfJ576X"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1396 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">10 Nov 2018</span><span class="item">ICLR 2019 Conference Paper1396 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Thank you for the review. We are currently revising the paper and will incorporate your helpful suggestions (to add discussion to CVPR work, add BPTT with larger T, and highlight the RBP algorithm).

- Novelty: First, we would like to address the novelty issue. Although both our work and the CVPR paper uses attention mechanism, the two methods are actually very different. The new weights in their method are based on Prototypical Networks, i.e. simply averaging the embedding. We however optimize the weights on the new task and  backprop through the optimization, which is a challenging step in learning our model. The attention mechanism is also formulated differently. Whereas the attended content is used as multiplicative gating in their work, we used it as an additive energy term in the overall objective function to optimize.

- Applying RBP to the CVPR work: The CVPR work is based on a Prototypical Network which computes weights for the novel classes in a single layer, and regular backpropagation is sufficient. Since there is no iterative optimization involved, we do not see anything that allows us to apply RBP to the CVPR work, or any need for it.

- Motivation of RBP: Since we have an iterative optimization procedure in the model, directly differentiating through the procedure is not straightforward. Also, as shown in the experiment, regular backprop through time does not learn a stable objective function. Prior work focus on the case where there is a closed form solution (Bertinetto et al. 2018), where RBP allows us to backprop through any converging optimization layers, which is more general.

- Best WD: Yes, in that experiment, no weight decay is needed (although adding a small amount of WD does not hurt the performance). In the other experiments, we found a small amount of weight decay (1E-5) helped.

- BPTT with larger T: Thank you for the suggestion. We are currently adding more experiments that use a larger T for BPTT and will update the paper with the latest results.</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div><div class="note_with_children"><div id="note_Hylc3mHb3m" class="note panel trashed"><div class="title_pdf_row clearfix"><h2 class="note_content_title">  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=rkxn7nR5KX&amp;noteId=Hylc3mHb3m"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">[Deleted]</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="item">ICLR 2019 Conference Paper1396 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_rklts7SZh7" class="note panel trashed"><div class="title_pdf_row clearfix"><h2 class="note_content_title">  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=rkxn7nR5KX&amp;noteId=rklts7SZh7"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">[Deleted]</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="item">ICLR 2019 Conference Paper1396 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_HylWwmBZh7" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Some clarification</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=rkxn7nR5KX&amp;noteId=HylWwmBZh7"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1396 AnonReviewer1</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">27 Oct 2018</span><span class="item">ICLR 2019 Conference Paper1396 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Hi,

I have some confusions in the paper.

(1) what's h_tilde in Eqn. (1)?
(2) how \delta_bar is computed in Table 1? for example, "LwoF (our implementation)", is it supposed to be (56.97 + 52.37)/2 - 74.58 = -19.91?
(3) Fig.1, the iterative process corresponds to the M-loop in Alg. 1? If so, it seems that the M-loop deals with L_Q, which is the query set, the "iterative solver" in Fig. 1 deals with support set only.</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_B1ghUyjmn7" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Response</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=rkxn7nR5KX&amp;noteId=B1ghUyjmn7"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1396 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">29 Oct 2018 (modified: 30 Oct 2018)</span><span class="item">ICLR 2019 Conference Paper1396 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Thank you for the questions.

(1) h_tilde is the original hidden representation, and we augment it with an extra dimension with value=1.

(2) When jointly testing base and novel classes, we quantify the drop in performance in each category, relative to testing the base and novel classes separately as follows:

If the Acc_A is base accuracy, Acc_B is few-shot accuracy, and Acc_joint is joint accuracy. Within Acc_joint, Acc_A’ is the base accuracy when tested jointly, and Acc_B’ is the few-shot accuracy when tested jointly. Then, \delta_bar is computed as:

\delta_bar = ½ (Acc_A’ - Acc_A) + ½ (Acc_B’ - Acc_B)

(3) The iterative process corresponds to Line 5 in Alg. 1, where it solves the L_S loss. M-loop is the backpropagation of gradients of the loop.</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div><div class="note_with_children"><div id="note_BklxABhTi7" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Interesting work, questions about problem setting and optimizer</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=rkxn7nR5KX&amp;noteId=BklxABhTi7"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">(anonymous)</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">24 Oct 2018</span><span class="item">ICLR 2019 Conference Paper1396 Public Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">
The idea of incremental few-shot learning in this paper is quite interesting. After reading the paper, I have two questions detailed in the below.

Q1. The same problem has been proposed and studied in two recent papers “Low-shot Visual Recognition by Shrinking and Hallucinating Features (ICCV 2017)” and “Low-Shot Learning from Imaginary Data (CVPR 2018)”. They address the same problem of classifying novel classes with a few labeled examples based on identifying a set of base classes. They also categorize the classes as “base” and “novel” class as this paper does. Since I did not find any discussion about these two papers in this paper, can you provide some comments about their differences?

Q2. In this paper, you use recurrent back-propagation as an optimizer, but most previous few-shot learning methods use SGD. Recurrent back-propagation is widely used in NLP because of the sequential nature of texts. However, an image is rarely treated as a sequence. Is there any particular reason for using recurrent back-propagation? Or did you see any critical advantages of using recurrent back-propagation rather than using SGD?

I am looking forward to your reply. Thanks a lot!
</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_Skgbo1iQ37" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Thank you for the comment</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=rkxn7nR5KX&amp;noteId=Skgbo1iQ37"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1396 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">29 Oct 2018</span><span class="item">ICLR 2019 Conference Paper1396 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">1) Thank you for your comments. We will add the discussion in our next version of the paper. Note that in our paper we compared to LwoF, which has better performance than the two papers mentioned above. We are planning to add experiments using the dataset proposed by Bharath &amp; Girshick for more thorough comparison.

The ICCV 2017 paper proposes the SGM loss, which makes the learned classifier from the few-shot examples have a smaller gradient value when learning on all examples.

The CVPR 2018 paper proposes the prototypical matching networks, a combination of prototypical network and matching network. The paper also adds hallucination, which generates new examples.

Different from these approaches, we directly learn a logistic regression classifier during the few-shot episode, which is very simple and straightforward. Although it has been shown to be worse in these prior work, we found that it can be improved significantly by backprop through the few-shot learning iterations to learn additional regularizer terms.


2) We think you might be mixing back-propagation through time (BPTT) commonly used to train recurrent neural networks with recurrent back-propagation (RBP). We are not trying to replace the SGD algorithm, but just proposing to use RBP to take the gradients. Typically, when training RNNs, people use backpropagation through time (BPTT), which unrolls the computation graph and takes the gradient. RBP is a different way of taking gradients, if the recurrent process converges to a fixed point. Here we found RBP is a better tool for learning the energy functions.
</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div></div></main></div>
  </div>
</div>


    <!-- Footer -->
    <footer class="sitemap">
      <div class="container">
        <div class="row hidden-xs">
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/venues">All Venues</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="/contact">Contact</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
    
        <div class="row visible-xs-block">
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/contact">Contact</a></li>
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
      </div>
    </footer>
    
    <footer class="sponsor">
      <div class="container">
        <div class="row">
          <div class="col-sm-10 col-sm-offset-1">
            <p class="text-center">
              OpenReview is created by the <a href="http://www.iesl.cs.umass.edu/" target="_blank">Information Extraction and Synthesis Laboratory</a>, College of Information and Computer Science, University of Massachusetts Amherst. We gratefully acknowledge the support of the OpenReview sponsors:  Google,  Facebook, NSF, the University of Massachusetts Amherst Center for Data Science, and Center for Intelligent Information Retrieval, as well as the Google Cloud Platform for donating the computing and networking services on which OpenReview.net runs.
            </p>
          </div>
        </div>
      </div>
    </footer>

  <div id="feedback-modal" class="modal fade" tabindex="-1" role="dialog">
    <div class="modal-dialog">
      <div class="modal-content">
        <div class="modal-header">
          <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button>
          <h3 class="modal-title">Send Feedback</h3>
        </div>
        <div class="modal-body">
          <p>Enter your feedback below and we'll get back to you as soon as possible.</p>
          <form action="/feedback" method="POST">
            <div class="form-group">
              <input type="email" name="from" class="form-control" placeholder="Email" />
            </div>
            <div class="form-group">
              <input type="text" name="subject" class="form-control" placeholder="Subject" />
            </div>
            <div class="form-group">
              <textarea name="message" class="form-control feedback-input" rows="5" placeholder="Message" required=""></textarea>
            </div>
          <ul id="ui-id-2" tabindex="0" class="ui-menu ui-widget ui-widget-content" style="display: none;"></ul></form>
        </div>
        <div class="modal-footer">
          <button type="button" class="btn btn-default" data-dismiss="modal">Cancel</button>
          <button type="button" class="btn btn-primary">Send</button>
        </div>
      </div>
    </div>
  </div>

  <script type="text/javascript" async="" src="https://www.google-analytics.com/analytics.js"></script><script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js"></script>
  <script>window.jQuery || document.write('&lt;script src="/static/js/vendor/jquery-2.2.4.min.js"&gt;&lt;\/script&gt;')</script>

  <script src="/static/dist/vendor.min.js"></script>
  <script src="/static/dist/templates.min.js"></script>
  <script src="/static/dist/openreview.min.js"></script>

    <script>window.legacyScripts = true;</script>


    <script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-108703919-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() { dataLayer.push(arguments); }
      gtag('js', new Date());
      gtag('config', 'UA-108703919-1');
    </script>


<div role="status" aria-live="assertive" aria-relevant="additions" class="ui-helper-hidden-accessible"></div></body></html>
<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" class="no-js"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>Linearizing Visual Processes with Deep Generative Models | OpenReview</title>
  <meta name="description" content="" />

      <meta name="citation_title" content="Linearizing Visual Processes with Deep Generative Models" />
        <meta name="citation_author" content="Anonymous" />
      <meta name="citation_publication_date" content="2018/09/27" />
      <meta name="citation_online_date" content="2018/09/27" />
      <meta name="citation_pdf_url" content="https://openreview.net/pdf?id=SkMPNoCcKQ" />
      <meta name="twitter:card" content="summary" />
      <meta name="twitter:site" content="@openreviewnet" />
      <meta name="og:title" content="Linearizing Visual Processes with Deep Generative Models" />
      <meta name="og:description" content="This work studies the problem of modeling non-linear visual processes by leveraging deep generative architectures for learning linear, Gaussian models of observed sequences. We propose a joint..." />
      <meta name="og:image" content="https://openreview.net/static/images/openreview_logo_512.png" />

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans:400,400i,700,700i" />

  <link rel="stylesheet" href="/static/css/bootstrap.min.css" />
  <link rel="stylesheet" href="/static/css/jquery-ui.min.css" />
  <link rel="stylesheet" href="/static/css/main.min.css" />
</head>

<body class="forum">
  <nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
  
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand home push-link" href="/"><strong>OpenReview</strong>.net</a>
      </div>
  
      <div id="navbar" class="navbar-collapse collapse">
        <form class="navbar-form navbar-left profile-search" role="search">
          <div class="form-group has-feedback">
            <input id="search_input" type="text" class="form-control ui-autocomplete-input" placeholder="Search ICLR 2019 Conference" autocomplete="off" />
            <span class="glyphicon glyphicon-search form-control-feedback" aria-hidden="true"></span>
          </div>
  
          <input id="search_group" type="hidden" value="ICLR.cc/2019/Conference" />
          <input id="search_content" type="hidden" value="all" />
        <ul id="ui-id-1" tabindex="0" class="ui-menu ui-widget ui-widget-content ui-autocomplete ui-front" style="display: none;"></ul></form>
  
        <ul class="nav navbar-nav navbar-right">
        
            <li id="user-menu"><a href="/login">Login</a></li>
        </ul>
      </div>
  
    </div>
  </nav>

  <div id="or-banner" class="banner" style="">
  <div class="container">
    <div class="row">
      <div class="col-xs-12"><a href="/group?id=ICLR.cc/2019/Conference" title="Venue Homepage"><img class="icon" src="/static/images/arrow_left.svg" /> Go to <strong>ICLR 2019 Conference</strong> homepage</a></div>
    </div>
  </div>
</div>
<div id="flash-message-container" class="alert alert-danger" role="alert" style="display: none;">
  <div class="container">
    <div class="row">
      <div class="col-xs-12">
        <div class="alert-content">
          <button type="button" class="close" aria-label="Close"><span aria-hidden="true">Ã—</span></button>
        </div>
      </div>
    </div>
  </div>
</div>

<div class="container">
  <div class="row">
    <div class="col-xs-12">
      <main id="content" class="clearfix openbanner-visible legacy-styles"><div id="note_SkMPNoCcKQ" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Linearizing Visual Processes with Deep Generative Models</a> <a class="note_content_pdf" href="/pdf?id=SkMPNoCcKQ" title="Download PDF" target="_blank"><img src="/static/images/pdf_icon_blue.svg" /></a> </h2></div><div class="meta_row"><span class="signatures">Anonymous</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">28 Sep 2018 (modified: 11 Oct 2018)</span><span class="item">ICLR 2019 Conference Blind Submission</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span><span class="item"><a class="action-bibtex-modal" data-bibtex="@inproceedings{    &#10;anonymous2019linearizing,    &#10;title={Linearizing Visual Processes with Deep Generative Models},    &#10;author={Anonymous},    &#10;booktitle={Submitted to International Conference on Learning Representations},    &#10;year={2019},    &#10;url={https://openreview.net/forum?id=SkMPNoCcKQ},    &#10;note={under review}    &#10;}">Show Bibtex</a></span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Abstract: </span><span class="note_content_value">This work studies the problem of modeling non-linear visual processes by leveraging deep generative architectures for learning linear, Gaussian models of observed sequences. We propose a joint learning framework, combining a multivariate autoregressive model and deep convolutional generative networks. After justification of theoretical assumptions of inearization, we propose an architecture that allows Variational Autoencoders and Generative Adversarial Networks to simultaneously learn the non-linear observation as well as the linear state-transition model from a sequence of observed frames. Finally, we demonstrate our approach on conceptual toy examples and dynamic textures.</span></div><div class="note_contents"><span class="note_content_field">Keywords: </span><span class="note_content_value">Genearative Adversarial Network, Variational Autoencoder, Wasserstein GAN, Autoregressive Model, Dynamic Texture, Video</span></div><div class="note_contents"><span class="note_content_field">TL;DR: </span><span class="note_content_value">We model non-linear visual processes as autoregressive noise via generative deep learning.</span></div><div class="reply_row clearfix"><div class="item" id="reply_count">3 Replies</div></div></div><hr class="small" /><div id="note_children"><div class="note_with_children"><div id="note_r1xAIMd33m" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>[Review] Linearizing Visual Processes with Deep Generative Models</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=SkMPNoCcKQ&amp;noteId=r1xAIMd33m"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper10 AnonReviewer3</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">04 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper10 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">[Paper Summary]
- The proposed work proposes a new method that model non-linear visual process with a deep version of a linear process (Markov process). The latent space is described by the linear process and the nonlinear mapping function from the latent space to image distribution.

[Pros]
- The model gives a well defined deep approximation to the Markov process (with Gaussian Form). The reviewer didn't follow every detailed step, but the overall direction seems fair.

[Cons]
- First of all, the practical strongpoints of the proposed work (applying linear process) compared to the existing deep sequential approaches (using the recurrent network) are not well investigated. The reviewer was difficult to find the benefit of using the proposed algorithm than RNN+VAE such as DRAW [1]. The proposed method can also use GAN for latent-to-image mapping, but using GAN to sequential model itself is not a novel techniques [2]. Maybe the existence of variance would be the difference, then the author should clarify it into the experiment section (more than the current version).

[1] Gregor, Karol, et al. "Draw: A recurrent neural network for image generation." arXiv preprint arXiv:1502.04623 (2015).
[2] Walker, Jacob, et al. "The pose knows: Video forecasting by generating pose futures." Computer Vision (ICCV), 2017 IEEE International Conference on. IEEE, 2017.

- Related work seems to omit some of the similar existing studies. The author should clarify the novelty of the proposed work from the mentioned papers.

[1] Karl, Maximilian, et al. "Deep variational bayes filters: Unsupervised learning of state space models from raw data." arXiv preprint arXiv:1605.06432 (2016).
[2] Gao, Yuanjun, et al. "Linear dynamical neural population models through nonlinear embeddings." Advances in neural information processing systems. 2016.
[3] Yoo, Y., Yun, S., Chang, H. J., Demiris, Y., &amp; Choi, J. Y. (2017, July). Variational autoencoded regression: high dimensional regression of visual data on complex manifold. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (pp. 3674-3683).

- The video generation sequence in figure 5 seems little trivial because most parts of the image are static. Is it possible to try the model with more complicated video such as UCF 101 (like [1])?

[1] Walker, Jacob, et al. "An uncertain future: Forecasting from static images using variational autoencoders." European Conference on Computer Vision. Springer, Cham, 2016.

[Summary]
The proposed paper provides well described linear model approximated by the deep network.  However, the reviewer is still skeptical for the novelty of the paper, and the strong point of the work compared to the existing deep sequence generation algorithms. The profound explanation of the problems would be required.
</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">3: Clear rejection</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_SJgelgdi3X" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>promising direction, but some important math mistakes and no baselines</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=SkMPNoCcKQ&amp;noteId=SJgelgdi3X"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper10 AnonReviewer2</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">04 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper10 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">This paper proposes a new deep generative model for sequences, particularly image sequences and video. By utilizing a linear structure in part of the model, this work aims to offer more efficient sampling, while also aiming for a simpler training procedure.


Unfortunately there are some important mistakes in the mathematical justification of the method provided in Section 3. One is the claim that "Eq. (1) is a special case of Eq. (2) ..." and later "The model Eq. (2) describes a much broader class of visual processes than Eq. (1)." A counterexample is to take n=2, d=1, and

A = [[ cos(\pi/4) -sin(\pi/4) ]
     [ sin(\pi/4)  cos(\pi/4) ]]
C = [[ 1 0 ]]
\bar{y} = 0

Since C^+ is [[ 1 ] [ 0 ]], the provided formula does not recover the periodic dynamics of Eq. (1) and is instead just a mean-reverting random walk. To make the counterexample more extreme, we can take n=1000 and d=1 with an A matrix that exhibits 500 distinct frequencies (with eigenvalues in complex conjugate pairs) and with C = [[ 1 1 ... 1 ]], then clearly in Eq. (1) the dynamical behavior is a sum of 500 oscillators, which can't be recovered by Eq. (2) (in which y_{t+1} depends only on y_{t}). More precisely, with d=1 Eq. (1) can represent a stationary process with any rational power spectral density (up to the right degree, depending on n) but Eq. (2), being first-order Markov on the observation sequence (stated as Assumption 1) can't. (It's incorrectly implied near the bottom of p. 2 that processes following the dynamics of Eq. (1) are first-order Markov on the y sequence, but they're not; that's the purpose of having a latent state.)

There are some other issues in Section 3 that are not mistakes but are unclear. It's inaccurate to describe C as a diffeomorphism (just before Sec 3.2) and \Gamma : R^d \to R^n as a diffeomorphism, since diffeomorphisms must be invertible and here n &lt; d, though it's clear from context that you mean their appropriate restrictions are diffeomorphisms. Remark 1 states the process noise must have covariance I - AA' without stating that, in addition to choosing a basis for the latent space in which states have a marginal standard Gaussian distribution, it must be chosen so that I - AA' is positive definite. The initial state distribution is not taken to be the stationary distribution of the latent state dynamics, yet a basis can only be chosen to satisfy Assumption 2 in stationarity. Some of the mathematics in Section 3.2 is unnecessary; \Gamma essentially serves as a coordinate chart, and notions of fixed points on manifolds (as in Proposition 1) is textbook stuff.

In the description of the learning procedure, no overall objective is specified, and the treatment of the constraint in Eq. (15) is weak (a squared Frobenius penalty is simply added into the objective).

One consequence of these correctness and clarity issues is that it's hard to understand how to relate this work to other ideas. In addition to having a general related works section, this paper should contrast the proposed model and fitting procedure with others. For example, how does this compare to fitting a nonlinear AR(1) model? Or an autoregressive model for p(y_{t+1} | y_t, ..., y_1) parameterized by an RNN? Or any of the various latent variable generative models for videos based on VAE architectures?


The other main issue with the current paper is a lack of baselines. As far as I can tell, there are no baselines of comparison in the experiments section. One clear baseline would be a nonlinear AR(1) model parameterizing p(h_{t+1} | h_t) directly, perhaps as a Gaussian with mean and variance that depend on h_t through a neural network. But there are lots of video models at this point, of both the autoregressive and latent variable flavor, and this paper must include some comparisons. Moreover, the modeling tasks considered here seem nonstandard.

To make up for the clarity and correctness issues with the mathematical justification of the approach in the paper as currently written, the results would have to be especially impressive compared to strong baselines, but the experiments section does not give enough information to make that evaluation.


Overall, there are some interesting ideas here but the paper needs more work to polish the mathematics and to produce convincing experiments.


Some minor suggestions:
 * It's confusing to write "linear, Gaussian models of observed sequences" in the abstract, since the models are not (completely) linear and the resulting distribution on observations is not Gaussian.
 * Since the model in Eq. (3) is one of those considered in the SVAE paper (namely in Sec 2.2 of the SVAE paper), and probably also in earlier works, it's worth citing some related work around Eq. (3).
 * It might be interesting to draw a comparison to subspace identification methods like 4SID, as described in "Subspace Identification for Linear Systems" by van Overschee and de Moor, or spectral methods for HMMs, as in "A Spectral Algorithm for learning Hidden Markov Models" by Hsu, Kakade, and Zhang.
 * It might be helpful to rename "MAR" to "VAR" for "vector autoregressive", since "MA" often stands for "moving average" in the context of VARMA models.
 * Writing "due to the curse of dimensionality" in Sec 3.2 is vague; what do you mean there?</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">3: Clear rejection</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_rJxOBJlRsX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>A nice idea and model with really lacking experimental validation</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=SkMPNoCcKQ&amp;noteId=rJxOBJlRsX"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper10 AnonReviewer1</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">24 Oct 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper10 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">Quick summary:

The author investigate if we can learn a linearized state space model using deep generative models to guide and transform non-linear dynamic observations into linear state space processes. A quick analysis of the feasibilty of the model and its relation to existing models is provided. Experimental results include a GAN and a VAE as the generative model on a few datasets.

Pros:

  - The model is interesting and the motivation is quite clear
  - analysis is quite nice
  - writing is quite clear and decent

Cons:

 - Extremely lacking experimental validation - there are literally no baseline models, no numbers or any kind of quantitative analysis. The figures show samples from the model with very little explanation or discussion and it's entirely unclear what we learn from this model. Scientifically speaking, this is not up to par.

Bottom line - I think this is a good start for a paper about an interesting model, but I don't feel that this teaches us anything about what the model learns and how it relates in practice to other models.</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">4: Ok but not good enough - rejection</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">3: The reviewer is fairly confident that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></main></div>
  </div>
</div>


    <!-- Footer -->
    <footer class="sitemap">
      <div class="container">
        <div class="row hidden-xs">
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/venues">All Venues</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="/contact">Contact</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
    
        <div class="row visible-xs-block">
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/contact">Contact</a></li>
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
      </div>
    </footer>
    
    <footer class="sponsor">
      <div class="container">
        <div class="row">
          <div class="col-sm-10 col-sm-offset-1">
            <p class="text-center">
              OpenReview is created by the <a href="http://www.iesl.cs.umass.edu/" target="_blank">Information Extraction and Synthesis Laboratory</a>, College of Information and Computer Science, University of Massachusetts Amherst. We gratefully acknowledge the support of the OpenReview sponsors:  Google,  Facebook, NSF, the University of Massachusetts Amherst Center for Data Science, and Center for Intelligent Information Retrieval, as well as the Google Cloud Platform for donating the computing and networking services on which OpenReview.net runs.
            </p>
          </div>
        </div>
      </div>
    </footer>

  <div id="feedback-modal" class="modal fade" tabindex="-1" role="dialog">
    <div class="modal-dialog">
      <div class="modal-content">
        <div class="modal-header">
          <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">Ã—</span></button>
          <h3 class="modal-title">Send Feedback</h3>
        </div>
        <div class="modal-body">
          <p>Enter your feedback below and we'll get back to you as soon as possible.</p>
          <form action="/feedback" method="POST">
            <div class="form-group">
              <input type="email" name="from" class="form-control" placeholder="Email" />
            </div>
            <div class="form-group">
              <input type="text" name="subject" class="form-control" placeholder="Subject" />
            </div>
            <div class="form-group">
              <textarea name="message" class="form-control feedback-input" rows="5" placeholder="Message" required=""></textarea>
            </div>
          <ul id="ui-id-2" tabindex="0" class="ui-menu ui-widget ui-widget-content" style="display: none;"></ul></form>
        </div>
        <div class="modal-footer">
          <button type="button" class="btn btn-default" data-dismiss="modal">Cancel</button>
          <button type="button" class="btn btn-primary">Send</button>
        </div>
      </div>
    </div>
  </div>

  <script type="text/javascript" async="" src="https://www.google-analytics.com/analytics.js"></script><script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js"></script>
  <script>window.jQuery || document.write('&lt;script src="/static/js/vendor/jquery-2.2.4.min.js"&gt;&lt;\/script&gt;')</script>

  <script src="/static/dist/vendor.min.js"></script>
  <script src="/static/dist/templates.min.js"></script>
  <script src="/static/dist/openreview.min.js"></script>

    <script>window.legacyScripts = true;</script>


    <script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-108703919-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() { dataLayer.push(arguments); }
      gtag('js', new Date());
      gtag('config', 'UA-108703919-1');
    </script>


<div role="status" aria-live="assertive" aria-relevant="additions" class="ui-helper-hidden-accessible"></div></body></html>
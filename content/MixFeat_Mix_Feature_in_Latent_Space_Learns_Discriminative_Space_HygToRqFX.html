<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" class="no-js"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>MixFeat: Mix Feature in Latent Space Learns Discriminative Space | OpenReview</title>
  <meta name="description" content="" />

      <meta name="citation_title" content="MixFeat: Mix Feature in Latent Space Learns Discriminative Space" />
        <meta name="citation_author" content="Anonymous" />
      <meta name="citation_publication_date" content="2018/09/27" />
      <meta name="citation_online_date" content="2018/09/27" />
      <meta name="citation_pdf_url" content="https://openreview.net/pdf?id=HygT9oRqFX" />
      <meta name="twitter:card" content="summary" />
      <meta name="twitter:site" content="@openreviewnet" />
      <meta name="og:title" content="MixFeat: Mix Feature in Latent Space Learns Discriminative Space" />
      <meta name="og:description" content="Deep learning methods perform well in various tasks. However, the over-fitting problem remains, where the performance decreases for unknown data. We here provide a novel method named MixFeat, which..." />
      <meta name="og:image" content="https://openreview.net/static/images/openreview_logo_512.png" />

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans:400,400i,700,700i" />

  <link rel="stylesheet" href="/static/css/bootstrap.min.css" />
  <link rel="stylesheet" href="/static/css/jquery-ui.min.css" />
  <link rel="stylesheet" href="/static/css/main.min.css" />
</head>

<body class="forum">
  <nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
  
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand home push-link" href="/"><strong>OpenReview</strong>.net</a>
      </div>
  
      <div id="navbar" class="navbar-collapse collapse">
        <form class="navbar-form navbar-left profile-search" role="search">
          <div class="form-group has-feedback">
            <input id="search_input" type="text" class="form-control ui-autocomplete-input" placeholder="Search ICLR 2019 Conference" autocomplete="off" />
            <span class="glyphicon glyphicon-search form-control-feedback" aria-hidden="true"></span>
          </div>
  
          <input id="search_group" type="hidden" value="ICLR.cc/2019/Conference" />
          <input id="search_content" type="hidden" value="all" />
        <ul id="ui-id-1" tabindex="0" class="ui-menu ui-widget ui-widget-content ui-autocomplete ui-front" style="display: none;"></ul></form>
  
        <ul class="nav navbar-nav navbar-right">
        
            <li id="user-menu"><a href="/login">Login</a></li>
        </ul>
      </div>
  
    </div>
  </nav>

  <div id="or-banner" class="banner" style="">
  <div class="container">
    <div class="row">
      <div class="col-xs-12"><a href="/group?id=ICLR.cc/2019/Conference" title="Venue Homepage"><img class="icon" src="/static/images/arrow_left.svg" /> Go to <strong>ICLR 2019 Conference</strong> homepage</a></div>
    </div>
  </div>
</div>
<div id="flash-message-container" class="alert alert-danger" role="alert" style="display: none;">
  <div class="container">
    <div class="row">
      <div class="col-xs-12">
        <div class="alert-content">
          <button type="button" class="close" aria-label="Close"><span aria-hidden="true">×</span></button>
        </div>
      </div>
    </div>
  </div>
</div>

<div class="container">
  <div class="row">
    <div class="col-xs-12">
      <main id="content" class="clearfix openbanner-visible legacy-styles"><div id="note_HygT9oRqFX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>MixFeat: Mix Feature in Latent Space Learns Discriminative Space</a> <a class="note_content_pdf" href="/pdf?id=HygT9oRqFX" title="Download PDF" target="_blank"><img src="/static/images/pdf_icon_blue.svg" /></a> </h2></div><div class="meta_row"><span class="signatures">Anonymous</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">28 Sep 2018 (modified: 11 Oct 2018)</span><span class="item">ICLR 2019 Conference Blind Submission</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span><span class="item"><a class="action-bibtex-modal" data-bibtex="@inproceedings{    &#10;anonymous2019mixfeat:,    &#10;title={MixFeat: Mix Feature in Latent Space Learns Discriminative Space},    &#10;author={Anonymous},    &#10;booktitle={Submitted to International Conference on Learning Representations},    &#10;year={2019},    &#10;url={https://openreview.net/forum?id=HygT9oRqFX},    &#10;note={under review}    &#10;}">Show Bibtex</a></span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Abstract: </span><span class="note_content_value">Deep learning methods perform well in various tasks. However, the over-fitting problem remains, where the performance decreases for unknown data. We here provide a novel method named MixFeat, which directly makes the latent space discriminative. MixFeat mixes two feature maps in each latent space and uses one of their labels for learning. We report improved results obtained using existing network models with MixFeat on CIFAR-10/100 datasets. In addition, we show that MixFeat effectively reduces the over-fitting problem even in the case that the training dataset is small or contains errors. We argue that MixFeat is complementary with existing methods that mix both images and labels, in that MixFeat is suitable for discrimination tasks while existing methods are suitable for regression tasks. MixFeat is easy to implement and can be added to various network models without additional computational cost in the inference phase.</span></div><div class="note_contents"><span class="note_content_field">Keywords: </span><span class="note_content_value">regularization, generalization, image classification, latent space, feature learning</span></div><div class="note_contents"><span class="note_content_field">TL;DR: </span><span class="note_content_value">We provide a novel method named MixFeat, which directly makes the latent space discriminative.</span></div><div class="reply_row clearfix"><div class="item" id="reply_count">3 Replies</div></div></div><hr class="small" /><div id="note_children"><div class="note_with_children"><div id="note_Syl8D1dqhX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Interesting idea, but missing clear explanations and important baselines.</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HygT9oRqFX&amp;noteId=Syl8D1dqhX"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper572 AnonReviewer3</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">03 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper572 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">This paper follows a recent trend to improve generalization by mixing data from training samples, in this case by mixing feature maps from different samples in the latent space. One of the feature maps is added as a kind of perturbation to the other one, so only the label from the main feature map is used as the learning target. MixFeat, the proposed method of adding ‘noise’ from another learning sample is tested on CIFAR-10 and CIFAR-100 with different architectures. The authors claim that the proposed method makes the latent space more discriminative. Multiple experiments show that it helps to avoid over-fitting. 

The core idea of mixing the latent spaces of two data samples is interesting and the results seem to indicate that it improves generalization, but I have two main criticisms of this work. First, it is unclear as to why this this approach works (or why it works better than similar methods) and the explanations offered are not satisfactory. The phrase “making features discriminative in the latent space” is used repeatedly, but it is not obvious exactly what is meant by this. Design choices are also not clearly motivated, for example what is the advantage of defining a and b as was done? The second criticism is that comparisons to manifold mixup should have been included.

Approach: 
- In “1 Introduction”, the second contribution of presenting “a guideline for judging whether labels should be mixed when mixing features for an individual purpose” is not clearly communicated. 
- Figure 1 is a nice idea to illustrate the types of mixed feature distributions, but is not convincing as a toy example. A visualization of how mixed features are placed in the learned latent space for real data would be more informative. The examples showing 0.4A+0.6B and 0.6A+0.4B are confusing - it’s not clear exactly how it relates to the formulation in (1).  
- In “2.3 Computation of MixFeat” there is no clear explanation on why the authors chose a and b. Can they just be some other random small values? Is it necessary to have this correlation (cos and sin) between two feature maps we want to mix? Questions like these are not clearly explained. Similar questions can be applied to formula (4) and (6). 
+ Explicitly pointing out how backpropagation works for MixFeat in (2) (5) (7) and Figure 2 is helpful.

Experiments: 
- The authors mentioned important related works in both “1 Introduction” and “4 Relationship with Previous Work”, but in Table 1, they compared the MixFeat with only standard Mixup. Manifold Mixup would be a  better comparison as it has better performance than standard mixup and is more closely related to MixFeat - MixFeat mixes features in every latent space while Manifold Mixup does in a randomly selected space (and standard mixup only mixes the inputs). 
- The method could be described as "adding some noise along samples' latent feature directions". An interesting perspective, and would have been nice to see a comparison of MixFeat vs. perturbing with gaussian noise to see how much the direction towards other examples helps.
+ The experiments to demonstrate the effectiveness of MixFeat for avoiding over-fitting are strong (aside from the missing baseline). The experiments showing robustness to different incorrect label ratios and with different training data size are convincing.
- In Figure 6 center, the x-axis is  or ( for original MixFeat and 1D-MixFeat, and  for Inner-MixFeat), but the authors didn’t make a clear distinction in both the figure caption and “3.3.1 Dimensions and Direction of the Distribution”, having it wrong for Inner-MixFeat with “6.94% ( = 0.02)” which should be “( = 0.02)”. 
+ The ablation study motivating the choice of where to apply MixFeat was appreciated.

Related works
+ Clearly presented and covered the relevant literature. 
- It would be helpful if the differences between MixFeat and the Mixup family is more clearly stated.
</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">5: Marginally below acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_B1eUiowt2Q" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Review</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HygT9oRqFX&amp;noteId=B1eUiowt2Q"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper572 AnonReviewer1</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">02 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper572 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">This paper proposes a method, so-called MixFeat that can mix features and labels. This method is in a similar line of the methods such as mixup and manifold mixup. 

pros)
(+) The proposed method looks simple and would have low computation cost at inference phase.
(+) The experiment of evaluating the possibility of reducing the number of datasets looks good.

cons)
(-) The advantages of the proposed method are not clarified. There should be at least one insight why this method can outperform others.
(+) Decomposition of r and theta in eq.(1) looks interesting, but there is no supporting ground to grasp the implicit meaning of this idea. Why the parameters a and b are reparameterized with r and theta?
(-) Figure 1 is not clearly illustrated and confusing. Just looking at the figure, one can understand mixup is better than others.
(-) This paper does not contain any results validated on ImageNet dataset. This kind of method should show the effectiveness on a large scale dataset such as ImageNet dataset.

comments)
- It would be better to compare with Shake-type method (shake-drop (<a href="https://arxiv.org/pdf/1802.02375.pdf)," target="_blank" rel="nofollow">https://arxiv.org/pdf/1802.02375.pdf),</a> shake-shake) and SwapOut (https://arxiv.org/pdf/1605.06465.pdf). 
- The performance of PyramidNet in Table 1 looks different from the original one in the original paper (https://arxiv.org/pdf/1610.02915.pdf).

The paper proposes an interesting idea, but it does not provide any insights on why it works or why the authors did like this. Furthermore, the experiments need to contain the results on a large scale dataset, and from the formulation eq.(1), the proposed method looks similar to a single-path shake-drop or shake-shake, so the authors should compare with those methods.</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">4: Ok but not good enough - rejection</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_rkeswodvh7" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Review</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HygT9oRqFX&amp;noteId=rkeswodvh7"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper572 AnonReviewer2</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">01 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper572 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">The paper proposes a method MixFeat for regularizing deep neural networks models, aiming at avoiding overfitting in training. The MixFeat interpolates, based on a careful selected mixing ratio, the hidden states (feature maps) of two randomly selected examples. Unlike MixUp, the MixFeat does not interpolate the labels of the two selected examples and the feature interpolation processes are conducted in the hidden space. Experiments on both Cifar10 and Cifar100 show that the networks with MixFeat improve their predictive accuracy as well as outperform networks with Mixup as regularizer.   

The paper is well written and easy to follow, and the experimental results on both Cifar10 and Cifar100 show promising results. Nevertheless, the idea of interpolating pairs of latent features for network regularization is not very novel. Additional, the experimental section is a bit weak in its current form. 

Main Remarks:

1.	MixFeat is very similar to Manifold-Mixup (Verma et al., Manifold Mixup: Learning Better Representations by Interpolating Hidden States), where both feature maps and labels of a pair of examples are mixed, so Manifold-Mixup would be a valid comparison baseline to MixFeat. In addition, the proposed method is similar to SMOTE (where features are mixed in the input space). In this sense, performance of SMOTE may be a useful comparison baseline as well.
2.	In the experimental section, the choice of parameter for Mixup seems arbitrary to me and may not be the optimal one. For example, for the Cifar10 and Cifar100 datasets, the original paper highlights that Alpha equals to one is a better choice to obtain better accuracy for ResNet. Also, as highlighted from AdaMixup (Guo et al., MixUp as Locally Linear Out-Of-Manifold Regularization), MixUp is quite sensitive to the choice of Alpha and suboptimal Alpha value easily leads to underfitting. 
3.	Some claims are not well justified. For example, the authors claim that MixFeat can reduce overfitting even with datasets with small sample size, but did not provide any training cost or errors in Figure6 to support that claim. 
4.	MixFeat is closely related to MixUp, and I would like to see more experiments with MixUp as baseline in terms of regularization effect. For example, it would be useful to include MixUp in Figures 4 and 6.

Minor remarks: 

1.	What were the parameters for MixFeat used for Table 1?
2.	Is the proposed method robust to adversarial examples as shown in MixUp and ManiFold-Mixup?
3.	How the incorrect labels are generated in Section 3.2.1 is not very clear to me.
4.	Since MixFeat is similar to Mixup, I wonder if MixFeat has the problem of “manifold intrusion” as suggested in AdaMixUp when generating samples from image pairs?  How sensitive is MixFeat to the parameters Theta and Pi? Would learning mixing policies as suggested by AdaMixUp make sense here?
</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">4: Ok but not good enough - rejection</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">3: The reviewer is fairly confident that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></main></div>
  </div>
</div>


    <!-- Footer -->
    <footer class="sitemap">
      <div class="container">
        <div class="row hidden-xs">
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/venues">All Venues</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="/contact">Contact</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
    
        <div class="row visible-xs-block">
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/contact">Contact</a></li>
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
      </div>
    </footer>
    
    <footer class="sponsor">
      <div class="container">
        <div class="row">
          <div class="col-sm-10 col-sm-offset-1">
            <p class="text-center">
              OpenReview is created by the <a href="http://www.iesl.cs.umass.edu/" target="_blank">Information Extraction and Synthesis Laboratory</a>, College of Information and Computer Science, University of Massachusetts Amherst. We gratefully acknowledge the support of the OpenReview sponsors:  Google,  Facebook, NSF, the University of Massachusetts Amherst Center for Data Science, and Center for Intelligent Information Retrieval, as well as the Google Cloud Platform for donating the computing and networking services on which OpenReview.net runs.
            </p>
          </div>
        </div>
      </div>
    </footer>

  <div id="feedback-modal" class="modal fade" tabindex="-1" role="dialog">
    <div class="modal-dialog">
      <div class="modal-content">
        <div class="modal-header">
          <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button>
          <h3 class="modal-title">Send Feedback</h3>
        </div>
        <div class="modal-body">
          <p>Enter your feedback below and we'll get back to you as soon as possible.</p>
          <form action="/feedback" method="POST">
            <div class="form-group">
              <input type="email" name="from" class="form-control" placeholder="Email" />
            </div>
            <div class="form-group">
              <input type="text" name="subject" class="form-control" placeholder="Subject" />
            </div>
            <div class="form-group">
              <textarea name="message" class="form-control feedback-input" rows="5" placeholder="Message" required=""></textarea>
            </div>
          <ul id="ui-id-2" tabindex="0" class="ui-menu ui-widget ui-widget-content" style="display: none;"></ul></form>
        </div>
        <div class="modal-footer">
          <button type="button" class="btn btn-default" data-dismiss="modal">Cancel</button>
          <button type="button" class="btn btn-primary">Send</button>
        </div>
      </div>
    </div>
  </div>

  <script type="text/javascript" async="" src="https://www.google-analytics.com/analytics.js"></script><script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js"></script>
  <script>window.jQuery || document.write('&lt;script src="/static/js/vendor/jquery-2.2.4.min.js"&gt;&lt;\/script&gt;')</script>

  <script src="/static/dist/vendor.min.js"></script>
  <script src="/static/dist/templates.min.js"></script>
  <script src="/static/dist/openreview.min.js"></script>

    <script>window.legacyScripts = true;</script>


    <script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-108703919-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() { dataLayer.push(arguments); }
      gtag('js', new Date());
      gtag('config', 'UA-108703919-1');
    </script>


<div role="status" aria-live="assertive" aria-relevant="additions" class="ui-helper-hidden-accessible"></div></body></html>
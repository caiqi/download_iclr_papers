<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" class="no-js"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>Explicit Information Placement on Latent Variables using Auxiliary Generative Modelling Task | OpenReview</title>
  <meta name="description" content="" />

      <meta name="citation_title" content="Explicit Information Placement on Latent Variables using Auxiliary Generative Modelling Task" />
        <meta name="citation_author" content="Anonymous" />
      <meta name="citation_publication_date" content="2018/09/27" />
      <meta name="citation_online_date" content="2018/09/27" />
      <meta name="citation_pdf_url" content="https://openreview.net/pdf?id=H1l-SjA5t7" />
      <meta name="twitter:card" content="summary" />
      <meta name="twitter:site" content="@openreviewnet" />
      <meta name="og:title" content="Explicit Information Placement on Latent Variables using Auxiliary..." />
      <meta name="og:description" content="Deep latent variable models, such as variational autoencoders, have been successfully used to disentangle factors of variation in image datasets. The structure of the representations learned by..." />
      <meta name="og:image" content="https://openreview.net/static/images/openreview_logo_512.png" />

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans:400,400i,700,700i" />

  <link rel="stylesheet" href="/static/css/bootstrap.min.css" />
  <link rel="stylesheet" href="/static/css/jquery-ui.min.css" />
  <link rel="stylesheet" href="/static/css/main.min.css" />
</head>

<body class="forum">
  <nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
  
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand home push-link" href="/"><strong>OpenReview</strong>.net</a>
      </div>
  
      <div id="navbar" class="navbar-collapse collapse">
        <form class="navbar-form navbar-left profile-search" role="search">
          <div class="form-group has-feedback">
            <input id="search_input" type="text" class="form-control ui-autocomplete-input" placeholder="Search ICLR 2019 Conference" autocomplete="off" />
            <span class="glyphicon glyphicon-search form-control-feedback" aria-hidden="true"></span>
          </div>
  
          <input id="search_group" type="hidden" value="ICLR.cc/2019/Conference" />
          <input id="search_content" type="hidden" value="all" />
        <ul id="ui-id-1" tabindex="0" class="ui-menu ui-widget ui-widget-content ui-autocomplete ui-front" style="display: none;"></ul></form>
  
        <ul class="nav navbar-nav navbar-right">
        
            <li id="user-menu"><a href="/login">Login</a></li>
        </ul>
      </div>
  
    </div>
  </nav>

  <div id="or-banner" class="banner" style="">
  <div class="container">
    <div class="row">
      <div class="col-xs-12"><a href="/group?id=ICLR.cc/2019/Conference" title="Venue Homepage"><img class="icon" src="/static/images/arrow_left.svg" /> Go to <strong>ICLR 2019 Conference</strong> homepage</a></div>
    </div>
  </div>
</div>
<div id="flash-message-container" class="alert alert-danger" role="alert" style="display: none;">
  <div class="container">
    <div class="row">
      <div class="col-xs-12">
        <div class="alert-content">
          <button type="button" class="close" aria-label="Close"><span aria-hidden="true">Ã—</span></button>
        </div>
      </div>
    </div>
  </div>
</div>

<div class="container">
  <div class="row">
    <div class="col-xs-12">
      <main id="content" class="clearfix openbanner-visible legacy-styles"><div id="note_H1l-SjA5t7" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Explicit Information Placement on Latent Variables using Auxiliary Generative Modelling Task</a> <a class="note_content_pdf" href="/pdf?id=H1l-SjA5t7" title="Download PDF" target="_blank"><img src="/static/images/pdf_icon_blue.svg" /></a> </h2></div><div class="meta_row"><span class="signatures">Anonymous</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">28 Sep 2018 (modified: 19 Nov 2018)</span><span class="item">ICLR 2019 Conference Blind Submission</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span><span class="item"><a class="action-bibtex-modal" data-bibtex="@inproceedings{    &#10;anonymous2019explicit,    &#10;title={Explicit Information Placement on Latent Variables using Auxiliary Generative Modelling Task},    &#10;author={Anonymous},    &#10;booktitle={Submitted to International Conference on Learning Representations},    &#10;year={2019},    &#10;url={https://openreview.net/forum?id=H1l-SjA5t7},    &#10;note={under review}    &#10;}">Show Bibtex</a></span><a class="note_content_pdf item" href="/revisions?id=H1l-SjA5t7" target="_blank">Show Revisions</a></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Abstract: </span><span class="note_content_value">Deep latent variable models, such as variational autoencoders, have been successfully used to disentangle factors of variation in image datasets. The structure of the representations learned by such models is usually observed after training and iteratively refined by tuning the network architecture and loss function. Here we propose a method that can explicitly place information into a specific subset of the latent variables. We demonstrate the use of the method in a task of disentangling global structure from local features in images. One subset of the latent variables is encouraged to represent local features through an auxiliary modelling task. In this auxiliary task, the global structure of an image is destroyed by dividing it into pixel patches which are then randomly shuffled. The full set of latent variables is trained to model the original data, obliging the remainder of the latent representation to model the global structure. We demonstrate that this approach successfully disentangles the latent variables for global structure from local structure by observing the generative samples of SVHN and CIFAR10. We also clustering the disentangled global structure of SVHN and found that the emerging clusters represent meaningful groups of global structures â€“ including digit identities and the number of digits presence. Finally, we discuss the problem of evaluating the clustering accuracy when ground truth categories are not expressive enough.</span></div><div class="note_contents"><span class="note_content_field">TL;DR: </span><span class="note_content_value">We propose a method that can explicitly place information into a specific subset of the latent variables in deep generative models.  We demonstrate the use of the method in a task of disentangling global structure from local features in images.  </span></div><div class="note_contents"><span class="note_content_field">Keywords: </span><span class="note_content_value">disentanglement, vae, clustering, prior imposition, deep generative models</span></div><div class="reply_row clearfix"><div class="item" id="reply_count">9 Replies</div></div></div><hr class="small" /><div id="note_children"><div class="note_with_children"><div id="note_HklzaBc32m" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>An interesting model without enough experimental justifications</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=H1l-SjA5t7&amp;noteId=HklzaBc32m"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper61 AnonReviewer1</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">04 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper61 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">This paper proposed a new training framework to disentangle global structures from local structures 
based on Variational Autoencoders (VAEs). They first generate a transformed image by shuffling the 
patches of the original image to destroy the global structures. The training task forces the model to
reconstruct the original image and shuffled images from different latent variables, thus separating 
global long-range structural correlations and local patch-wise correlations .

Instead of adjusting the objective function or model structure, the paper proposed a new and simple
training framework to disentangle the global and local structures, which is novel. 

The experiment results are good on SVHN. Some visual inspection experiments on CIFAR10 are performed. 
The plot (Figure2 (d)) is very blurry and people cannot really tell local structure from it. The rest experiments 
are all based on SVHN, which is too simple. 

More experiments based on other types of data sets with clear global structures such as faces or stop signs will 
be more convincing.

In the digit dataset, the local and global structures are relatively easy to separate. However, in Table 1, the 
performance of VAE+Auxiliary is not better than two of the other methods.

The idea in this paper is novel but experiments do not seem to be enough. More experiments on datasets 
with clear global and local structure separations with careful analyses are required to make the paper stronger.</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">6: Marginally above acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_BJlSjVJxAQ" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Thanks for your review</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=H1l-SjA5t7&amp;noteId=BJlSjVJxAQ"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper61 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">19 Nov 2018</span><span class="item">ICLR 2019 Conference Paper61 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">We would like to thank Reivewer 1 for your time and the review.
We agree that more experiments based on other types of dataset will make the result stronger which we hope to perform in a follow up work. However, we believe that the current results already give substantial evidences that the method successfully disentangle local and global structure.

While the performance of VAE+Auxiliary in digit identity clustering is not higher than two of the other methods, we found that the grouping can corresponds to other global features such as how many digits are in the image and the global-colour style. Therefore, the lower clustering accuracy does not mean that the method poorly disentangle local and global information but rather suggesting that the digit identity clustering is an incomplete evaluation metric for unsupervised clustering. We hope that reviewer 1 see that, in the context of this paper, the experiments have substantially fulfilled their proposed of showing that the method can disentangle global and local information as intended.</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div><div class="note_with_children"><div id="note_rklJyvKq3X" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Good paper; a broader analysis beyond global-local disentanglement is desirable.</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=H1l-SjA5t7&amp;noteId=rklJyvKq3X"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper61 AnonReviewer2</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">03 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper61 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">The paper proposes a method to disentangle latent variables for certain factors of interest in an image by considering the original input image and a transformation of the image where information about the factors of interest is removed. The generative process is then modeled by having two latent variables --  the first responsible for generating the transformed image whereas both latent variables are responsible for generating the original input image. This inductive bias naturally enforces that the second latent variable will not model the information which the first needs to reconstruct the transformed image, due to the VAE objective penalizing redundancy in information present in the latents. The paper demonstrates this in one setting where the transformation is random shuffling of image patches, which should remove the global information of the original input image.

The methodology of the paper was concise and easy to follow. The simple inductive bias presented in the paper for disentangling local and global information is very interesting. It is not obvious that shuffling image patches at a particular scale would lead to complete loss of global information, but the paper does show results on SVHN and CIFAR10 for which global information is sufficiently disentangled. The results for digit identity clustering were great for showing the correlation between their learnt global information and label information.

The paper introduced their model as a general purpose strategy for placing desired information in latent variables using auxiliary tasks, but focus was directed to the global vs local line of analysis. While giving examples for what kind of information can be removed, the authors mentioned that color to gray-scale might be one possibility.  It would have been interesting to see this and other possibilities explored in the paper. I feel that the idea deserves a broader analysis beyond just a single choice of disentanglement.

It is mentioned in the paper that having a single inference network for the posterior as opposed to the factorized one is conceivable. I would be curious to see an analysis of how that works out as compared to the separate encoders case.

Overall, the paper has a novel idea which is well motivated and executed in terms of experiments.</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">7: Good paper, accept</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_HJem9qJxA7" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Thanks for your review</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=H1l-SjA5t7&amp;noteId=HJem9qJxA7"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper61 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">19 Nov 2018</span><span class="item">ICLR 2019 Conference Paper61 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">We thank reviewer2 for the kind and constructive review. 
We agree that broader analysis beyond global-local disentanglement is desirable and we hope to perform more experiments in a follow up work.</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div><div class="note_with_children"><div id="note_H1l0mwe53m" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Approach seems limited and the source of improvement is not clear</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=H1l-SjA5t7&amp;noteId=H1l0mwe53m"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper61 AnonReviewer3</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">03 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper61 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">This work proposes an approach for explicitly placing information in a subset of the latent variables. The approach is to construct an auxiliary generative model that takes as input the set of latent variables subtracted from the target subset, which is used to model modified data samples that do not contain the desired information. 

Experiments focus on learning global information. The auxiliary model is then given data that have their global information destroyed via random shuffling of image patches.

# Approach seems limited.
 - This approach seems very limited, as there must exist a known transformation that removes the desired information. Apart from global vs. local, can the authors provide more examples of what sort of information this approach can disentangle? (Even for global vs. local, is there a transformation that can remove local information as opposed to global information?)
 - Can this approach learn multiple factors as opposed to just two? 
 - What if the desired factors are not clearly disjoint and collectively exhaustive? (e.g. mustache vs. gender on human faces.)

# More ablations or experiments with comparable settings would be desirable.
 - What is the choice of beta in the beta-VAE training objective? Apart from 1.2, this isn't mentioned. My concern here is that beta might be affecting the result more than the proposed training algorithm. Can the proposed approach perform just as well without a modified objective? Ablation studies that show the proposed algorithm can improve upon the baseline in all settings would make this a stronger paper. (e.g. this approach with normal VAE objective, and normal VAE objective without auxiliary task for the clustering experiment.)
 - Why were 30 discrete categories used in the clustering experiment? Is this still comparable to the approaches that use 10, which would correspond to the number of classes?

# Related work.
There are some well-cited works that the authors may have missed. These are ultimately different approaches, but perhaps the authors can obtain some inspiration from these:
- Tranforming autoencoders [1] also apply a transformation to the image, but the goal is to learn the factor corresponding to the transformation, rather than the complement as in this work.
- An opposing approach for explicit information placement with a modified training procedure (where the target information is directly placed in the target subset and can handle multiple factors) is DC-IGN [2]. I believe the DC-IGN approach is more general and can handle a superset of the tasks of this approach, without requiring an auxiliary decoder. Comparing to this approach, I wonder if it would be better to provide samples that exhibit a particular factor, or samples that conceal the factor?

[1] Hinton, Geoffrey E., Alex Krizhevsky, and Sida D. Wang. "Transforming auto-encoders." International Conference on Artificial Neural Networks. Springer, Berlin, Heidelberg, 2011.
[2] Kulkarni, Tejas D., et al. "Deep convolutional inverse graphics network." Advances in neural information processing systems. 2015.</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">4: Ok but not good enough - rejection</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_SyxYOL1lRm" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Rebuttal</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=H1l-SjA5t7&amp;noteId=SyxYOL1lRm"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper61 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">19 Nov 2018</span><span class="item">ICLR 2019 Conference Paper61 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">We thank reviewer3 for the comprehensive review. We would like to address each of the reviewer's concerns individually. (This will include some discussions above only seen by authors, reviewers, area chairs and program chairs.) 

# Is the approach really limited?

It is true that that the transformation that removes the desired information must be known before hand which is the main assumption in the paper. 
Other conceivable transformations are (i) removal of colour information by converting image to grey scale, (ii) removal of orientation information with random rotation and positional shift, (iii) removal of temporal correlation using shuffling in a time-series data and etc. We hope that that this paper could ignite a discussion around what transformation can be created to impose prior knowledge into the model. These prior transformation could be something that we observed in biology, for example, we observe global-local information disentanglement in our perception. Is there other hard-coded disentanglement in biology? This is rather an interesting problem in our opinion.

Can this method learn more factor than just two? It is conceivable that there could be more than one information of interests that get destroyed in a transformation. For example, one latent factor could model middle-range correlations if the transformation remove long-range correlations through shuffling process and short-range correlations get destroyed through a blurring process (e.g. local smoothing transformation). Another two factors could represent long-rang and short-range correlations.

What if the desired factors are not clearly disjoint and collectively exhaustive? This is an interesting question. We do not think that our current approach can disentangle continuous features. In a future work, there could be an auxiliary task method that can create continuous latent variables. We hope that this paper create interesting open problems for future research.

# More ablations or experiments with comparable settings would be desirable.

In our experiments, we found that the disentanglement of global and local information is very robust to different values of beta. In experiment 1.2 we use beta=1.0 which is the same as using the original VAE objective. However, beta does affect the quality of the generative samples (blurriness). For experiment 1.1, different beta produce similar disentanglement results, we use beta=20 to produce the figures as it created nicest looking samples. We uses beta=40 for all clustering experiments which had been searched from beta=\{1, 10, 20, 30, 40, 50, 60\} for the best digit identity clustering results. Thanks to reviewer3, we incorporated this information into the revision.

Regarding the clustering result, we believe that the resulting accuracy number cannot be used to compare the quality of the clustering methods. We observe that the global structure contains more information than just digit identity. It also contains information such as whether or not there are distracting digits in the image. We are not concern with improving upon baseline but rather to confirm that our method can disentangle global-local information and the further analysis have shown that the grouping corresponds to more than just the digit identity. The use of 30 clusters helps us identify the grouping of other types of global information in addition to the digit identity. Therefore, the identity clustering performance does not directly translate into the ability to disentangle local and global variables.

# Related work

We would like to thank reviewer 3 for suggesting the related works that we have missed. These were incorporated in the revision. 

As discussed in the comments above (visible only to authors and area chairs), there is an overhead regarding grouping of data into batches in DC-IGN approach. We agree that DC-IGN could potentially perform the same task as our model or more. However, our method can reduce the effort of needing to group the data or use labelled data by instead thinking more about prior knowledge (transformation function) of the entire dataset. 

The contributions of this paper are 
(i) Suggest that there is another method of imposing prior knowledge into algorithmic design of the latent variable model. We believe this can be categorised as a self-supervised learning approach (a kind of unsupervised learning) which have not been explored much in the context of the latent variable model.

(ii) Show that it can be used to disentangle global and local information through experiments.</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div></div></main></div>
  </div>
</div>


    <!-- Footer -->
    <footer class="sitemap">
      <div class="container">
        <div class="row hidden-xs">
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/venues">All Venues</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="/contact">Contact</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
    
        <div class="row visible-xs-block">
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/contact">Contact</a></li>
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
      </div>
    </footer>
    
    <footer class="sponsor">
      <div class="container">
        <div class="row">
          <div class="col-sm-10 col-sm-offset-1">
            <p class="text-center">
              OpenReview is created by the <a href="http://www.iesl.cs.umass.edu/" target="_blank">Information Extraction and Synthesis Laboratory</a>, College of Information and Computer Science, University of Massachusetts Amherst. We gratefully acknowledge the support of the OpenReview sponsors:  Google,  Facebook, NSF, the University of Massachusetts Amherst Center for Data Science, and Center for Intelligent Information Retrieval, as well as the Google Cloud Platform for donating the computing and networking services on which OpenReview.net runs.
            </p>
          </div>
        </div>
      </div>
    </footer>

  <div id="feedback-modal" class="modal fade" tabindex="-1" role="dialog">
    <div class="modal-dialog">
      <div class="modal-content">
        <div class="modal-header">
          <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">Ã—</span></button>
          <h3 class="modal-title">Send Feedback</h3>
        </div>
        <div class="modal-body">
          <p>Enter your feedback below and we'll get back to you as soon as possible.</p>
          <form action="/feedback" method="POST">
            <div class="form-group">
              <input type="email" name="from" class="form-control" placeholder="Email" />
            </div>
            <div class="form-group">
              <input type="text" name="subject" class="form-control" placeholder="Subject" />
            </div>
            <div class="form-group">
              <textarea name="message" class="form-control feedback-input" rows="5" placeholder="Message" required=""></textarea>
            </div>
          <ul id="ui-id-2" tabindex="0" class="ui-menu ui-widget ui-widget-content" style="display: none;"></ul></form>
        </div>
        <div class="modal-footer">
          <button type="button" class="btn btn-default" data-dismiss="modal">Cancel</button>
          <button type="button" class="btn btn-primary">Send</button>
        </div>
      </div>
    </div>
  </div>

  <script type="text/javascript" async="" src="https://www.google-analytics.com/analytics.js"></script><script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js"></script>
  <script>window.jQuery || document.write('&lt;script src="/static/js/vendor/jquery-2.2.4.min.js"&gt;&lt;\/script&gt;')</script>

  <script src="/static/dist/vendor.min.js"></script>
  <script src="/static/dist/templates.min.js"></script>
  <script src="/static/dist/openreview.min.js"></script>

    <script>window.legacyScripts = true;</script>


    <script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-108703919-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() { dataLayer.push(arguments); }
      gtag('js', new Date());
      gtag('config', 'UA-108703919-1');
    </script>


<div role="status" aria-live="assertive" aria-relevant="additions" class="ui-helper-hidden-accessible"></div></body></html>
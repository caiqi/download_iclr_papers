<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" class="no-js"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>Learning a Neural-network-based Representation for Open Set Recognition | OpenReview</title>
  <meta name="description" content="" />

      <meta name="citation_title" content="Learning a Neural-network-based Representation for Open Set Recognition" />
        <meta name="citation_author" content="Anonymous" />
      <meta name="citation_publication_date" content="2018/09/27" />
      <meta name="citation_online_date" content="2018/09/27" />
      <meta name="citation_pdf_url" content="https://openreview.net/pdf?id=r1elIi09K7" />
      <meta name="twitter:card" content="summary" />
      <meta name="twitter:site" content="@openreviewnet" />
      <meta name="og:title" content="Learning a Neural-network-based Representation for Open Set..." />
      <meta name="og:description" content="In this paper, we present a neural network based representation for addressing the open set recognition problem. In this representation instances from the same class are close to each other while..." />
      <meta name="og:image" content="https://openreview.net/static/images/openreview_logo_512.png" />

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans:400,400i,700,700i" />

  <link rel="stylesheet" href="/static/css/bootstrap.min.css" />
  <link rel="stylesheet" href="/static/css/jquery-ui.min.css" />
  <link rel="stylesheet" href="/static/css/main.min.css" />
</head>

<body class="forum">
  <nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
  
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand home push-link" href="/"><strong>OpenReview</strong>.net</a>
      </div>
  
      <div id="navbar" class="navbar-collapse collapse">
        <form class="navbar-form navbar-left profile-search" role="search">
          <div class="form-group has-feedback">
            <input id="search_input" type="text" class="form-control ui-autocomplete-input" placeholder="Search ICLR 2019 Conference" autocomplete="off" />
            <span class="glyphicon glyphicon-search form-control-feedback" aria-hidden="true"></span>
          </div>
  
          <input id="search_group" type="hidden" value="ICLR.cc/2019/Conference" />
          <input id="search_content" type="hidden" value="all" />
        <ul id="ui-id-1" tabindex="0" class="ui-menu ui-widget ui-widget-content ui-autocomplete ui-front" style="display: none;"></ul></form>
  
        <ul class="nav navbar-nav navbar-right">
        
            <li id="user-menu"><a href="/login">Login</a></li>
        </ul>
      </div>
  
    </div>
  </nav>

  <div id="or-banner" class="banner" style="">
  <div class="container">
    <div class="row">
      <div class="col-xs-12"><a href="/group?id=ICLR.cc/2019/Conference" title="Venue Homepage"><img class="icon" src="/static/images/arrow_left.svg" /> Go to <strong>ICLR 2019 Conference</strong> homepage</a></div>
    </div>
  </div>
</div>
<div id="flash-message-container" class="alert alert-danger" role="alert" style="display: none;">
  <div class="container">
    <div class="row">
      <div class="col-xs-12">
        <div class="alert-content">
          <button type="button" class="close" aria-label="Close"><span aria-hidden="true">×</span></button>
        </div>
      </div>
    </div>
  </div>
</div>

<div class="container">
  <div class="row">
    <div class="col-xs-12">
      <main id="content" class="clearfix openbanner-visible legacy-styles"><div id="note_r1elIi09K7" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Learning a Neural-network-based Representation for Open Set Recognition</a> <a class="note_content_pdf" href="/pdf?id=r1elIi09K7" title="Download PDF" target="_blank"><img src="/static/images/pdf_icon_blue.svg" /></a> </h2></div><div class="meta_row"><span class="signatures">Anonymous</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">28 Sep 2018 (modified: 11 Oct 2018)</span><span class="item">ICLR 2019 Conference Blind Submission</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span><span class="item"><a class="action-bibtex-modal" data-bibtex="@inproceedings{    &#10;anonymous2019learning,    &#10;title={Learning a Neural-network-based Representation for Open Set Recognition},    &#10;author={Anonymous},    &#10;booktitle={Submitted to International Conference on Learning Representations},    &#10;year={2019},    &#10;url={https://openreview.net/forum?id=r1elIi09K7},    &#10;note={under review}    &#10;}">Show Bibtex</a></span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Abstract: </span><span class="note_content_value">In this paper, we present a neural network based representation for addressing the open set recognition problem. In this representation instances from the same class are close to each other while instances from different classes are further apart, resulting in statistically significant improvement when compared to other approaches on three datasets from two different domains.   
</span></div><div class="note_contents"><span class="note_content_field">Keywords: </span><span class="note_content_value">open set recognition</span></div><div class="note_contents"><span class="note_content_field">TL;DR: </span><span class="note_content_value">In this paper, we present a neural network based representation for addressing the open set recognition problem.</span></div><div class="reply_row clearfix"><div class="item" id="reply_count">8 Replies</div></div></div><hr class="small" /><div id="note_children"><div class="note_with_children"><div id="note_BJgJzVP9hQ" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>A reasonable  paper needing further justifications</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=r1elIi09K7&amp;noteId=BJgJzVP9hQ"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper142 AnonReviewer2</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">03 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper142 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">The paper proposed a NN-based model for open set recognition via finding a better feature space where larger inter-class (P2) and smaller intra-class distances (P1) are satisfied. In the proposed model, the inter- and intra-class distances are measured basing on the mean of final linear layer features from each class, and a kind of L2 loss is defined to ensure the properties of the feature space during the training progress. Then the proposed outlier score defined as the minimum inter-class distance becomes the key for the open set recognition task.

Generally, this paper is well written and easy to read. The proposed threshold estimation method for outlier score based on assumed contamination ratio is reasonable. And three datasets in two domains are used to prove the model’s effectiveness.

Major comments:
1.	This paper seems less novel.
There exist several methods aiming to find a better feature space satisfying the mentioned feature distance properties by adjusting the optimized loss functions, such as Center Loss (Wen et.al 2016) and Additive Angular Margin (Deng et.al 2018). I think the idea Combining ii-loss with Cross Entropy Loss proposed in this paper is quite similar to the Center Loss except that
a)	the ii-loss contains a part for maximizing the minimum inter-class distance;
b)	the ii-loss and cross entropy loss are optimized separately.
Since results shown in Center Loss that without pushing the inter-class distance, the feature space still satisfied P1 and P2, this paper seems not that novel, at least some comparation can be added to analyze the improvement for adding the inter-class part.

2.	This paper seems less convincing as well.
The paper introduces that the two properties (larger inter-class and smaller intra-class distances) can lead to larger spaces among known classes for the instances of the unknown classes to occupy. However, it keeps uncertain if this can be generalized to unseen classes. In this sense, it is better to conduct some additional theoretical analysis or perform more experiments to validate this. In particular, only one plot was performed to verify this point on one single dataset. Maybe more plots of the distributions can be provided on more additional datasets.
</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">4: Ok but not good enough - rejection</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_Byxcf0zWRm" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Additional baseline</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=r1elIi09K7&amp;noteId=Byxcf0zWRm"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper142 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">20 Nov 2018</span><span class="item">ICLR 2019 Conference Paper142 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">We thank the reviewer for this comment.

As the reviewer noted  there are differences between the central loss and our proposed ii-loss 
1. Our loss function has an additional component for maximizing the minimum inter-class distance.
2. The ii-loss and cross entropy loss are optimized separately.
3. ii-loss can be used without cross entropy loss
4. Our proposed approach shows the applicability of such feature learning to open set recognition problem. 

We have conducted further experiments to quantify the advantage of adding the inter-class distance term in ii-loss. In these experiments we use central loss to train:
MNIST dataset: 30-run average AUC=0.9264 
Android dataset: 30-run average AUC=0.7514
MS dataset: 30-run average AUC=0.9234

In all experiments ii-loss based approach records a statistically significant improvement over central loss based approach.

Finally, we would like to point out that the paper on center loss did not focus on open-set recognition.  However, our paper focuses on open-set recognition. Also, the papers on center loss and triple-center loss focus on computer vision-related problems.  However, our paper discusses the utility of our proposed approaches in two very different domains: computer security and computer vision.
</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div><div class="note_with_children"><div id="note_rJlQzEz9hX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>The paper focuses on open set classification which is a clearly desirable feature for all machine learning classification algorithms. The idea is very simple and the experiments should include more comparative results with the baselines.</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=r1elIi09K7&amp;noteId=rJlQzEz9hX"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper142 AnonReviewer3</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">03 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper142 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">
The paper focuses on open set classification where one wants to design a classifier able to accurately classify samples from training (known classes) and able to reject samples from unknown classes. Such a feature is would be clearly desirable for all machine learning classification algorithms. The paper presents a representation learning based approach for this problem. 

The idea is very simple. It consists in learning a neural classifier with a constraint on the representation space of samples (i.e. the one implemented in a chosen hidden layer of the network) aiming at optimizing a Fisher-discriminant-like criterion. This criterion aims at minimizing the variance of the representation of the samples within a class and to make representations of samples from different classes (actually the means per class) well separated. The learning is eventually performed by adding a usual cross entropy classification loss on the output layer to the Fisher like criterion. The rejection of samples from unknown classes is performed via a threshold on the minimum distance of a sample representation and the class means in the representations space.  The idea is well thought but the innovation is indeed low. 

Experiments are performed on three, but small, datasets including the simple Mnist dataset. Experimental results compare the proposed approach and its variants to two recent baselines, OpenMax and G_OpenMax. Experiments show the proposed approach outperform the two baselines but in some cases the confidence interval is quite large and prevent definitive conclusions (e.g. up to 0.05 in Table 2). Visualization of projected data show as expected the interesting feature of the representation space. Yet the experimental analysis does not seem as deeps the ones in the two papers where baselines were published. For instance results are shown with respect to a measure of the experimental setting named openness in [Ge and al.]. Moreover the paper by  [Ge and al.] conclude to the superiority of their proposal with respect to OpenMax which is not fully consistent with the results reported in this paper. Also experiments were performed on much bigger datasets in these two references with ILSVRC 2012 dataset in [Bendale and al., 2016] while [Ge and al.]  used a handwritten diet dataset with more than 350 classes. It would drastically strengthen the paper if the authors could provide comparative results on these datasets too.</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">4: Ok but not good enough - rejection</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_Bylokk7bRQ" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Difference in experimental results </a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=r1elIi09K7&amp;noteId=Bylokk7bRQ"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper142 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">20 Nov 2018</span><span class="item">ICLR 2019 Conference Paper142 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">We thank the reviewer for this comment.

The inconsistency between results reported in g-openmax and our work can be down to the evaluation methodology. Since the evaluation methodology used by g-openmax is not clearly stated in the g-openmax paper, it difficult to exactly reproduce the results. That being said we have clearly detailed our experiment methodology and use the same experiment  framework for all of the evaluated approaches.
</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div><div class="note_with_children"><div id="note_SylxCvAFom" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>question on generalisation</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=r1elIi09K7&amp;noteId=SylxCvAFom"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures"><a href="/profile?id=~ioui_wc1" class="profile-link">ioui wc</a></span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">21 Oct 2018</span><span class="item">ICLR 2019 Conference Paper142 Public Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Hi, I have a question on reducing overlap in feature space between samples from train categories and unknown categories. 
I agree that maximizing inter-class separation and minimizing the intra-class separation is beneficial and indeed can reduce overlap in the feature space. However, as far as I known from the metric learning field, this benefit is only true when testing on samples from trained categries, and it will not generalise to samples from untrained unknown categories, except that you really get enougth data to trained a generic metric learning network. That is, samples from untrained unknown categories, when mapped into the feature space, will not have desired non-ovelapping ranges. As you can see from Figure 2, the distribution of trained categories is ideal, while the distribution of untrained categories just are a mess, and worsely, overlapping with the distribution of trained categories. so that in fundamental, your idea to maximize inter-class separation and minimize the intra-class separation seems not generalise well to untrained catogories. </span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_rkgcjZmWCX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>clarification </a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=r1elIi09K7&amp;noteId=rkgcjZmWCX"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper142 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">20 Nov 2018</span><span class="item">ICLR 2019 Conference Paper142 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Than you for your comment.
Figure 2 is shows two figures z0-z1 and z0-z2 , where z0, z1, z2 are there dimensions from the size dimensional z-layer. Overlap in these figures does not necessary mean real over lap. It simply means it appears as over lap when viewed from that dimensions perspective. This is backed by the improved open set recognition performance shown in the experimental section.</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div><div class="note_with_children"><div id="note_SJlGGPyBj7" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>The method needs more discussions and more comparison baselines.</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=r1elIi09K7&amp;noteId=SJlGGPyBj7"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper142 AnonReviewer1</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">18 Oct 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper142 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">This paper deals with the open set classification problem, where in addition to the known classes, the method should also be able to recognize the unknown class. The main idea is based on two parts: learning a discriminative representation, and a threshold based detection rule. To learn the embedding, the authors propose to minimize the inner class distance (between each instance to its center) and enlarge the distance between centers. The outlier score of an instance is computed as the minimum distance between known class prototypes. Experiments on various datasets show the ability of the learned method.

I'm not completely sure whether the whole approach is novel or not in the open set recognition domain, but both parts are not novel enough. Pulling similar instances together and pushing dissimilar ones away is the main idea in embedding learning. The ii-loss is similar to the triplet-center loss in the paper "He et al. Triplet-Center Loss for Multi-View 3D Object Retrieval. CVPR18". 

Although in the experiments the proposed method achieves good results in most cases, the reviewer suggests the authors comparing with more baselines to make the work solid.
1. Comparing with other embedding learning methods with the same outlier detection score. 
The authors should prove that the proposed embedding is important enough in the open set case. For example, using the center loss (Wen et al. A discriminative feature learning approach for deep face recognition. ECCV16), triplet-center loss, triplet loss (computing class centers after embedding).

2. Discuss more on the outlier score part. 
How to differentiate the known class outlier and new class? Will the problem be more difficult when the unknown class contains more heterogeneous classes? The authors can also apply existing open set recognition rule on the learned embedding.

Some detailed questions:
1. What's the difference between "the network weights are first updated to minimize on ii-loss and then in a separate step updated to minimize cross entropy loss" and optimize both loss terms simultaneously?
2. "We assume that a certain percent of the training set to be noise/outliers", how to determine the concrete value? Is 1% the helpful one for all cases?
3. Since there is not optimize over the unknown classes in training, could the reason for "the unknown class instances fully occupy the open space between the known classes" is the unknown classes are randomly sampled from the whole class set? For example, if classes about animals are known classes and classes about scene compose the unknown class, will the unknown class also occupy the whole space in this case?
4. What is the motivation of making "the unknown class instances fully occupy the open space between the known classes"?</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">5: Marginally below acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_HkxnIemb0Q" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Detailed response </a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=r1elIi09K7&amp;noteId=HkxnIemb0Q"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper142 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">20 Nov 2018</span><span class="item">ICLR 2019 Conference Paper142 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">We thank the reviewer for this comment.

We have conducted further experiments to quantify the advantage of  ii-loss over central loss. Here are the results from experiments on using central loss:
MNIST dataset: 30-run average AUC=0.9264 
Android dataset: 30-run average AUC=0.7514
MS dataset: 30-run average AUC=0.9234

In all cases ii-loss based approach records a statistically significant improvement over central loss based approach.

The authors of triplet-center loss (which incorporates inter-class distance) also found improvement over center-loss in (regular) classification tasks.   Also, although both ii-loss and triplet-center loss consider inter-class distance, ii-loss has less computational overhead.   In ii-loss, centroids (centers) are first calculated and inter-class distances between centroids are then calculated.  In triplet-center loss, for each sample, the closest sample from another class need to be found.  

With regards to the reviewers question about how to differentiate the known class outlier and new class:
- Our work focuses on differentiating new class rather than on the problem of known class outliers. Although we believe the proposed approach can be applied to the known class outlier problem we have not conducted experiments to verify this.

With regards to heterogeneous unknown classes:
- The open set problem is actually easier when the unknown classes are more different from the known classes. 

The following are answers to the detail questions:
1. There shouldn’t be much of a difference between optimizing the ii-loss and cross-entropy loss separately or simultaneously. Our decision to do this separately was many an engineering decision to allow as to experiment with different network topology.
2. In our experiments we found the 1% contamination ratio to be widely applicable. We chose contamination ratio based threshold because it is easier to understand by the user. For example, if catching more unknown class instances is more important to the user she/he can set a higher contamination ratio and vise versa.
3. When the unknown class and the known class are different (for example the reviewer mentions animals vs scene) the unknown classes are not projected close to any articular known class hence occupying more space between the known classes. The more difficult problem is when the unknown classes are very similar to the known. In which case their projection  will be closer to one of the known and might even overlap making it more difficult. Hence why in the classes in our experiments are similar.
4. The motivation for making "the unknown class instances fully occupy the open space between the known classes" is to reduce the chance of unknown class projection overlapping a known class projection.

Finally, we would like to point out that the papers on center loss and triplet-center loss did not focus on open-set recognition.  However, our paper focuses on open-set recognition. Also, the papers on center loss and triple-center loss focus on computer vision-related problems.  However, our paper discusses the utility of our proposed approaches in two very different domains: computer security and computer vision.
</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div></div></main></div>
  </div>
</div>


    <!-- Footer -->
    <footer class="sitemap">
      <div class="container">
        <div class="row hidden-xs">
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/venues">All Venues</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="/contact">Contact</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
    
        <div class="row visible-xs-block">
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/contact">Contact</a></li>
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
      </div>
    </footer>
    
    <footer class="sponsor">
      <div class="container">
        <div class="row">
          <div class="col-sm-10 col-sm-offset-1">
            <p class="text-center">
              OpenReview is created by the <a href="http://www.iesl.cs.umass.edu/" target="_blank">Information Extraction and Synthesis Laboratory</a>, College of Information and Computer Science, University of Massachusetts Amherst. We gratefully acknowledge the support of the OpenReview sponsors:  Google,  Facebook, NSF, the University of Massachusetts Amherst Center for Data Science, and Center for Intelligent Information Retrieval, as well as the Google Cloud Platform for donating the computing and networking services on which OpenReview.net runs.
            </p>
          </div>
        </div>
      </div>
    </footer>

  <div id="feedback-modal" class="modal fade" tabindex="-1" role="dialog">
    <div class="modal-dialog">
      <div class="modal-content">
        <div class="modal-header">
          <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button>
          <h3 class="modal-title">Send Feedback</h3>
        </div>
        <div class="modal-body">
          <p>Enter your feedback below and we'll get back to you as soon as possible.</p>
          <form action="/feedback" method="POST">
            <div class="form-group">
              <input type="email" name="from" class="form-control" placeholder="Email" />
            </div>
            <div class="form-group">
              <input type="text" name="subject" class="form-control" placeholder="Subject" />
            </div>
            <div class="form-group">
              <textarea name="message" class="form-control feedback-input" rows="5" placeholder="Message" required=""></textarea>
            </div>
          <ul id="ui-id-2" tabindex="0" class="ui-menu ui-widget ui-widget-content" style="display: none;"></ul></form>
        </div>
        <div class="modal-footer">
          <button type="button" class="btn btn-default" data-dismiss="modal">Cancel</button>
          <button type="button" class="btn btn-primary">Send</button>
        </div>
      </div>
    </div>
  </div>

  <script type="text/javascript" async="" src="https://www.google-analytics.com/analytics.js"></script><script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js"></script>
  <script>window.jQuery || document.write('&lt;script src="/static/js/vendor/jquery-2.2.4.min.js"&gt;&lt;\/script&gt;')</script>

  <script src="/static/dist/vendor.min.js"></script>
  <script src="/static/dist/templates.min.js"></script>
  <script src="/static/dist/openreview.min.js"></script>

    <script>window.legacyScripts = true;</script>


    <script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-108703919-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() { dataLayer.push(arguments); }
      gtag('js', new Date());
      gtag('config', 'UA-108703919-1');
    </script>


<div role="status" aria-live="assertive" aria-relevant="additions" class="ui-helper-hidden-accessible"></div></body></html>
<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" class="no-js"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>Implicit Autoencoders | OpenReview</title>
  <meta name="description" content="" />

      <meta name="citation_title" content="Implicit Autoencoders" />
        <meta name="citation_author" content="Anonymous" />
      <meta name="citation_publication_date" content="2018/09/27" />
      <meta name="citation_online_date" content="2018/09/27" />
      <meta name="citation_pdf_url" content="https://openreview.net/pdf?id=HyMRaoAqKX" />
      <meta name="twitter:card" content="summary" />
      <meta name="twitter:site" content="@openreviewnet" />
      <meta name="og:title" content="Implicit Autoencoders" />
      <meta name="og:description" content="In this paper, we describe the " implicit="" autoencoder"="" (iae),="" a="" generative="" autoencoder="" in="" which="" both="" the="" path="" and="" recognition="" are="" parametrized="" by="" distributions.="" we="" use..."="" />
      <meta name="og:image" content="https://openreview.net/static/images/openreview_logo_512.png" />

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans:400,400i,700,700i" />

  <link rel="stylesheet" href="/static/css/bootstrap.min.css" />
  <link rel="stylesheet" href="/static/css/jquery-ui.min.css" />
  <link rel="stylesheet" href="/static/css/main.min.css" />
</head>

<body class="forum">
  <nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
  
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand home push-link" href="/"><strong>OpenReview</strong>.net</a>
      </div>
  
      <div id="navbar" class="navbar-collapse collapse">
        <form class="navbar-form navbar-left profile-search" role="search">
          <div class="form-group has-feedback">
            <input id="search_input" type="text" class="form-control ui-autocomplete-input" placeholder="Search ICLR 2019 Conference" autocomplete="off" />
            <span class="glyphicon glyphicon-search form-control-feedback" aria-hidden="true"></span>
          </div>
  
          <input id="search_group" type="hidden" value="ICLR.cc/2019/Conference" />
          <input id="search_content" type="hidden" value="all" />
        <ul id="ui-id-1" tabindex="0" class="ui-menu ui-widget ui-widget-content ui-autocomplete ui-front" style="display: none;"></ul></form>
  
        <ul class="nav navbar-nav navbar-right">
        
            <li id="user-menu"><a href="/login">Login</a></li>
        </ul>
      </div>
  
    </div>
  </nav>

  <div id="or-banner" class="banner" style="">
  <div class="container">
    <div class="row">
      <div class="col-xs-12"><a href="/group?id=ICLR.cc/2019/Conference" title="Venue Homepage"><img class="icon" src="/static/images/arrow_left.svg" /> Go to <strong>ICLR 2019 Conference</strong> homepage</a></div>
    </div>
  </div>
</div>
<div id="flash-message-container" class="alert alert-danger" role="alert" style="display: none;">
  <div class="container">
    <div class="row">
      <div class="col-xs-12">
        <div class="alert-content">
          <button type="button" class="close" aria-label="Close"><span aria-hidden="true">×</span></button>
        </div>
      </div>
    </div>
  </div>
</div>

<div class="container">
  <div class="row">
    <div class="col-xs-12">
      <main id="content" class="clearfix openbanner-visible legacy-styles"><div id="note_HyMRaoAqKX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Implicit Autoencoders</a> <a class="note_content_pdf" href="/pdf?id=HyMRaoAqKX" title="Download PDF" target="_blank"><img src="/static/images/pdf_icon_blue.svg" /></a> </h2></div><div class="meta_row"><span class="signatures">Anonymous</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">28 Sep 2018 (modified: 13 Nov 2018)</span><span class="item">ICLR 2019 Conference Blind Submission</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span><span class="item"><a class="action-bibtex-modal" data-bibtex="@inproceedings{    &#10;anonymous2019implicit,    &#10;title={Implicit Autoencoders},    &#10;author={Anonymous},    &#10;booktitle={Submitted to International Conference on Learning Representations},    &#10;year={2019},    &#10;url={https://openreview.net/forum?id=HyMRaoAqKX},    &#10;note={under review}    &#10;}">Show Bibtex</a></span><a class="note_content_pdf item" href="/revisions?id=HyMRaoAqKX" target="_blank">Show Revisions</a></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Abstract: </span><span class="note_content_value">In this paper, we describe the "implicit autoencoder" (IAE), a generative autoencoder in which both the generative path and the recognition path are parametrized by implicit distributions. We use two generative adversarial networks to define the reconstruction and the regularization cost functions of the implicit autoencoder, and derive the learning rules based on maximum-likelihood learning. Using implicit distributions allows us to learn more expressive posterior and conditional likelihood distributions for the autoencoder. Learning an expressive conditional likelihood distribution enables the latent code to only capture the abstract and high-level information of the data, while the remaining information is captured by the implicit conditional likelihood distribution. For example, we show that implicit autoencoders can disentangle the global and local information, and perform deterministic or stochastic reconstructions of the images. We further show that implicit autoencoders can disentangle discrete underlying factors of variation from the continuous factors in an unsupervised fashion, and perform clustering and semi-supervised learning.</span></div><div class="note_contents"><span class="note_content_field">Keywords: </span><span class="note_content_value">Unsupervised Learning, Generative Models, Variational Inference, Generative Adversarial Networks.</span></div><div class="note_contents"><span class="note_content_field">TL;DR: </span><span class="note_content_value">We propose a generative autoencoder that can learn expressive posterior and conditional likelihood distributions using implicit distributions, and train the model using a new formulation of the ELBO.</span></div><div class="reply_row clearfix"><div class="item" id="reply_count">7 Replies</div></div></div><hr class="small" /><div id="note_children"><div class="note_with_children"><div id="note_HJg9eC9Anm" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Experiments in paper do not implement the objective in paper.</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HyMRaoAqKX&amp;noteId=HJg9eC9Anm"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper852 AnonReviewer1</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">06 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper852 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">This paper introduces the implicit autoencoder, which purports to be a VAE with an implicit encoding and decoding distribution.

My principle problem with the paper and reason for my strong rejection is that there appears to be a complete separation between the discussion and theory of the paper and the actual experiments run.  The paper's discussion and theory all centers around rewriting the ordinary ELBO lower bound on the marginal likelihood in equations (4) through (7) where it is shown that this can be recast in the form of two KL divergences, one between the representational joint q(x,z) = p_data(x) encoder(z|x) and the 'reconstruction joint' r(x,z) = encoder_marginal(z) decoder(x|z), and one between the encoding marginal q(z) and the generative prior p(z).   The entire text of the paper then discusses the similarities between this formulation of the objective and some of the alternatives as well as discussing how this objective might behave in various limits.

However, this is not the objective that is actually trained. In the  "Training Process" section is it revealed that an ordinary GAN discriminator is trained.  The ordinary GAN objective does not minimize a KL divergence, it is a minimax formulation of a Jensen Shannon divergence as the original GAN paper notes.  More specifically, you can optimize a KL divergence with a GAN, as shown in the f-GAN paper (1606.00709) but this requires attention be paid to the functional form of the loss and structure of the discriminator.  No such care was taken in this case.  As such the training process does not minimize the objective derived or discussed.  Not to mention that in practice a further hack is employed wherein only the negative example passes gradients to the generator.  

While is not specified in the training process section, assuming the ordinary GAN objective (Equation 1) is used, according to their own reference (AVB) the optimal decoder should be:  D = 1/(1 + r(z,x)/q(z,x))  for which we have that what they deem the 'generative loss of the reconstruction GAN' is T = log(1 + r(z,x)/q(z,x))  .   When we take unbiased gradients of the expectation of this quantity, we do not obtain an unbiased gradient of the KL divergence between q(z,x) and r(z,x).

Throughout the paper, factorized Gaussian distributions are equated with tractable variational approximations.  While it is common to use a mean field gaussian distribution for the decoder in VAEs this is by no means required.  Many papers have investigated the use of more powerful autoregressive or flow based decoders, as this paper itself cites (van der Oord et al. 2016).  The text further misrepresents the current literature when it claims that the IAE uniquely "generalizes the idea of deterministic reconstruction to stochastic reconstruction by learning a decoder distribution that learns to match to the inverse encoder distribution".  All VAEs have employ stochastic reconstruction, if the authors again here meant to distinguish a powerful implicit decoder from a mean field gaussian one, the choice of language here is wrong.

Given that there are three joint distributions in equation (the generative model, the representational joint and the reconstruction joint), the use of Conditional entropy H(x|z) and mutual information I(x, z) are ambiguous.  While the particular joint distribution is implied by context in the equations, please spell it out for the reader.

The "Global vs. Local Decomposition of Information in IAEs" section conflates dimensionality with information capacity.  While these are likely correlated for real neural networks, at least fundamentally an arbitrary amount of information could be stored in even a 1 dimensional continuous random variable.  This is not addressed.  

The actual experiments look nice, its just that objective used to train the resulting networks is not the one presented in the paper. 

</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">2: Strong rejection</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">3: The reviewer is fairly confident that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_HJxMkUiu6m" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Rebuttal (Part 2)</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HyMRaoAqKX&amp;noteId=HJxMkUiu6m"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper852 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">14 Nov 2018</span><span class="item">ICLR 2019 Conference Paper852 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Reviewer: "Not to mention that in practice a further hack is employed wherein only the negative example passes gradients to the generator."

In order to match r(x,z) to q(x,z), we back-propagate the reconstruction discriminator gradient through negative examples. In this case, we are considering q(x,z) as the target distribution that r(x,z) is trained to match to. The process of learning r(x,z) requires learning the encoder, which indirectly changes the underlying target distribution q(x,z) to a new target distribution q(x,z). In other words, r(x,z) is aiming a moving target distribution, which is q(x,z), and once the reconstruction discriminator is confused, we will have r(x,z)=q(x,z). We empirically observed that by only back-propagating through negative examples, we will provide a more stable target distribution for r(x,z) to aim for, which results in a more stable training dynamic and better empirical performance.
==============
Reviewer: "Many papers have investigated the use of more powerful autoregressive or flow-based decoders, as this paper itself cites (van der Oord et al. 2016)."

We have extensively discussed these autoregressive-decoder models in several parts of the paper (page 4 and 5), and have cited all the related works such as "PixelVAE", "Variational Lossy Autoencoders", "PixelGAN", "Fixing the broken ELBO" and "Associative compression networks". In page 5, for example, we mention the advantages of implicit-decoder based models to autoregressive-decoder based models by explaining that implicit decoders can scale to larger images, are less computationally expensive, and can capture vector representations for the local statistics.
==============
Reviewer: "The text further misrepresents the current literature when it claims that the IAE uniquely generalizes the idea of deterministic reconstruction to stochastic reconstruction by learning a decoder distribution that learns to match to the inverse encoder distribution."

This statement was made in the context of comparing the reconstruction cost of IAEs with VAEs. The reconstruction cost of IAEs, unlike that of VAEs, explicitly tries to match the decoder distribution p(x|z) to the inverse encoder distribution q(x|z). We revised our paper and modified this statement based on the reviewer's suggestions.
==============
Reviewer: "the use of Conditional entropy H(x|z) and mutual information I(x, z) are ambiguous."

In the page 2 of the paper, these terms have been explicitly defined: "The entropy of the data distribution H(x), the entropy of the latent code H(z), the mutual information I(x;z), and the conditional entropies H(x|z) and H(z|x) are all defined under the joint data distribution q(x,z) and its marginals p_data(x) and q(z)."
==============
Reviewer: "The "Global vs. Local Decomposition of Information in IAEs" section conflates dimensionality with information capacity. While these are likely correlated for real neural networks, at least fundamentally an arbitrary amount of information could be stored in even a 1 dimensional continuous random variable. This is not addressed."

We updated the paper by adding a section explaining how the Bits-Back argument is also applicable to continuous random variables in neural networks.</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_rke6Qaqu6m" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Rebuttal (Part 1)</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HyMRaoAqKX&amp;noteId=rke6Qaqu6m"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper852 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">14 Nov 2018</span><span class="item">ICLR 2019 Conference Paper852 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">We thank the reviewer for the feedback.

The reviewer has a principle concern about one of the arguments of our paper, which has resulted in a very strong negative feedback about the whole paper. This argument is that the KL divergence between two distributions p(x) and q(x) can be *approximately* minimized by training a GAN that tries to match these two distributions. More specifically, the theoretical contribution of our paper is to re-derive the ELBO as the summation of two KL divergences and a fixed term: -KL(q(z)||p(z))-KL(q(x,z)||r(x,z))-H_data. These KL divergences are not tractable to optimize, so the empirical contribution of our paper is to show that we can use GANs to approximately minimize each of these KL divergences, and that the resulting *empirical* algorithm can perform useful tasks such as variational inference, clustering or semi-supervised learning.

Firstly, we would like to point out that, theoretically, the standard GAN optimizes the JS divergence, which is a symmetric divergence, whose square root is a metric. In the minimization of the JS divergence, we try to get the two distributions as close as possible, which almost always results in the minimization of the KL divergence. There could be some pathological cases where the KL divergence does not decrease, but we empirically show that this approximate optimization works in our experiments. That being said, we never claimed that we are exactly optimizing the ELBO, and in several parts of the paper we have explicitly pointed out that we are only approximately optimizing the ELBO. For example, in the paper, we mention that "This KL divergence is *approximately* minimized with the reconstruction GAN", or that "This is the same regularization cost function used in AAEs, and is *approximately* minimized with the regularization GAN".

Secondly, replacing an intractable divergence with another tractable divergence is a common idea used in many generative models such as adversarial autoencoders, the wake-sleep algorithm or ALI/BiGANs. In fact, the adversarial autoencoder (Eq. 5) uses the *exact same approximation* that we use, by replacing the intractable KL(q(z)||p(z)) in the code space with the adversarial cost. The concern of the reviewer can be similarly raised for the adversarial autoencoder, as it does not exactly optimizes the ELBO; nevertheless, the adversarial autoencoder shows that this approximation results in a useful generative model. Another example is the wake-sleep algorithm, in which the wake-phase optimizes the right KL divergence of data and model, but the sleep phase replaces this KL divergence with the reversed KL divergence and optimizes that instead. As the result, the wake-sleep algorithm does not exactly optimizes the ELBO; nevertheless, it is very successful in training sigmoid belief networks. Another example is the ALI/BiGAN methods which use the JS divergence in their formulations, but recently many papers such as [1] have argued that these methods are *approximately* optimizing the ELBO.
Similar to all these works, in implicit autoencoders, by replacing intractable KL divergences with the adversarial training, we are not exactly optimizing the ELBO; nevertheless, we empirically show that the adversarial training can actually match the distributions that the KL divergence aims to match; and this results in a useful and practical algorithm. For example, the IAE can successfully learn expressive variational posteriors that can almost perfectly match the true posteriors (Fig. 9) using adversarial training; the IAE can empirically achieve very competitive clustering and semi-supervised learning results (Section 2.1.2); and can perform useful tasks such as high-level vs. low-level decomposition of information (Fig. 2,3,4).

Thirdly, as the reviewer points out, the objective of the GAN can be modified to optimize any f-divergence including the KL divergence. Thus, in theory, by replacing the KL divergences of the IAE with the f-GAN objectives, we can very closely follow the gradient of the ELBO. Indeed, in the initial phases of this project, we did perform some experiments with the f-GAN objective, but observed that its empirical performance is very similar to the original GAN objective. This result has also been independently reported in many other works including the original f-GAN paper, which reports that "all three divergences [JS, KL and Hellinger] produce equally realistic samples". So given that the f-divergence objective did not bring any empirical benefit in our case, we chose to perform the experiments of this project with the standard GAN objective.

Finally, We revised our paper by adding a paragraph to fully discuss this issue and to better clarify both our theoretical and empirical contributions. We hope that this revision of the paper along with the above response address the main concern of the reviewer.

[1] Ferenc Huszár. Variational inference using implicit distributions, 2017.</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div><div class="note_with_children"><div id="note_Sklgza8C3m" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Interesting models (with a potentially indifferent encoder?)</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HyMRaoAqKX&amp;noteId=Sklgza8C3m"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper852 AnonReviewer3</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">06 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper852 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">The paper presents two generative autoencoding models, that optimize a variational objective by adversarial training of implicit distributions. Applications in generative modeling, clustering, semi-supervised learning and disentangling “global” vs “local” variations in data are presented. 

In particular, the first model, called implicit autoencoder, maximizes the ELBO using two adversarial objectives: an adversarial regularizer penalizes the deviation of the aggregated posterior from the prior and the adversarial reconstruction penalizes the disagreement between the joint distribution and the joint reconstruction. Since both implicit distributions use a noise source, they can both explain variations in the data. The paper argues (and presents experimental results to suggest) that the global vs local information is the separation in these two components. The second architecture, called _flipped_ implicit autoencoder replaces the role of code and input in the first architecture, changing the training objective to reverse KL-divergence. The relationship between the proposed models to several prior works including ALI, BiGAN, AVB, adversarial autoencoders, wake-sleep, infoGAN is discussed. 

The paper is nicely written, and the theory part seems to be sound. The strength of this paper is that it ties together a variety of different autoencoding generative architectures. In particular, I found it interesting that AVB and InfoGAN become special cases of the regular and flipped model, where an implicit term in the loss is replaced by an explicit likelihood term. 

I have some issues/questions (did I miss something obvious?):

1) A mode of failure: suppose the encoder simply produces a garbled code that does not reflect that data manifold, yet it has the right aggregated posterior. In this case, the implicit generator and discriminator should ignore the code. However, the generator can still match the joint reconstruction and to the correct joint distribution. The loss can go towards its minimum. Note that this is not a problem in AVB.

2) Global vs local info: a closely related issue to previous failure mode is that encoder has no incentive to produce informative codes. While the paper argues that the size of the code can decide the decomposition of local vs. global information, even for a wide bottleneck in the autoencoder, the code can have no (or very little) information.

3) Could you please elaborate on the footnotes of page 3?</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">7: Good paper, accept</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_H1gmOkF5T7" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Rebuttal</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HyMRaoAqKX&amp;noteId=H1gmOkF5T7"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper852 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">15 Nov 2018</span><span class="item">ICLR 2019 Conference Paper852 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">We thank the reviewer for the positive feedback.

1,2) We have a detailed discussion about the global vs. local decomposition of information in Appendix C. In the case of having a wide bottleneck and a powerful implicit decoder p(x|z), the ELBO does not prefer one decomposition of information to another. So in this case, as the reviewer points out, in theory, the network can capture all the information solely by the latent code, solely by the implicit decoder, or by a combination of them. However, empirically, it is the *dynamic of training/optimization* and not the objective that determines the decomposition of information. The architecture of the IAE is very similar to that of the standard autoencoder. In fact, if we remove the local latent code, the IAE becomes a deterministic autoencoder, and the network learns the same kind of high-level concepts that an autoencoder would learn. However, in the presence of the local code, as shown by our empirical experiments, the network tries to capture as much information as possible by the latent code, but instead of averaging over the remaining information and generating blurry images, it captures the distribution of the remaining information by the implicit decoder.

3) In order to match r(x,z) to q(x,z), we back-propagate the reconstruction discriminator gradient through negative examples. In this case, we are considering q(x,z) as the target distribution that r(x,z) is trained to match to. The process of learning r(x,z) requires learning the encoder, which indirectly changes the underlying target distribution q(x,z) to a new target distribution q(x,z). In other words, r(x,z) is aiming a moving target distribution, which is q(x,z), and once the reconstruction discriminator is confused, we will have r(x,z)=q(x,z). We empirically observed that by only back-propagating through negative examples, we will provide a more stable target distribution for r(x,z) to aim for, which results in a more stable training dynamic and better empirical performance.</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div><div class="note_with_children"><div id="note_BkxEplmjnm" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Increasing the expressiveness of decoder by an implicit decoder looks interesting, and it enables the decompositions of high-level abstract information from low one.</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HyMRaoAqKX&amp;noteId=BkxEplmjnm"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper852 AnonReviewer2</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">03 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper852 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">The paper proposed an implicit auto-encoder, featuring both the encoder and decoder constituted by implicit distributions. Adversary training is used train the models, similar to the technique used in the AVB model. The main difference with AVB is the use of an implicit decoder, which endows the model with the ability to disentangle the data into high-level abstract representation and local representation. Although sharing some similarities, the extension of using implicit decoder is interesting, and leading to some interesting results. 

My main concern on this paper is the lack of any quantitive results to compare with other similar models. We only see the model can do some task, but cannot assess how well it did comparing to other models.</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">6: Marginally above acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">3: The reviewer is fairly confident that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_BJxHUqBopm" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Rebuttal</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HyMRaoAqKX&amp;noteId=BJxHUqBopm"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper852 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">16 Nov 2018</span><span class="item">ICLR 2019 Conference Paper852 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">We thank the reviewer for the feedback.
The main claim of our paper is that IAEs can learn useful unsupervised representations using their latent code. This is because the latent code of the IAE can only focus on capturing high-level abstractions, while the remaining low-level information is separately captured by the implicit decoder. While we have done many qualitative experiments to support our claim, we believe that the best currently available method to quantitatively evaluate unsupervised representations is to evaluate them on downstream tasks. So we quantitatively evaluated the usefulness of the IAE representations in our clustering and semi-supervised learning experiments on the MNIST and the SVHN datasets, and showed that the IAE can achieve very competitive results (Section 2.1.2 and Section 3.1). However, we believe it is important for the generative modeling research community to find better metrics for evaluating the quality of unsupervised representations in generative models.</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div></div></main></div>
  </div>
</div>


    <!-- Footer -->
    <footer class="sitemap">
      <div class="container">
        <div class="row hidden-xs">
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/venues">All Venues</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="/contact">Contact</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
    
        <div class="row visible-xs-block">
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/contact">Contact</a></li>
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
      </div>
    </footer>
    
    <footer class="sponsor">
      <div class="container">
        <div class="row">
          <div class="col-sm-10 col-sm-offset-1">
            <p class="text-center">
              OpenReview is created by the <a href="http://www.iesl.cs.umass.edu/" target="_blank">Information Extraction and Synthesis Laboratory</a>, College of Information and Computer Science, University of Massachusetts Amherst. We gratefully acknowledge the support of the OpenReview sponsors:  Google,  Facebook, NSF, the University of Massachusetts Amherst Center for Data Science, and Center for Intelligent Information Retrieval, as well as the Google Cloud Platform for donating the computing and networking services on which OpenReview.net runs.
            </p>
          </div>
        </div>
      </div>
    </footer>

  <div id="feedback-modal" class="modal fade" tabindex="-1" role="dialog">
    <div class="modal-dialog">
      <div class="modal-content">
        <div class="modal-header">
          <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button>
          <h3 class="modal-title">Send Feedback</h3>
        </div>
        <div class="modal-body">
          <p>Enter your feedback below and we'll get back to you as soon as possible.</p>
          <form action="/feedback" method="POST">
            <div class="form-group">
              <input type="email" name="from" class="form-control" placeholder="Email" />
            </div>
            <div class="form-group">
              <input type="text" name="subject" class="form-control" placeholder="Subject" />
            </div>
            <div class="form-group">
              <textarea name="message" class="form-control feedback-input" rows="5" placeholder="Message" required=""></textarea>
            </div>
          <ul id="ui-id-2" tabindex="0" class="ui-menu ui-widget ui-widget-content" style="display: none;"></ul></form>
        </div>
        <div class="modal-footer">
          <button type="button" class="btn btn-default" data-dismiss="modal">Cancel</button>
          <button type="button" class="btn btn-primary">Send</button>
        </div>
      </div>
    </div>
  </div>

  <script type="text/javascript" async="" src="https://www.google-analytics.com/analytics.js"></script><script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js"></script>
  <script>window.jQuery || document.write('&lt;script src="/static/js/vendor/jquery-2.2.4.min.js"&gt;&lt;\/script&gt;')</script>

  <script src="/static/dist/vendor.min.js"></script>
  <script src="/static/dist/templates.min.js"></script>
  <script src="/static/dist/openreview.min.js"></script>

    <script>window.legacyScripts = true;</script>


    <script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-108703919-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() { dataLayer.push(arguments); }
      gtag('js', new Date());
      gtag('config', 'UA-108703919-1');
    </script>


<div role="status" aria-live="assertive" aria-relevant="additions" class="ui-helper-hidden-accessible"></div></body></html>
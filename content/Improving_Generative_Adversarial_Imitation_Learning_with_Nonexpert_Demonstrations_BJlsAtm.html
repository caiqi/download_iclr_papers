<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" class="no-js"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>Improving Generative Adversarial Imitation Learning with Non-expert Demonstrations | OpenReview</title>
  <meta name="description" content="" />

      <meta name="citation_title" content="Improving Generative Adversarial Imitation Learning with Non-expert Demonstrations" />
        <meta name="citation_author" content="Anonymous" />
      <meta name="citation_publication_date" content="2018/09/27" />
      <meta name="citation_online_date" content="2018/09/27" />
      <meta name="citation_pdf_url" content="https://openreview.net/pdf?id=BJl65sA9tm" />
      <meta name="twitter:card" content="summary" />
      <meta name="twitter:site" content="@openreviewnet" />
      <meta name="og:title" content="Improving Generative Adversarial Imitation Learning with Non-expert..." />
      <meta name="og:description" content="Imitation learning aims to learn an optimal policy from expert demonstrations and its recent combination with deep learning has shown impressive performance. However, collecting a large number of..." />
      <meta name="og:image" content="https://openreview.net/static/images/openreview_logo_512.png" />

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans:400,400i,700,700i" />

  <link rel="stylesheet" href="/static/css/bootstrap.min.css" />
  <link rel="stylesheet" href="/static/css/jquery-ui.min.css" />
  <link rel="stylesheet" href="/static/css/main.min.css" />
</head>

<body class="forum">
  <nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
  
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand home push-link" href="/"><strong>OpenReview</strong>.net</a>
      </div>
  
      <div id="navbar" class="navbar-collapse collapse">
        <form class="navbar-form navbar-left profile-search" role="search">
          <div class="form-group has-feedback">
            <input id="search_input" type="text" class="form-control ui-autocomplete-input" placeholder="Search ICLR 2019 Conference" autocomplete="off" />
            <span class="glyphicon glyphicon-search form-control-feedback" aria-hidden="true"></span>
          </div>
  
          <input id="search_group" type="hidden" value="ICLR.cc/2019/Conference" />
          <input id="search_content" type="hidden" value="all" />
        <ul id="ui-id-1" tabindex="0" class="ui-menu ui-widget ui-widget-content ui-autocomplete ui-front" style="display: none;"></ul></form>
  
        <ul class="nav navbar-nav navbar-right">
        
            <li id="user-menu"><a href="/login">Login</a></li>
        </ul>
      </div>
  
    </div>
  </nav>

  <div id="or-banner" class="banner" style="">
  <div class="container">
    <div class="row">
      <div class="col-xs-12"><a href="/group?id=ICLR.cc/2019/Conference" title="Venue Homepage"><img class="icon" src="/static/images/arrow_left.svg" /> Go to <strong>ICLR 2019 Conference</strong> homepage</a></div>
    </div>
  </div>
</div>
<div id="flash-message-container" class="alert alert-danger" role="alert" style="display: none;">
  <div class="container">
    <div class="row">
      <div class="col-xs-12">
        <div class="alert-content">
          <button type="button" class="close" aria-label="Close"><span aria-hidden="true">×</span></button>
        </div>
      </div>
    </div>
  </div>
</div>

<div class="container">
  <div class="row">
    <div class="col-xs-12">
      <main id="content" class="clearfix openbanner-visible legacy-styles"><div id="note_BJl65sA9tm" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Improving Generative Adversarial Imitation Learning with Non-expert Demonstrations</a> <a class="note_content_pdf" href="/pdf?id=BJl65sA9tm" title="Download PDF" target="_blank"><img src="/static/images/pdf_icon_blue.svg" /></a> </h2></div><div class="meta_row"><span class="signatures">Anonymous</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">28 Sep 2018 (modified: 11 Oct 2018)</span><span class="item">ICLR 2019 Conference Blind Submission</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span><span class="item"><a class="action-bibtex-modal" data-bibtex="@inproceedings{    &#10;anonymous2019improving,    &#10;title={Improving Generative Adversarial Imitation Learning with Non-expert Demonstrations},    &#10;author={Anonymous},    &#10;booktitle={Submitted to International Conference on Learning Representations},    &#10;year={2019},    &#10;url={https://openreview.net/forum?id=BJl65sA9tm},    &#10;note={under review}    &#10;}">Show Bibtex</a></span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Abstract: </span><span class="note_content_value">Imitation learning aims to learn an optimal policy from expert demonstrations and its recent combination with deep learning has shown impressive performance. However, collecting a large number of expert demonstrations for deep learning is time-consuming and requires much expert effort. In this paper, we propose a method to improve generative adversarial imitation learning by using additional information from non-expert demonstrations which are easier to obtain. The key idea of our method is to perform multiclass classification to learn discriminator functions where non-expert demonstrations are regarded as being drawn from an extra class. Experiments in continuous control tasks demonstrate that our method learns optimal policies faster and has more stable performance than the  generative adversarial imitation learning baseline.</span></div><div class="note_contents"><span class="note_content_field">Keywords: </span><span class="note_content_value">Imitation learning, Generative adversarial imitation learning</span></div><div class="note_contents"><span class="note_content_field">TL;DR: </span><span class="note_content_value">We improve GAIL by learning discriminators using multiclass classification with non-expert regarded as an extra class.</span></div><div class="reply_row clearfix"><div class="item" id="reply_count">5 Replies</div></div></div><hr class="small" /><div id="note_children"><div class="note_with_children"><div id="note_rJxYAkx46m" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Interesting idea but experimental comparison may not be fair, also sensitivity to lambda parameter is unclear</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=BJl65sA9tm&amp;noteId=rJxYAkx46m"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper575 AnonReviewer1</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">10 Nov 2018</span><span class="item">ICLR 2019 Conference Paper575 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">Description:

This paper presents a variant of imitation-based reinforcement learning, when in addition to example trajectories of an expert , example trajectories of non-experts are available.

In brief, the method is a variant of the GAIL method for adversarial training. In GAIL, the policy is optimized to minimize the ability to discriminate (classify) two classes: trajectories of the expert vs. trajectories from the policy, where the discrimination ability is measured by a neural network discriminator function optimized for maximal discriminative ability. In the proposed  method "M-GAIL", the idea is that the discriminator is forced to also discriminate a third class of non-expert demonstrations, but policy optimization is done ignoring the non-expert demonstrations and classifying only the usual two classes with the discriminator.

The M-GAIL method is compared to GAIL on four control tasks with different amounts of simulated non-expert demonstrations available, and  it outperforms GAIL if the simulated non-expert demonstrations are chosen to be relatively good ones (simulated from a policy having 70% of expert performance).


Evaluation:

The method is described relatively well and the idea of incorporating nonexpert demonstrations seems sound.

It is not clear to me if the experiment is fair, since M-GAIL learns from more data than GAIL which learns from the expert demonstrations only. It is unclear to me why the experiments did not attempt to supply the nonexpert demonstrations to GAIL too - one could e.g. have naively pooled the nonexpert demonstration into one of GAIL's binary classes, "expert" or "policy". This is especially concerning since bett

The method also requires the additional parameter lambda which affects performance in the experiments - it is not clear how to set it in practice, does e.g. cross-validation etc. need to be used? It would be useful to know more about sensitivity to lambda, experiments only consider two values.


Additional comments:

In the methodological derivation, it was unclear to me why only one parameter lambda is used to control class balance, why not two parameters controlling prevalence of the expert class, policy class, and nonexpert class?

In proposition 1 the fact that the bias vanishes when lambda=0 seems trivial because eq. 9 reduces to the first term on the right hand side.

In eq. 5 it's not quite right to call the right-hand side a loglikelihood. Loglikelihoods should be sums over observations of each class (thus emphasizing classes with more data) whereas here each term is an expectation - or do you assume the number of samples corresponding to each expectation term is equal?

Clarify the notation d_phi when you introduce it near eq. 3.
</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">5: Marginally below acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">3: The reviewer is fairly confident that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_HJl1UZlN6Q" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Correction to broken sentence</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=BJl65sA9tm&amp;noteId=HJl1UZlN6Q"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper575 AnonReviewer1</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">10 Nov 2018</span><span class="item">ICLR 2019 Conference Paper575 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">The sentence "This is especially concerning since bett" was missing some words, it should have read as follows: "This is especially concerning since best performance in M-GAIL depends on quality of the non-expert demonstrations, hence GAIL could also benefit from them under some quality settings."</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div><div class="note_with_children"><div id="note_BygZOLGGaQ" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Formulation seems unnecessary compared to existing imitation learning frameworks</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=BJl65sA9tm&amp;noteId=BygZOLGGaQ"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper575 AnonReviewer4</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">09 Nov 2018</span><span class="item">ICLR 2019 Conference Paper575 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">This paper proposes M-GAIL, which performs imitation learning from expert as well as sub-optimal demonstrations. This work builds off of GAIL (Ho et. al 2016) but modifies the discriminator with an additional class corresponding to sub-optimal demonstrations. The authors show empirically that including these sub-optimal demonstrations into the training process leads to faster and improved learning.

While allowing the use of sub-optimal demonstrations is important and could have useful benefits in practice, I find the new algorithmic formulation unnecessary when compared to previous works. One of the theoretical benefits of MaxCausalEnt IRL (and by extension GAIL) is that because the model is probabilistic, not all demonstrations need to be reward-maximizing. The definition of optimality is relaxed from meaning exact reward maximization to coming from some optimal distribution over trajectories.

Correct me if I am wrong, but in the case of this work, the proposed algorithm seems equivalent to adding the "sub-optimal" demonstrations to the expert demonstrations, but down-weighting each sub-optimal demonstration be a factor of \lambda. Thus, I don't believe we need to introduce an entirely new algorithm, with the concept of a 3rd class, to solve this problem. The existing MaxEnt frameworks seem to handle the notion of sub-optimality proposed in this paper just as well, interpreting the "sub-optimal" demonstrations as low-probability expert demonstrations. This feels cleaner and more intuitive than the current proposed explanation as maximizing a mixture of two reward functions (in the IRL view) or minimizing occupancy measure divergence over 3 distributions (in the IL view). If this equivalence is true, I would encourage the authors to include this discussion in the main paper, and if not, discuss the differences and possibly compare against this simple strategy as a baseline.

I find the empirical results quite interesting, even though the gains seem small. Including sub-optimal demonstrations to learn from could be a nice trick to improve the learning of GAIL-like algorithms, which is nice to know. I am curious if the authors tried annealing the \lambda term from 1.0 to 0.0, as lambda=1.0 is likely easier to learn from, but lambda=0.0 would have better asymptotic performance.</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">5: Marginally below acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_S1g02-Kc3X" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Intersting idea</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=BJl65sA9tm&amp;noteId=S1g02-Kc3X"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper575 AnonReviewer2</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">03 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper575 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">Summary:
This paper is about adversarial imitation learning and how data from non experts can be used to improve representation learning of the discriminator function. They also change the training objective because minmax does not lead to an optimal policy in the proposed setting. The data from non experts is used a separate class (so the discriminator learns to discriminate between expert, agent and non-expert policy). 

Clarity: well written, with an intro to both relative fields - reinforcement learning and imitation learning. 

Comments:
Overall, quite a neat idea - the information from non expert policy can help with representation learning, and the authors show that it is indeed the case via a number of experiments 
At the same time, i wonder if the third class is required. It seems that gail in the experiments eventually reaches the same performance (figure 1) by looking at more agents trajectories. why can't non expert trajectories be considered as an initial set of agent trajectories? If multiclass is indeed required, it would be nice to see a comparison of what happens when non experts trajectories were just considered agents
Another thing i am surprised about is the leel of variance of GAIL in Figure 1. In table 1 we see that standard errors between the new method and gail are comparable, where does such a huge diff in var come from in Figure 1?
Also the sensitivity of the algorithm to lambda - how would one go setting it? In the experiments it seems that authors just try two different values (0.1 and 0.5) but i assume this really should be a hyperparameter search for this. Is lambda dependent on the number of expert and non expert demonstrations that are available?



</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">7: Good paper, accept</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">3: The reviewer is fairly confident that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_rklN7J19hQ" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>too little contribution</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=BJl65sA9tm&amp;noteId=rklN7J19hQ"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper575 AnonReviewer3</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">02 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper575 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">The paper proposes a modification of GAIL (Ho &amp; Ermon, 2016) to make use of non-expert data. The non-expert data is used by training a classifier to classify between roll-outs of the current policy, expert demonstrations and non-expert demonstrations. Similar to GAIL, the policy is iteratively updated using TRPO with a cost that is given by the log probability of predicting the policy. The use of non-expert data acts as regularization in order to learn better features similar to universum prescription (Zhang &amp; LeCun, 2017).  

The paper is well-written and very clear. The general problem setting is interesting, but I think it is of rather little significance, because I do not see many clear applications. The evaluation focuses on simulated robots, however gathering non-expert data on real robots would be very expensive, so the approach would not make a lot of sense here (even if we replace TRPO a more sample efficient rl method). The paper mentions the game of Go, but learning a policy on such large state spaces is not feasible without major modification and significant computational effort. However, the paper also mentions autonomous driving, which might be a more convincing application, because we can have a lot of demonstrations that we do not want to label as expert trajectories. I think the paper would profit a lot from having an experiment where the importance of making use of non-expert data becomes evident.

The approach seems sound, although I think that we can not expect much benefit from using the unlabelled data in the proposed way. By not making any assumptions on the non-expert data, they do not carry any information about the objective; the information that they carry about the system dynamics is not exploited for the RL update. Instead, the use of non-expert data is restricted to learning better features for discriminating between the agent and the expert. However, non-expert data is typically not cheaper than policy roll-outs and better features could also be learned by using more samples from the policy. The experiments also show only slight benefits, especially when comparing the final performance (instead of total returns) and accounting for the additional system interactions needed for generating the non-expert data. To make the comparison fairer, we could consider using a few more system interactions (variable K in the paper) per iteration for standard GAIL, so that the total number of function evaluations would match those of M-GAIL after a certain number of iterations. Especially if K is appropriately tuned, it is not clear whether we could still show an advantage of M-GAIL. It would also be interesting to show, whether we can benefit from using the policy roll-outs of previous iterations as non-expert data for the current iteration (in the traditional IL setting where no non-expert data is available a priori).

The main weakness of the paper is, that the novelty seems marginal. Instead of doing binary classification with cross-entropy loss, we're doing three-class classification with cross-entropy loss and use it for binary classification (by throwing away the auxiliary logit for predicting the non-expert class). Did I miss any other difference to GAIL? We can argue whether the policy objective is different (to me, H_\phi of M-GAIL corresponds to the discriminator of GAIL and the objective is exactly the same), however, even if we call it a minor modification, we would have very little novelty in the approach. As the paper does also not compensate for this with very good results or thorough theoretical analysis, I think that the contribution is too minor.

I do not see the point of section 4.4. and the related appendix A2. For all I understand, it proves that when using lambda=0 (standard GAIL, right?), the proof of Fu et al. (2018) for GAIL is valid (i.e. we learn a completely useless reward function that does not carry any additional information compared to the policy), and when using lambda!=0 we learn something different. I don't see the the purpose of this statement and I don't think that it needs to be proven. The paper argues, that for small lambda we can treat the discriminator logits as approximations of these (completely useless) reward functions--without providing any bound. As I do not see why this would be useful, I think the section should be removed. 

Minor:
Typo: "[...]due to its dependent[sic] on the linearity of reward functions and good feature engineering" 
</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">4: Ok but not good enough - rejection</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></main></div>
  </div>
</div>


    <!-- Footer -->
    <footer class="sitemap">
      <div class="container">
        <div class="row hidden-xs">
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/venues">All Venues</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="/contact">Contact</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
    
        <div class="row visible-xs-block">
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/contact">Contact</a></li>
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
      </div>
    </footer>
    
    <footer class="sponsor">
      <div class="container">
        <div class="row">
          <div class="col-sm-10 col-sm-offset-1">
            <p class="text-center">
              OpenReview is created by the <a href="http://www.iesl.cs.umass.edu/" target="_blank">Information Extraction and Synthesis Laboratory</a>, College of Information and Computer Science, University of Massachusetts Amherst. We gratefully acknowledge the support of the OpenReview sponsors:  Google,  Facebook, NSF, the University of Massachusetts Amherst Center for Data Science, and Center for Intelligent Information Retrieval, as well as the Google Cloud Platform for donating the computing and networking services on which OpenReview.net runs.
            </p>
          </div>
        </div>
      </div>
    </footer>

  <div id="feedback-modal" class="modal fade" tabindex="-1" role="dialog">
    <div class="modal-dialog">
      <div class="modal-content">
        <div class="modal-header">
          <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button>
          <h3 class="modal-title">Send Feedback</h3>
        </div>
        <div class="modal-body">
          <p>Enter your feedback below and we'll get back to you as soon as possible.</p>
          <form action="/feedback" method="POST">
            <div class="form-group">
              <input type="email" name="from" class="form-control" placeholder="Email" />
            </div>
            <div class="form-group">
              <input type="text" name="subject" class="form-control" placeholder="Subject" />
            </div>
            <div class="form-group">
              <textarea name="message" class="form-control feedback-input" rows="5" placeholder="Message" required=""></textarea>
            </div>
          <ul id="ui-id-2" tabindex="0" class="ui-menu ui-widget ui-widget-content" style="display: none;"></ul></form>
        </div>
        <div class="modal-footer">
          <button type="button" class="btn btn-default" data-dismiss="modal">Cancel</button>
          <button type="button" class="btn btn-primary">Send</button>
        </div>
      </div>
    </div>
  </div>

  <script type="text/javascript" async="" src="https://www.google-analytics.com/analytics.js"></script><script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js"></script>
  <script>window.jQuery || document.write('&lt;script src="/static/js/vendor/jquery-2.2.4.min.js"&gt;&lt;\/script&gt;')</script>

  <script src="/static/dist/vendor.min.js"></script>
  <script src="/static/dist/templates.min.js"></script>
  <script src="/static/dist/openreview.min.js"></script>

    <script>window.legacyScripts = true;</script>


    <script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-108703919-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() { dataLayer.push(arguments); }
      gtag('js', new Date());
      gtag('config', 'UA-108703919-1');
    </script>


<div role="status" aria-live="assertive" aria-relevant="additions" class="ui-helper-hidden-accessible"></div></body></html>
<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" class="no-js"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>Learning Corresponded Rationales for Text Matching | OpenReview</title>
  <meta name="description" content="" />

      <meta name="citation_title" content="Learning Corresponded Rationales for Text Matching" />
        <meta name="citation_author" content="Anonymous" />
      <meta name="citation_publication_date" content="2018/09/27" />
      <meta name="citation_online_date" content="2018/09/27" />
      <meta name="citation_pdf_url" content="https://openreview.net/pdf?id=rklQas09tm" />
      <meta name="twitter:card" content="summary" />
      <meta name="twitter:site" content="@openreviewnet" />
      <meta name="og:title" content="Learning Corresponded Rationales for Text Matching" />
      <meta name="og:description" content="The ability to predict matches between two sources of text has a number of applications including natural language inference (NLI) and question answering (QA). While flexible neural models have..." />
      <meta name="og:image" content="https://openreview.net/static/images/openreview_logo_512.png" />

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans:400,400i,700,700i" />

  <link rel="stylesheet" href="/static/css/bootstrap.min.css" />
  <link rel="stylesheet" href="/static/css/jquery-ui.min.css" />
  <link rel="stylesheet" href="/static/css/main.min.css" />
</head>

<body class="forum">
  <nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
  
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand home push-link" href="/"><strong>OpenReview</strong>.net</a>
      </div>
  
      <div id="navbar" class="navbar-collapse collapse">
        <form class="navbar-form navbar-left profile-search" role="search">
          <div class="form-group has-feedback">
            <input id="search_input" type="text" class="form-control ui-autocomplete-input" placeholder="Search ICLR 2019 Conference" autocomplete="off" />
            <span class="glyphicon glyphicon-search form-control-feedback" aria-hidden="true"></span>
          </div>
  
          <input id="search_group" type="hidden" value="ICLR.cc/2019/Conference" />
          <input id="search_content" type="hidden" value="all" />
        <ul id="ui-id-1" tabindex="0" class="ui-menu ui-widget ui-widget-content ui-autocomplete ui-front" style="display: none;"></ul></form>
  
        <ul class="nav navbar-nav navbar-right">
        
            <li id="user-menu"><a href="/login">Login</a></li>
        </ul>
      </div>
  
    </div>
  </nav>

  <div id="or-banner" class="banner" style="">
  <div class="container">
    <div class="row">
      <div class="col-xs-12"><a href="/group?id=ICLR.cc/2019/Conference" title="Venue Homepage"><img class="icon" src="/static/images/arrow_left.svg" /> Go to <strong>ICLR 2019 Conference</strong> homepage</a></div>
    </div>
  </div>
</div>
<div id="flash-message-container" class="alert alert-danger" role="alert" style="display: none;">
  <div class="container">
    <div class="row">
      <div class="col-xs-12">
        <div class="alert-content">
          <button type="button" class="close" aria-label="Close"><span aria-hidden="true">×</span></button>
        </div>
      </div>
    </div>
  </div>
</div>

<div class="container">
  <div class="row">
    <div class="col-xs-12">
      <main id="content" class="clearfix openbanner-visible legacy-styles"><div id="note_rklQas09tm" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Learning Corresponded Rationales for Text Matching</a> <a class="note_content_pdf" href="/pdf?id=rklQas09tm" title="Download PDF" target="_blank"><img src="/static/images/pdf_icon_blue.svg" /></a> </h2></div><div class="meta_row"><span class="signatures">Anonymous</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">28 Sep 2018 (modified: 11 Oct 2018)</span><span class="item">ICLR 2019 Conference Blind Submission</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span><span class="item"><a class="action-bibtex-modal" data-bibtex="@inproceedings{    &#10;anonymous2019learning,    &#10;title={Learning Corresponded Rationales for Text Matching},    &#10;author={Anonymous},    &#10;booktitle={Submitted to International Conference on Learning Representations},    &#10;year={2019},    &#10;url={https://openreview.net/forum?id=rklQas09tm},    &#10;note={under review}    &#10;}">Show Bibtex</a></span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Abstract: </span><span class="note_content_value">The ability to predict matches between two sources of text has a number of applications including natural language inference (NLI) and question answering (QA). While flexible neural models have become effective tools in solving these tasks, they are rarely transparent in terms of the mechanism that mediates the prediction. In this paper, we propose a self-explaining architecture where the model is forced to highlight, in a dependent manner, how spans of one side of the input match corresponding segments of the other side in order to arrive at the overall decision. The text spans are regularized to be coherent and concise, and their correspondence is captured explicitly. The text spans -- rationales -- are learned entirely as latent mechanisms, guided only by the distal supervision from the end-to-end task. We evaluate our model on both NLI and QA using three publicly available datasets.  Experimental results demonstrate quantitatively and qualitatively that our method delivers interpretable justification of the prediction without sacrificing state-of-the-art performance. Our code and data split will be publicly available. </span></div><div class="note_contents"><span class="note_content_field">Keywords: </span><span class="note_content_value">interpretability, rationalization, text matching, dependent selection</span></div><div class="note_contents"><span class="note_content_field">TL;DR: </span><span class="note_content_value">We propose a novel self-explaining architecture to predict matches between two sequences of texts. Specifically, we introduce the notion of corresponded rationales and learn to extract them by the distal supervision from the downstream task.</span></div><div class="reply_row clearfix"><div class="item" id="reply_count">3 Replies</div></div></div><hr class="small" /><div id="note_children"><div class="note_with_children"><div id="note_SJeyrnU0h7" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Interesting model with somewhat promising experiments, could benefit from some more comparisons</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=rklQas09tm&amp;noteId=SJeyrnU0h7"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper787 AnonReviewer3</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">06 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper787 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">This paper is about learning paired rationales that include the corresponding relevant spans of the (question, passage) or (premise, hypothesis).  Experimental results show the same or better accuracies using just the fraction of the input selected as when the whole input is used.

While there has been prior work on learning rationales, this is the first I have seen that included this fine-grained pairing.  The paper also learns these rationales without explicitly labeled rationales but rather with only the distant supervision of the overall question answering or natural language inference task.

This paper could be made stronger by including an experimental evaluation of accuracy in an adversarial setting.  The model developed here might be well-suited for adversarial SquAD examples in which an extra sentence has been added.  It would be interesting to see these results.  This paper does include a somewhat similar adversarial evaluation (Section 4.3) but adds extra information to NLI examples.  Since for NLI, unlike QA, the extra sentence can change the correct label (can flip from entailment to contradiction), accuracy was not able to be evaluated.

Experimentally, it would be good to compare against some prior work that doesn't include the pairing.  Perhaps an interpretability model based on the passage only without fine-grained pairing with the question?  My apologies if this corresponds to "Independent", I was somewhat confused by descriptions of the baseline.

The descriptions of the baselines was the least clear part of this paper.  It would be helpful to improve the clarity of Section 4.1 (perhaps adding a figure).

Optional suggestion: consider breaking up the experiment section into two subsections: one for the cases in which the question rationales are provided (results in Table 1), and one for the cases in which the question-side rationales are learned as well (Table 2).  By putting all descriptions together, the paper explains two different settings and then needs to discuss which baselines are applicable to each setting and dataset and why.</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">6: Marginally above acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_H1eiY7Ys2X" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Review</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=rklQas09tm&amp;noteId=H1eiY7Ys2X"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper787 AnonReviewer2</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">04 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper787 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">
This paper tackles the problem of generating rationales for text matching problems (i.e., two pieces of text are given). The approach is in a similar spirit as (Lei et al, 2016) while the latter mainly focuses on one piece of text for text classification problems and this work focuses on generating pairs of rationales. The approach has been evaluated on NLI and QA datasets, which demonstrates that the generated rationales are sensible and comes at a cost of accuracy.

The approach employs a generation-encoding-generation schema: it firsts generates the rationale from one side as a sequence tagging problem, re-encodes the rationales and predicts the rationale on the other side as a span prediction problem. Leveraging a match-LSTM framework and generated rationales for prediction, the model can be trained using a policy gradient method.

Overall, I think this problem is novel and interesting. However, I am not fully convinced whether the proposed solution (and its implementation) is the right way to do so. Also, the paper writing needs to much improved.

First of all, there is certainly a drop in the end task performance while it is unclear whether the derived rationales are really that useful (if the goal is interpretability) in the current evaluation. I am not convinced by the noisy SciTrail evaluation for rationales -- the noisy part p’ can be totally irrelevant and assume that the rationale generation component learns some sort of alignment between two parts, so it is not surprising that the model will not select words from p’ and it doesn’t really show that the rationales are useful. I think it is necessary to conduct some human evaluation for generate rationales and also provide some simple baselines for comparison (for example, just converting the soft-attention in math-LSTM to some hard selections) and see if this interpretability (at a cost of task performance) is really worthy or not.

Secondly, I am not sure that whether the current way of generating the rationale pairs really makes sense or not.
It casts the rationale generation on one side as a tagging problem while the rationale generation on the other side as a span prediction problem. Why is that? Do you make any assumption that the two pieces of texts are not symmetric (e.g., one side is much longer than the other side like most of the current QA setup)?

There is a regularization term for both x and y but it seems that there isn’t any constraint that the generated rationales on the y side are not overlapping. Is it a problem or not? I don’t know how this is dealt with in the implementation.

Understanding sec 3 takes some efforts and I think the presentation could be much improved. For example, q * {x^k} is not defined -- I assume it means extracting the subset of q based on the 1’s in {x^k}. The equations in Sec 3.2 can be made clearer.

Finally, it is also unclear that how the 3 datasets were chosen. There are so many NLI and QA datasets (some of them are more popular and more competitive) at this point. Is there a reason that these datasets were chosen? There is a setup called ‘no rationalization w/ re-encoding’ which means that the rationale is already provided on one side, but is unclear that whether the OpenIE tuple and the searchQA queries can be used as rationales directly.

Minor points:
- Distal supervision -&gt; distant supervision
- The first paragraph of Introduction, “absent attention or rationale mechanisms”, what does it mean by ‘absent attention’? Isn’t it the case that all the models used attention mechanisms?
</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">4: Ok but not good enough - rejection</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_Sye_Ff482m" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Interpretability is important; but without human data we cannot evaluate it</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=rklQas09tm&amp;noteId=Sye_Ff482m"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper787 AnonReviewer1</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">31 Oct 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper787 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">This paper proposes an approach to introduce interpretability in NLP tasks involving text matching. However, the evaluation is not evaluated using human input, thus it is not clear whether the model is indeed meeting this important goal. Furthermore, there is no direct comparison against related work on the same topic, so it is not possible to assess the contributions over the state of the art on the topic. In more detail:

- There are versions of attention mechanisms that are spare and differentiable. See here: 
From Softmax to Sparsemax: A Sparse Model of Attention and Multi-Label Classification
André F. T. Martins, Ramón Fernandez Astudillo 

- Why is "rationalizing textual matching" different than other approaches to explaining the predictions of a model? As far as I can tell, thresholding on existing attention would give the same output. I am not arguing that there is nothing different, but there should be a direct comparison, especially since eventually the method proposed is thresholded as well by limiting the number of highlights.

- A key assumption in the paper is that the method identifies rationales that humans would find useful as explanations. However there is no evaluation of this assumption. For a recent example of how such human evaluation could be done see:
D. Nguyen. Comparing automatic and human evaluation of local explanations for text classification. NAACL 2018
<a href="http://www.dongnguyen.nl/publications/nguyen-naacl2018.pdf" target="_blank" rel="nofollow">http://www.dongnguyen.nl/publications/nguyen-naacl2018.pdf</a>

- I don't agree that explanations are sufficient if removing them doesn't degrade performance. While these two are related concepts, the quality of the explanation to a human is different to a system. In fact, more text can degrade performance when it is unrelated. See the experiments of this paper:
Adversarial Examples for Evaluating Reading Comprehension Systems.
Robin Jia and Percy Liang. EMNLP 2017: http://stanford.edu/~robinjia/pdf/emnlp2017-adversarial.pdf

- Reducing the selection of rationales to sequence tagging eventually done as classification is suboptimal compared to work on submodular optimization (cited in the introduction) if being concise is important. A comparison is needed.

- There is an argument that the training objective makes generated rationales corresponded and sufficient. This requires some evidence to support it.

- What is the "certificate of exclusion of unselected parts" that the proposed method has?

- An important argument is that the performance does not degrade. However there is no comparison against state of the art models to verfiy it.</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">3: Clear rejection</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></main></div>
  </div>
</div>


    <!-- Footer -->
    <footer class="sitemap">
      <div class="container">
        <div class="row hidden-xs">
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/venues">All Venues</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="/contact">Contact</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
    
        <div class="row visible-xs-block">
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/contact">Contact</a></li>
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
      </div>
    </footer>
    
    <footer class="sponsor">
      <div class="container">
        <div class="row">
          <div class="col-sm-10 col-sm-offset-1">
            <p class="text-center">
              OpenReview is created by the <a href="http://www.iesl.cs.umass.edu/" target="_blank">Information Extraction and Synthesis Laboratory</a>, College of Information and Computer Science, University of Massachusetts Amherst. We gratefully acknowledge the support of the OpenReview sponsors:  Google,  Facebook, NSF, the University of Massachusetts Amherst Center for Data Science, and Center for Intelligent Information Retrieval, as well as the Google Cloud Platform for donating the computing and networking services on which OpenReview.net runs.
            </p>
          </div>
        </div>
      </div>
    </footer>

  <div id="feedback-modal" class="modal fade" tabindex="-1" role="dialog">
    <div class="modal-dialog">
      <div class="modal-content">
        <div class="modal-header">
          <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button>
          <h3 class="modal-title">Send Feedback</h3>
        </div>
        <div class="modal-body">
          <p>Enter your feedback below and we'll get back to you as soon as possible.</p>
          <form action="/feedback" method="POST">
            <div class="form-group">
              <input type="email" name="from" class="form-control" placeholder="Email" />
            </div>
            <div class="form-group">
              <input type="text" name="subject" class="form-control" placeholder="Subject" />
            </div>
            <div class="form-group">
              <textarea name="message" class="form-control feedback-input" rows="5" placeholder="Message" required=""></textarea>
            </div>
          <ul id="ui-id-2" tabindex="0" class="ui-menu ui-widget ui-widget-content" style="display: none;"></ul></form>
        </div>
        <div class="modal-footer">
          <button type="button" class="btn btn-default" data-dismiss="modal">Cancel</button>
          <button type="button" class="btn btn-primary">Send</button>
        </div>
      </div>
    </div>
  </div>

  <script type="text/javascript" async="" src="https://www.google-analytics.com/analytics.js"></script><script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js"></script>
  <script>window.jQuery || document.write('&lt;script src="/static/js/vendor/jquery-2.2.4.min.js"&gt;&lt;\/script&gt;')</script>

  <script src="/static/dist/vendor.min.js"></script>
  <script src="/static/dist/templates.min.js"></script>
  <script src="/static/dist/openreview.min.js"></script>

    <script>window.legacyScripts = true;</script>


    <script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-108703919-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() { dataLayer.push(arguments); }
      gtag('js', new Date());
      gtag('config', 'UA-108703919-1');
    </script>


<div role="status" aria-live="assertive" aria-relevant="additions" class="ui-helper-hidden-accessible"></div></body></html>
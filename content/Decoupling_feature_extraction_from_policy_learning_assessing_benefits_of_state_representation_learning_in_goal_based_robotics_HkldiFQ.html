<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" class="no-js"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>Decoupling feature extraction from policy learning: assessing benefits of state representation learning in goal based robotics | OpenReview</title>
  <meta name="description" content="" />

      <meta name="citation_title" content="Decoupling feature extraction from policy learning: assessing benefits of state representation learning in goal based robotics" />
        <meta name="citation_author" content="Anonymous" />
      <meta name="citation_publication_date" content="2018/09/27" />
      <meta name="citation_online_date" content="2018/09/27" />
      <meta name="citation_pdf_url" content="https://openreview.net/pdf?id=Hkl-di09FQ" />
      <meta name="twitter:card" content="summary" />
      <meta name="twitter:site" content="@openreviewnet" />
      <meta name="og:title" content="Decoupling feature extraction from policy learning: assessing..." />
      <meta name="og:description" content="Scaling end-to-end reinforcement learning to control real robots from vision presents a series of challenges, in particular in terms of sample efficiency. Against end-to-end learning, state..." />
      <meta name="og:image" content="https://openreview.net/static/images/openreview_logo_512.png" />

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans:400,400i,700,700i" />

  <link rel="stylesheet" href="/static/css/bootstrap.min.css" />
  <link rel="stylesheet" href="/static/css/jquery-ui.min.css" />
  <link rel="stylesheet" href="/static/css/main.min.css" />
</head>

<body class="forum">
  <nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
  
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand home push-link" href="/"><strong>OpenReview</strong>.net</a>
      </div>
  
      <div id="navbar" class="navbar-collapse collapse">
        <form class="navbar-form navbar-left profile-search" role="search">
          <div class="form-group has-feedback">
            <input id="search_input" type="text" class="form-control ui-autocomplete-input" placeholder="Search ICLR 2019 Conference" autocomplete="off" />
            <span class="glyphicon glyphicon-search form-control-feedback" aria-hidden="true"></span>
          </div>
  
          <input id="search_group" type="hidden" value="ICLR.cc/2019/Conference" />
          <input id="search_content" type="hidden" value="all" />
        <ul id="ui-id-1" tabindex="0" class="ui-menu ui-widget ui-widget-content ui-autocomplete ui-front" style="display: none;"></ul></form>
  
        <ul class="nav navbar-nav navbar-right">
        
            <li id="user-menu"><a href="/login">Login</a></li>
        </ul>
      </div>
  
    </div>
  </nav>

  <div id="or-banner" class="banner" style="">
  <div class="container">
    <div class="row">
      <div class="col-xs-12"><a href="/group?id=ICLR.cc/2019/Conference" title="Venue Homepage"><img class="icon" src="/static/images/arrow_left.svg" /> Go to <strong>ICLR 2019 Conference</strong> homepage</a></div>
    </div>
  </div>
</div>
<div id="flash-message-container" class="alert alert-danger" role="alert" style="display: none;">
  <div class="container">
    <div class="row">
      <div class="col-xs-12">
        <div class="alert-content">
          <button type="button" class="close" aria-label="Close"><span aria-hidden="true">Ã—</span></button>
        </div>
      </div>
    </div>
  </div>
</div>

<div class="container">
  <div class="row">
    <div class="col-xs-12">
      <main id="content" class="clearfix openbanner-visible legacy-styles"><div id="note_Hkl-di09FQ" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Decoupling feature extraction from policy learning: assessing benefits of state representation learning in goal based robotics</a> <a class="note_content_pdf" href="/pdf?id=Hkl-di09FQ" title="Download PDF" target="_blank"><img src="/static/images/pdf_icon_blue.svg" /></a> </h2></div><div class="meta_row"><span class="signatures">Anonymous</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">28 Sep 2018 (modified: 11 Oct 2018)</span><span class="item">ICLR 2019 Conference Blind Submission</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span><span class="item"><a class="action-bibtex-modal" data-bibtex="@inproceedings{    &#10;anonymous2019decoupling,    &#10;title={Decoupling feature extraction from policy learning: assessing benefits of state representation learning in goal based robotics},    &#10;author={Anonymous},    &#10;booktitle={Submitted to International Conference on Learning Representations},    &#10;year={2019},    &#10;url={https://openreview.net/forum?id=Hkl-di09FQ},    &#10;note={under review}    &#10;}">Show Bibtex</a></span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Abstract: </span><span class="note_content_value">Scaling end-to-end reinforcement learning to control real robots from vision presents a series of challenges, in particular in terms of sample efficiency. Against end-to-end learning, state representation learning can help learn a compact, efficient and relevant representation of states that speeds up policy learning, reducing the number of samples needed, and that is easier to interpret. We evaluate several state representation learning methods on goal based robotics tasks and propose a new unsupervised model that stacks representations and combines strengths of several of these approaches. This method encodes all the relevant features, performs on par or better than end-to-end learning, and is robust to hyper-parameters change.</span></div><div class="note_contents"><span class="note_content_field">Keywords: </span><span class="note_content_value">reinforcement learning, state representation learning, feature extraction, robotics, deep learning</span></div><div class="note_contents"><span class="note_content_field">TL;DR: </span><span class="note_content_value">We evaluate the benefits of decoupling feature extraction from policy learning in robotics and propose a new way of combining state representation learning methods.</span></div><div class="reply_row clearfix"><div class="item" id="reply_count">3 Replies</div></div></div><hr class="small" /><div id="note_children"><div class="note_with_children"><div id="note_rklb2FSeam" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>This paper on SRL provides some interesting results, but it methods should be better motivated, and its conclusions be made more precise..</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=Hkl-di09FQ&amp;noteId=rklb2FSeam"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper326 AnonReviewer3</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">07 Nov 2018</span><span class="item">ICLR 2019 Conference Paper326 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">This paper discusses State Representation Learning for RL from camera images. Specifically, it proposes to use a state representation consisting of 2 (or 3) parts that are trained separately on different aspects of the relevant state: reward prediction, image reconstruction and (inverse) model learning. The paper is easy to read, and seems technically sound. However, the conclusions do not directly follow from the results, so should be made more precise. The contribution is minor, and the reasoning behind it could be better motivated. 

The most important point of critique is that the conclusion that the split representation is the best is at best premature. The presented results indicate that SRL is useful (Table 1), and that auto-encoding alone is often not enough. Other than that, the different approaches tested all work well in different tasks. The discussion of the results reflects this, but the introduction and conclusion suggest otherwise.

The same problem also occurs for the conclusion about the robustness of SRL approaches. In the main text, no results are presented that warrant such a conclusion. The appendix includes some tests in this direction, but conclusions should not be based on material that is only available in the appendix. Furthermore, even the tests in the appendix are not comprehensive enough to to warrant the conclusion as written.

The second point is the motivation of the split approach: it seems in direct contradiction with the "disentangled" and "compact" demands the authors pose. Because the parts of the state that are needed for multiple different prediction tasks (reconstruction, inverse model, etc.) need to be in the final
state representation multiple times. Due to the shared feature extractor, the contradictory objectives (and hence the need for tuning of the weights in the cost function) are still a potential problem.

Minor points:

- The choice for these tasks is not motivated well. Please indicate why these tasks are chosen. It seems the robot arm task is very similar to the navigation task, due to robot arm's end effector being position controlled directly. Why is it worthwhile to study this task separately?

- The GTC metric is not very well established (yet). Please provide some extra information on how it is calculated. This should also include some discussion on why this metric allows judging sufficiency and disentangledness. How would rotating the measurement frame of the ground-truth influence the results?

- Why are the robotics priors not in Table 1?</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">5: Marginally below acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_Bke6q_IRhQ" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Unclear approach and contribution</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=Hkl-di09FQ&amp;noteId=Bke6q_IRhQ"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper326 AnonReviewer1</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">06 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper326 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">This paper aims at comparing end-to-end learning vs separately learning a state representation and subsequently a controller.

While this would be a relevant and important topic, the paper does not currently present consistent evidence to support this hypothesis.

In particular:
- The approach proposed in the approach is not explained in sufficient details. After reading Sec.4 I have only a very vague and high-level idea of how the proposed approach might work. In Figure.2, what is I_t? What is the model that you are training? How are you learning this model? how do you define L_inverse?
- The cited literature about state representation learning is absolutely incomplete. Papers like Lange et al. , WahlstrÃ¶m et al. and Finn et al. and citations herewithin.
- From the experimental results, it is difficult to say anything definitive about the proposed hypothesis. 1) There are multiple end-to-end approaches in the literature, with significant differences in performance. which one are you using? (it seem A2C and PPO, but to which label do they correspond in the tables?) 2) How do you tune the weights of the reward function proposed? This seems an important design choice, but it is not much discussed. 3) In the table reported (e.g., Table 1) it does not seem to me that SRL consistently outperforms other approaches. Even for the arm tasks, Random features seem to outperform the proposed approach (and indeed all the methods except the ground truth). What is going on there?

OverallÂ¸ the paper would benefit from a clearer and more detailed text, and from improved experiments and comparisons.

Minor comments:
- It is unclear to me what "goal-based robotic tasks" means. How do you define a task without a goal?
- An important and missing characteristic of a suitable state representation should be the generalization. In fact, a good representation would ideally allow the agent to generalize to some degree. 
- It seems very odd to me that the "action should be implicitly encoded into the state representation" could you elaborate of the motivation for this and the effects?

References:
- Autonomous reinforcement learning on raw visual input data in a real-world application
S Lange, M Riedmiller, A Voigtlander
Neural Networks (IJCNN), The 2012 International Joint Conference on, 1-8
- From pixels to torques: Policy learning with deep dynamical models
N WahlstrÃ¶m, TB SchÃ¶n, MP Deisenroth
arXiv preprint arXiv:1502.02251
-  Deep Visual Foresight for Planning Robot Motion
Chelsea Finn, Sergey Levine
International Conference on Robotics and Automation (ICRA), 2017 </span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">3: Clear rejection</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_BJg5O9zd2Q" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Interesting experiment results, unfortunately lacking in terms of new insights.</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=Hkl-di09FQ&amp;noteId=BJg5O9zd2Q"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper326 AnonReviewer2</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">01 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper326 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">The paper is easy to read and the presentation is clear, and I really appreciate this.

The authors address the very important topic of feature extraction and state representation learning. New results in this area are always valuable and welcome. However, my feeling is that the paper falls short in terms of making sufficient new contributions for an ICLR paper. 

1. The authors propose to learn a state representation by either training using a combined loss function, or training several representations using multiple loss functions followed by stacking. These are standard and well-known techniques in machine learning. The key contribution one looks for is in terms of new insights on why and when each approach works. The paper fails to provide much insight in this regard. Take this simple scenario: Suppose my input image is actually generated by a linear map plus gaussian noise on the true states. Then I can simply use a PCA as my "auto encoder" and happily learn a high quality state representation close to the ground truth. We know why this works. In the real task, the image is a complex non-linear transformation of the true states. What insights do I gain from this work in terms of how I should tackle this?

2. Section 3 states some desirable characteristics in constructing a state representation. These are well-known and fundamental aspects of machine learning -- applicable to almost all models that we want to learn. In this sense, I do not find the section very informative.

3. The empirical results (say, Table 1) seem too noisy to interpret (other than that using the ground truth provides the best performance). It almost seems to suggest that one should simply use random features (as done in the "extreme learning machine" approach). Again, not much insight to draw from this.

4. Last comment. Suppose I have a new robotic goal-directed task and my inputs are camera images. Does this work tell me something that I don't already know in terms of learning new feature representation that is highly suitable for my task?



</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">4: Ok but not good enough - rejection</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></main></div>
  </div>
</div>


    <!-- Footer -->
    <footer class="sitemap">
      <div class="container">
        <div class="row hidden-xs">
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/venues">All Venues</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="/contact">Contact</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
    
        <div class="row visible-xs-block">
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/contact">Contact</a></li>
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
      </div>
    </footer>
    
    <footer class="sponsor">
      <div class="container">
        <div class="row">
          <div class="col-sm-10 col-sm-offset-1">
            <p class="text-center">
              OpenReview is created by the <a href="http://www.iesl.cs.umass.edu/" target="_blank">Information Extraction and Synthesis Laboratory</a>, College of Information and Computer Science, University of Massachusetts Amherst. We gratefully acknowledge the support of the OpenReview sponsors:  Google,  Facebook, NSF, the University of Massachusetts Amherst Center for Data Science, and Center for Intelligent Information Retrieval, as well as the Google Cloud Platform for donating the computing and networking services on which OpenReview.net runs.
            </p>
          </div>
        </div>
      </div>
    </footer>

  <div id="feedback-modal" class="modal fade" tabindex="-1" role="dialog">
    <div class="modal-dialog">
      <div class="modal-content">
        <div class="modal-header">
          <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">Ã—</span></button>
          <h3 class="modal-title">Send Feedback</h3>
        </div>
        <div class="modal-body">
          <p>Enter your feedback below and we'll get back to you as soon as possible.</p>
          <form action="/feedback" method="POST">
            <div class="form-group">
              <input type="email" name="from" class="form-control" placeholder="Email" />
            </div>
            <div class="form-group">
              <input type="text" name="subject" class="form-control" placeholder="Subject" />
            </div>
            <div class="form-group">
              <textarea name="message" class="form-control feedback-input" rows="5" placeholder="Message" required=""></textarea>
            </div>
          <ul id="ui-id-2" tabindex="0" class="ui-menu ui-widget ui-widget-content" style="display: none;"></ul></form>
        </div>
        <div class="modal-footer">
          <button type="button" class="btn btn-default" data-dismiss="modal">Cancel</button>
          <button type="button" class="btn btn-primary">Send</button>
        </div>
      </div>
    </div>
  </div>

  <script type="text/javascript" async="" src="https://www.google-analytics.com/analytics.js"></script><script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js"></script>
  <script>window.jQuery || document.write('&lt;script src="/static/js/vendor/jquery-2.2.4.min.js"&gt;&lt;\/script&gt;')</script>

  <script src="/static/dist/vendor.min.js"></script>
  <script src="/static/dist/templates.min.js"></script>
  <script src="/static/dist/openreview.min.js"></script>

    <script>window.legacyScripts = true;</script>


    <script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-108703919-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() { dataLayer.push(arguments); }
      gtag('js', new Date());
      gtag('config', 'UA-108703919-1');
    </script>


<div role="status" aria-live="assertive" aria-relevant="additions" class="ui-helper-hidden-accessible"></div></body></html>
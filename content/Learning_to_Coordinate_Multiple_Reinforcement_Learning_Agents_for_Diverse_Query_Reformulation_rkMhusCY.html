<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" class="no-js"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>Learning to Coordinate Multiple Reinforcement Learning Agents for Diverse Query Reformulation | OpenReview</title>
  <meta name="description" content="" />

      <meta name="citation_title" content="Learning to Coordinate Multiple Reinforcement Learning Agents for Diverse Query Reformulation" />
        <meta name="citation_author" content="Anonymous" />
      <meta name="citation_publication_date" content="2018/09/27" />
      <meta name="citation_online_date" content="2018/09/27" />
      <meta name="citation_pdf_url" content="https://openreview.net/pdf?id=rkMhusC5Y7" />
      <meta name="twitter:card" content="summary" />
      <meta name="twitter:site" content="@openreviewnet" />
      <meta name="og:title" content="Learning to Coordinate Multiple Reinforcement Learning Agents for..." />
      <meta name="og:description" content="We propose a method to efficiently learn diverse strategies in reinforcement learning for query reformulation in the tasks of document retrieval and question answering. In the proposed framework an..." />
      <meta name="og:image" content="https://openreview.net/static/images/openreview_logo_512.png" />

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans:400,400i,700,700i" />

  <link rel="stylesheet" href="/static/css/bootstrap.min.css" />
  <link rel="stylesheet" href="/static/css/jquery-ui.min.css" />
  <link rel="stylesheet" href="/static/css/main.min.css" />
</head>

<body class="forum">
  <nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
  
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand home push-link" href="/"><strong>OpenReview</strong>.net</a>
      </div>
  
      <div id="navbar" class="navbar-collapse collapse">
        <form class="navbar-form navbar-left profile-search" role="search">
          <div class="form-group has-feedback">
            <input id="search_input" type="text" class="form-control ui-autocomplete-input" placeholder="Search ICLR 2019 Conference" autocomplete="off" />
            <span class="glyphicon glyphicon-search form-control-feedback" aria-hidden="true"></span>
          </div>
  
          <input id="search_group" type="hidden" value="ICLR.cc/2019/Conference" />
          <input id="search_content" type="hidden" value="all" />
        <ul id="ui-id-1" tabindex="0" class="ui-menu ui-widget ui-widget-content ui-autocomplete ui-front" style="display: none;"></ul></form>
  
        <ul class="nav navbar-nav navbar-right">
        
            <li id="user-menu"><a href="/login">Login</a></li>
        </ul>
      </div>
  
    </div>
  </nav>

  <div id="or-banner" class="banner" style="">
  <div class="container">
    <div class="row">
      <div class="col-xs-12"><a href="/group?id=ICLR.cc/2019/Conference" title="Venue Homepage"><img class="icon" src="/static/images/arrow_left.svg" /> Go to <strong>ICLR 2019 Conference</strong> homepage</a></div>
    </div>
  </div>
</div>
<div id="flash-message-container" class="alert alert-danger" role="alert" style="display: none;">
  <div class="container">
    <div class="row">
      <div class="col-xs-12">
        <div class="alert-content">
          <button type="button" class="close" aria-label="Close"><span aria-hidden="true">×</span></button>
        </div>
      </div>
    </div>
  </div>
</div>

<div class="container">
  <div class="row">
    <div class="col-xs-12">
      <main id="content" class="clearfix openbanner-visible legacy-styles"><div id="note_rkMhusC5Y7" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Learning to Coordinate Multiple Reinforcement Learning Agents for Diverse Query Reformulation</a> <a class="note_content_pdf" href="/pdf?id=rkMhusC5Y7" title="Download PDF" target="_blank"><img src="/static/images/pdf_icon_blue.svg" /></a> </h2></div><div class="meta_row"><span class="signatures">Anonymous</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">28 Sep 2018 (modified: 11 Oct 2018)</span><span class="item">ICLR 2019 Conference Blind Submission</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span><span class="item"><a class="action-bibtex-modal" data-bibtex="@inproceedings{    &#10;anonymous2019learning,    &#10;title={Learning to Coordinate Multiple Reinforcement Learning Agents for Diverse Query Reformulation},    &#10;author={Anonymous},    &#10;booktitle={Submitted to International Conference on Learning Representations},    &#10;year={2019},    &#10;url={https://openreview.net/forum?id=rkMhusC5Y7},    &#10;note={under review}    &#10;}">Show Bibtex</a></span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Abstract: </span><span class="note_content_value">We propose a method to efficiently learn diverse strategies in reinforcement learning for query reformulation in the tasks of document retrieval and question answering. In the proposed framework an agent consists of multiple specialized sub-agents and a meta-agent that learns to aggregate the answers from sub-agents to produce a final answer. Sub-agents are trained on disjoint partitions of the training data, while the meta-agent is trained on the full training set. Our method makes learning faster, because it is highly parallelizable, and has better generalization performance than strong baselines, such as an ensemble of agents trained on the full data. We show that the improved performance is due to the increased diversity of reformulation strategies. </span></div><div class="note_contents"><span class="note_content_field">Keywords: </span><span class="note_content_value">Reinforcement Learning, Multi-agent, Information Retrieval, Question-Answering, Query Reformulation, Query Expansion</span></div><div class="note_contents"><span class="note_content_field">TL;DR: </span><span class="note_content_value">Multiple diverse query reformulation agents trained with reinforcement learning to improve search engines.</span></div><div class="reply_row clearfix"><div class="item" id="reply_count">5 Replies</div></div></div><hr class="small" /><div id="note_children"><div class="note_with_children"><div id="note_rJxJYI8T37" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Learning to Coordinate Multiple Reinforcement Learning Agents for Diverse Query Reformulation</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=rkMhusC5Y7&amp;noteId=rJxJYI8T37"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper391 AnonReviewer2</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">05 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper391 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">The authors proposed a variant of ensemble method in reinforcement learning for query reformulation. They train multiple specialized sub-agents on disjoint partitions of the training data, and use a meta-agent, which can see all the training data, to decide the final answer. This can speed up the training thanks to parallelization. They observed that this can improve the diversity of learnt reformulations and the overall performance in some cases. 


Strengths
1. The paper is clear and easy to follow.
2. Multiple evaluation metrics and baseline models are considered

Weaknesses
1. The proposed method is simple and lacks novelty.
2. The performance improvement is marginal and some empirical results are not carefully analyzed. 


Significance
Exploring a diverse set of strategies is beneficial in reinforcement learning. This paper focuses on two aspects of this problem. One is how to learn diverse agents and the other one is how to efficiently learn these agents efficiently, which are important concerns in practice. 


Originality
The model learning approach they proposed is merely a simple variant of ensemble learning. The main difference is they train sub-agents on disjoint partitions of the training data, which seems a trivial modification although this shows to improve the overall model performance.


Technical Quality
Overall, the experiments are well-thought, but the following questions need to be explained:
1.	In the Introduction, the authors claim three contributions they made in this paper. My question is, if the third one is really an important contribution, why didn’t the authors demonstrate it in detail in the main text? Attaching it to the appendix could make the reader confused about its significance.
2.	In Table-1, the authors claim that their proposed architectures can outperform the baseline RL-10-Ensemble with only 1/10 time. The sub-agents are trained on a partition of the training set. My question is, are these sub-agents trained in parallel on different machine? If so, why cannot the RL-10-Ensemble be trained in parallel through some multithread or distributed computation? The implementation of the proposed model and the baseline seems not that fair.
3.	The main architecture is described in section 3.3 and 3.4, including the Sub-agents and the Aggregator. However, in Appendix C.1, the authors claim that the gains the proposed method comes mostly from the pool of diverse reformulators, and not from the simple use of a re-ranking function (Aggregator). This is confusing because if it is true, the proposed method is really reduced to an ensemble of the baseline model.
4.	In Table-2, some of the results are worse than the baseline methods like Re-Ranker. Although the authors claim the re-ranking is a post-processing, Re-Ranker performs significantly better than the proposed model. If the authors want to better demonstrate the advantages of the proposed model, a comparison between the proposed model with re-ranking and the Re-Ranker is required.
5.	In Table 10, why the proposed method fails to produce the right answer whereas the other methods perform well?
</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">4: Ok but not good enough - rejection</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">3: The reviewer is fairly confident that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_SkloQyKK3X" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Strong empirical results. Would like to see more analysis</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=rkMhusC5Y7&amp;noteId=SkloQyKK3X"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper391 AnonReviewer1</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">02 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper391 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">Summary:
The authors propose to train multiple distinct agents, each over a different subset of the training set. A meta-agent, known as the aggregator, groups and scores answers from the sub-agents for any given input. 

Each agent produces a unique reformulation that is applied to the environment, producing an answer for the reformulated query. The aggregator receives the original query and the answers provided by the environment and produces a relevance score for each answer with respect to the original query that is a function of both components.

The final answer is select using this relevance score, as well as an aggregate ranking score for over the space of reformulations for each answer.

The aggregator is trained to minimize the cross-entropy of the relevance score. Each reformulation agent is trained using Recall@40 as a reward for retrieving the correct answer from the environment given their reformulation. 

The authors argue that learning multiple specialized sub-agents is easier than learning a generalist agent responsible for being able to model the entire training data. Authors shows that this strategy is even more generalizable than training an ensemble for the same number of agents over the entire training set. Authors apply the approach to query reformulation for document retrieval and QA.

Review:

Pros:
-The paper provides convincing empirical evidence that training multiple distinct agents on different partitions of a dataset to learn to reformulate queries for environment feedback is a more efficient and accurate approach than training single or ensemble model on the whole dataset. Empirical result show that both the addition of the aggregator and the exclusivity of the agents contributes to this effect. Baselines are considerable and in-depth (though it seems like the Hui et al., 2017 model that is SOTA on TREC-CAR could be shown in Table 1 as well)
-The paper is well written and easy to understand in the approach.

Cons:
-The authors could do a better job explaining a couple of unclear points. First, how did the authors come up with equation 2 for computing the relevance score? While the empirical investigation in Table 8 indicates it does better than other simpler formulations, it’s not clear why the authors were motivated to try this one.
-I don’t come away with an idea of WHY the author’s proposed approach works better. While the empirical investigation is a contribution in it of itself, the results seem slightly counterintuitive. It’s not clear why a random partition should be better than a semantically-motivated partition. It’s also not clear why training the reformulating agents individually on these partitions would do better than an ensemble. I find the paper interesting, but the analysis of these results is missing.

Questions:
Why does the function for z_j in equation 2 need to be so complicated? Why are the CNN features of the query concatenated twice in the first part. What does the dot operator in the second part of the equation correspond to?</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">7: Good paper, accept</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_ryeOhUMtn7" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Novelty limited and experiments not convincing enough </a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=rkMhusC5Y7&amp;noteId=ryeOhUMtn7"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper391 AnonReviewer3</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">02 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper391 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">In this paper, authors proposed an ensemble approach for query reformulation (QR).  The basic idea is that 1) train a bunch of models/sub-agents on subsets, e.g., randomly partitioned, of the training data; 2) and then train an additional meta model/meta-agent to aggregate the results from the step 1).  They conduct experiments on document retrieval and question answering tasks to show the effectiveness of the proposed model.

This paper is well written and easy to follow.  
However there are several my concerns. 

1. It is counter intuitive, e.g., why sub-agents trained on full training dataset obtain worse results than on its subset. Regarding diversity, one may use different random seeds or different dropout rates instead of sample a subset of training data. 

2. The baseline is much lower than the current SOTA systems. Such as the best result on SearchQA in this paper is 50.5 in terms of F1 score. However R3 and Re-Ranker obtains 55.3 and 60.6 respectively. Could the proposed approach be adapted on those models? Note that those SOTA systems are released.

3. The proposed system is quite similar to Nogueira&amp; Cho 2017 and Buck et al. 2018. I'm not very sure the contribution of this work and its novelty.  

Questions:
1. Why the authors didn't use beam search during the sub-agent training? 
2. It seems that the proposed framework is a pipeline model: firstly it trains a bunch of sub-agents; and then trains meta-agent. Is it possible to fine-tune the model jointly?
3. What is Extra Budget in Table 1?    </span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">5: Marginally below acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_BJxNrTCQn7" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>questions about TREC-CAR experiments</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=rkMhusC5Y7&amp;noteId=BJxNrTCQn7"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">(anonymous)</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">29 Oct 2018</span><span class="item">ICLR 2019 Conference Paper391 Public Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Thanks for your submission!  I had a few comments on the experimentation.

1. Your results for Lucene, PRF, and RM3 in Table 1 and 4 seem quite low compared to results presented in the TREC CAR overview paper (<a href="https://trec.nist.gov/pubs/trec26/papers/Overview-CAR.pdf," target="_blank" rel="nofollow">https://trec.nist.gov/pubs/trec26/papers/Overview-CAR.pdf,</a> Figure 4).  The UNH.bm25 achieves a MAP of 12.2, RPrecision of 9.7, MRR of 18.3, and NDCG of 19.6.  UNH.expan achieves a MAP of 14.4, RPrecision of 11.4, MRR of 21.2, and NDCG of 22.6.  These can be found here: https://trec.nist.gov/pubs/trec26/appendices/car.html

2. Did you stop and stem for your baselines (Lucene, PRF, and RM3)?  This may explain the low performance.  

</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_SkxftzzHhm" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Answer about TREC-CAR experiments</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=rkMhusC5Y7&amp;noteId=SkxftzzHhm"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper391 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">30 Oct 2018</span><span class="item">ICLR 2019 Conference Paper391 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Thanks for your comments!

1. As noticed by the TREC-CAR organizers (<a href="https://groups.google.com/forum/#!topic/trec-car/0rpzY_6dP5c)," target="_blank" rel="nofollow">https://groups.google.com/forum/#!topic/trec-car/0rpzY_6dP5c),</a> the numbers in the TREC-CAR overview paper are inflated by ~15%. For example, the report paper from 2017's top submission system shows ~2.3 points lower MAP scores than the ones published in the overview paper (https://trec.nist.gov/pubs/trec26/papers/MPIID5-CAR.pdf, table 3).

The numbers we report in the paper are the non-inflated ones (i.e., computed with the "-c" option in the trec_eval tool) hence the lower numbers.

2. We tried to remove stop words and stemming (using NLTK), but we did not notice any improvement in performance.

</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div></div></main></div>
  </div>
</div>


    <!-- Footer -->
    <footer class="sitemap">
      <div class="container">
        <div class="row hidden-xs">
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/venues">All Venues</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="/contact">Contact</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
    
        <div class="row visible-xs-block">
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/contact">Contact</a></li>
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
      </div>
    </footer>
    
    <footer class="sponsor">
      <div class="container">
        <div class="row">
          <div class="col-sm-10 col-sm-offset-1">
            <p class="text-center">
              OpenReview is created by the <a href="http://www.iesl.cs.umass.edu/" target="_blank">Information Extraction and Synthesis Laboratory</a>, College of Information and Computer Science, University of Massachusetts Amherst. We gratefully acknowledge the support of the OpenReview sponsors:  Google,  Facebook, NSF, the University of Massachusetts Amherst Center for Data Science, and Center for Intelligent Information Retrieval, as well as the Google Cloud Platform for donating the computing and networking services on which OpenReview.net runs.
            </p>
          </div>
        </div>
      </div>
    </footer>

  <div id="feedback-modal" class="modal fade" tabindex="-1" role="dialog">
    <div class="modal-dialog">
      <div class="modal-content">
        <div class="modal-header">
          <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button>
          <h3 class="modal-title">Send Feedback</h3>
        </div>
        <div class="modal-body">
          <p>Enter your feedback below and we'll get back to you as soon as possible.</p>
          <form action="/feedback" method="POST">
            <div class="form-group">
              <input type="email" name="from" class="form-control" placeholder="Email" />
            </div>
            <div class="form-group">
              <input type="text" name="subject" class="form-control" placeholder="Subject" />
            </div>
            <div class="form-group">
              <textarea name="message" class="form-control feedback-input" rows="5" placeholder="Message" required=""></textarea>
            </div>
          <ul id="ui-id-2" tabindex="0" class="ui-menu ui-widget ui-widget-content" style="display: none;"></ul></form>
        </div>
        <div class="modal-footer">
          <button type="button" class="btn btn-default" data-dismiss="modal">Cancel</button>
          <button type="button" class="btn btn-primary">Send</button>
        </div>
      </div>
    </div>
  </div>

  <script type="text/javascript" async="" src="https://www.google-analytics.com/analytics.js"></script><script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js"></script>
  <script>window.jQuery || document.write('&lt;script src="/static/js/vendor/jquery-2.2.4.min.js"&gt;&lt;\/script&gt;')</script>

  <script src="/static/dist/vendor.min.js"></script>
  <script src="/static/dist/templates.min.js"></script>
  <script src="/static/dist/openreview.min.js"></script>

    <script>window.legacyScripts = true;</script>


    <script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-108703919-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() { dataLayer.push(arguments); }
      gtag('js', new Date());
      gtag('config', 'UA-108703919-1');
    </script>


<div role="status" aria-live="assertive" aria-relevant="additions" class="ui-helper-hidden-accessible"></div></body></html>
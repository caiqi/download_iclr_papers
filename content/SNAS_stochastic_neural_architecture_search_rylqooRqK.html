<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" class="no-js"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>SNAS: stochastic neural architecture search | OpenReview</title>
  <meta name="description" content="" />

      <meta name="citation_title" content="SNAS: stochastic neural architecture search" />
        <meta name="citation_author" content="Anonymous" />
      <meta name="citation_publication_date" content="2018/09/27" />
      <meta name="citation_online_date" content="2018/09/27" />
      <meta name="citation_pdf_url" content="https://openreview.net/pdf?id=rylqooRqK7" />
      <meta name="twitter:card" content="summary" />
      <meta name="twitter:site" content="@openreviewnet" />
      <meta name="og:title" content="SNAS: stochastic neural architecture search" />
      <meta name="og:description" content="We propose Stochastic Neural Architecture Search (SNAS), an economical end-to-end solution to Neural Architecture Search (NAS) that trains neural operation parameters and architecture distribution..." />
      <meta name="og:image" content="https://openreview.net/static/images/openreview_logo_512.png" />

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans:400,400i,700,700i" />

  <link rel="stylesheet" href="/static/css/bootstrap.min.css" />
  <link rel="stylesheet" href="/static/css/jquery-ui.min.css" />
  <link rel="stylesheet" href="/static/css/main.min.css" />
</head>

<body class="forum">
  <nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
  
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand home push-link" href="/"><strong>OpenReview</strong>.net</a>
      </div>
  
      <div id="navbar" class="navbar-collapse collapse">
        <form class="navbar-form navbar-left profile-search" role="search">
          <div class="form-group has-feedback">
            <input id="search_input" type="text" class="form-control ui-autocomplete-input" placeholder="Search ICLR 2019 Conference" autocomplete="off" />
            <span class="glyphicon glyphicon-search form-control-feedback" aria-hidden="true"></span>
          </div>
  
          <input id="search_group" type="hidden" value="ICLR.cc/2019/Conference" />
          <input id="search_content" type="hidden" value="all" />
        <ul id="ui-id-1" tabindex="0" class="ui-menu ui-widget ui-widget-content ui-autocomplete ui-front" style="display: none;"></ul></form>
  
        <ul class="nav navbar-nav navbar-right">
        
            <li id="user-menu"><a href="/login">Login</a></li>
        </ul>
      </div>
  
    </div>
  </nav>

  <div id="or-banner" class="banner" style="">
  <div class="container">
    <div class="row">
      <div class="col-xs-12"><a href="/group?id=ICLR.cc/2019/Conference" title="Venue Homepage"><img class="icon" src="/static/images/arrow_left.svg" /> Go to <strong>ICLR 2019 Conference</strong> homepage</a></div>
    </div>
  </div>
</div>
<div id="flash-message-container" class="alert alert-danger" role="alert" style="display: none;">
  <div class="container">
    <div class="row">
      <div class="col-xs-12">
        <div class="alert-content">
          <button type="button" class="close" aria-label="Close"><span aria-hidden="true">×</span></button>
        </div>
      </div>
    </div>
  </div>
</div>

<div class="container">
  <div class="row">
    <div class="col-xs-12">
      <main id="content" class="clearfix openbanner-visible legacy-styles"><div id="note_rylqooRqK7" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>SNAS: stochastic neural architecture search</a> <a class="note_content_pdf" href="/pdf?id=rylqooRqK7" title="Download PDF" target="_blank"><img src="/static/images/pdf_icon_blue.svg" /></a> </h2></div><div class="meta_row"><span class="signatures">Anonymous</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">28 Sep 2018 (modified: 20 Nov 2018)</span><span class="item">ICLR 2019 Conference Blind Submission</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span><span class="item"><a class="action-bibtex-modal" data-bibtex="@inproceedings{    &#10;anonymous2019snas:,    &#10;title={SNAS: stochastic neural architecture search},    &#10;author={Anonymous},    &#10;booktitle={Submitted to International Conference on Learning Representations},    &#10;year={2019},    &#10;url={https://openreview.net/forum?id=rylqooRqK7},    &#10;note={under review}    &#10;}">Show Bibtex</a></span><a class="note_content_pdf item" href="/revisions?id=rylqooRqK7" target="_blank">Show Revisions</a></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Abstract: </span><span class="note_content_value">We propose Stochastic Neural Architecture Search (SNAS), an economical end-to-end solution to Neural Architecture Search (NAS) that trains neural operation parameters and architecture distribution parameters in same round of back-propagation, while maintaining the completeness and differentiablity of the NAS pipeline. In this work, NAS is modeled as an optimization problem on parameters of a joint distribution for the search space in a cell. To leverage the gradient information in generic differentiable loss for architecture search, a novel search gradient is proposed. We prove that this search gradient optimizes the same objective as reinforcement-learning-based NAS, but assigns credits to structural decisions more efficiently. This credit assignment is further augmented with locally decomposable reward to enforce a resource-efficient constraint. In experiments on CIFAR-10, SNAS takes less epochs to find a cell architecture with state-of-the-art accuracy than non-differentiable evolution-based and reinforcement-learning-based NAS, which is also transferable to ImageNet. It is also shown that child networks of SNAS can maintain the validation accuracy in searching, with which attention-based NAS requires parameter retraining to compete, exhibiting potentials to stride towards efficient NAS on big datasets.</span></div><div class="note_contents"><span class="note_content_field">Keywords: </span><span class="note_content_value">Neural Architecture Search</span></div><div class="reply_row clearfix"><div class="item" id="reply_count">13 Replies</div></div></div><hr class="small" /><div id="note_children"><div class="note_with_children"><div id="note_rkxfcO6yCm" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Some question about the experiments.</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=rylqooRqK7&amp;noteId=rkxfcO6yCm"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">(anonymous)</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">19 Nov 2018</span><span class="item">ICLR 2019 Conference Paper648 Public Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Hi authors.
This is an interesting work, but I feel that some experimental comparisons are a little bit unfair as follows:

1. In Table 2, the authors report DARTS* has a test error of 3.15%, which is claimed as reproduced by the released code. I also run their codes and can obtain a similar performance with 2.86%. Reporting 3.15% might be misleading to others readers, and make other researchers wrongly refer the results of DARTS in the following papers.

2. DARTS has conducted results on both CNN and RNN. Why SNAS does not report the RNN results?

3. Would you mind to give more explanation about Figure 4?

4. In Figure 3, how did you run ENAS? In addition, do these three methods use the same training and validation set? Based on the GitHub issue of DARTS, the validation accuracy of DARTS does not have an explicit connection with the performance of the discovered model. How about the connection between the validation accuracy of SNAS and the final discovered model of SNAS?

5. For NAS approaches, there is usually a variance of the performance of the final discovered model. Would you mind to report the results of three runs of SNAS?</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_Hyg3FnObpX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Derivation of child network for SOTA comparison</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=rylqooRqK7&amp;noteId=Hyg3FnObpX"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">(anonymous)</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">08 Nov 2018</span><span class="item">ICLR 2019 Conference Paper648 Public Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Hi authors!
I am so impressed by your paper because it feels like this is a connection between NAS and DARTS.
However, I am curious about some details on CIFAR10 evaluation.
Within a cell, there are 7 nodes right as DARTS right?
Then, how is the number of initial channels set? The same number of initial channels 16 applies as search mode?
If so, it seems to me that the number of parameters reported seems so large.
Could you specify the number of initial channels plus another hyperparmeters to clarify the evaluation setting?

Anyway, thanks for the nice paper!</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_S1lt6f7zpm" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>On initial channel number</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=rylqooRqK7&amp;noteId=S1lt6f7zpm"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper648 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">09 Nov 2018</span><span class="item">ICLR 2019 Conference Paper648 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Thank you for the question.

For fair comparison with DARTS, we employed the same set of hyperparameters as specified in the code publicly released by its authors. I bet the number of initial channels in your question refers to the channel number used for the first cell in the network according to the code. During CIFAR10 evaluation, the number of initial channels is set to 36 rather than 16. This will lead to an increase in the number of parameters.

We will add more hyperparameter details in the revised version. Hope this can answer your question and thanks again for the comment.
</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_Skl7rA7zaQ" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>More clarification</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=rylqooRqK7&amp;noteId=Skl7rA7zaQ"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">(anonymous)</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">09 Nov 2018</span><span class="item">ICLR 2019 Conference Paper648 Public Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Thank you for your quick and kind reply!
To my knowledge, for CIFAR10 evaluation, the number of layers was set to 20(reported in the paper), the number of nodes within a cell was set to 7(adopted from search) and the number of initial channels was set to 36(in the comment above). 
Then, the number of parameters should be much larger than 3.3M I think... Thus, think if the number of initial channels was set to 36, the number of layers should have been set to 8 as search mode to match the number of parameters reported in SOTA comparison table... Is it wrong?


</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_SkxDoOiBpQ" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>On parameter size </a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=rylqooRqK7&amp;noteId=SkxDoOiBpQ"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper648 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">11 Nov 2018</span><span class="item">ICLR 2019 Conference Paper648 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Thank you for your question.

We have implemented a counting function to reproduce the result of DARTS and used it to count the parameter size of our network.

Do you mind showing how you reached the claim that the size should be much larger?</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_r1gLByK8TQ" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>20 Layers + 36 initial channels -&gt; Too much parameters</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=rylqooRqK7&amp;noteId=r1gLByK8TQ"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">(anonymous)</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">12 Nov 2018</span><span class="item">ICLR 2019 Conference Paper648 Public Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Thanks for your reply!! As I run the code in github of DARTS paper, the parameter size was about 7M when a recurrent cell with 7 intermediate nodes is evaluated under the setting of 20 layers and 36 initial channels. Thus, I thought I should have reduced the number of nodes or the number of layers whatever...</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div></div></div></div></div></div></div><div class="note_with_children"><div id="note_BkxZlzashX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Novel approach that addresses some shortcomings of the previous NAS techniques.</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=rylqooRqK7&amp;noteId=BkxZlzashX"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper648 AnonReviewer1</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">04 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper648 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">This paper improves upon ENAS and DARTS by taking a differentiable approach to NAS and optimizing the objective across the distribution of child graphs. This technique allows for end-to-end architecture search while constraining resource usage and allowing parameter sharing by generating effective reusable child graphs.

SNAS employs Gumbel random variables which gives it better gradients and makes learning more robust compared to ENAS. The use of Gumbel variables also allow SNAS to directly optimize the NAS objective which is an advantage over DARTS.

The resource constraint regularization is interesting. Regularizing on the parameters that describe the architecture can help constrain resource usage during the forward pass. 

The proposed method is novel but the main concern here is that there is no clear win over existing techniques in terms of performance. I can't see anywhere in the tables where you demonstrate a clear improvement over DARTS or ENAS.

Furthermore, in your child network evaluation with CIFAR-10, you mention that the comparison is without fine-tuning. Do you think this might be contributing to the performance gap in DARTS?
</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">6: Marginally above acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_B1g-LCSsn7" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Official Review</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=rylqooRqK7&amp;noteId=B1g-LCSsn7"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper648 AnonReviewer2</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">04 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper648 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">Summary:
This paper proposes Stochastic Neural Architecture Search (SNAS), a method to automatically and efficiently search for neural architectures. It is built upon 2 existing works on these topics, namely ENAS (Pham et al 2018) and DARTS (Liu et al 2018).

SNAS provides nice theory and explanation of gradient computations, unites the strengths and avoid the weaknesses of ENAS and DARTS. There are many details in the paper, including the Appendix. The idea is as follows:
+------------+---------------------+-------------------------+
| Method | Differentiable | Directly Optimize |
|                |                           |    NAS reward       |
+------------+---------------------+-------------------------+
| ENAS     |      No                |        Yes                   |
| DARTS   |      Yes               |        No                    |
| SNAS     |      Yes               |        Yes                   |
+------------+---------------------+-------------------------+
SNAS inherits the idea of ENAS and DARTS by superpositioning all possible architectures into a Directed Acyclic Graph (DAG), effectively sharing the weights among all architectures. However, SNAS improves over ENAS and DARTS as follows (Section 2.2):

1. SNAS improves over ENAS in that it allows independent sampling at edges in the shared DAG, leading to a more tractable gradient at the edges of the DAG, which in turn allows more tractable Monte Carlo estimation of the gradients with respect to the architectural parameters.

2. While DARTS also has the property (1), DARTS implements this by computing the expected value at each node in the DAG, with respect to the joint distribution of the input edges and the operations. This makes DARTS not optimize the direct NAS objective. SNAS, due to their smart manipulation of architectural gradients using Gumbel variables, still optimizes the same objective with NAS and ENAS, but has a smoother gradients.

Experimental results in the paper show that SNAS finds architectures on CIFAR-10 that are comparable to those found by ENAS and DARTS, using a reasonable amount of computing resource. These architectures can also be transferred to learn competent models on ImageNet, like those of DARTS. Furthermore, experimental observations (Figure 3) are consistent with the theory above, that is:

1. The search process of SNAS is more stable than that of ENAS (as SNAS samples with a smaller variance).
2. Architectures found by SNAS perform better than those of DARTS, as SNAS searches directly for the NAS reward of the sampled models. 

Strengths:
1. SNAS unites the strengths and avoids the weaknesses of ENAS and DARTS

2. SNAS provides a nice theory, which is verified through their experimental results.

Weaknesses:
I don’t really have any complaints about this paper. Some presentations of the paper might have been improved, e.g. the discussion on the ZERO operation in other comments should have been included.
</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">7: Good paper, accept</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_rkeruyjYhX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>On ZERO operation</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=rylqooRqK7&amp;noteId=rkeruyjYhX"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">(anonymous)</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">02 Nov 2018</span><span class="item">ICLR 2019 Conference Paper648 Public Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">I have tried to run the released code of DARTS and found that in the code, the operation ZERO is omitted during the derivation process. I also checked the logit of ZERO operation learned by DARTS, and found that in the normal cell, it is the largest in most edges.

Is the same derivation code used by SNAS and thus omitting ZERO operation in the experiments? If not, could you please give an explanation to:
1) whether the logit of ZERO is the largest in most edges of the normal cell learned by SNAS?
2) If the result is different from DARTS, why is this difference?</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_Hkxvf8zq27" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>ZERO operation is just as other operations if no complexity constraint is added</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=rylqooRqK7&amp;noteId=Hkxvf8zq27"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper648 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">03 Nov 2018</span><span class="item">ICLR 2019 Conference Paper648 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Thank you for your interesting discovery and the questions. 

0) derivation code for SNAS is the same as DARTS? 
No. We have implemented our derivation method to replace the one provided by DARTS as SNAS uses fundamentally different one. But in our replication of DARTS, we ran the implementation publicly released without checking the code for derivation. We are trying to replicate DARTS's result again, taking your claim into consideration. 

1) is the logit of ZERO the largest in most edges of the normal cell? 
As introduced in Section 2.4 in our paper, SNAS employs a complexity loss to encourage sparsity in child network. This is different from ENAS and DARTS which directly select two input edges for each node. With a relatively large hyperparameter for this complexity loss, the logit of ZERO dominates some of the edges, though the child network still have other non-ZERO edges to keep it connected. If no complexity loss is added, the child network tends to remain the complete topology, which is actually one of our motivations to introduce complexity loss. 

2) reason for this discrepancy 
Assuming that your result is valid, it is explained by DARTS‘s authors to be the underdetermined contribution and rescaling effect of ZERO in the mixed op. We have the following two hypotheses for the discrepancy between SNAS and DARTS, which would be added to revised version if we can prove them with mathematical deduction: 
a. different from the softmax attention in DARTS, SNAS employs Gumbel-Softmax, whose mechanism involves Gumbel random variables. With equivalent logit and temperature, the random variable vector from Gumbel-Softmax is possibly more one-hot than the deterministic softmax attention. The more discrete network could amplify the incapability of ZERO for a smaller loss, thus the logit of it would not be boosted. 
b. the gradients back-propagated through deterministic softmax and Gumbel-Softmax are different. As provided in Section 2.3 and Appendix C in our paper, there is stochasticity (random variables Z) involved in the search gradients in SNAS. Given the special trait of ZERO that O(x)=0, it is possible to be a local optimum or a gradient blackhole for deterministic softmax, which is probably escaped by Gumbel-Softmax with the stochasticity. </span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div><div class="note_with_children"><div id="note_SJxvc_VdhX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>An incremental work on NAS with good experiment results. </a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=rylqooRqK7&amp;noteId=SJxvc_VdhX"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper648 AnonReviewer3</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">01 Nov 2018 (modified: 19 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper648 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span><a class="note_content_pdf item" href="/revisions?id=SJxvc_VdhX" target="_blank">Show Revisions</a></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">This work refines the NAS method for efficient neural architecture search. The paper brings new methods for gradient/reward updates and credit assignment. 

pros: 
1. An improvement on gradient calculation and reward back-propagation mechanism
2. Good experiment results and fair comparisons

cons:
1. Missing details on how to use the gradient information to generate child network structures. In eq.2, multiplying each one-hot random variable Zij to each edge (i, j) in the DAG can obtain a child graph whose intermediate nodes are xj. However, it is still unclear how to generate the child graph. More details on generating child network based on gradient information is expected. 
2. In SNAS, P(z) is assumed fully factorizable. Factors are parameterized with alpha and learnt along with operation parameters theta. The factorization of p(Z) is based on the observation that NAS is a task with fully delayed rewards in a deterministic environment. That is, the feedback signal is only ready after the whole episode is done and all state transitions distributions are delta functions. In eq. 3, the authors use the training/testing loss directly as reward, while the previous method uses a constant reward from validation accuracy. It is unclear why using the training/testing loss can improve the results? 
</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">6: Marginally above acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_BJxaZ7Kojm" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Missing detail</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=rylqooRqK7&amp;noteId=BJxaZ7Kojm"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">(anonymous)</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">23 Oct 2018</span><span class="item">ICLR 2019 Conference Paper648 Public Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">It is unclear how the authors obtain the child network for DARTS. As is mentioned by the paper, the architecture derivation step in DARTS consists of two steps. (1) Remove operations with relatively weak attention and the zero operation. (2) Remove relatively ambiguous edges. As we know, these removed operations and edges make up a very large percentage of the softmax score. After the removal, the scale of the value of the nodes (output feature maps) drops significantly. Do we need to re-scale the value of output feature maps for compensation?  I cannot reproduce the result of 54.66% in Table 1.</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_S1ZWK63j7" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>On child network derivation</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=rylqooRqK7&amp;noteId=S1ZWK63j7"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper648 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">24 Oct 2018</span><span class="item">ICLR 2019 Conference Paper648 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Thank you for the question. 

The derivation method for DARTS is stated in Section 2.4 in their paper, details could also be found in the implementation publicly released by authors. In our paper we paraphrase it to give an explanation to the drop in accuracy after this derivation. As stated in your comments, "these removed operations and edges make up a very large percentage of the softmax score". Through this comparison we want to emphasize SNAS's consistency in child network derivation, because of explicitly taking it, i.e. sampling, into account in the searching loss. 

In this comparison, child networks are directly tested after the derivation for both SNAS and our replication of DARTS. No re-scaling or any other extra transformation is involved. But we do find that by using the unrolled option, DARTS's result (54.66%) falls less than the non-unrolled one (34.37%). SNAS, in contrast, shows slightly better result (90.67%) after derivation than at the end of searching (88.54%), probably as the latter one is a Monte Carlo estimate of expectation. 

We will add more details into the revised version, thanks again for this comment. </span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div></div></main></div>
  </div>
</div>


    <!-- Footer -->
    <footer class="sitemap">
      <div class="container">
        <div class="row hidden-xs">
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/venues">All Venues</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="/contact">Contact</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
    
        <div class="row visible-xs-block">
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/contact">Contact</a></li>
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
      </div>
    </footer>
    
    <footer class="sponsor">
      <div class="container">
        <div class="row">
          <div class="col-sm-10 col-sm-offset-1">
            <p class="text-center">
              OpenReview is created by the <a href="http://www.iesl.cs.umass.edu/" target="_blank">Information Extraction and Synthesis Laboratory</a>, College of Information and Computer Science, University of Massachusetts Amherst. We gratefully acknowledge the support of the OpenReview sponsors:  Google,  Facebook, NSF, the University of Massachusetts Amherst Center for Data Science, and Center for Intelligent Information Retrieval, as well as the Google Cloud Platform for donating the computing and networking services on which OpenReview.net runs.
            </p>
          </div>
        </div>
      </div>
    </footer>

  <div id="feedback-modal" class="modal fade" tabindex="-1" role="dialog">
    <div class="modal-dialog">
      <div class="modal-content">
        <div class="modal-header">
          <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button>
          <h3 class="modal-title">Send Feedback</h3>
        </div>
        <div class="modal-body">
          <p>Enter your feedback below and we'll get back to you as soon as possible.</p>
          <form action="/feedback" method="POST">
            <div class="form-group">
              <input type="email" name="from" class="form-control" placeholder="Email" />
            </div>
            <div class="form-group">
              <input type="text" name="subject" class="form-control" placeholder="Subject" />
            </div>
            <div class="form-group">
              <textarea name="message" class="form-control feedback-input" rows="5" placeholder="Message" required=""></textarea>
            </div>
          <ul id="ui-id-2" tabindex="0" class="ui-menu ui-widget ui-widget-content" style="display: none;"></ul></form>
        </div>
        <div class="modal-footer">
          <button type="button" class="btn btn-default" data-dismiss="modal">Cancel</button>
          <button type="button" class="btn btn-primary">Send</button>
        </div>
      </div>
    </div>
  </div>

  <script type="text/javascript" async="" src="https://www.google-analytics.com/analytics.js"></script><script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js"></script>
  <script>window.jQuery || document.write('&lt;script src="/static/js/vendor/jquery-2.2.4.min.js"&gt;&lt;\/script&gt;')</script>

  <script src="/static/dist/vendor.min.js"></script>
  <script src="/static/dist/templates.min.js"></script>
  <script src="/static/dist/openreview.min.js"></script>

    <script>window.legacyScripts = true;</script>


    <script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-108703919-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() { dataLayer.push(arguments); }
      gtag('js', new Date());
      gtag('config', 'UA-108703919-1');
    </script>


<div role="status" aria-live="assertive" aria-relevant="additions" class="ui-helper-hidden-accessible"></div></body></html>
<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" class="no-js"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>Online abstraction with MDP homomorphisms for Deep Learning | OpenReview</title>
  <meta name="description" content="" />

      <meta name="citation_title" content="Online abstraction with MDP homomorphisms for Deep Learning" />
        <meta name="citation_author" content="Ondrej Biza" />
        <meta name="citation_author" content="Robert Platt" />
      <meta name="citation_publication_date" content="2018/09/27" />
      <meta name="citation_online_date" content="2018/09/27" />
      <meta name="citation_pdf_url" content="https://openreview.net/pdf?id=B1gVRi0qFQ" />
      <meta name="twitter:card" content="summary" />
      <meta name="twitter:site" content="@openreviewnet" />
      <meta name="og:title" content="Online abstraction with MDP homomorphisms for Deep Learning" />
      <meta name="og:description" content="Abstraction of Markov Decision Processes is a useful tool for solving complex problems, as it can ignore unimportant aspects of an environment, simplifying the process of learning an optimal..." />
      <meta name="og:image" content="https://openreview.net/static/images/openreview_logo_512.png" />

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans:400,400i,700,700i" />

  <link rel="stylesheet" href="/static/css/bootstrap.min.css" />
  <link rel="stylesheet" href="/static/css/jquery-ui.min.css" />
  <link rel="stylesheet" href="/static/css/main.min.css" />
</head>

<body class="forum">
  <nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
  
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand home push-link" href="/"><strong>OpenReview</strong>.net</a>
      </div>
  
      <div id="navbar" class="navbar-collapse collapse">
        <form class="navbar-form navbar-left profile-search" role="search">
          <div class="form-group has-feedback">
            <input id="search_input" type="text" class="form-control ui-autocomplete-input" placeholder="Search ICLR 2019 Conference" autocomplete="off" />
            <span class="glyphicon glyphicon-search form-control-feedback" aria-hidden="true"></span>
          </div>
  
          <input id="search_group" type="hidden" value="ICLR.cc/2019/Conference" />
          <input id="search_content" type="hidden" value="all" />
        <ul id="ui-id-1" tabindex="0" class="ui-menu ui-widget ui-widget-content ui-autocomplete ui-front" style="display: none;"></ul></form>
  
        <ul class="nav navbar-nav navbar-right">
        
            <li id="user-menu"><a href="/login">Login</a></li>
        </ul>
      </div>
  
    </div>
  </nav>

  <div id="or-banner" class="banner" style="">
  <div class="container">
    <div class="row">
      <div class="col-xs-12"><a href="/group?id=ICLR.cc/2019/Conference" title="Venue Homepage"><img class="icon" src="/static/images/arrow_left.svg" /> Go to <strong>ICLR 2019 Conference</strong> homepage</a></div>
    </div>
  </div>
</div>
<div id="flash-message-container" class="alert alert-danger" role="alert" style="display: none;">
  <div class="container">
    <div class="row">
      <div class="col-xs-12">
        <div class="alert-content">
          <button type="button" class="close" aria-label="Close"><span aria-hidden="true">×</span></button>
        </div>
      </div>
    </div>
  </div>
</div>

<div class="container">
  <div class="row">
    <div class="col-xs-12">
      <main id="content" class="clearfix openbanner-visible legacy-styles"><div id="note_B1gVRi0qFQ" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Online abstraction with MDP homomorphisms for Deep Learning</a> <a class="note_content_pdf" href="/pdf?id=B1gVRi0qFQ" title="Download PDF" target="_blank"><img src="/static/images/pdf_icon_blue.svg" /></a> </h2></div><div class="meta_row"><span class="signatures"><a href="/profile?email=bizaondr%40fit.cvut.cz" class="profile-link" data-toggle="tooltip" data-placement="bottom" title="" data-original-title="bizaondr@fit.cvut.cz">Ondrej Biza</a>, <a href="/profile?email=rplatt%40ccs.neu.edu" class="profile-link" data-toggle="tooltip" data-placement="bottom" title="" data-original-title="rplatt@ccs.neu.edu">Robert Platt</a></span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">28 Sep 2018 (modified: 20 Nov 2018)</span><span class="item">ICLR 2019 Conference Withdrawn Submission</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Abstract: </span><span class="note_content_value">Abstraction of Markov Decision Processes is a useful tool for solving complex problems, as it can ignore unimportant aspects of an environment, simplifying the process of learning an optimal policy. In this paper, we propose a new algorithm for finding abstract MDPs in environments with continuous state spaces. It is based on MDP homomorphisms, a structure-preserving mapping between MDPs. We demonstrate our algorithm's ability to learns abstractions from collected experience and show how to reuse the abstractions to guide exploration in new tasks the agent encounters. Our novel task transfer method beats a baseline based on a deep Q-network.</span></div><div class="note_contents"><span class="note_content_field">Keywords: </span><span class="note_content_value">reinforcement learning, abstraction, mdp homomorphism, deep learning, robotics</span></div><div class="note_contents"><span class="note_content_field">TL;DR: </span><span class="note_content_value">We create abstract models of environments from experience and use them to learn new tasks faster.</span></div><div class="reply_row clearfix"><div class="item" id="reply_count">3 Replies</div></div></div><hr class="small" /><div id="note_children"><div class="note_with_children"><div id="note_HygB7YOTpQ" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Submission Withdrawn by the Authors</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=B1gVRi0qFQ&amp;noteId=HygB7YOTpQ"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper883 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">17 Nov 2018</span><span class="item">ICLR 2019 Conference Paper883 Withdraw Submission</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Withdrawal confirmation: </span><span class="note_content_value">I have read and agree with the withdrawal statement on behalf of myself and my co-authors.</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_HyePSGzq3Q" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>interesting idea but ends up tackling a simple case and many elements are unclear</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=B1gVRi0qFQ&amp;noteId=HyePSGzq3Q"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper883 AnonReviewer3</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">03 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper883 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">The paper aims at developing a methodology that uses the idea of MDP homomorphisms to transform a complex MDP with a continuous state space to a simpler one. 

This idea is interesting but overall the paper ends up tackling a rather simple case, which is solving a deterministic MDP with one reward also called the goal. The problem was first formulated with a MDP with sparse rewards but then, without much explanation, all discussions (and all experiments) are done with "one goal". The paper states for instance that the "agent can choose the best state-action block to execute based on the length of the shortest path to the goal from each node". So there is in fact no possibility to deal with the case of multiple rewards. Indeed, looking for the shortest path to the closest reward isn't the strategy that will maximize the cumulative discounted returns in general.

In addition, I have doubts about the scalability of the algorithm. For instance, to deal with the difficult exploration part that is required for the algorithm, the paper uses the vanilla version of the deep Q-network (section 5.4). However DQN is known to have difficulties with tasks that have sparse rewards. And if the task ends up being solved quite well with DQN, it is unclear what the motivation is for the MDP homomorphisms (first sentence in the introduction is "Abstraction is a useful tool for effective control in complex environments").

In addition, the descriptions of the experiments and results seem to lack key elements to  understand them (see comments below).

Detailed comments:
- It is not clear to me why the word "online" is emphasized in the title. In the introduction, you also mention that the "algorithm does not depend on a particular model–we replace the convolutional network with a decision tree in one experiment". In that case, you maybe do not need "deep learning" in the title either.
- (minor) Why do you state that you use a "one hot encoding" for a binary variable (description of the puck stacking)? You could just use one input that is either 0 or 1 (instead of 01 and 10 that is implied by the idea of one hot encoding)?
- (minor) It is stated that the replay buffer is limited to 10000 transitions due to memory constraints. But one transition consists in a frame of (28*C)^2 where I did not find the value of C but I guess it would reasonably be less or equal to 4 so that one frame takes less than 10kB. If that is right, 10000 of them would be less than 100MB, which seems a rather low memory constraint?
- (minor) Section 6.2: a grid of size 3x3 is mentioned but the examples in Fig 1(d) seems to be on a 4x4?
- Figure 1 (a) and (b): why isn't there any information relative to variance between the results over different random seeds?
- Figure 2: I'm puzzled by the shape of the cumulative reward curve obtained through the epochs. Why is it that smooth, while there are instabilities usually. In addition, why is there a significant different regime at exactly 1000 and 1500 epochs, respectively for figure (a) and (b)?
- The discussion on transfer learning/exploration (section 5.5) is not clear to me. In addition discussing settings such as the following do not seem of broad interest/novelty "If we have the prior knowledge that the goal from the previous task is on the path to the goal, (...)".</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">4: Ok but not good enough - rejection</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">3: The reviewer is fairly confident that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_HJea_TwSjX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>promising, but currently limited result</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=B1gVRi0qFQ&amp;noteId=HJea_TwSjX"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper883 AnonReviewer2</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">18 Oct 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper883 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">Summary:
The paper describes an algorithm for training a classifier to approximate homomorphisms from online trajectory data.  The mappings are then used to solve the resulting abstract deterministic shortest path problem.  A method is also proposed for encapsulating these abstract solutions into options and re-using them in the transfer setting.  Experiments in a puck stacking task and blocks world demonstrate the effectiveness of the new method.

Review:

The empirical results of the paper are promising but I was discouraged by the restricted setting considered by the authors and the complete lack of theoretical guarantees, even with these restrictions.   

The introduction of the paper discusses sequential decision making in the realm of MDPs, but the problems tackled in the paper are far from general MDPs.  The environments are restricted to be deterministic and have one or more goal states, with all other states having equal reward.  This is much more like deterministic path planning, and that is ok to do theoretical work in, but no theory results are given in this paper.  In particular, no guarantees are given about the convergence of the algorithm – in fact the authors point out many cases where the algorithm over or under fits he classifier and fails at the underlying task.  A true analysis of the theoretical properties of this approach with a simple classifier in discrete state/action space seems needed, OR experiments showing it can actually succeed in non-deterministic domains.  Without one of these, the result seems incomplete.

The algorithm itself is also not very clearly explained.  In particular, the classifier seems to be trained to predict what state/action blocks will be encountered from the current state and a selected action?  But then there is wording saying that the classifier is “predicting all state/action blocks can be executed from a given state”.  Does this mean you are “predicting *the outcome* of all state action/blocks that can be executed…”.  Predicting the outcome makes sense but I do not understand why you need to predict what blocks can be executed.  Overall, the description on page 3 and the difficult to define set notation in the pseudocode on page 4 are not clear enough to make the result reproducible.  There should be a more straightforward explanation or a 2-3 state example one can follow here.

I also do not understand why the transfer result was not directly compared to Soni &amp; Singh’s work, referenced in the paper.  That work also builds a homomorphism and uses it in transfer learning yet not even a qualitative comparison of the approaches is really done.
</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">5: Marginally below acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">3: The reviewer is fairly confident that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></main></div>
  </div>
</div>


    <!-- Footer -->
    <footer class="sitemap">
      <div class="container">
        <div class="row hidden-xs">
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/venues">All Venues</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="/contact">Contact</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
    
        <div class="row visible-xs-block">
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/contact">Contact</a></li>
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
      </div>
    </footer>
    
    <footer class="sponsor">
      <div class="container">
        <div class="row">
          <div class="col-sm-10 col-sm-offset-1">
            <p class="text-center">
              OpenReview is created by the <a href="http://www.iesl.cs.umass.edu/" target="_blank">Information Extraction and Synthesis Laboratory</a>, College of Information and Computer Science, University of Massachusetts Amherst. We gratefully acknowledge the support of the OpenReview sponsors:  Google,  Facebook, NSF, the University of Massachusetts Amherst Center for Data Science, and Center for Intelligent Information Retrieval, as well as the Google Cloud Platform for donating the computing and networking services on which OpenReview.net runs.
            </p>
          </div>
        </div>
      </div>
    </footer>

  <div id="feedback-modal" class="modal fade" tabindex="-1" role="dialog">
    <div class="modal-dialog">
      <div class="modal-content">
        <div class="modal-header">
          <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button>
          <h3 class="modal-title">Send Feedback</h3>
        </div>
        <div class="modal-body">
          <p>Enter your feedback below and we'll get back to you as soon as possible.</p>
          <form action="/feedback" method="POST">
            <div class="form-group">
              <input type="email" name="from" class="form-control" placeholder="Email" />
            </div>
            <div class="form-group">
              <input type="text" name="subject" class="form-control" placeholder="Subject" />
            </div>
            <div class="form-group">
              <textarea name="message" class="form-control feedback-input" rows="5" placeholder="Message" required=""></textarea>
            </div>
          <ul id="ui-id-2" tabindex="0" class="ui-menu ui-widget ui-widget-content" style="display: none;"></ul></form>
        </div>
        <div class="modal-footer">
          <button type="button" class="btn btn-default" data-dismiss="modal">Cancel</button>
          <button type="button" class="btn btn-primary">Send</button>
        </div>
      </div>
    </div>
  </div>

  <script type="text/javascript" async="" src="https://www.google-analytics.com/analytics.js"></script><script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js"></script>
  <script>window.jQuery || document.write('&lt;script src="/static/js/vendor/jquery-2.2.4.min.js"&gt;&lt;\/script&gt;')</script>

  <script src="/static/dist/vendor.min.js"></script>
  <script src="/static/dist/templates.min.js"></script>
  <script src="/static/dist/openreview.min.js"></script>

    <script>window.legacyScripts = true;</script>


    <script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-108703919-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() { dataLayer.push(arguments); }
      gtag('js', new Date());
      gtag('config', 'UA-108703919-1');
    </script>


<div role="status" aria-live="assertive" aria-relevant="additions" class="ui-helper-hidden-accessible"></div></body></html>
<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" class="no-js"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>PointGrow: Autoregressively Learned Point Cloud Generation with Self-Attention | OpenReview</title>
  <meta name="description" content="" />

      <meta name="citation_title" content="PointGrow: Autoregressively Learned Point Cloud Generation with Self-Attention" />
        <meta name="citation_author" content="Yongbin Sun" />
        <meta name="citation_author" content="Yue Wang" />
        <meta name="citation_author" content="Ziwei Liu" />
        <meta name="citation_author" content="Joshua E. Siegel" />
        <meta name="citation_author" content="Sanjay Sarma" />
      <meta name="citation_publication_date" content="2018/09/27" />
      <meta name="citation_online_date" content="2018/09/27" />
      <meta name="citation_pdf_url" content="https://openreview.net/pdf?id=r1eWW2RqFX" />
      <meta name="twitter:card" content="summary" />
      <meta name="twitter:site" content="@openreviewnet" />
      <meta name="og:title" content="PointGrow: Autoregressively Learned Point Cloud Generation with..." />
      <meta name="og:description" content="A point cloud is an agile 3D representation, efficiently modeling an object's surface geometry. However, these surface-centric properties also pose challenges on designing tools to recognize and..." />
      <meta name="og:image" content="https://openreview.net/static/images/openreview_logo_512.png" />

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans:400,400i,700,700i" />

  <link rel="stylesheet" href="/static/css/bootstrap.min.css" />
  <link rel="stylesheet" href="/static/css/jquery-ui.min.css" />
  <link rel="stylesheet" href="/static/css/main.min.css" />
</head>

<body class="forum">
  <nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
  
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand home push-link" href="/"><strong>OpenReview</strong>.net</a>
      </div>
  
      <div id="navbar" class="navbar-collapse collapse">
        <form class="navbar-form navbar-left profile-search" role="search">
          <div class="form-group has-feedback">
            <input id="search_input" type="text" class="form-control ui-autocomplete-input" placeholder="Search ICLR 2019 Conference" autocomplete="off" />
            <span class="glyphicon glyphicon-search form-control-feedback" aria-hidden="true"></span>
          </div>
  
          <input id="search_group" type="hidden" value="ICLR.cc/2019/Conference" />
          <input id="search_content" type="hidden" value="all" />
        <ul id="ui-id-1" tabindex="0" class="ui-menu ui-widget ui-widget-content ui-autocomplete ui-front" style="display: none;"></ul></form>
  
        <ul class="nav navbar-nav navbar-right">
        
            <li id="user-menu"><a href="/login">Login</a></li>
        </ul>
      </div>
  
    </div>
  </nav>

  <div id="or-banner" class="banner" style="">
  <div class="container">
    <div class="row">
      <div class="col-xs-12"><a href="/group?id=ICLR.cc/2019/Conference" title="Venue Homepage"><img class="icon" src="/static/images/arrow_left.svg" /> Go to <strong>ICLR 2019 Conference</strong> homepage</a></div>
    </div>
  </div>
</div>
<div id="flash-message-container" class="alert alert-danger" role="alert" style="display: none;">
  <div class="container">
    <div class="row">
      <div class="col-xs-12">
        <div class="alert-content">
          <button type="button" class="close" aria-label="Close"><span aria-hidden="true">Ã—</span></button>
        </div>
      </div>
    </div>
  </div>
</div>

<div class="container">
  <div class="row">
    <div class="col-xs-12">
      <main id="content" class="clearfix openbanner-visible legacy-styles"><div id="note_r1eWW2RqFX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>PointGrow: Autoregressively Learned Point Cloud Generation with Self-Attention</a> <a class="note_content_pdf" href="/pdf?id=r1eWW2RqFX" title="Download PDF" target="_blank"><img src="/static/images/pdf_icon_blue.svg" /></a> </h2></div><div class="meta_row"><span class="signatures"><a href="/profile?email=yb_sun%40mit.edu" class="profile-link" data-toggle="tooltip" data-placement="bottom" title="" data-original-title="yb_sun@mit.edu">Yongbin Sun</a>, <a href="/profile?email=yuewang%40csail.mit.edu" class="profile-link" data-toggle="tooltip" data-placement="bottom" title="" data-original-title="yuewang@csail.mit.edu">Yue Wang</a>, <a href="/profile?email=zwliu.hust%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="bottom" title="" data-original-title="zwliu.hust@gmail.com">Ziwei Liu</a>, <a href="/profile?email=j_siegel%40mit.edu" class="profile-link" data-toggle="tooltip" data-placement="bottom" title="" data-original-title="j_siegel@mit.edu">Joshua E. Siegel</a>, <a href="/profile?email=sesarma%40mit.edu" class="profile-link" data-toggle="tooltip" data-placement="bottom" title="" data-original-title="sesarma@mit.edu">Sanjay Sarma</a></span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">28 Sep 2018 (modified: 20 Nov 2018)</span><span class="item">ICLR 2019 Conference Withdrawn Submission</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Abstract: </span><span class="note_content_value">A point cloud is an agile 3D representation, efficiently modeling an object's surface geometry. However, these surface-centric properties also pose challenges on designing tools to recognize and synthesize point clouds. This work presents a novel autoregressive model, PointGrow, which generates realistic point cloud samples from scratch or conditioned from given semantic contexts. Our model operates recurrently, with each point sampled according to a conditional distribution given its previously-generated points. Since point cloud object shapes are typically encoded by long-range interpoint dependencies, we augment our model with dedicated self-attention modules to capture these relations. Extensive evaluation demonstrates that PointGrow achieves satisfying performance on both unconditional and conditional point cloud generation tasks, with respect to fidelity, diversity and semantic preservation. Further, conditional PointGrow learns a smooth manifold of given images where 3D shape interpolation and arithmetic calculation can be performed inside.</span></div><div class="note_contents"><span class="note_content_field">Keywords: </span><span class="note_content_value">point cloud generation, autoregressive models, self-attention</span></div><div class="note_contents"><span class="note_content_field">TL;DR: </span><span class="note_content_value">An autoregressive deep learning model for generating diverse point clouds.</span></div><div class="reply_row clearfix"><div class="item" id="reply_count">4 Replies</div></div></div><hr class="small" /><div id="note_children"><div class="note_with_children"><div id="note_ryxWM9zTpm" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Submission Withdrawn by the Authors</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=r1eWW2RqFX&amp;noteId=ryxWM9zTpm"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1142 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">17 Nov 2018</span><span class="item">ICLR 2019 Conference Paper1142 Withdraw Submission</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Withdrawal confirmation: </span><span class="note_content_value">I have read and agree with the withdrawal statement on behalf of myself and my co-authors.</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_HkgtWta2n7" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Comparison with the state-of-the-art is incomplete</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=r1eWW2RqFX&amp;noteId=HkgtWta2n7"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1142 AnonReviewer1</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">05 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper1142 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">The paper presents an approach for generating 3D shapes as point clouds. The approach consider a lexicographic ordering of points according to the (x, y, z) coordinates and train a model to predict points in order given the previous predictions. The conditional distribution is modeling using a self-attention mechanisms that consider multiplicative interactions between representations.  

The model is evaluated in two ways. First  for point-cloud generation which is evaluated both qualitatively and for unsupervised learning of point-cloud representations. Second as a decoder for image to shape completion tasks. 

Comments:

1. Lexicographic overlong of points seems like a poor choice for shape representation. It is sensitive to object rotation, missing parts, etc. 
2. The method is not compared with other approaches for point-cloud generation that have improved over the 3D R2N2 approach the paper compares against. In particular 
    1. AtlastNet and FoldingNet (CVPR 2018) consider parameterization of point clouds as a function of (x,y) coordinates to encoded the 2 manifold nature of the shape.

    2. Multiresolution Tree Networks (ECCV 2018) -- that consider 1D ordering of points obtained from a KD tree ordering of points. This approach is directly comparable to the proposed approach and reports 86.4% accuracy for unsupervised representation learning on ModelNet40 classification. The improvements over the approach that uses fully-connected layers such as PointSetGen (Fan et al, 2017) is marginal (.640 -&gt; 0.656 improvement in IOU). MRTNet and AtlasNet report improvements by a larger margin over PointSetGen. 

    3. Other baselines for image to shape generation that generate shapes using hierarchical voxel-based representation (OctTree networks Riegler et al.), view-based models (Lin et al., AAAI 2018), etc. are missing.

In summary the representation is not well motivated and the evaluation is incomplete. In particular comparison to several recent works on 3D shape generation is missing.</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">3: Clear rejection</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_HJlf7BGrnX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>OK paper, but does not seem particularly novel, and experiments seem inconclusive</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=r1eWW2RqFX&amp;noteId=HJlf7BGrnX"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1142 AnonReviewer2</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">30 Oct 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper1142 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">Summary:
The paper introduces a generative model for point clouds. The main idea is to use an auto-regressive model, essentially a version of pixel-RNN, which generates points one-by-one. In addition, authors use an attention model to handle longer-range interactions.

Pros:
+ The paper is relatively easy to follow.
+ Developing new generative models for 3D objects and in particular point clouds is clearly a very important problem.
+ The overall approach of using pixel RNN-like models for this task makes a lot of sense.
+ Using attention to extract global features also seems reasonable in this context.
+ Experiments show that the proposed models performance is on par or better than the existing methods (although see cons).
+ Shape completion is a nice bonus of the model.

Cons:
- Although the approach seems reasonable, it is not entirely clear what is the message of the paper: is it that we should use autoregressive models to generate point clouds, or use the attention / global context?
- Whether the work is very novel is not clear: both of the main contributions (shape of the generative distribution and using the context / attention) have already been done before (albeit maybe not in exactly the same context).
- As for the experimental evaluation, since there are no ablation studies, it is hard to see which part of the model is actually important for the performance.
- One of the major issues with pixelRNN is its scalability. It is inherently sequential and thus does not scale really well to large outputs. Thus it is a bit strange that scalability is not really discussed in the paper.
- (minor) Figures 2 and 4 are not very helpful.
</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">6: Marginally above acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_HJe8viNVnX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Interesting paper! Please address the concerns listed below.</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=r1eWW2RqFX&amp;noteId=HJe8viNVnX"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1142 AnonReviewer3</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">29 Oct 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper1142 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">Paper summary:
This paper studies the problem of point cloud generation using deep autoregressive models. More specifically, it proposed a novel architecture called PointGrow network that is able to iteratively generate 3D point cloud unconditionally or conditioned on semantic context (e.g., 2D image, class label, or partial 3D point cloud). Key design is a context-aware operation that aggregates all the previously generated points dynamically by fetching and averaging. For experimental evaluations, this paper used a subset of ShapeNet (objects from 7 categories), ModelNet40 and PASCAL 3D+ dataset. 

==
Novelty &amp; Significance:
This is a very interesting paper that applies the pixelCNN (Oord et al. 2016) framework to 3D point cloud generation. Despite the high-quality generation results shown in the paper, reviewer feels the novelty of this paper is quite limited: (1) The iterative generation has been explored to some extent in image domain; (2) Similar self-attention operators have been proposed before on point cloud recognition and generation (e.g., Qi et al 2017, Wang et al 2018).

==
Quality &amp; Presentation:
Overall, this paper provides solid comparisons with previous work in terms of generation quality and representation power. However, reviewers have a few concerns in terms of experimental design.

Q1: For the unconditional version, please comment on the performance when training the proposed PointGrow network on all categories. Does it work or not?

Q2: In Figure 3, the visualization of self-attention field looks a bit noisy. For example, most of the activated context points are not very relevant to the point on the table (on 3rd row, 7th column of Figure 3). Please clarify this in the rebuttal.

Q3: In Table 1 and Table 2, it makes more sense to provide information  such as model complexity as well. 

Q4: For unsupervised feature learning, the results will be much more convincing if the proposed model is also trained on 55 categories. It is an important ablation study.

Q5: The shape completion experiment is a bit artificial. As the points are generated by some pre-defined order, the PointGrow framework may not be able to perform shape completion task in general (e.g., to complete the shape given two wings of an airplane).

Q6: For image condition interpolation (see Figure 9), reviewer would like to know the performance with other categories. Please comment on the performance in the rebuttal.

</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">6: Marginally above acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></main></div>
  </div>
</div>


    <!-- Footer -->
    <footer class="sitemap">
      <div class="container">
        <div class="row hidden-xs">
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/venues">All Venues</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="/contact">Contact</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
    
        <div class="row visible-xs-block">
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/contact">Contact</a></li>
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
      </div>
    </footer>
    
    <footer class="sponsor">
      <div class="container">
        <div class="row">
          <div class="col-sm-10 col-sm-offset-1">
            <p class="text-center">
              OpenReview is created by the <a href="http://www.iesl.cs.umass.edu/" target="_blank">Information Extraction and Synthesis Laboratory</a>, College of Information and Computer Science, University of Massachusetts Amherst. We gratefully acknowledge the support of the OpenReview sponsors:  Google,  Facebook, NSF, the University of Massachusetts Amherst Center for Data Science, and Center for Intelligent Information Retrieval, as well as the Google Cloud Platform for donating the computing and networking services on which OpenReview.net runs.
            </p>
          </div>
        </div>
      </div>
    </footer>

  <div id="feedback-modal" class="modal fade" tabindex="-1" role="dialog">
    <div class="modal-dialog">
      <div class="modal-content">
        <div class="modal-header">
          <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">Ã—</span></button>
          <h3 class="modal-title">Send Feedback</h3>
        </div>
        <div class="modal-body">
          <p>Enter your feedback below and we'll get back to you as soon as possible.</p>
          <form action="/feedback" method="POST">
            <div class="form-group">
              <input type="email" name="from" class="form-control" placeholder="Email" />
            </div>
            <div class="form-group">
              <input type="text" name="subject" class="form-control" placeholder="Subject" />
            </div>
            <div class="form-group">
              <textarea name="message" class="form-control feedback-input" rows="5" placeholder="Message" required=""></textarea>
            </div>
          <ul id="ui-id-2" tabindex="0" class="ui-menu ui-widget ui-widget-content" style="display: none;"></ul></form>
        </div>
        <div class="modal-footer">
          <button type="button" class="btn btn-default" data-dismiss="modal">Cancel</button>
          <button type="button" class="btn btn-primary">Send</button>
        </div>
      </div>
    </div>
  </div>

  <script type="text/javascript" async="" src="https://www.google-analytics.com/analytics.js"></script><script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js"></script>
  <script>window.jQuery || document.write('&lt;script src="/static/js/vendor/jquery-2.2.4.min.js"&gt;&lt;\/script&gt;')</script>

  <script src="/static/dist/vendor.min.js"></script>
  <script src="/static/dist/templates.min.js"></script>
  <script src="/static/dist/openreview.min.js"></script>

    <script>window.legacyScripts = true;</script>


    <script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-108703919-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() { dataLayer.push(arguments); }
      gtag('js', new Date());
      gtag('config', 'UA-108703919-1');
    </script>


<div role="status" aria-live="assertive" aria-relevant="additions" class="ui-helper-hidden-accessible"></div></body></html>
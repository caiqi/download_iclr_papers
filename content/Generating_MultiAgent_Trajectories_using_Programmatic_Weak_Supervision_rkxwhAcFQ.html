<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" class="no-js"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>Generating Multi-Agent Trajectories using Programmatic Weak Supervision | OpenReview</title>
  <meta name="description" content="" />

      <meta name="citation_title" content="Generating Multi-Agent Trajectories using Programmatic Weak Supervision" />
        <meta name="citation_author" content="Anonymous" />
      <meta name="citation_publication_date" content="2018/09/27" />
      <meta name="citation_online_date" content="2018/09/27" />
      <meta name="citation_pdf_url" content="https://openreview.net/pdf?id=rkxw-hAcFQ" />
      <meta name="twitter:card" content="summary" />
      <meta name="twitter:site" content="@openreviewnet" />
      <meta name="og:title" content="Generating Multi-Agent Trajectories using Programmatic Weak..." />
      <meta name="og:description" content="We study the problem of training sequential generative models for capturing coordinated multi-agent trajectory behavior, such as  offensive basketball gameplay.  When modeling such settings, it is..." />
      <meta name="og:image" content="https://openreview.net/static/images/openreview_logo_512.png" />

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans:400,400i,700,700i" />

  <link rel="stylesheet" href="/static/css/bootstrap.min.css" />
  <link rel="stylesheet" href="/static/css/jquery-ui.min.css" />
  <link rel="stylesheet" href="/static/css/main.min.css" />
</head>

<body class="forum">
  <nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
  
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand home push-link" href="/"><strong>OpenReview</strong>.net</a>
      </div>
  
      <div id="navbar" class="navbar-collapse collapse">
        <form class="navbar-form navbar-left profile-search" role="search">
          <div class="form-group has-feedback">
            <input id="search_input" type="text" class="form-control ui-autocomplete-input" placeholder="Search ICLR 2019 Conference" autocomplete="off" />
            <span class="glyphicon glyphicon-search form-control-feedback" aria-hidden="true"></span>
          </div>
  
          <input id="search_group" type="hidden" value="ICLR.cc/2019/Conference" />
          <input id="search_content" type="hidden" value="all" />
        <ul id="ui-id-1" tabindex="0" class="ui-menu ui-widget ui-widget-content ui-autocomplete ui-front" style="display: none;"></ul></form>
  
        <ul class="nav navbar-nav navbar-right">
        
            <li id="user-menu"><a href="/login">Login</a></li>
        </ul>
      </div>
  
    </div>
  </nav>

  <div id="or-banner" class="banner" style="">
  <div class="container">
    <div class="row">
      <div class="col-xs-12"><a href="/group?id=ICLR.cc/2019/Conference" title="Venue Homepage"><img class="icon" src="/static/images/arrow_left.svg" /> Go to <strong>ICLR 2019 Conference</strong> homepage</a></div>
    </div>
  </div>
</div>
<div id="flash-message-container" class="alert alert-danger" role="alert" style="display: none;">
  <div class="container">
    <div class="row">
      <div class="col-xs-12">
        <div class="alert-content">
          <button type="button" class="close" aria-label="Close"><span aria-hidden="true">×</span></button>
        </div>
      </div>
    </div>
  </div>
</div>

<div class="container">
  <div class="row">
    <div class="col-xs-12">
      <main id="content" class="clearfix openbanner-visible legacy-styles"><div id="note_rkxw-hAcFQ" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Generating Multi-Agent Trajectories using Programmatic Weak Supervision</a> <a class="note_content_pdf" href="/pdf?id=rkxw-hAcFQ" title="Download PDF" target="_blank"><img src="/static/images/pdf_icon_blue.svg" /></a> </h2></div><div class="meta_row"><span class="signatures">Anonymous</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">28 Sep 2018 (modified: 11 Oct 2018)</span><span class="item">ICLR 2019 Conference Blind Submission</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span><span class="item"><a class="action-bibtex-modal" data-bibtex="@inproceedings{    &#10;anonymous2019generating,    &#10;title={Generating Multi-Agent Trajectories using Programmatic Weak Supervision},    &#10;author={Anonymous},    &#10;booktitle={Submitted to International Conference on Learning Representations},    &#10;year={2019},    &#10;url={https://openreview.net/forum?id=rkxw-hAcFQ},    &#10;note={under review}    &#10;}">Show Bibtex</a></span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Abstract: </span><span class="note_content_value">We study the problem of training sequential generative models for capturing coordinated multi-agent trajectory behavior, such as  offensive basketball gameplay.  When modeling such settings, it is often beneficial to design hierarchical models that can capture long-term coordination using intermediate variables.  Furthermore, these intermediate variables should capture interesting high-level behavioral semantics in an interpretable and manipulable way. We present a hierarchical framework that can effectively learn such sequential generative models.  Our approach is inspired by recent work on leveraging programmatically produced weak labels, which we extend to the spatiotemporal regime. In addition to synthetic settings, we show how to instantiate our framework to effectively model complex interactions between basketball players and generate realistic multi-agent trajectories of basketball gameplay over long time periods. We validate our approach using both quantitative and qualitative evaluations, including a user study comparison conducted with professional sports analysts.</span></div><div class="note_contents"><span class="note_content_field">Keywords: </span><span class="note_content_value">deep learning, generative models, imitation learning, hierarchical methods, data programming, weak supervision, spatiotemporal</span></div><div class="note_contents"><span class="note_content_field">TL;DR: </span><span class="note_content_value">We blend deep generative models with programmatic weak supervision to generate coordinated multi-agent trajectories of significantly higher quality than previous baselines.</span></div><div class="reply_row clearfix"><div class="item" id="reply_count">7 Replies</div></div></div><hr class="small" /><div id="note_children"><div class="note_with_children"><div id="note_r1lOYyQWRX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>General comments to revewiers</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=rkxw-hAcFQ&amp;noteId=r1lOYyQWRX"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1178 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">20 Nov 2018</span><span class="item">ICLR 2019 Conference Paper1178 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">We thank all reviewers for their insightful comments and will make updates to the paper as needed. We briefly summarize our contributions below.

We work in a novel sequential modeling setting in which the target phenomenon (coordinated multi-agent behavior) is inherently non-deterministic and multimodal. Current approaches do not scale to the complexity of this problem because the space of all possible multi-agent trajectories is exponentially large w.r.t. the number of agents, and the agents are often highly coordinated. 

We propose an efficient solution that uses a simple labeling function in sequential generative models to learn a macro-intent latent variable that encodes long-term intent and captures the coordination between agents. Our results demonstrate that our model generates trajectories of significantly higher quality than current baselines. Lastly, we highlight that our approach provides a degree of control and interpretability not offered by other baselines; the macro-intent variables are well understood (since they originate from a heuristic labeling function) and their effect on generated samples can be easily analyzed. 

We believe that this work opens a new line of research into algorithms that can provide users with various degrees of control during sample generation. Current alternatives involve learning latent variables in a fully unsupervised fashion and inspecting them after training for interpretable features. Our work uses labeling functions to directly control sample generation in ways that can be specified by the user. For example, the labeling function we used for basketball allows users to control where they want players to go (see Figure 6a in our paper). We are very excited about future work in this direction. 
</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_Bkgtp0yHaX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Paper proposes multi-agent sequential generative models. This is influential beyond toy simulations presented in the paper.</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=rkxw-hAcFQ&amp;noteId=Bkgtp0yHaX"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1178 AnonReviewer1</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">11 Nov 2018</span><span class="item">ICLR 2019 Conference Paper1178 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">Very strong paper, building on top of variational RNNs for multi-agent sequential generation. Dialogue use case is mentioned in Discussion is indeed very exciting. The approach extends VRNN to a hierarchical setup with high level coordination via a shared learned latent variable. The evaluations are not very strong due to toy task setup, however the approach is clear and impactful.</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">7: Good paper, accept</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">3: The reviewer is fairly confident that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_S1lglem-0Q" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>AnonReviewer1 Response</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=rkxw-hAcFQ&amp;noteId=S1lglem-0Q"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1178 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">20 Nov 2018</span><span class="item">ICLR 2019 Conference Paper1178 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Thank you for reviewing our paper and providing insightful feedback. We respond to your main points below.

&gt; “The evaluations are not very strong due to toy setup.”

We emphasize that, although we use a 2D perspective of the game of basketball, this setting of modeling multi-agent tracking data is still highly non-trivial due to the following reasons:
- Such data is often fine-grained and spans long time horizons.
- Models must reason over all possible multi-agent trajectories, which is exponentially large w.r.t. the number of agents and time horizon.
- Expert behavior is often inherently non-deterministic (being unpredictable on offense) and current methods struggle to accurately capture such multimodal behavior. 
- Modeling the coordination between agents is crucial for generating realistic trajectories (e.g. executing a specific offensive play in basketball).

Our approach provides an efficient solution that addresses all the aforementioned challenges, whereas current state-of-the-art baselines perform very poorly in this task (e.g. players going out of bounds, players not moving cohesively, etc.). See (<a href="http://bit.ly/2DAu1Ub)" target="_blank" rel="nofollow">http://bit.ly/2DAu1Ub)</a> for some comparisons, which is the same link provided in the footnote on page 5. Lastly, we comment that coaches and sports analysts evaluate team strategies using a 2D view of the game, so our solution in this space is practically relevant.</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div><div class="note_with_children"><div id="note_BJgg0sJQpm" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Hierarchical latent variables with weak supervision help learning a global coordination between cooperative agents.</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=rkxw-hAcFQ&amp;noteId=BJgg0sJQpm"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1178 AnonReviewer2</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">09 Nov 2018</span><span class="item">ICLR 2019 Conference Paper1178 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">
This paper proposes training multiple generative models that share a common latent variable, which is learned in a weakly supervised fashion, to achieve high level coordination between multiple agents. Each agent has a separate VRNN model which is conditioned on the agent’s own trajectory history as well as the shared latent variable. The model is trained to maximize the ELBO objective and log-likelihood over macro-intent labels. Experimental results are conducted over a basketball gameplay dataset (to model the trajectories of the offensive team members) and a synthetic dataset. The results show that the proposed model is on-par with the baseline models in terms of ELBO while showing that it can model multi-modality better and is preferred more by humans. 

In general, the paper is well written and the overall framework captures the essence of the problem that the authors are trying to solve.
Furthermore, incorporating an auxiliary latent variable to model the coordination between multiple agents is interesting.
I have several comments related to the strength of the baselines and contribution of individual components in the proposed model.


Major Comments

- It seems that VRNN-single and VRNN-indep are two models on the far two ends of a spectrum. To understand the contribution of the shared macro-intent, how would an intermediate baseline model where a set of parameters are shared between agents and each agent also has an independent set of parameters perform? This could be accomplished by sharing the parameters of the first layer of GRU networks and learning the second layer parameters independently.

- How is the threshold for macro-intent generation selected? How does this parameter affect the overall performance? Since the smoothness of the segments between two macro-intents depend on this parameter, I am wondering its effect on the learned posterior distribution.

- Rather than using the prediction of the macro-intent RNN as a single global vector (\hat{g}_t), could using separate vectors for each agent (corresponding blocks of \hat{g}_t) as inputs to VRNN give the same results? Since the macro-intent RNN is already aware of all the macro-intents, it would be interesting to see if individual macro-intents are sufficient for VRNN to generate corresponding trajectories.


Minor Comments

- Do results in Table (1) come from sampling or using mode of the distributions? How peaked are the learned posterior distributions?
- What is the performance of the macro-intent RNN model?
- In Eq (2), “&lt;=T” should be “&lt;=t” (as in Eq (11) in Chung 2015).
- In Page 6, bullet point 4: it should be “except we maximize the mutual information…”
</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">6: Marginally above acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">3: The reviewer is fairly confident that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_ryeTwe7bAm" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>AnonReviewer2 Response</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=rkxw-hAcFQ&amp;noteId=ryeTwe7bAm"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1178 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">20 Nov 2018</span><span class="item">ICLR 2019 Conference Paper1178 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Thank you for reviewing our paper and providing insightful feedback. We respond to your main points below.

&gt; “... how would an intermediate baseline model where a set of parameters are shared and each agent also has an independent set of parameters perform?”

Following your suggestion, we trained such a model where the positions of all players are fed into a single GRU network, but independent networks are used to compute latent variables for each agent. This is a mix between VRNN-single and VRNN-indep, which we will call VRNN-mixed, and achieves an ELBO of 2331 and similar statistics as VRNN-indep (we will update Table 1 and Table 3). We’ve also included some generated samples at (<a href="https://bit.ly/2S66iO9)." target="_blank" rel="nofollow">https://bit.ly/2S66iO9).</a> However, we emphasize that this model remains fundamentally different from our solution, as our solution provides a degree of controllability and interpretability (through macro-intents) not offered by these baselines. 

&gt; “How is the threshold for macro-intent generation selected.”

The threshold is chosen such that it qualitatively matches realistic basketball behavior (i.e. when a basketball player is considered stationary).  We are running more experiments with different thresholds and will add the results in a future comment.

However, the reviewer raises a very interesting question regarding the effect of labeling functions on the stability and robustness of the model. One can imagine other domains where labeling functions come from a variety of sources, some of which are noisy or redundant. Designing an algorithm that can process these labels and incorporate them into sample generation is a new line of research that we are very excited about.

&gt; “... could using separate [macro-intent] vector for each agent … give the same result?

In the basketball setting, individual macro-intents are in fact sufficient for generating corresponding trajectories. However, this is mainly an architectural detail that is domain-dependent and not the most important part of our contributions. For example, one can also define macro-intents that cannot be factorized for each agent, such as friendly/unfriendly behavior in the Boids model included in our experiments.

&gt; Minor Comments

The results come from sampling from the posterior distribution. The average standard deviation of the learned posterior distribution is around 0.08 per latent dimension. The standard deviation of the learned likelihood of the data is very peaked (often less than 0.01). The macro-intent RNN model achieves a log-likelihood of 2180, which is an improvement over the RNN-gauss model but still worse than all VRNN models. We will update the paper to correct for typos. 
</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div><div class="note_with_children"><div id="note_rygJogZanm" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Heuristic labeling enables learning of hierarchical model without needing to marginalize over latent variables</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=rkxw-hAcFQ&amp;noteId=rygJogZanm"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1178 AnonReviewer3</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">05 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper1178 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value"># Summary

The paper proposes training generative models that produce multi-agent trajectories using heuristic functions that label variables that would otherwise be latent in training data. The generative models are hierarchical, and these latent variables correspond to higher level goals in agent behavior. The paper focuses on basketball offenses as a motivating scenario in which multiple agents have coordinated high-level behavior. The generative models are RNNs where each output is fed into the decoder of a variational autoencoder to produce observed states. The authors add an intermediate layer to capture the latent variables, called macro-intents. The parameters are learned by maximizing an evidence lower bound.

Experiments qualitatively and quantitatively show that the hierarchical model produces realistic multi-agent traces.

# Comments

The paper presents a sensible solution for heuristically labeling latent variables. It is not particularly surprising that the model then learns useful behavior because it no longer has to maximize the marginal likelihood over all possible macro-intents. What is more interesting is that a heuristic labeling function is sufficient to label macro-intents that lead to learning realistic basketball offenses and swarm behavior.

Are any of the baselines (VRNN-single, VRNN-indep, and VRNN-mi) equivalent to training the hierarchical model by maximizing an ELBO on the marginal likelihood? I do not think this comparison is done, which might be interesting to quantify how much of a difference heuristic labeling makes. Of course, the potentially poor fit of a variational distribution would confound the results.

# Minor things

1) In the caption of Table 1, it says "Our hierarchical model achieves higher log-likelihoods than baselines for both datasets." Are not the reported scores evidence lower-bounds? So it achieves a higher evidence lower bound, but without actually computing the true likelihood, could not the other models have higher likelihoods?

2) Under "Human preference study" it says "All judges preferred our model over the baselines with 98% statistical significance." I am not familiar with this terminology. Does that mean that a p value for some null hypothesis is .02?

3) Something is wrong with the citation commands. Perhaps \citep should be used.</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">6: Marginally above acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">3: The reviewer is fairly confident that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_BygisxQbCm" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>AnonReviewer3 Response</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=rkxw-hAcFQ&amp;noteId=BygisxQbCm"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1178 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">20 Nov 2018</span><span class="item">ICLR 2019 Conference Paper1178 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Thank you for reviewing our paper and providing insightful feedback. We respond to your main points below.

&gt; “What is more interesting is that a heuristic labeling function is sufficient to label macro-intents that lead to learning realistic basketball offense and swarm behavior.”

Yes, we are very excited at the new lines of research that this opens up. One can envision many settings in which users wish to have diverse and detailed control over what’s being generated. We believe models with this degree of control can be learned by incorporating labeling functions defined by users according to their preferences. We are very excited about future work in this direction.

&gt; “Are any … baselines … equivalent to training the hierarchical model by maximizing an ELBO on the marginal likelihood?”

If we understand the reviewer’s question, then VRNN-mi does exactly this by introducing a global latent variable (in place of macro-intent weak labels) and maximizing the ELBO as well as the mutual information between the global latent variable and the trajectory. We will update the paper to make this more clear.

&gt; “... could not the other models have higher likelihoods?”

Yes, a higher ELBO does not imply a higher true likelihood, as it depends on the tightness of the bound. Computing the exact likelihood is infeasible, but it can be approximated with importance sampling. However, we note that likelihoods do not necessary correspond to quality of generated samples, as evidenced by our experiments and by [1]. Furthermore, reporting ELBOs is often sufficient when quantitatively comparing models [2,3,4].

“&gt; ... 98% statistical significance.”

We performed a one-sample t-test, where the null hypothesis is that the gains come from a zero-mean distribution (which would mean that both models are preferred equally).

[1] Theis et al. A note on the evaluation of generative models.
[2] Chung et al. A recurrent latent variable model for sequential data.
[3] Fraccaro et al. Sequential neural models with stochastic layers.
[4] Goyal et al. Z-forcing: training stochastic recurrent networks. 
</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div></div></main></div>
  </div>
</div>


    <!-- Footer -->
    <footer class="sitemap">
      <div class="container">
        <div class="row hidden-xs">
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/venues">All Venues</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="/contact">Contact</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
    
        <div class="row visible-xs-block">
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/contact">Contact</a></li>
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
      </div>
    </footer>
    
    <footer class="sponsor">
      <div class="container">
        <div class="row">
          <div class="col-sm-10 col-sm-offset-1">
            <p class="text-center">
              OpenReview is created by the <a href="http://www.iesl.cs.umass.edu/" target="_blank">Information Extraction and Synthesis Laboratory</a>, College of Information and Computer Science, University of Massachusetts Amherst. We gratefully acknowledge the support of the OpenReview sponsors:  Google,  Facebook, NSF, the University of Massachusetts Amherst Center for Data Science, and Center for Intelligent Information Retrieval, as well as the Google Cloud Platform for donating the computing and networking services on which OpenReview.net runs.
            </p>
          </div>
        </div>
      </div>
    </footer>

  <div id="feedback-modal" class="modal fade" tabindex="-1" role="dialog">
    <div class="modal-dialog">
      <div class="modal-content">
        <div class="modal-header">
          <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button>
          <h3 class="modal-title">Send Feedback</h3>
        </div>
        <div class="modal-body">
          <p>Enter your feedback below and we'll get back to you as soon as possible.</p>
          <form action="/feedback" method="POST">
            <div class="form-group">
              <input type="email" name="from" class="form-control" placeholder="Email" />
            </div>
            <div class="form-group">
              <input type="text" name="subject" class="form-control" placeholder="Subject" />
            </div>
            <div class="form-group">
              <textarea name="message" class="form-control feedback-input" rows="5" placeholder="Message" required=""></textarea>
            </div>
          <ul id="ui-id-2" tabindex="0" class="ui-menu ui-widget ui-widget-content" style="display: none;"></ul></form>
        </div>
        <div class="modal-footer">
          <button type="button" class="btn btn-default" data-dismiss="modal">Cancel</button>
          <button type="button" class="btn btn-primary">Send</button>
        </div>
      </div>
    </div>
  </div>

  <script type="text/javascript" async="" src="https://www.google-analytics.com/analytics.js"></script><script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js"></script>
  <script>window.jQuery || document.write('&lt;script src="/static/js/vendor/jquery-2.2.4.min.js"&gt;&lt;\/script&gt;')</script>

  <script src="/static/dist/vendor.min.js"></script>
  <script src="/static/dist/templates.min.js"></script>
  <script src="/static/dist/openreview.min.js"></script>

    <script>window.legacyScripts = true;</script>


    <script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-108703919-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() { dataLayer.push(arguments); }
      gtag('js', new Date());
      gtag('config', 'UA-108703919-1');
    </script>


<div role="status" aria-live="assertive" aria-relevant="additions" class="ui-helper-hidden-accessible"></div></body></html>
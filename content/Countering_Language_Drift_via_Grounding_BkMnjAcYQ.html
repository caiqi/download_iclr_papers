<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" class="no-js"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>Countering Language Drift via Grounding | OpenReview</title>
  <meta name="description" content="" />

      <meta name="citation_title" content="Countering Language Drift via Grounding" />
        <meta name="citation_author" content="Anonymous" />
      <meta name="citation_publication_date" content="2018/09/27" />
      <meta name="citation_online_date" content="2018/09/27" />
      <meta name="citation_pdf_url" content="https://openreview.net/pdf?id=BkMn9jAcYQ" />
      <meta name="twitter:card" content="summary" />
      <meta name="twitter:site" content="@openreviewnet" />
      <meta name="og:title" content="Countering Language Drift via Grounding" />
      <meta name="og:description" content="While reinforcement learning (RL) shows a lot of promise for natural language processing—e.g. when fine-tuning natural language systems for optimizing a certain objective—there has been little..." />
      <meta name="og:image" content="https://openreview.net/static/images/openreview_logo_512.png" />

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans:400,400i,700,700i" />

  <link rel="stylesheet" href="/static/css/bootstrap.min.css" />
  <link rel="stylesheet" href="/static/css/jquery-ui.min.css" />
  <link rel="stylesheet" href="/static/css/main.min.css" />
</head>

<body class="forum">
  <nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
  
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand home push-link" href="/"><strong>OpenReview</strong>.net</a>
      </div>
  
      <div id="navbar" class="navbar-collapse collapse">
        <form class="navbar-form navbar-left profile-search" role="search">
          <div class="form-group has-feedback">
            <input id="search_input" type="text" class="form-control ui-autocomplete-input" placeholder="Search ICLR 2019 Conference" autocomplete="off" />
            <span class="glyphicon glyphicon-search form-control-feedback" aria-hidden="true"></span>
          </div>
  
          <input id="search_group" type="hidden" value="ICLR.cc/2019/Conference" />
          <input id="search_content" type="hidden" value="all" />
        <ul id="ui-id-1" tabindex="0" class="ui-menu ui-widget ui-widget-content ui-autocomplete ui-front" style="display: none;"></ul></form>
  
        <ul class="nav navbar-nav navbar-right">
        
            <li id="user-menu"><a href="/login">Login</a></li>
        </ul>
      </div>
  
    </div>
  </nav>

  <div id="or-banner" class="banner" style="">
  <div class="container">
    <div class="row">
      <div class="col-xs-12"><a href="/group?id=ICLR.cc/2019/Conference" title="Venue Homepage"><img class="icon" src="/static/images/arrow_left.svg" /> Go to <strong>ICLR 2019 Conference</strong> homepage</a></div>
    </div>
  </div>
</div>
<div id="flash-message-container" class="alert alert-danger" role="alert" style="display: none;">
  <div class="container">
    <div class="row">
      <div class="col-xs-12">
        <div class="alert-content">
          <button type="button" class="close" aria-label="Close"><span aria-hidden="true">×</span></button>
        </div>
      </div>
    </div>
  </div>
</div>

<div class="container">
  <div class="row">
    <div class="col-xs-12">
      <main id="content" class="clearfix openbanner-visible legacy-styles"><div id="note_BkMn9jAcYQ" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Countering Language Drift via Grounding</a> <a class="note_content_pdf" href="/pdf?id=BkMn9jAcYQ" title="Download PDF" target="_blank"><img src="/static/images/pdf_icon_blue.svg" /></a> </h2></div><div class="meta_row"><span class="signatures">Anonymous</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">28 Sep 2018 (modified: 20 Nov 2018)</span><span class="item">ICLR 2019 Conference Blind Submission</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span><span class="item"><a class="action-bibtex-modal" data-bibtex="@inproceedings{    &#10;anonymous2019countering,    &#10;title={Countering Language Drift via Grounding},    &#10;author={Anonymous},    &#10;booktitle={Submitted to International Conference on Learning Representations},    &#10;year={2019},    &#10;url={https://openreview.net/forum?id=BkMn9jAcYQ},    &#10;note={under review}    &#10;}">Show Bibtex</a></span><a class="note_content_pdf item" href="/revisions?id=BkMn9jAcYQ" target="_blank">Show Revisions</a></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Abstract: </span><span class="note_content_value">While reinforcement learning (RL) shows a lot of promise for natural language processing—e.g. when fine-tuning natural language systems for optimizing a certain objective—there has been little investigation into potential language drift: when an external reward is used to train a system, the agents’ communication protocol may easily and radically diverge from natural language. By re-casting translation as a communication game, we show that language drift indeed happens when pre-trained agents are fine-tuned with policy gradient methods. We contend that simply adding a "naturalness" constraint to the reward, e.g. by using language model log likelihood, does not fully address the issue, and argue that (perceptual) grounding is required. That is, while language model constraints impose syntactic conformity, they do not lead to semantic correspondence. Our experiments show that grounded models give the best communication performance, while retaining English syntax along with the ability to convey the intended semantics.</span></div><div class="note_contents"><span class="note_content_field">Keywords: </span><span class="note_content_value">grounding, policy gradient, language drift, reinforcement learning</span></div><div class="note_contents"><span class="note_content_field">TL;DR: </span><span class="note_content_value">Grounding helps avoid language drift during fine-tuning natural language agents with policy gradients.</span></div><div class="reply_row clearfix"><div class="item" id="reply_count">10 Replies</div></div></div><hr class="small" /><div id="note_children"><div class="note_with_children"><div id="note_SJlxDKzanX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Countering Language Drift via Grounding</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=BkMn9jAcYQ&amp;noteId=SJlxDKzanX"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper568 AnonReviewer2</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">05 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper568 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">Summary:
This paper tries to verify a hypothesis that language grounding DO help to overcome language drift when two agents creating their own protocol in order to communicate with each other. There are several constraints to enforce: 1) naturalness, say "Englishness", 2) grounded in visual semantics. The experiments prove that both constraints help the most (say, BLUE score). 1) w/o 2) restricts the vocabulary into a small set with the most frequent words, while 1) with 2) can resemble the original distribution. 

Strength:
- How to make the protocol automatically created by two agents much explainable/meaningful is a very interesting topic. This paper explores plausible constraints to reach this goal. 

Weakness:
- Visual grounding task brings more data there. To fairly compare, I hope to add one more baseline PG+LM+G_text, where G_text simply means to use text data (captions) alone, i.e., without visual signals.
</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">6: Marginally above acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">3: The reviewer is fairly confident that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_rkeBW0olCm" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Author response</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=BkMn9jAcYQ&amp;noteId=rkeBW0olCm"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper568 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">20 Nov 2018</span><span class="item">ICLR 2019 Conference Paper568 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Dear AnonReviewer2,

Thank you for your constructive feedback! We agree that making multi agent communication more interpretable is both interesting and important.

- Grounding “brings more data” :  thanks for pointing this out. We added this stronger baseline where the LM was trained on both WikiText103 and the captions from Flickr30k and MS COCO datasets (see Table 4, LM=All), and found that introducing visual grounding still outperforms this baseline. </span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div><div class="note_with_children"><div id="note_S1l0qNZYhm" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Is BLEU the right metric?</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=BkMn9jAcYQ&amp;noteId=S1l0qNZYhm"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper568 AnonReviewer3</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">02 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper568 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">The paper presents an approach to refining a translation system with grounding (in addition to LM scores) in the loop to manage linguistic drift.  The intuition is straightforward and results are clearly presented, but the gains are unfortunately much weaker than I would have hoped for.  

The results for both Fr-En and Fr-En-De only show very small gains for adding grounding, often with PG+LM results being within 1 std-dev of the PG+LM+G results.  Otherwise, the results are quite nice with interesting increases in linguistic diversity.  This leads me to wonder if this approach would show more gains with a human evaluation rather than BLEU score. 

What is the performance of PG+G without the +LM?  

Minor -- In Fig 2, should the green line (PG+LM) have continued climbing to &gt;21 BLEU?</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">6: Marginally above acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_rygcGRjlRm" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Author response</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=BkMn9jAcYQ&amp;noteId=rygcGRjlRm"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper568 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">20 Nov 2018</span><span class="item">ICLR 2019 Conference Paper568 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Dear AnonReviewer3,

Thank you for your helpful comments! Please see our response below.

- Is BLEU the right metric? : Given the availability of ground truth English references, we believe BLEU is the best metric we have, as it is clearly interpretable and well-understood. BLEU of course also has weaknesses, and we agree that a human evaluation would be very interesting. In this setting, however, we believe BLEU is sufficient for making our argument.

- Gains for adding grounding are small (within 1 std dev): We agree that the results for PG+LM and PG+LM+G are often close in BLEU score. Our qualitative analyses, on the other hand, strongly indicate that PG and PG+LM models learn a biased token distribution: namely, PG finetuning ignores the content words, while the PG+LM finetuning excessively encourages them. We find that visual grounding is key to retaining the original token distribution.

- The results of PG+G without +LM is shown in Table 4, with PG+LM+G with “LM=None”. In hindsight we see that we should have made this clearer: we updated the table to make this stand out more. The PG+G model, although outperformed by PG+LM and PG+LM+G, still produces less drift than the vanilla PG finetuning alone.

- Fig. 2, would PG+LM continue to over 21? : We used the same early stopping criteria based on communication performance (Fr-&gt;En-&gt;De BLEU) for all our models. Hence this model was early stopped at that point.</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div><div class="note_with_children"><div id="note_SJezHMdwnQ" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Important topic, but uncertain about framing and significance of results</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=BkMn9jAcYQ&amp;noteId=SJezHMdwnQ"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper568 AnonReviewer1</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">01 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper568 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">This paper poses and addresses the problem of language drift in multi-agent communication paradigms. When two pretrained natural-language agents are jointly optimized to communicate and solve some external non-linguistic objective, their internal communication often diverges to a code-like, unnatural communication system. This paper solves this “language drift” problem by requiring that the messages between agents be usable as inputs to an image caption retrieval system. They demonstrate that the jointly optimized agents perform best when regularized in this manner to prevent language drift.

1. Framing: I’m uncertain about the framing of this paper. The authors pose the problem of “language drift,” which is indeed a frequent problem in multi-agent communication tasks where the principle supervision involves non-linguistic inputs and outputs. They then design a three-language MT task as a test case, where the inputs and outputs are both linguistic. Why attack this particular task and grounding solution? I can imagine some potential goals of the paper, but also see more direct ways to address each of the potential goals than what the authors have chosen:
1a. Study how to counter language drift in general — why not choose a more intuitive two-agent communication task, e.g. navigation, game playing, etc.?
1b. Study how to counter language drift in the MT task — aren’t there simpler solutions to prevent language drift in this particular task? e.g. require “cycle-consistency” – that it be possible to reconstruct the French input using the French output? Why pick multimodal grounding, given that it imposes substantial additional data requirements?
1c. Build a better/more data-efficient machine translation system — this could be an interesting goal and suitable for the paper, but this doesn’t seem to be the framing that the authors intend.

2. Interpretation of first results:
2a. Thanks for including standard deviation estimates! I think it’s also important that you do some sort of significance testing on the comparison between PG+LM+G and PG+LM performance for Fr-&gt;En-&gt;De — these numbers look pretty close to me. You could run e.g. a simple sign test on examples within each corpus between the two conditions.
2b. It would also be good to know how robust your results are to hyperparameter settings (especially the entropy regularization hyperparameter).

3. Token frequency results: These are intriguing but quite confusing to me!
3a. How sensitive are these results to your entropy regularization setup? How does PG behave without entropy regularization?
3b. Table 6 shows that the PG model has very different drift for different POS categories. Does this explain away the change in the token frequency distribution? What do the token frequency effects look like for PG within the open-class / content word categories (i.e., controlling for the huge difference in closed-class behavior)?

4. Minor comments:
4a. There’s a related problem in unsupervised representation learning for language. Work on VAEs for language, for example, has shown that the encoder often collapses meaning differences in the latent representation, and leans on an overly powerful decoder in order to pick up all of the lost information. It would be good to reference this work in your framing (see e.g. Bowman et al. (2015)).
4b. In sec. 3.1 you overload notation for R. Can you subscript these so that it’s especially clear in your results which systems are following which reward function?
4c. Great to show some qualitative examples in Table 7 — can you explicitly state where these are from (dev set vs. test set?) and whether they are randomly sampled?

References:
Bowman et al. (2015). Generating sentences from a continuous space. <a href="https://arxiv.org/abs/1511.06349" target="_blank" rel="nofollow">https://arxiv.org/abs/1511.06349</a>
</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">6: Marginally above acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_H1g4VRjeRQ" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Author response</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=BkMn9jAcYQ&amp;noteId=H1g4VRjeRQ"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper568 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">20 Nov 2018</span><span class="item">ICLR 2019 Conference Paper568 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Dear AnonReviewer1, 

Thank you for your very detailed feedback, we appreciate your efforts! Please see our response below.

Response to 1(a, b, c) : please see the separate response to AnonReviewer1 and AC below.

(2a) We agree that Fr-&gt;En-&gt;De results are pretty close between PG+LM and PG+LM+G. Our qualitative analyses, on the other hand, strongly indicate that PG and PG+LM learn a biased token distribution, and that visual grounding is key to retaining the original token distribution.

(2b/3a) We performed a thorough grid search over entropy regularisation, and selected \alpha_entr = 0.001 based on Fr-&gt;En-&gt;De performance on the validation set. A lower value (or no regularisation) would sometimes lead to models being stuck with only a few vocabulary words being used (therefore higher variance in the overall results). When a larger value is used, the Fr-&gt;En agent uses excessively many tokens, and the models do not converge. 

(3b) Yes, this seems to affect the token frequency distribution. Vanilla PG training significantly discourages function words: period and comma are ranked much lower for PG than for English reference (see Table 9). Meanwhile, PG encourages content/open-class words. In Table 9, content words such as “red”, “blue”, “city”, “white” are ranked high for PG, much more so than other models.

(4a) This is a very interesting point. We mentioned this in the related work section in our revision.

(4b) Thanks for the suggestion. This is fixed in the revision.
 
(4c) These are random samples from the development set. We modified the captions to reflect this.</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_SkgsYLlzT7" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>An additional extremely simple baseline?</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=BkMn9jAcYQ&amp;noteId=SkgsYLlzT7"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper568 Area Chair1</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">09 Nov 2018</span><span class="item">ICLR 2019 Conference Paper568 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Hello, area chair here.

I agree with the reviewer here on point 1: this setting is a bit artificial, and it seems that there are much simpler ways to prevent language drift. In addition to the "cycle consistency" loss, it seems even easier to occasionally sample batches of French-English data, and train on these batches using the original MLE objective that was used to pre-train the model. Do the methods in this paper have any advantages over this simple auxiliary objective?

I could see an argument that maybe grounding in images is more cognitively plausible if you were trying to simulate how babies learn or something like that, but in this case the experimental setting of having two MT systems is far from cognitively plausible in the first place.</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_SJlXH6cm6m" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Author response</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=BkMn9jAcYQ&amp;noteId=SJlXH6cm6m"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper568 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">10 Nov 2018</span><span class="item">ICLR 2019 Conference Paper568 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Dear AnonReviewer1 and AC,

Thank you both for your constructive feedback! We think there is a slight misunderstanding here: the reason we have chosen this setup is exactly because this particular task and setup directly addresses the problem of language drift, in a way where the semantics stays identical while the communication channel gets only extrinsic reward (i.e., the meaning is exactly the same for all languages and modalities). In addition, every single utterance has very clear and very well-known metrics, in the shape of BLEU and NLL/perplexity, allowing us to measure performance at every single step.

We would very much welcome any suggestions for other tasks where this setup would be possible, and where data is available, but we think that AnonReviewer1's suggestions (while of course very welcome) do not satisfy these criteria: other two-agent communication tasks such as navigation or game-playing have neither clearly defined metrics nor easily available NL data. Hence, we do not think our setup is artificial, but ideal for understanding the problem as best as we possibly can.

As for auxiliary objectives or other solutions for preventing drift:
- If cycle-consistency means a French-French auto-encoder with English intermediary, that is a much weaker setting than French-German with English intermediary, because there is no way for the agents to focus on superficial information and really only the meaning of the sentence is at stake. Our setting is much more difficult than this sort of cycle-consistency, as the focus is on the semantics, which is why we want to avoid language drift in the first place. In other words, cycle-consistency is a special case of what we've done, we do not expect any different result from it.
- Occasionally sampling batches of French-English data with the original MLE objective does not prevent drift, unless we do that so often that we undo the advantages of fine-tuning. Note that performance is much better than training simply with an MLE objective, due to fine-tuning. Occasionally training with MLE will avoid some drift but at the expense of performance improvements. Our work clearly shows that the alternative solution of adding language model constraints is insufficient.

If you like, we would be happy to train French-French and German-German autoencoders, with English intermediates, and show that the same results hold as what we report for the harder French-German case. Similarly, we would be happy to add experiments showing that occasionally training on batches with MLE does not work as well as our proposed solution.

With regard to cognitive plausibility of the three-way translation task, we disagree: In 2009, the United States Census Bureau reported that about 20 percent of Americans speak a language other than English at home. Therefore we would like to point out that this three-way translation task, using English as an intermediate language, is not only cognitively plausible but a reality for one fifth of Americans.

A useful interpretation of our setup is that Agent A is communicating their (French) thoughts in English so that Agent B understands the intended message in their (German) thoughts. In a sense our setup is more plausible than the cycle-consistent autoencoder, because no two people speak exactly the same language or have exactly the same thoughts.
</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_r1gYCKweAQ" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Concerns about applicability of method</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=BkMn9jAcYQ&amp;noteId=r1gYCKweAQ"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper568 Area Chair1</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">20 Nov 2018</span><span class="item">ICLR 2019 Conference Paper568 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Hello,

Thank you for the comprehensive response. 

&gt; We would very much welcome any suggestions for other tasks where this setup would be possible, and where data is available, but we think that AnonReviewer1's suggestions (while of course very welcome) do not satisfy these criteria: other two-agent communication tasks such as navigation or game-playing have neither clearly defined metrics nor easily available NL data.

I'm concerned by this: does this mean that there are no tasks for which the proposed method here is actually applicable? If it is such as struggle to come up with an appropriate test bed, then it seems that the underlying motivation itself is lacking.

&gt; With regard to cognitive plausibility of the three-way translation task, we disagree: In 2009, the United States Census Bureau reported that about 20 percent of Americans speak a language other than English at home. 

Right, but the language they learn at home is not learned by translating between two other languages, like the task presented here. Rather, it is learned by grounding in inputs (acquired through vision) from the world around. To see an example of a more cognitively plausible model, please see, for example "Learning Words from Sights and Sounds: a Computational Model" (Roy and Pentland, Cognitive Science 2002)

&gt; A useful interpretation of our setup is that Agent A is communicating their (French) thoughts in English so that Agent B understands the intended message in their (German) thoughts. In a sense our setup is more plausible than the cycle-consistent autoencoder, because no two people speak exactly the same language or have exactly the same thoughts.

I can understand that this might be a proxy for the task of "thoughts" in one person's brain to "thoughts" in another, but then the question becomes, how do you get the supervision for "thoughts -&gt; English" in the first place? The point of this paper is preventing language "drift", which is divergence from an original model that has been trained on "thoughts -&gt; English", but if the whole method it predicated on having this original model, then it's not clear to me why this model is interesting and/or useful.

Sorry if this sounds somewhat negative, but I'd really like to understand the motivation. Thanks!</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div></div></div></div></div></div></main></div>
  </div>
</div>


    <!-- Footer -->
    <footer class="sitemap">
      <div class="container">
        <div class="row hidden-xs">
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/venues">All Venues</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="/contact">Contact</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
    
        <div class="row visible-xs-block">
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/contact">Contact</a></li>
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
      </div>
    </footer>
    
    <footer class="sponsor">
      <div class="container">
        <div class="row">
          <div class="col-sm-10 col-sm-offset-1">
            <p class="text-center">
              OpenReview is created by the <a href="http://www.iesl.cs.umass.edu/" target="_blank">Information Extraction and Synthesis Laboratory</a>, College of Information and Computer Science, University of Massachusetts Amherst. We gratefully acknowledge the support of the OpenReview sponsors:  Google,  Facebook, NSF, the University of Massachusetts Amherst Center for Data Science, and Center for Intelligent Information Retrieval, as well as the Google Cloud Platform for donating the computing and networking services on which OpenReview.net runs.
            </p>
          </div>
        </div>
      </div>
    </footer>

  <div id="feedback-modal" class="modal fade" tabindex="-1" role="dialog">
    <div class="modal-dialog">
      <div class="modal-content">
        <div class="modal-header">
          <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button>
          <h3 class="modal-title">Send Feedback</h3>
        </div>
        <div class="modal-body">
          <p>Enter your feedback below and we'll get back to you as soon as possible.</p>
          <form action="/feedback" method="POST">
            <div class="form-group">
              <input type="email" name="from" class="form-control" placeholder="Email" />
            </div>
            <div class="form-group">
              <input type="text" name="subject" class="form-control" placeholder="Subject" />
            </div>
            <div class="form-group">
              <textarea name="message" class="form-control feedback-input" rows="5" placeholder="Message" required=""></textarea>
            </div>
          <ul id="ui-id-2" tabindex="0" class="ui-menu ui-widget ui-widget-content" style="display: none;"></ul></form>
        </div>
        <div class="modal-footer">
          <button type="button" class="btn btn-default" data-dismiss="modal">Cancel</button>
          <button type="button" class="btn btn-primary">Send</button>
        </div>
      </div>
    </div>
  </div>

  <script type="text/javascript" async="" src="https://www.google-analytics.com/analytics.js"></script><script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js"></script>
  <script>window.jQuery || document.write('&lt;script src="/static/js/vendor/jquery-2.2.4.min.js"&gt;&lt;\/script&gt;')</script>

  <script src="/static/dist/vendor.min.js"></script>
  <script src="/static/dist/templates.min.js"></script>
  <script src="/static/dist/openreview.min.js"></script>

    <script>window.legacyScripts = true;</script>


    <script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-108703919-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() { dataLayer.push(arguments); }
      gtag('js', new Date());
      gtag('config', 'UA-108703919-1');
    </script>


<div role="status" aria-live="assertive" aria-relevant="additions" class="ui-helper-hidden-accessible"></div></body></html>
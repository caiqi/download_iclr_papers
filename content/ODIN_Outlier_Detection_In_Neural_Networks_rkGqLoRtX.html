<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" class="no-js"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>ODIN: Outlier Detection In Neural Networks | OpenReview</title>
  <meta name="description" content="" />

      <meta name="citation_title" content="ODIN: Outlier Detection In Neural Networks" />
        <meta name="citation_author" content="Anonymous" />
      <meta name="citation_publication_date" content="2018/09/27" />
      <meta name="citation_online_date" content="2018/09/27" />
      <meta name="citation_pdf_url" content="https://openreview.net/pdf?id=rkGqLoR5tX" />
      <meta name="twitter:card" content="summary" />
      <meta name="twitter:site" content="@openreviewnet" />
      <meta name="og:title" content="ODIN: Outlier Detection In Neural Networks" />
      <meta name="og:description" content="Adoption of deep learning in safety-critical systems raise the need for understanding what deep neural networks do not understand. Several methodologies to estimate model uncertainty have been..." />
      <meta name="og:image" content="https://openreview.net/static/images/openreview_logo_512.png" />

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans:400,400i,700,700i" />

  <link rel="stylesheet" href="/static/css/bootstrap.min.css" />
  <link rel="stylesheet" href="/static/css/jquery-ui.min.css" />
  <link rel="stylesheet" href="/static/css/main.min.css" />
</head>

<body class="forum">
  <nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
  
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand home push-link" href="/"><strong>OpenReview</strong>.net</a>
      </div>
  
      <div id="navbar" class="navbar-collapse collapse">
        <form class="navbar-form navbar-left profile-search" role="search">
          <div class="form-group has-feedback">
            <input id="search_input" type="text" class="form-control ui-autocomplete-input" placeholder="Search ICLR 2019 Conference" autocomplete="off" />
            <span class="glyphicon glyphicon-search form-control-feedback" aria-hidden="true"></span>
          </div>
  
          <input id="search_group" type="hidden" value="ICLR.cc/2019/Conference" />
          <input id="search_content" type="hidden" value="all" />
        <ul id="ui-id-1" tabindex="0" class="ui-menu ui-widget ui-widget-content ui-autocomplete ui-front" style="display: none;"></ul></form>
  
        <ul class="nav navbar-nav navbar-right">
        
            <li id="user-menu"><a href="/login">Login</a></li>
        </ul>
      </div>
  
    </div>
  </nav>

  <div id="or-banner" class="banner" style="">
  <div class="container">
    <div class="row">
      <div class="col-xs-12"><a href="/group?id=ICLR.cc/2019/Conference" title="Venue Homepage"><img class="icon" src="/static/images/arrow_left.svg" /> Go to <strong>ICLR 2019 Conference</strong> homepage</a></div>
    </div>
  </div>
</div>
<div id="flash-message-container" class="alert alert-danger" role="alert" style="display: none;">
  <div class="container">
    <div class="row">
      <div class="col-xs-12">
        <div class="alert-content">
          <button type="button" class="close" aria-label="Close"><span aria-hidden="true">×</span></button>
        </div>
      </div>
    </div>
  </div>
</div>

<div class="container">
  <div class="row">
    <div class="col-xs-12">
      <main id="content" class="clearfix openbanner-visible legacy-styles"><div id="note_rkGqLoR5tX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>ODIN: Outlier Detection In Neural Networks</a> <a class="note_content_pdf" href="/pdf?id=rkGqLoR5tX" title="Download PDF" target="_blank"><img src="/static/images/pdf_icon_blue.svg" /></a> </h2></div><div class="meta_row"><span class="signatures">Anonymous</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">28 Sep 2018 (modified: 11 Oct 2018)</span><span class="item">ICLR 2019 Conference Blind Submission</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span><span class="item"><a class="action-bibtex-modal" data-bibtex="@inproceedings{    &#10;anonymous2019odin:,    &#10;title={ODIN: Outlier Detection In Neural Networks},    &#10;author={Anonymous},    &#10;booktitle={Submitted to International Conference on Learning Representations},    &#10;year={2019},    &#10;url={https://openreview.net/forum?id=rkGqLoR5tX},    &#10;note={under review}    &#10;}">Show Bibtex</a></span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Abstract: </span><span class="note_content_value">Adoption of deep learning in safety-critical systems raise the need for understanding what deep neural networks do not understand. Several methodologies to estimate model uncertainty have been proposed, but these methodologies constrain either how the neural network is trained or constructed. We present Outlier Detection In Neural networks (ODIN), an assumption-free method for detecting outlier observations during prediction, based on principles widely used in manufacturing process monitoring. By using a linear approximation of the hidden layer manifold, we add prediction-time outlier detection to models after training without altering architecture or training. We demonstrate that ODIN efficiently detect outliers during prediction on Fashion-MNIST, ImageNet-synsets and speech command recognition.</span></div><div class="note_contents"><span class="note_content_field">Keywords: </span><span class="note_content_value">Outlier Detection, Model Uncertainty, Safety</span></div><div class="note_contents"><span class="note_content_field">TL;DR: </span><span class="note_content_value">An add-on method for deep learning to detect outliers during prediction-time</span></div><div class="reply_row clearfix"><div class="item" id="reply_count">5 Replies</div></div></div><hr class="small" /><div id="note_children"><div class="note_with_children"><div id="note_ryl2MJBZ67" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>The paper studied interesting outlier detection algorithm but the novelty is limited</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=rkGqLoR5tX&amp;noteId=ryl2MJBZ67"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper199 AnonReviewer3</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">08 Nov 2018</span><span class="item">ICLR 2019 Conference Paper199 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">The paper studied interesting outlier detection algorithm but the novelty is limited.
This paper studies about the outlier detection under the neural network framework. However, it just applied the idea of partial least squares regression model on top of extracted features from the max-pooling layers of the CNN. The proposed approach is independent of any neural network or machine learning structure. The experiments are shown on fashion-mnist, cats and dogs and speech command recognition experiment using LSTM-model. This kind of direct application of the existing algorithm is not enough for publication in ICLR. </span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">5: Marginally below acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_ryeA6MXxTQ" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>ODIN: outlier detection in neural networks</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=rkGqLoR5tX&amp;noteId=ryeA6MXxTQ"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper199 AnonReviewer2</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">07 Nov 2018</span><span class="item">ICLR 2019 Conference Paper199 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">This paper studies how to better recognise classes that are found in the training set, and identify those that are not in the training set, using neural network methods. They call this as "outlier detection in neural networks".  I have several questions about this paper.

First, the definition of outlier is ambiguous. The classes that are not in the training set do not necessarily belong to outliers. In this respect, I felt the evaluations are problematic, as the unused data have been considered as outliers. The performance metrics used are therefore not entirely appropriate, as they are used to evaluate how good is the classifier. Even you define the unused data as outliers, such outliers cannot be directly considered as outliers in the network, a drift of the training model from the actual physical model should be quantified with different inputs to the system. 

Second, the actual contribution is the incorporation of equation (7) and (8) into the network layers, based on a linear approximation - something like applying PCA type of operation on the activations in different layers. There is no validation on the assumptions made, or any empirical study on the assumptions made about the "disentangle manifolds" and "approximately linear". 

Third, the paper lacks proofread and there are some typos and grammtical issues visual at several places, such as "systems raises", "that uses reconstruction residual", "multitide"  "see 3.1", "CNN:s", etc.

Fourth, in the experiments, the linear operation is applied to different layers and different networks, what's the reasoning behind this?

Some specific comments:
How t_new is obtained in equation (4)?</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">4: Ok but not good enough - rejection</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_Sylay4rY2X" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Applying existing outlier detection techniques to the more informative features output by the NN layers</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=rkGqLoR5tX&amp;noteId=Sylay4rY2X"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper199 AnonReviewer1</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">02 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper199 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">Summary
-------
The paper applies an existing outlier detection technique (PLS - Partial Least Squares) to intermediate layer(s) of neural networks.


Main Comments
-------------

1. The approach is similar to spectral anomaly detection where reconstruction error in lower dimensional space is used as the anomaly score. The higher layers of the neural network are good at identifying more informative features. Applying existing algorithms to these layers often improve algorithm accuracy. The proposed approach benefits from the same phenomena. The paper therefore lacks novelty.

1. Section 4: "...using MC-Dropout (Gal &amp; Ghahramani, 2016) since it is well-established and straightforward to implement even though it has received criticism (Osband et al., 2016)."

The benchmark methods are not state-of-the-art and were merely convenient to implement. Stronger benchmarks for anomaly detection techniques with images should be used. One traditional LOF variant relevant for comparison here is [1]. Other spectral techniques should also be considered.

2. Section 4.2: "...experiment, but both Mahalanobis distance and LOF fail to detect both cars and horses using 50 % R2"

The comparison and the observation with R2 50% does not convey anything beyond obvious since it is already known that a factor as low as 50% looses almost half the information (variance in data).

Comparison of all various R2 (50, 80, 90, 95, 99)% factors is not relevant. These results might be presented for sensitivity analysis. Either the R2 should be fixed to a constant value (like 80 or 90% which performs well consistently) or a single value should be selected by automatic means. Currently, the experiments merely give an illusion of being rigorous without actually being so.

3. The datasets and experiments are not sufficient. Std. errors are also not shown.

References:
[1] J. He, Y. Liu, and R. Lawrence. Graph-based Rare Category Detection. ICDM 2008 (<a href="http://faculty.engineering.asu.edu/jingruihe/wp-content/uploads/2015/06/GRCD.pdf)" target="_blank" rel="nofollow">http://faculty.engineering.asu.edu/jingruihe/wp-content/uploads/2015/06/GRCD.pdf)</a>
</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">4: Ok but not good enough - rejection</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_rklJ6IkyT7" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Response to AnonReviewer1</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=rkGqLoR5tX&amp;noteId=rklJ6IkyT7"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper199 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">06 Nov 2018</span><span class="item">ICLR 2019 Conference Paper199 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Thank you very much for reading our paper and providing feedback. Before revising the paper, we would like to make a few clarifications.

Firstly, we would like to clarify that we do not apply PLS in the paper. We are inspired by a property of PLS. PLS is a regression method that also carries a model of the input data. Using this model, it is possible to detect outliers after model fitting without modifications to the model. This is what we intend to provide for neural networks by modelling the intermediate layers. 

Comment 1. You are correct that our method builds on existing techniques. Our contribution is to use it as a proxy to predictive uncertainty without needing iterative Monte Carlo-sampling or restricting model architecture in a one-step distance measurement. Depending on the application, iterative sampling during prediction may be infeasible or modifying the model architecture to fit the constraints of prior art methods harm the predictive performance. We provide a way to add outlier detection, or uncertainty, to predictive neural networks in an add-on fashion that is independent of the underlying model. We intend to clarify the paper to emphasize this.

Regarding choosing MC-Dropout as benchmark, the motivation is poorly formulated by us and we apologize for the lack of clarity. What we mean is that due to its simplicity it is currently used in practice [1-4] and as benchmark in several of our cited prior art. We did not use it merely due to ease of implementation. MC-Dropout is also an example of an uncertainty method that requires iterative Monte-Carlo sampling, which our method does not. We intend to show that our method perform at least as well as the benchmark without the constraints associated with the benchmark. We will edit our paper to make our intents clear.

We thank for the proposed reference method but we do not think it falls into the scope of this paper under the current page limits.

Comment 2. We believe that there are a few misunderstandings in this comment and would like to clarify.

First we would like to note that information is not necessarily the same as variance in data, and that it depends on noise levels. We chose to include a low R2 to show that the information to noise ratio is high in later layers of neural networks, and we comment on this only very briefly in the experiments section. We only include it for completeness and could be omitted.

Secondly, The R2 level is the single most influential factor on the performance of our method, and experiment 1 and 2 are performed to establish a value that performs well consistently, not to give an illusion of being rigorous. In experiment 3, we build upon the findings in experiments 1 and 2 and demonstrate a case using a different type of network and other data source. 

Comment 3. We would appreciate if you specify in more detail how the datasets and experiments are not sufficient. The challenge of experiments regarding prediction time outlier detection is that it is not known beforehand what type of outliers may be encountered, and we attempt to simulate this using excluded classes from the same data domain. Regarding standard errors, since our method does not depend on Monte Carlo-sampling, the performance on a given dataset is deterministic. While it is possible to bootstrap the statistics to provide standard errors, we do not think this is relevant for the scope of this paper.

[1]. Lütjens, B., Everett, M., &amp; How, J. P. (2018). Safe Reinforcement Learning with Model Uncertainty Estimates. arXiv preprint arXiv:1810.08700.
[2]. Richard Webster, B., Anthony, S., &amp; Scheirer, W. (2018). Psyphy: a psychophysics driven evaluation framework for visual recognition. IEEE transactions on pattern analysis and machine intelligence.
[3]. Gibson, E., Giganti, F., Hu, Y., Bonmati, E., Bandula, S., Gurusamy, K., ... &amp; Barratt, D. C. (2018). Automatic multi-organ segmentation on abdominal CT with dense v-networks. IEEE Transactions on Medical Imaging.
[4]. Janet, J. P., &amp; Kulik, H. J. (2017). Predicting electronic structure properties of transition metal complexes with neural networks. Chemical Science, 8(7), 5137-5152.
</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div><div class="note_with_children"><div id="note_BJl5vCCeqm" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Unfortunate naming mistake</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=rkGqLoR5tX&amp;noteId=BJl5vCCeqm"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper199 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">02 Oct 2018</span><span class="item">ICLR 2019 Conference Paper199 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Dear readers and reviewers,

We have discovered that we made a mistake during our literature review, which unfortunately resulted in a naming conflict. At ICLR 2018, there was a paper published that introduced a method the authors named ODIN (<a href="https://openreview.net/forum?id=H1VGkIxRZ)." target="_blank" rel="nofollow">https://openreview.net/forum?id=H1VGkIxRZ).</a> The authors solve a similar problem to what we do in regards to image classification using a completely different methodology. So even though we unfortunately named our method the same, our submission is still original and propose a new method solving how to detect outliers during prediction.

We will correct this mistake once the review process is finished by finding a new name and including the above reference in the literature review.

Kind regards,
The authors</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></main></div>
  </div>
</div>


    <!-- Footer -->
    <footer class="sitemap">
      <div class="container">
        <div class="row hidden-xs">
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/venues">All Venues</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="/contact">Contact</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
    
        <div class="row visible-xs-block">
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/contact">Contact</a></li>
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
      </div>
    </footer>
    
    <footer class="sponsor">
      <div class="container">
        <div class="row">
          <div class="col-sm-10 col-sm-offset-1">
            <p class="text-center">
              OpenReview is created by the <a href="http://www.iesl.cs.umass.edu/" target="_blank">Information Extraction and Synthesis Laboratory</a>, College of Information and Computer Science, University of Massachusetts Amherst. We gratefully acknowledge the support of the OpenReview sponsors:  Google,  Facebook, NSF, the University of Massachusetts Amherst Center for Data Science, and Center for Intelligent Information Retrieval, as well as the Google Cloud Platform for donating the computing and networking services on which OpenReview.net runs.
            </p>
          </div>
        </div>
      </div>
    </footer>

  <div id="feedback-modal" class="modal fade" tabindex="-1" role="dialog">
    <div class="modal-dialog">
      <div class="modal-content">
        <div class="modal-header">
          <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button>
          <h3 class="modal-title">Send Feedback</h3>
        </div>
        <div class="modal-body">
          <p>Enter your feedback below and we'll get back to you as soon as possible.</p>
          <form action="/feedback" method="POST">
            <div class="form-group">
              <input type="email" name="from" class="form-control" placeholder="Email" />
            </div>
            <div class="form-group">
              <input type="text" name="subject" class="form-control" placeholder="Subject" />
            </div>
            <div class="form-group">
              <textarea name="message" class="form-control feedback-input" rows="5" placeholder="Message" required=""></textarea>
            </div>
          <ul id="ui-id-2" tabindex="0" class="ui-menu ui-widget ui-widget-content" style="display: none;"></ul></form>
        </div>
        <div class="modal-footer">
          <button type="button" class="btn btn-default" data-dismiss="modal">Cancel</button>
          <button type="button" class="btn btn-primary">Send</button>
        </div>
      </div>
    </div>
  </div>

  <script type="text/javascript" async="" src="https://www.google-analytics.com/analytics.js"></script><script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js"></script>
  <script>window.jQuery || document.write('&lt;script src="/static/js/vendor/jquery-2.2.4.min.js"&gt;&lt;\/script&gt;')</script>

  <script src="/static/dist/vendor.min.js"></script>
  <script src="/static/dist/templates.min.js"></script>
  <script src="/static/dist/openreview.min.js"></script>

    <script>window.legacyScripts = true;</script>


    <script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-108703919-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() { dataLayer.push(arguments); }
      gtag('js', new Date());
      gtag('config', 'UA-108703919-1');
    </script>


<div role="status" aria-live="assertive" aria-relevant="additions" class="ui-helper-hidden-accessible"></div></body></html>
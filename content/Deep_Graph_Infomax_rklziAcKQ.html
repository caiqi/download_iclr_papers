<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" class="no-js"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>Deep Graph Infomax | OpenReview</title>
  <meta name="description" content="" />

      <meta name="citation_title" content="Deep Graph Infomax" />
        <meta name="citation_author" content="Anonymous" />
      <meta name="citation_publication_date" content="2018/09/27" />
      <meta name="citation_online_date" content="2018/09/27" />
      <meta name="citation_pdf_url" content="https://openreview.net/pdf?id=rklz9iAcKQ" />
      <meta name="twitter:card" content="summary" />
      <meta name="twitter:site" content="@openreviewnet" />
      <meta name="og:title" content="Deep Graph Infomax" />
      <meta name="og:description" content="We present Deep Graph Infomax (DGI), a general approach for learning node representations within graph-structured data in an unsupervised manner. DGI relies on maximizing mutual information between..." />
      <meta name="og:image" content="https://openreview.net/static/images/openreview_logo_512.png" />

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans:400,400i,700,700i" />

  <link rel="stylesheet" href="/static/css/bootstrap.min.css" />
  <link rel="stylesheet" href="/static/css/jquery-ui.min.css" />
  <link rel="stylesheet" href="/static/css/main.min.css" />
</head>

<body class="forum">
  <nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
  
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand home push-link" href="/"><strong>OpenReview</strong>.net</a>
      </div>
  
      <div id="navbar" class="navbar-collapse collapse">
        <form class="navbar-form navbar-left profile-search" role="search">
          <div class="form-group has-feedback">
            <input id="search_input" type="text" class="form-control ui-autocomplete-input" placeholder="Search ICLR 2019 Conference" autocomplete="off" />
            <span class="glyphicon glyphicon-search form-control-feedback" aria-hidden="true"></span>
          </div>
  
          <input id="search_group" type="hidden" value="ICLR.cc/2019/Conference" />
          <input id="search_content" type="hidden" value="all" />
        <ul id="ui-id-1" tabindex="0" class="ui-menu ui-widget ui-widget-content ui-autocomplete ui-front" style="display: none;"></ul></form>
  
        <ul class="nav navbar-nav navbar-right">
        
            <li id="user-menu"><a href="/login">Login</a></li>
        </ul>
      </div>
  
    </div>
  </nav>

  <div id="or-banner" class="banner" style="">
  <div class="container">
    <div class="row">
      <div class="col-xs-12"><a href="/group?id=ICLR.cc/2019/Conference" title="Venue Homepage"><img class="icon" src="/static/images/arrow_left.svg" /> Go to <strong>ICLR 2019 Conference</strong> homepage</a></div>
    </div>
  </div>
</div>
<div id="flash-message-container" class="alert alert-danger" role="alert" style="display: none;">
  <div class="container">
    <div class="row">
      <div class="col-xs-12">
        <div class="alert-content">
          <button type="button" class="close" aria-label="Close"><span aria-hidden="true">Ã—</span></button>
        </div>
      </div>
    </div>
  </div>
</div>

<div class="container">
  <div class="row">
    <div class="col-xs-12">
      <main id="content" class="clearfix openbanner-visible legacy-styles"><div id="note_rklz9iAcKQ" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Deep Graph Infomax</a> <a class="note_content_pdf" href="/pdf?id=rklz9iAcKQ" title="Download PDF" target="_blank"><img src="/static/images/pdf_icon_blue.svg" /></a> </h2></div><div class="meta_row"><span class="signatures">Anonymous</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">28 Sep 2018 (modified: 11 Oct 2018)</span><span class="item">ICLR 2019 Conference Blind Submission</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span><span class="item"><a class="action-bibtex-modal" data-bibtex="@inproceedings{    &#10;anonymous2019deep,    &#10;title={Deep Graph Infomax},    &#10;author={Anonymous},    &#10;booktitle={Submitted to International Conference on Learning Representations},    &#10;year={2019},    &#10;url={https://openreview.net/forum?id=rklz9iAcKQ},    &#10;note={under review}    &#10;}">Show Bibtex</a></span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Abstract: </span><span class="note_content_value">We present Deep Graph Infomax (DGI), a general approach for learning node representations within graph-structured data in an unsupervised manner. DGI relies on maximizing mutual information between patch representations and corresponding high-level summaries of graphs---both derived using established graph convolutional network architectures. The learnt patch representations summarize subgraphs centered around nodes of interest, and can thus be reused for downstream node-wise learning tasks. In contrast to most prior approaches to graph representation learning, DGI does not rely on random walks, and is readily applicable to both transductive and inductive learning setups. We demonstrate competitive performance on a variety of node classification benchmarks, which at times even exceeds the performance of supervised learning.</span></div><div class="note_contents"><span class="note_content_field">Keywords: </span><span class="note_content_value">Unsupervised Learning, Graph Neural Networks, Graph Convolutions, Mutual Information, Infomax, Deep Learning</span></div><div class="note_contents"><span class="note_content_field">TL;DR: </span><span class="note_content_value">A new method for unsupervised representation learning on graphs, relying on maximizing mutual information between local and global representations in a graph. State-of-the-art results, competitive with supervised learning.</span></div><div class="reply_row clearfix"><div class="item" id="reply_count">8 Replies</div></div></div><hr class="small" /><div id="note_children"><div class="note_with_children"><div id="note_BygK5QSXp7" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Authors should quote more recent results for PPI dataset</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=rklz9iAcKQ&amp;noteId=BygK5QSXp7"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">(anonymous)</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">10 Nov 2018</span><span class="item">ICLR 2019 Conference Paper513 Public Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">It has already been noted that GraphSAGE models can achieve superior results (20-30% improvement) with a different hyperparameter setting on PPI than what was reported in the original paper. It is even mentioned in the Arxiv version of GraphSAGE. It is unfair to report such low scores and I also encourage the authors to update DGI's hyperparam setting correspondingly and report newer numbers.</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_B1eoGoSQpX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>More recent results for PPI are reported</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=rklz9iAcKQ&amp;noteId=B1eoGoSQpX"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper513 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">10 Nov 2018</span><span class="item">ICLR 2019 Conference Paper513 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Hello,

Thank you for your comment!

All reported improvements in PPI results concern solely the fully supervised setup; not the unsupervised one. And, indeed, this is the supervised result we report---namely, the avg. pooling architecture from the GaAN paper (Zhang et al., UAI 2018), which we report, is one example of a supervised result that substantially (30+%) improves on the supervised result reported in the original GraphSAGE paper (of 0.612).</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div><div class="note_with_children"><div id="note_Skei4zS7a7" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Needs more explanation on how this is different from Embedding Propagation work</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=rklz9iAcKQ&amp;noteId=Skei4zS7a7"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">(anonymous)</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">10 Nov 2018</span><span class="item">ICLR 2019 Conference Paper513 Public Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">The work has similarity to Embedding Propagation (Duran et al, NIPS 2017) work, where the node's embedding is made similar to averaged 1-hop neighbors. DGI seems to have extended this idea into a framework. Where the neighbor's summary obtained with an averaging function is abstracted and called as readout function. The embeddings/feature (projection) has been now obtained with a GCN encoder. 

Though, there is a mention of this work. I feel enough justice to the earlier work has not been given.</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_HkgHlf-qnX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Solid work, will have high impact</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=rklz9iAcKQ&amp;noteId=HkgHlf-qnX"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper513 AnonReviewer3</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">03 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper513 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">This paper describes an approach for unsupervised learning of node features on a graph (with known structure), so that learned local representations represent community information that has high mutual info with a graph-level summary. The general idea is they apply InfoMax to graphs via graph convolutional networks (GCN), and report impressive results, including rivaling supervised learning methods for node classification. The 3 experiments are on paper topic classification, social network modeling, and protein classification.

The idea of using InfoMax with GCNs for unsupervised node learning is clever and timely, the technical contribution is solid, the experiments are executed well, and the paper is clear and easy to read.</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">9: Top 15% of accepted papers, strong accept</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_SygCVOYun7" class="note panel trashed"><div class="title_pdf_row clearfix"><h2 class="note_content_title">  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=rklz9iAcKQ&amp;noteId=SygCVOYun7"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">[Deleted]</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="item">ICLR 2019 Conference Paper513 Public Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_B1lVxghvnm" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Idea is interesting; realization is graph-specific</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=rklz9iAcKQ&amp;noteId=B1lVxghvnm"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper513 AnonReviewer1</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">01 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper513 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">This paper proposes an unsupervised approach to learning node representations. The basic steps are: (1) use an encoder E to learn node vectors, (2) use a readout function R to summarize node vectors into the graph vector, (3) use a scoring function D to score how much the node vectors are aligned with the graph vector, and (4) maximize the scores for the given graph meanwhile minimize the those from the negative distribution.

I feel that the idea is interesting; however, the paper is less well written and the realization of the idea has drawbacks as well.

1. Presentation of Section 3.2 can be improved. The proposed approach becomes clear only toward the end.

2. Naming and wording is misleading. The title and the whole paper use the wording "mutual information", whereas in reality, the loss function is a cross entropy.

3. In equation (1), it is unclear why the authors take expectation with respect to the distribution of graphs before summing the scores for one particular graph. Should the order of the expectation and summation be swapped?

4. The proposal is more like a framework than a specific method. The encoder and the negative distribution need to be separately designed for different graphs.

Good things about the proposal:

5. The downstream classification results are quite comparable to those of supervised methods (except for the PPI data).

6. The learned node representations possess a clear clustering structure (Figure 3).

Minor comments:

7. In the third paragraph of section 4.3, the authors state that "... for the GCN model in the fully supervised setting". GCN should be a semi-supervised method rather than a fully-supervised one.

8. In the last paragraph of section 4.3, what is a "randomly initialized graph convolutional network" and how is it different from the proposal?
</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">5: Marginally below acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_BkeOgwpm37" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Alternative information-theoretic objective for unsupervised graph representation learning</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=rklz9iAcKQ&amp;noteId=BkeOgwpm37"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper513 AnonReviewer2</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">29 Oct 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper513 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">This paper adapts the Deep Informax (DIM; Hjelm et al. 2018) method, which was used on
image data, into the graph domain. The architecture of the neural network and
the learning cost function are given by figure 1 and eq.(1), respectively.

The idea is to maximize the mutual information between a local representation
(of a "patch" defined by graph adjacency) and a global representation (of the entire graph),
so those different local patches are encouraged to carry some shared
global information.

This is in contrast to most unsupervised graph encoders, where the objective is
to fit the random walk similarities (node adjacency on the graph).

In an unsupervised learning scenario, where the graph structure and node features
are given, the authors achieved state-of-the-art performance on transductive and
inductive node classification tasks, in some cases even better than supervised baselines. 

The paper is well written. I recommend acceptance and have the following concerns.

Main comment 1

The title suggests that there are some information theory contents. 
However, section 3 does not include much information theory.
Rather, the author(s) directly give eq.(1) with pointers to references and informal discussions.
This is not so helpful. It is not straightforward for
the reader to relate eq.(1) with the definition of mutual information.
Ideally, before eq.(1) there should be one or two equations (with text)
to introduce the Jesen-Shannon MI estimation and information theoretic bounds etc.

Overall, due to this, the contribution is mainly on adapting the DIM method info the graph domain. Although the experimental results are good, there is not much theoretical insight or "recreative" introduction of the DIM method from the authors' perspectives. This is the main reason for that it is not a strong accept.

Main comment 2

A motivation of the proposition is to "not rely on random walks", or graph node adjacency.
Notice that random walks can be intuitively regarded as higher order node adjacency.
However, the encoder, which is based on GCN, does rely on the adjacency matrix,
as the convolution is done in local neighborhoods (that can also be defined based on
random-walk similarities). The authors are therefore suggested to make it
clear in related places that, it is the cost function which is not based
on node adjacency, although the neural network structure does rely on it.

As a related question, in the inductive experiments, in the mini-batch of 256 nodes
randomly selected, or selected by a local patch of the graph which is connected or nearby?
If it is the latter case, the cost function does rely on random-walk similarities,
as the summary vector will be a local patch average.

Questions:

-The summary vector is the average of all node features. On large graphs, the
average may carry less information as compared to small graphs. It can be
observed that on Pubmed and Reddit, the performance improvement is not as
high as the other small graphs. Could you comment on this?

-In the baseline "DeepWalk+features", are the two different types of features directly concatenated?

-Is it straightforward to apply DGI to link prediction tasks?

-It that a concern that the random corruption function will cause a high variance of the gradient?
</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">7: Good paper, accept</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">3: The reviewer is fairly confident that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_rJl0fT6itQ" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>The experiments about transductive learning are incomplete</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=rklz9iAcKQ&amp;noteId=rJl0fT6itQ"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures"><a href="/profile?id=~Ming_Ding1" class="profile-link">Ming Ding</a></span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">28 Sep 2018 (modified: 17 Oct 2018)</span><span class="item">ICLR 2019 Conference Paper513 Public Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">I think the idea is very interesting. But in the experiments under transductive semi-supervised learning setting, some methods with better performance are missed, for example GAT(Velickovic et al., 2018) and even our GraphSGAN(Ding et al., 2018). I know that this method is actually inductive but you should at least cite and list above results.</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_SkxB37p2t7" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Provided results</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=rklz9iAcKQ&amp;noteId=SkxB37p2t7"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper513 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">29 Sep 2018 (modified: 19 Oct 2018)</span><span class="item">ICLR 2019 Conference Paper513 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Hi Ming,

Thanks for your comment and kind feedback!

DGI performs unsupervised learning, so comparisons with supervised methods are inappropriate---the supervised methods we did include were the ones that used similar propagation rules as our encoders. In the transductive case, this was the GCN---as it uses an identical propagation rule (with one extra layer).

We'll cite GraphSGAN as an indicator of the current supervised state-of-the-art in an updated version of the paper -- thanks!</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div></div></main></div>
  </div>
</div>


    <!-- Footer -->
    <footer class="sitemap">
      <div class="container">
        <div class="row hidden-xs">
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/venues">All Venues</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="/contact">Contact</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
    
        <div class="row visible-xs-block">
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/contact">Contact</a></li>
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
      </div>
    </footer>
    
    <footer class="sponsor">
      <div class="container">
        <div class="row">
          <div class="col-sm-10 col-sm-offset-1">
            <p class="text-center">
              OpenReview is created by the <a href="http://www.iesl.cs.umass.edu/" target="_blank">Information Extraction and Synthesis Laboratory</a>, College of Information and Computer Science, University of Massachusetts Amherst. We gratefully acknowledge the support of the OpenReview sponsors:  Google,  Facebook, NSF, the University of Massachusetts Amherst Center for Data Science, and Center for Intelligent Information Retrieval, as well as the Google Cloud Platform for donating the computing and networking services on which OpenReview.net runs.
            </p>
          </div>
        </div>
      </div>
    </footer>

  <div id="feedback-modal" class="modal fade" tabindex="-1" role="dialog">
    <div class="modal-dialog">
      <div class="modal-content">
        <div class="modal-header">
          <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">Ã—</span></button>
          <h3 class="modal-title">Send Feedback</h3>
        </div>
        <div class="modal-body">
          <p>Enter your feedback below and we'll get back to you as soon as possible.</p>
          <form action="/feedback" method="POST">
            <div class="form-group">
              <input type="email" name="from" class="form-control" placeholder="Email" />
            </div>
            <div class="form-group">
              <input type="text" name="subject" class="form-control" placeholder="Subject" />
            </div>
            <div class="form-group">
              <textarea name="message" class="form-control feedback-input" rows="5" placeholder="Message" required=""></textarea>
            </div>
          <ul id="ui-id-2" tabindex="0" class="ui-menu ui-widget ui-widget-content" style="display: none;"></ul></form>
        </div>
        <div class="modal-footer">
          <button type="button" class="btn btn-default" data-dismiss="modal">Cancel</button>
          <button type="button" class="btn btn-primary">Send</button>
        </div>
      </div>
    </div>
  </div>

  <script type="text/javascript" async="" src="https://www.google-analytics.com/analytics.js"></script><script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js"></script>
  <script>window.jQuery || document.write('&lt;script src="/static/js/vendor/jquery-2.2.4.min.js"&gt;&lt;\/script&gt;')</script>

  <script src="/static/dist/vendor.min.js"></script>
  <script src="/static/dist/templates.min.js"></script>
  <script src="/static/dist/openreview.min.js"></script>

    <script>window.legacyScripts = true;</script>


    <script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-108703919-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() { dataLayer.push(arguments); }
      gtag('js', new Date());
      gtag('config', 'UA-108703919-1');
    </script>


<div role="status" aria-live="assertive" aria-relevant="additions" class="ui-helper-hidden-accessible"></div></body></html>
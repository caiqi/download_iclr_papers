<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" class="no-js"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>Probabilistic Federated Neural Matching | OpenReview</title>
  <meta name="description" content="" />

      <meta name="citation_title" content="Probabilistic Federated Neural Matching" />
        <meta name="citation_author" content="Anonymous" />
      <meta name="citation_publication_date" content="2018/09/27" />
      <meta name="citation_online_date" content="2018/09/27" />
      <meta name="citation_pdf_url" content="https://openreview.net/pdf?id=SygHGnRqK7" />
      <meta name="twitter:card" content="summary" />
      <meta name="twitter:site" content="@openreviewnet" />
      <meta name="og:title" content="Probabilistic Federated Neural Matching" />
      <meta name="og:description" content="In federated learning problems, data is scattered across different servers and exchanging or pooling it is often impractical or prohibited. We develop a Bayesian nonparametric framework for..." />
      <meta name="og:image" content="https://openreview.net/static/images/openreview_logo_512.png" />

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans:400,400i,700,700i" />

  <link rel="stylesheet" href="/static/css/bootstrap.min.css" />
  <link rel="stylesheet" href="/static/css/jquery-ui.min.css" />
  <link rel="stylesheet" href="/static/css/main.min.css" />
</head>

<body class="forum">
  <nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
  
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand home push-link" href="/"><strong>OpenReview</strong>.net</a>
      </div>
  
      <div id="navbar" class="navbar-collapse collapse">
        <form class="navbar-form navbar-left profile-search" role="search">
          <div class="form-group has-feedback">
            <input id="search_input" type="text" class="form-control ui-autocomplete-input" placeholder="Search ICLR 2019 Conference" autocomplete="off" />
            <span class="glyphicon glyphicon-search form-control-feedback" aria-hidden="true"></span>
          </div>
  
          <input id="search_group" type="hidden" value="ICLR.cc/2019/Conference" />
          <input id="search_content" type="hidden" value="all" />
        <ul id="ui-id-1" tabindex="0" class="ui-menu ui-widget ui-widget-content ui-autocomplete ui-front" style="display: none;"></ul></form>
  
        <ul class="nav navbar-nav navbar-right">
        
            <li id="user-menu"><a href="/login">Login</a></li>
        </ul>
      </div>
  
    </div>
  </nav>

  <div id="or-banner" class="banner" style="">
  <div class="container">
    <div class="row">
      <div class="col-xs-12"><a href="/group?id=ICLR.cc/2019/Conference" title="Venue Homepage"><img class="icon" src="/static/images/arrow_left.svg" /> Go to <strong>ICLR 2019 Conference</strong> homepage</a></div>
    </div>
  </div>
</div>
<div id="flash-message-container" class="alert alert-danger" role="alert" style="display: none;">
  <div class="container">
    <div class="row">
      <div class="col-xs-12">
        <div class="alert-content">
          <button type="button" class="close" aria-label="Close"><span aria-hidden="true">×</span></button>
        </div>
      </div>
    </div>
  </div>
</div>

<div class="container">
  <div class="row">
    <div class="col-xs-12">
      <main id="content" class="clearfix openbanner-visible legacy-styles"><div id="note_SygHGnRqK7" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Probabilistic Federated Neural Matching</a> <a class="note_content_pdf" href="/pdf?id=SygHGnRqK7" title="Download PDF" target="_blank"><img src="/static/images/pdf_icon_blue.svg" /></a> </h2></div><div class="meta_row"><span class="signatures">Anonymous</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">28 Sep 2018 (modified: 14 Nov 2018)</span><span class="item">ICLR 2019 Conference Blind Submission</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span><span class="item"><a class="action-bibtex-modal" data-bibtex="@inproceedings{    &#10;anonymous2019probabilistic,    &#10;title={Probabilistic Federated Neural Matching},    &#10;author={Anonymous},    &#10;booktitle={Submitted to International Conference on Learning Representations},    &#10;year={2019},    &#10;url={https://openreview.net/forum?id=SygHGnRqK7},    &#10;note={under review}    &#10;}">Show Bibtex</a></span><a class="note_content_pdf item" href="/revisions?id=SygHGnRqK7" target="_blank">Show Revisions</a></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Abstract: </span><span class="note_content_value">In federated learning problems, data is scattered across different servers and exchanging or pooling it is often impractical or prohibited. We develop a Bayesian nonparametric framework for federated learning with neural networks. Each data server is assumed to train local neural network weights, which are modeled through our framework. We then develop an inference approach that allows us to synthesize a more expressive global network without additional supervision or data pooling. We then demonstrate the efficacy of our approach on federated learning problems simulated from two popular image classification datasets.</span></div><div class="note_contents"><span class="note_content_field">Keywords: </span><span class="note_content_value">Bayesian nonparametrics, Indian Buffet Process, Federated Learning</span></div><div class="note_contents"><span class="note_content_field">TL;DR: </span><span class="note_content_value">We propose a Bayesian nonparametric model for federated learning with neural networks.</span></div><div class="reply_row clearfix"><div class="item" id="reply_count">7 Replies</div></div></div><hr class="small" /><div id="note_children"><div class="note_with_children"><div id="note_B1lO8WT_p7" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Rebuttal</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=SygHGnRqK7&amp;noteId=B1lO8WT_p7"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1262 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">14 Nov 2018</span><span class="item">ICLR 2019 Conference Paper1262 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">We thank the reviewers for their feedback. We've uploaded the revised draft to resolve reviewers' concerns. Individual responses follow below.</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_B1x1LTanhQ" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Unclear advantage</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=SygHGnRqK7&amp;noteId=B1x1LTanhQ"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1262 AnonReviewer1</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">05 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper1262 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">The paper uses the beta process to do federated neural matching. The brief experimental results show worse performance than the other techniques compared with. Also, the motivation for the hierarchical beta process isn't clear, since each group has a single Bernoulli process. This makes learning each second level beta process a meaningless task. Why not have a single beta-Bernoulli process?</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">4: Ok but not good enough - rejection</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">3: The reviewer is fairly confident that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_rJgwugpdaQ" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Authors response</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=SygHGnRqK7&amp;noteId=rJgwugpdaQ"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1262 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">14 Nov 2018</span><span class="item">ICLR 2019 Conference Paper1262 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">We thank the reviewer for the feedback and provide answers to the raised concerns below.

Regarding experiments: In our experiments each of the baselines is violating at least one of the constraints of the federated learning problem we are studying, i.e. single round of communication, no access to data after training local models and compressed global model. All baselines considered have a significant advantage by violating some of those conditions. Therefore the goal of the experiments was to show that we can achieve comparable performance with our method (PFNM) while adhering to all constraints, not to outperform the baselines. Indeed outperforming an ensemble by performing model averaging in the space of weights is extremely challenging, especially for many batches with fewer data points. We have added an additional experiment to compare with baselines satisfying all of the problem constraints. This experiment (Fig. 2) shows that PFNM outperforms all "fair" baselines by a good margin.

Regarding Hierarchical Beta Process (HBP): We do not learn parameters of the second level Beta processes (except in the streaming case). Instead, those are integrated out and do not have any negative effect on the learning. We agree that it is possible to consider one global Beta process and a Bernoulli process per batch, however the group structure introduced by the second level Beta processes is important for the streaming case to infer heterogeneity of global atoms distributions across groups (Section 3.3; see Fig. 3b in Supplement for experimental evaluation of streaming case).</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div><div class="note_with_children"><div id="note_SJekcov5nQ" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>An interesting idea, but slightly contrived and lacking empirical support</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=SygHGnRqK7&amp;noteId=SJekcov5nQ"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1262 AnonReviewer2</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">03 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper1262 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">The paper develops a novel solution for federated learning under three constraints, i.e. no data pooling (which distillation violates), infrequent communication (which iterative distributed learning violates), and modest-sized global model (which ensemble model violates). This is acknowledgedly a kind of unique setting, and the proposed solution does fit it well.

However, I have the following two main concerns
1. The major attack on distillation from an ensemble is that it needs to pool data across all sources which has cost and privacy concerns. However I'm not entirely convinced this "data pooling" is really necessary. One could argue distillation might as well be performed with simply an extra dataset that could be collected (sampled) elsewhere.
Plus, even though the proposed solution doesn't need to do "data pooling", it is effectively doing "model pooling" which may has its own costs and issues, e.g. the assumptions that one has access to all the parameters of the local models, and that all those local models should more or less be homogeneous to allow such pooling to happen, might not hold.

2. The idea of applying Beta-Bernoulli Process to uncover the underlying global model from a pool of local models is interesting. But I would very much like to see comparisons to some other simpler baselines, e.g. using dictionary learning to extract the common set of basis shared among the local models, or perhaps the slightly fancier DP-means (Kulis &amp; Jordan, 2012)? Especially the lack of a meaningful improvement over the compared baselines from the empirical studies makes me wonder whether the BBP is indeed fit for purpose or even necessary for this task.

Some other questions/comments,
1. I'd be interested to see what the authors think about the connection between their proposed PFNM to Hinton's dropout, which could also be interpreted as performing an implicit "model pooling" over an ensemble of local models sharing weights among each other.

2. After introducing the notation for "-j", I'd suggest not to abuse "j" to keep denoting (dummy) indices in summations (e.g. Eq.(7), (8), etc.) - I might prefer swapping it with e.g. "j'" in $B^{j'}_{i,l}$, $v_{j'l}$ and $\sigma^2_{j'}$ to avoid confusions.

3. When the number of batches J gets larger, which means a smaller batch size and therefore also a larger variance among the local models, would it be beneficial to also increase the noise variances $\sigma_j$ accordingly to allow a better fit?</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">6: Marginally above acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_rJgnheTOaX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Authors response</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=SygHGnRqK7&amp;noteId=rJgnheTOaX"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1262 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">14 Nov 2018</span><span class="item">ICLR 2019 Conference Paper1262 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">We thank the reviewer for their time and interesting suggestions. We have added additional experiments to the draft (first paragraph of Section 4) to help address the concerns and we provide additional comments below.

Regarding distillation from an ensemble and DP-means: We think that our method can be considered complementary to knowledge distillation when it is possible to obtain some amount of additional data. In particular, to train a distillation network, one would need to decide on the number of hidden neurons and the weight initialization for this network. Since local networks' weights are available, it is desirable to reuse them. However, a naive strategy of model averaging in the parameter space does not work well. McMahan et al. (2017) (see Figure 1 of their paper) empirically observed that sharing initialization across neural networks improves the performance of naive averaging of weights. DP-means, as you suggested, could be another option. It is also possible to simply pick one of the local models at random for initialization. In the added experiment (Fig. 2), we show that our PFNM method provides the best model pooling solution among all of these alternatives. These alternative methods are the more appropriate baselines for our method. In our previous experiments all `baselines' had some kind of intrinsic advantage over our setting and our goal was to achieve comparable performance, rather than outperform them. For example, improving upon an ensemble by pooling models in the parameter space seems very challenging, if at all possible, especially in the large number of batches and small batch size regime.

Regarding dropout: The important difference between our setting and dropout (when viewed as model pooling) is that we aggregate networks trained independently, while dropout may be viewed as implicitly aggregating networks trained sequentially, i.e. each new network is initialized from a previous one. The permutation invariance phenomenon motivating PFNM implies that a neural network with L hidden neurons has at least $L!$ equivalent permuted neural networks that are equivalent local optima. When neural networks are trained independently, it is possible that they converge to similar, up to a permutation, solutions. That is one of the reasons naive averaging of weights (since it ignores permutations) performs poorly and matching based model pooling is more appropriate. The dropout case is the opposite of this, since when trained sequentially, it seems much less likely that a neural network will jump from one permutation invariant local optima to another, making naive averaging of weights obtained throughout training with dropout work well.

Regarding choice of $\sigma_j$ for smaller batch sizes: Currently we set $\sigma_j$ to be same for all $j$. In Section 4.3, Fig. 4 and 5 of the Supplementary material we present some sensitivity analysis. Empirically $\sigma_j$ does not have much effect when partition is homogeneous and causes minor fluctuations in performance for heterogeneous cases. From the modeling perspective, higher $\sigma_j$ implies smaller global model size since local neurons assume higher variation and become "more willing" to be matched to existing global neurons.

Thank you for the suggestions regarding notations - we will revise the manuscript accordingly.

Reference: Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and Blaise Aguera y Arcas.
Communication-efficient learning of deep networks from decentralized data. In Artificial Intelligence and Statistics, pp. 1273–1282, 2017.</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div><div class="note_with_children"><div id="note_S1lgPnb_n7" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>interesting way to combine neural networks trained locally on federated data using a Beta-Bernoulli process</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=SygHGnRqK7&amp;noteId=S1lgPnb_n7"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1262 AnonReviewer3</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">01 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper1262 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">Summary: The paper considers federate learning of neural networks, i.e. data are distributed on multiple machines and the allocation of data points is potentially inhomogenous and unbalanced. The paper proposes a method to combine multiple networks trained locally on different data shards and form a global neural network. The key idea is to identify and reuse neurons that can be used for all shards and add new neurons to the global network if necessary. The matching and combination process is done via MAP inference of a model using a Beta-Bernoulli process. Some experiments on federated learning demonstrate the performance of the proposed method.

General evaluation (+ pro/ - con, more specific comments/questions below):
+ the paper is very well-written -- the BBP presentation is light but very accessible. The experimental set up seems sound.
+ the matching procedure is novel for federated training of neural networks, as far as I know, but might not be if you are a Bayesian nonparametric person, as the paper pointed out similar techniques have been used for topic models.
- the results seem to back up the claim that the proposed is a good candidate for combining networks at the end of training, but the performance is very similar or inferior to naive combination methods and that the global network is way larger than individual local network and nearly as large as simply aggregating all neurons together.
- the comparison to recent federated learning methods is lacking (e.g. McMahan et al, 2017) (perhaps less communication efficient than the proposed method, but more accurate).

Specific comments/questions/suggestions:
- the MAP update for the weights given the assignment matrix is interesting and resembles exactly how the Bayesian committee machine algorithm of Tresp (2000) works, except that the variances are not learnt for each parameter but fixed for each neuron. On this, there are several hyperparameters for the model, e.g. variance sigma_j -- how are these tuned/selected?
- the local neural networks are very mall (only 50 neurons per layer). How do they perform on the test set on the homogeneous case? Is there a performance loss by combining these networks together?
- the compression rate is not that fantastic, i.e. the global network tends to add new neuron for each local neuron considered. Is this because it is in general very hard to identify similar neuron and group them together? In the homogeneous case, surely there are some neurons that might be similar. Or is it because of the MAP inference procedure/local optima?</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">6: Marginally above acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_HJx1mbpd67" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Authors response</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=SygHGnRqK7&amp;noteId=HJx1mbpd67"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1262 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">14 Nov 2018</span><span class="item">ICLR 2019 Conference Paper1262 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">We thank the reviewer for their time and interesting suggestions. We have added additional experiments to the draft (first paragraph of Section 4) to help address your concerns and we provide additional comments below.

To address concerns regarding performance, compression rates, comparison to McMahan et al. (2017), and local neural networks we conducted an additional experiment (please see first paragraph of Section 4 and Fig. 2). In our previous experiments all `baselines' had some kind of intrinsic advantage over our setting and our goal was to achieve comparable performance, rather than outperform them. For example, improving upon an ensemble by averaging models in the parameter space seems very challenging -- if possible at all -- especially for higher number of batches and smaller batch sizes. A more fair comparison would be against approaches fully compatible with the federated learning problem studied in this work. 

In particular, we concur that the baselines you suggested are well suited as "fair" baselines, i.e. the performance of local neural networks and Federated Averaging of McMahan et al. (2017) with a single communication. McMahan et al. (2017)  (Figure 1 in their paper) empirically observed that sharing initialization across neural networks improves the performance of naive averaging of weights and used this idea to propose Federate Averaging. To implement Federated Averaging we shared initialization across batches and trained local neural networks with one hidden layer and 300 neurons for 10 epochs and then performed weighted averaging to obtain the global model. In Fig. 2 (main text) we see that even with shared initialization averaging of weights does not perform well for higher number of batches and/or heterogeneous data partitioning. In this experiment, for PFNM we trained local neural networks with 100 neurons each (and no constraints on how they were initialized). We considered two values of $\gamma_0$, one that results in larger model but better performance and a degenerate one resulting in the model of the size of the local net, but sacrificing performance quality. PFNM with $\gamma_0=1$ (truncated at 700 neurons; other hyperparameters were fixed to $\sigma^2_0=10$ and $\sigma^2_j=1$ for each j) consistently outperforms all baselines. In this experiment compression is relatively significant, i.e. when J=100, max size is 10000, whereas PFNM used around 500 neurons in the global model.

We also note that when it is permissible to do multiple communication rounds to improve the performance, PFNM may serve as good initialization (setting $\gamma_0$ very small to enforce global model to be of the same size as local models) to Federated Averaging without the need to share common initialization across local neural networks.

Regarding hyperparameters: when comparing to baselines satisfying the constraints (Fig. 2) we set $\sigma_j=1$ for every j and $\sigma^2_0=10$ across all experiments for fair comparison. When comparing to baselines with extra resources (Fig. 3) we set $\sigma^2_0=10$ and value of $\sigma_j$ was shared across $j$ and selected based on the train data performance. Please see section "Parameter sensitivity analysis for PFNM" in the Supplementary (Section 4.3, Fig. 4 and Fig. 5) for more details. In summary, we observed that $\sigma_j$ does not have much effect when partition is homogeneous and causes minor fluctuations in performance for heterogeneous cases.</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div></div></main></div>
  </div>
</div>


    <!-- Footer -->
    <footer class="sitemap">
      <div class="container">
        <div class="row hidden-xs">
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/venues">All Venues</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="/contact">Contact</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
    
        <div class="row visible-xs-block">
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/contact">Contact</a></li>
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
      </div>
    </footer>
    
    <footer class="sponsor">
      <div class="container">
        <div class="row">
          <div class="col-sm-10 col-sm-offset-1">
            <p class="text-center">
              OpenReview is created by the <a href="http://www.iesl.cs.umass.edu/" target="_blank">Information Extraction and Synthesis Laboratory</a>, College of Information and Computer Science, University of Massachusetts Amherst. We gratefully acknowledge the support of the OpenReview sponsors:  Google,  Facebook, NSF, the University of Massachusetts Amherst Center for Data Science, and Center for Intelligent Information Retrieval, as well as the Google Cloud Platform for donating the computing and networking services on which OpenReview.net runs.
            </p>
          </div>
        </div>
      </div>
    </footer>

  <div id="feedback-modal" class="modal fade" tabindex="-1" role="dialog">
    <div class="modal-dialog">
      <div class="modal-content">
        <div class="modal-header">
          <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button>
          <h3 class="modal-title">Send Feedback</h3>
        </div>
        <div class="modal-body">
          <p>Enter your feedback below and we'll get back to you as soon as possible.</p>
          <form action="/feedback" method="POST">
            <div class="form-group">
              <input type="email" name="from" class="form-control" placeholder="Email" />
            </div>
            <div class="form-group">
              <input type="text" name="subject" class="form-control" placeholder="Subject" />
            </div>
            <div class="form-group">
              <textarea name="message" class="form-control feedback-input" rows="5" placeholder="Message" required=""></textarea>
            </div>
          <ul id="ui-id-2" tabindex="0" class="ui-menu ui-widget ui-widget-content" style="display: none;"></ul></form>
        </div>
        <div class="modal-footer">
          <button type="button" class="btn btn-default" data-dismiss="modal">Cancel</button>
          <button type="button" class="btn btn-primary">Send</button>
        </div>
      </div>
    </div>
  </div>

  <script type="text/javascript" async="" src="https://www.google-analytics.com/analytics.js"></script><script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js"></script>
  <script>window.jQuery || document.write('&lt;script src="/static/js/vendor/jquery-2.2.4.min.js"&gt;&lt;\/script&gt;')</script>

  <script src="/static/dist/vendor.min.js"></script>
  <script src="/static/dist/templates.min.js"></script>
  <script src="/static/dist/openreview.min.js"></script>

    <script>window.legacyScripts = true;</script>


    <script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-108703919-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() { dataLayer.push(arguments); }
      gtag('js', new Date());
      gtag('config', 'UA-108703919-1');
    </script>


<div role="status" aria-live="assertive" aria-relevant="additions" class="ui-helper-hidden-accessible"></div></body></html>
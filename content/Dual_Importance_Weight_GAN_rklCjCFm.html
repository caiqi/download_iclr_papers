<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" class="no-js"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>Dual Importance Weight GAN | OpenReview</title>
  <meta name="description" content="" />

      <meta name="citation_title" content="Dual Importance Weight GAN" />
        <meta name="citation_author" content="Anonymous" />
      <meta name="citation_publication_date" content="2018/09/27" />
      <meta name="citation_online_date" content="2018/09/27" />
      <meta name="citation_pdf_url" content="https://openreview.net/pdf?id=rkl5CjC9Fm" />
      <meta name="twitter:card" content="summary" />
      <meta name="twitter:site" content="@openreviewnet" />
      <meta name="og:title" content="Dual Importance Weight GAN" />
      <meta name="og:description" content="Generative Adversarial Networks (GAN) are trained to generate a sample image of interest. To this end, generative network of GAN learns implicit distribution of true dataset from the classification..." />
      <meta name="og:image" content="https://openreview.net/static/images/openreview_logo_512.png" />

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans:400,400i,700,700i" />

  <link rel="stylesheet" href="/static/css/bootstrap.min.css" />
  <link rel="stylesheet" href="/static/css/jquery-ui.min.css" />
  <link rel="stylesheet" href="/static/css/main.min.css" />
</head>

<body class="forum">
  <nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
  
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand home push-link" href="/"><strong>OpenReview</strong>.net</a>
      </div>
  
      <div id="navbar" class="navbar-collapse collapse">
        <form class="navbar-form navbar-left profile-search" role="search">
          <div class="form-group has-feedback">
            <input id="search_input" type="text" class="form-control ui-autocomplete-input" placeholder="Search ICLR 2019 Conference" autocomplete="off" />
            <span class="glyphicon glyphicon-search form-control-feedback" aria-hidden="true"></span>
          </div>
  
          <input id="search_group" type="hidden" value="ICLR.cc/2019/Conference" />
          <input id="search_content" type="hidden" value="all" />
        <ul id="ui-id-1" tabindex="0" class="ui-menu ui-widget ui-widget-content ui-autocomplete ui-front" style="display: none;"></ul></form>
  
        <ul class="nav navbar-nav navbar-right">
        
            <li id="user-menu"><a href="/login">Login</a></li>
        </ul>
      </div>
  
    </div>
  </nav>

  <div id="or-banner" class="banner" style="">
  <div class="container">
    <div class="row">
      <div class="col-xs-12"><a href="/group?id=ICLR.cc/2019/Conference" title="Venue Homepage"><img class="icon" src="/static/images/arrow_left.svg" /> Go to <strong>ICLR 2019 Conference</strong> homepage</a></div>
    </div>
  </div>
</div>
<div id="flash-message-container" class="alert alert-danger" role="alert" style="display: none;">
  <div class="container">
    <div class="row">
      <div class="col-xs-12">
        <div class="alert-content">
          <button type="button" class="close" aria-label="Close"><span aria-hidden="true">×</span></button>
        </div>
      </div>
    </div>
  </div>
</div>

<div class="container">
  <div class="row">
    <div class="col-xs-12">
      <main id="content" class="clearfix openbanner-visible legacy-styles"><div id="note_rkl5CjC9Fm" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Dual Importance Weight GAN</a> <a class="note_content_pdf" href="/pdf?id=rkl5CjC9Fm" title="Download PDF" target="_blank"><img src="/static/images/pdf_icon_blue.svg" /></a> </h2></div><div class="meta_row"><span class="signatures">Anonymous</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">28 Sep 2018 (modified: 11 Oct 2018)</span><span class="item">ICLR 2019 Conference Blind Submission</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span><span class="item"><a class="action-bibtex-modal" data-bibtex="@inproceedings{    &#10;anonymous2019dual,    &#10;title={Dual Importance Weight GAN},    &#10;author={Anonymous},    &#10;booktitle={Submitted to International Conference on Learning Representations},    &#10;year={2019},    &#10;url={https://openreview.net/forum?id=rkl5CjC9Fm},    &#10;note={under review}    &#10;}">Show Bibtex</a></span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Abstract: </span><span class="note_content_value">Generative Adversarial Networks (GAN) are trained to generate a sample image of interest. To this end, generative network of GAN learns implicit distribution of true dataset from the classification samples with candidate generated samples. However, in real implementation of GAN, training the generative network with limited number of candidate samples guarantees to properly represent neither true distribution nor the distribution of generator outputs. In this paper, we propose dual importance weights for the candidate samples represented in the latent space of auto-encoder. The auto-encoder is pre-trained with real target dataset. Therefore, the latent space representation allows us to compare real distribution and the distribution of generated samples explicitly. Dual importance weights iteratively maximize the representation of generated samples for both distributions: current generator outputs and real dataset. Proposed generative model not only resolves mode collapse problem of GAN but also improves the convergence on target distribution. Experimental evaluation shows that the proposed network learns complete modes of target distribution more stable and faster than state of the art methods. </span></div><div class="reply_row clearfix"><div class="item" id="reply_count">3 Replies</div></div></div><hr class="small" /><div id="note_children"><div class="note_with_children"><div id="note_SJeGSR-kpm" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Promising idea but devil in the details?</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=rkl5CjC9Fm&amp;noteId=SJeGSR-kpm"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper920 AnonReviewer2</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">06 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper920 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">The paper proposes a novel approach to address the issue of mode collapse in the GANs. I see two interesting ideas here: (a) Since the GAN formulation seeks to achieve distributional alignment by the generator PDF end the PDF corresponding to the real, target data, the paper proposes to represent the real data using the embedding from an AE encoder, and, (b) achieve distributional alignment via an importance sampling formulation. The paper claims that their implementation of the above ideas helps improves the issues of mode collapse and mode oscillation, thereby (?) improving sample diversity and speeds up convergence. 

The ideas seem promising and I was hoping that the paper carefully implemented an approach based on the above, compared with the existing approaches and reported the results carefully. I find that the paper falls short of doing this and does not merit a publication at this point. A major revision of the work is needed.

The main shortcomings of the paper follow:

1.	Clarity: The paper greatly suffers from a loose handling of technical concepts and terminology; statements are not made in a careful and measured manner; and, grammatical mistakes abound. There are too many to list them all. Following are exemplary but symptomatic of the way the entire paper is written.

a.	“Dual importance weights iteratively maximize the representation of generated samples for both distributions”. Maximize the representation?

b.	“Experimental evaluation shows that the proposed network learns complete modes of target distribution more stable and faster than state of the art methods.” What is meant by ‘more stable’? Please provide the metric used to measure the stability and indicate which experiment validates this claim.

c.	“Main reason of mode collapsing problem is that the discriminator is incapable of delivering any information about samples’ diversity. Once the generator finds optimal point of a fixed discriminator in each generator training step, the network produces same samples driving the expectation value in objective function becomes minimum regardless of input noise vectors.” Loose and overly broad statements about the underlying problems and speculations about the mechanisms and underlying behavior of the algorithms – both the state of the art ones and the proposed one, shouldn’t be made unless there is a strong justification provided via mathematical proofs or experiments. 

d.	“Auto-encoder not only decreases the dimensionality of input data but also finds optimal abstraction of input data for better discrimination between subjects.” Optimal abstraction of input data for better discrimination between subjects? 

e.	Equation (2) should use the 2-norm since s_r and s_g are not scalars. 

2.	Implementation and technical details:

a.	The distance defined in Equation (2) and using it to modify the generator loss function in (3) seems to be based on a heuristic. The authors should formally derive it from importance sampling. This will help formally ground the proposed modifications to the objective function and help understand the expected benefits and the convergence properties better.

b.	Secondly, the proposed distance function in (2) is supposed to be obtained using a kernel density estimator. KDEs bring their own challenges, especially when used in high-dimension spaces. It is not clear what the bias/ variance properties of the proposed KDE estimator are and how it impacts the overall objective. Further, no details are shared about the dimensionality of the embedding space and the bandwidths used to compute the KDE.

c.	Beyond the KDE, there are other mathematical / implementation details missing making it practically impossible to replicate results. For example, what are the mathematical expressions for the two set of weight?

d.	High quality sample ratio (HQS) metric is neither defined nor cited from other works. It is not clear how the quality is measured and how the high-quality samples are obtained. 

3.	Insufficient/ inadequate experimental validation:

a.	While experiments on toy dataset (mixture of gaussian) shows slight improvements compared to baselines, the experiments on CIFAR and MNIST only report qualitative results in Figure 4,5 and 6. This is not sufficient to establish that the proposed approach works better than approaches compared with. 

b.	Quantitative evaluation on real datasets using the IS or the FID score (or even the metrics in Table 1) to establish the claimed improvement in performance – sample diversity and the quality of generated images. Perceptual measures such as SSIM and the one proposed in Zhang et al (CVPR 2018, arXiv 1801.03924) should be used to measure image quality. Precision, Recall and F1 can be used to provide a measure of similarity between the real and generated data.

c.	The claim about improved convergence is not adequately validated. 

d.	Aside: Since the real target data is represented by an AE embedding, the time taken to train the AE should be used when comparing baselines that do not have pre-training, in Figure 4. 

I’m willing to revise my opinion if the authors address the above issues in the forthcoming discussion phase.
</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">4: Ok but not good enough - rejection</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_rJlUvU-p27" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Insufficient motivation, evaluation, and comparison to prior work</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=rkl5CjC9Fm&amp;noteId=rJlUvU-p27"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper920 AnonReviewer1</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">05 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper920 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">Summary:
This paper proposes an approach to tackle mode collapse in GANs by using a pretrained autoencoder. Kernel density estimators are used to approximate the density of the generated and the real samples in the feature space of the autoencoder, using a buffer of samples over multiple iterations. A new regularization term is added to the generator loss that pulls together random real and generated samples in the embedding space, with a weight proportional to their distance and the product of their likelihoods. The approach is evaluated on a number of low-d toy problems, stacked MNIST, and CIFAR-10. 

Overall, I found the paper fairly confusing and poorly written, with unconvincing experiments. The added regularization term is not well-motivated, not theoretically grounded, and it’s not clear whether it even helps on any of the image datasets (Fig 5f exhibits clear mode collapse of the proposed approach). There are also a number of related papers that were not discussed but exhibit similarities to this technique (matching in the feature space of an autoencoder). The authors should review the related work, elaborate on the theoretical justification and properties of the proposed regularizer, and perform more quantitative evaluations on image datasets.

Strengths:
+ I appreciated the quantitative comparison on the low-d toy datasets (2d and 3d MoGs), reporting modes captured, and JSD.
+ The idea of combining non-parametric density estimators with GANs is interesting and underexplored.

Weaknesses:
- Poorly written, incorrect grammar throughout that distracts from the content along with a number of factually incorrect statements about concepts and related work.
- Missing discussion/comparison to numerous related works: (1) autoencoders and GANs: ALI/BiGAN, MMD (e.g. Generative Moment Matching Networks) that leverage IPMs on top of feature spaces often learned by autoencoders, FID/KID that match densities in feature space, VAE-GANs that incorporate a reconstruction loss in feature space. (2) dynamics-based approaches for avoiding mode collapse, e.g. Numerics of GANs. (3) Kernel-density based approaches to GAN training kernel (Sinn &amp; Rawat, 2017), (4) connections to continual learning in GANs where buffers of data are used (Seff et al., 2017).
- The proposed approach is poorly motivated and presented. Are there any theoretical guarantees when using the extra dual importance-weighted distance? Why do you need a time-varying KDE estimate for the the fixed data density? Why pull arbitrary real and generated pairs together in the feature space? 
- Experiments looking at proposed approach over steps give the proposed technique an unfair advantage as you have to train an autoencoder first and that does not count towards the step count. You should evaluate wall time vs. a quantitative metric (# modes?) and offset your technique by the time it takes to train the autoencoder.
- No quantitative metrics on image experiments (e.g. # modes on stacked MNIST, FID/KID for CIFAR-10).
- Fig 5f shows that the proposed technique has horrible problems with mode collapse (row 5 has the same green 4 repeated).

Minor nits:
- “Trained to generate a sample image” -&gt; distribution of images, not a single image
- “Main reason of mode collapsing problem is that the discriminator is incapable of delivering any information...” citation? That is one of many hypothesis. The explanation that follows does not make sense as the discriminator is continually updated over training, not fixed.
- “Auto-encoder trained with real dataset optimally reduces the dimension of the dataset” -&gt; optimal in what sense? Citation or more explanation needed.
- Eq 2 should be ||s_r - s_g|| as s_r and s_g are vectors, not scalars
- I found the panels on your technique in Fig 2 confusing. I think presenting an example in 1d could be simpler to understand.
- Missing details on KDE. What Kernel? How many samples did you use in the buffer?
- Fig 6: how did you choose these panels? Were they random? Cherry picked? The DCGAN paper does not exhibit nearly as extreme mode collapse in their figures.
- How did you choose alpha? How did you choose parameters of the KDE?
</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">3: Clear rejection</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_BJxGzPMc2X" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Exploiting importance sampling in the latent space of auto-encoder to alleviate mode collapse</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=rkl5CjC9Fm&amp;noteId=BJxGzPMc2X"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper920 AnonReviewer3</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">03 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper920 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">This paper proposed a new regularizer for the objective of GAN’s generator, with the purpose of alleviating the mode collapse problem. More specifically, with a pretrained auto-encoder, the regularizer is defined as a weighted distance between the latent codes of data samples and generated samples. Two different weights are used for data samples and generated samples, respectively. Accordingly comes the name “Dual Importance Weight GAN”.

Even though experimental results seem convincing, the paper is not considered well-written. Detailed comments are listed below.

(1) Notations are confusing. For example, it’s hard to tell vectors from scalars.
(2) I think the introduced weights, w_r and w_k, play an important part in the proposed algorithm. However, there are no related analysis or experiments to discuss their influence.
(3) In the paragraph before Sec. 4, the authors mentioned “we calculate distances among all real samples to all generated samples and assign pair one by one minimizing average distance” What does that mean? Mini-batch learning is used in the experiments, right? 
</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">5: Marginally below acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></main></div>
  </div>
</div>


    <!-- Footer -->
    <footer class="sitemap">
      <div class="container">
        <div class="row hidden-xs">
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/venues">All Venues</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="/contact">Contact</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
    
        <div class="row visible-xs-block">
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/contact">Contact</a></li>
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
      </div>
    </footer>
    
    <footer class="sponsor">
      <div class="container">
        <div class="row">
          <div class="col-sm-10 col-sm-offset-1">
            <p class="text-center">
              OpenReview is created by the <a href="http://www.iesl.cs.umass.edu/" target="_blank">Information Extraction and Synthesis Laboratory</a>, College of Information and Computer Science, University of Massachusetts Amherst. We gratefully acknowledge the support of the OpenReview sponsors:  Google,  Facebook, NSF, the University of Massachusetts Amherst Center for Data Science, and Center for Intelligent Information Retrieval, as well as the Google Cloud Platform for donating the computing and networking services on which OpenReview.net runs.
            </p>
          </div>
        </div>
      </div>
    </footer>

  <div id="feedback-modal" class="modal fade" tabindex="-1" role="dialog">
    <div class="modal-dialog">
      <div class="modal-content">
        <div class="modal-header">
          <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button>
          <h3 class="modal-title">Send Feedback</h3>
        </div>
        <div class="modal-body">
          <p>Enter your feedback below and we'll get back to you as soon as possible.</p>
          <form action="/feedback" method="POST">
            <div class="form-group">
              <input type="email" name="from" class="form-control" placeholder="Email" />
            </div>
            <div class="form-group">
              <input type="text" name="subject" class="form-control" placeholder="Subject" />
            </div>
            <div class="form-group">
              <textarea name="message" class="form-control feedback-input" rows="5" placeholder="Message" required=""></textarea>
            </div>
          <ul id="ui-id-2" tabindex="0" class="ui-menu ui-widget ui-widget-content" style="display: none;"></ul></form>
        </div>
        <div class="modal-footer">
          <button type="button" class="btn btn-default" data-dismiss="modal">Cancel</button>
          <button type="button" class="btn btn-primary">Send</button>
        </div>
      </div>
    </div>
  </div>

  <script type="text/javascript" async="" src="https://www.google-analytics.com/analytics.js"></script><script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js"></script>
  <script>window.jQuery || document.write('&lt;script src="/static/js/vendor/jquery-2.2.4.min.js"&gt;&lt;\/script&gt;')</script>

  <script src="/static/dist/vendor.min.js"></script>
  <script src="/static/dist/templates.min.js"></script>
  <script src="/static/dist/openreview.min.js"></script>

    <script>window.legacyScripts = true;</script>


    <script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-108703919-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() { dataLayer.push(arguments); }
      gtag('js', new Date());
      gtag('config', 'UA-108703919-1');
    </script>


<div role="status" aria-live="assertive" aria-relevant="additions" class="ui-helper-hidden-accessible"></div></body></html>
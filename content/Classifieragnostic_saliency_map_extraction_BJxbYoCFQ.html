<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" class="no-js"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>Classifier-agnostic saliency map extraction | OpenReview</title>
  <meta name="description" content="" />

      <meta name="citation_title" content="Classifier-agnostic saliency map extraction" />
        <meta name="citation_author" content="Anonymous" />
      <meta name="citation_publication_date" content="2018/09/27" />
      <meta name="citation_online_date" content="2018/09/27" />
      <meta name="citation_pdf_url" content="https://openreview.net/pdf?id=BJxbYoC9FQ" />
      <meta name="twitter:card" content="summary" />
      <meta name="twitter:site" content="@openreviewnet" />
      <meta name="og:title" content="Classifier-agnostic saliency map extraction" />
      <meta name="og:description" content="Extracting saliency maps, which indicate parts of the image important to classification, requires many tricks to achieve satisfactory performance when using classifier-dependent methods. Instead..." />
      <meta name="og:image" content="https://openreview.net/static/images/openreview_logo_512.png" />

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans:400,400i,700,700i" />

  <link rel="stylesheet" href="/static/css/bootstrap.min.css" />
  <link rel="stylesheet" href="/static/css/jquery-ui.min.css" />
  <link rel="stylesheet" href="/static/css/main.min.css" />
</head>

<body class="forum">
  <nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
  
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand home push-link" href="/"><strong>OpenReview</strong>.net</a>
      </div>
  
      <div id="navbar" class="navbar-collapse collapse">
        <form class="navbar-form navbar-left profile-search" role="search">
          <div class="form-group has-feedback">
            <input id="search_input" type="text" class="form-control ui-autocomplete-input" placeholder="Search ICLR 2019 Conference" autocomplete="off" />
            <span class="glyphicon glyphicon-search form-control-feedback" aria-hidden="true"></span>
          </div>
  
          <input id="search_group" type="hidden" value="ICLR.cc/2019/Conference" />
          <input id="search_content" type="hidden" value="all" />
        <ul id="ui-id-1" tabindex="0" class="ui-menu ui-widget ui-widget-content ui-autocomplete ui-front" style="display: none;"></ul></form>
  
        <ul class="nav navbar-nav navbar-right">
        
            <li id="user-menu"><a href="/login">Login</a></li>
        </ul>
      </div>
  
    </div>
  </nav>

  <div id="or-banner" class="banner" style="">
  <div class="container">
    <div class="row">
      <div class="col-xs-12"><a href="/group?id=ICLR.cc/2019/Conference" title="Venue Homepage"><img class="icon" src="/static/images/arrow_left.svg" /> Go to <strong>ICLR 2019 Conference</strong> homepage</a></div>
    </div>
  </div>
</div>
<div id="flash-message-container" class="alert alert-danger" role="alert" style="display: none;">
  <div class="container">
    <div class="row">
      <div class="col-xs-12">
        <div class="alert-content">
          <button type="button" class="close" aria-label="Close"><span aria-hidden="true">×</span></button>
        </div>
      </div>
    </div>
  </div>
</div>

<div class="container">
  <div class="row">
    <div class="col-xs-12">
      <main id="content" class="clearfix openbanner-visible legacy-styles"><div id="note_BJxbYoC9FQ" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Classifier-agnostic saliency map extraction</a> <a class="note_content_pdf" href="/pdf?id=BJxbYoC9FQ" title="Download PDF" target="_blank"><img src="/static/images/pdf_icon_blue.svg" /></a> </h2></div><div class="meta_row"><span class="signatures">Anonymous</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">28 Sep 2018 (modified: 11 Oct 2018)</span><span class="item">ICLR 2019 Conference Blind Submission</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span><span class="item"><a class="action-bibtex-modal" data-bibtex="@inproceedings{    &#10;anonymous2019classifier-agnostic,    &#10;title={Classifier-agnostic saliency map extraction},    &#10;author={Anonymous},    &#10;booktitle={Submitted to International Conference on Learning Representations},    &#10;year={2019},    &#10;url={https://openreview.net/forum?id=BJxbYoC9FQ},    &#10;note={under review}    &#10;}">Show Bibtex</a></span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Abstract: </span><span class="note_content_value">Extracting saliency maps, which indicate parts of the image important to classification, requires many tricks to achieve satisfactory performance when using classifier-dependent methods. Instead, we propose classifier-agnostic saliency map extraction, which finds all parts of the image that any classifier could use, not just one given in advance. We observe that the proposed approach extracts higher quality saliency maps and outperforms existing weakly-supervised localization techniques, setting the new state of the art result on the ImageNet dataset.</span></div><div class="note_contents"><span class="note_content_field">Keywords: </span><span class="note_content_value">saliency maps, explainable AI, convolutional neural networks, generative adversarial training, classification</span></div><div class="note_contents"><span class="note_content_field">TL;DR: </span><span class="note_content_value">We propose a new saliency map extraction method which results in extracting higher quality maps.</span></div><div class="reply_row clearfix"><div class="item" id="reply_count">3 Replies</div></div></div><hr class="small" /><div id="note_children"><div class="note_with_children"><div id="note_HyxqVGlT37" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>classifier-agnostic method for object localization</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=BJxbYoC9FQ&amp;noteId=HyxqVGlT37"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper418 AnonReviewer3</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">05 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper418 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">This paper proposes a classifier-agnostic method for saliency map extraction. In order to address the dependence of saliency map extraction on the classifier, the authors propose to learn a saliency mapping by considering all possible classifiers (i.e., a certain classifier structure w.r.t. the space of all its parameters). The goal is to find the relevant features in the data that work with all possible classifiers. The proposed framework is formulated as a min-max game between two players: a mask m corresponding to the saliency mapping, and a function f sampled from a set of classifiers with the same structure but different parameters. The mapping m is optimized to maximize the masked-out classification error (such that m captures all relevant features whose removal can maximally confuse the classifier), while f is optimized to minimize the mask-out classification error.

The idea of how to formulate the classifier set and how to sample from the set is interesting. However, I have some concerns regarding the overall model:

1) It seems not quite convincing to me why the model should involve an adversarial game. In particular, why f should be optimized to minimize the masked-out classification error? I understand that by doing this, f has an opposite goal with m so as to force m to capture as many relevant features as possible. However, I do not think f has a natural motivation to minimize the maxed-out error. In my opinion, it seems more convincing if f is optimized to minimize the masked-in classification error, but not necessarily the masked-out one. I think this also explains why the model works better by adding the classification loss over original images in Eq. (8). Would it be more natural if we optimize both f and m to minimize the masked-in classification error? And it would easier to train compared with the min-max model. Maybe some more explanation on the motivation of such an adversarial game can be helpful.

2) I was curious whether the alternating optimization of m and f would cause the cumulation of errors? I mean, if in some iteration m just captures irrelevant features, f will still be optimized to accomodate to such a bad mapping. Would such kind of error accumulate during training?

3) In Algorithm 1, after \theta_m is learned, how is m is determined?</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">4: Ok but not good enough - rejection</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">3: The reviewer is fairly confident that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_Sklh9zM237" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Improvement (maybe) of saliency maps by introducing technical improvements over previous work</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=BJxbYoC9FQ&amp;noteId=Sklh9zM237"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper418 AnonReviewer2</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">04 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper418 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">This paper introduces a new saliency map extractor that seems to improve state-of-the-art results. Saliency maps are tools that can be useful to understand the decision-making of deep networks for object recognition; advances in this research topic may lead to a better understanding of the functioning of deep networks.

The paper is based on the approach of Fan et al. (2017). The improvements over Fan et al. seem to be mainly technical: the objective function and the optimization procedure. This makes the novelty of the paper quite thin, as the main underlying idea of the paper was previously introduced. 

The algorithm is introduced without motivating well the different choices. What are the intuitions and evidence that guided the design of the algorithm? How are the technical choices made? Answers to these questions may help to understand how this paper builds on Fan et al. and other previous works.

The experiments compare a comprehensive set of algorithms and show an improvement over previous works. Yet, the OM metric is only compared for a few of these algorithms and it is unclear why is so. Also, the qualitative examples do not clarify how the proposed method improves over state-of-the-art (it would be useful to compare with qualitative examples of previous work). It remains unclear how much of an improvement over state-of-the-art there is.

In summary, I think the paper could be valuable as the proposed algorithm may improve state-of-the-art results. Yet, these results and the novelty of the paper are not entirely clear.</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">5: Marginally below acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_r1gvfkii27" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Issues with novelty and improvements in relation to prior works</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=BJxbYoC9FQ&amp;noteId=r1gvfkii27"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper418 AnonReviewer1</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">04 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper418 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">This paper focuses on the extraction of high-quality model-agnostic saliency maps. The authors argue that when an extracted saliency map is directly dependent on a model, then it might not be useful for a different classifier and thus not general enough. To overcome this problem, they consider all the possible classifiers weighted by their posterior probabilities. This problem cannot be solved explicitly, and the authors suggest a scheme to approximate the solution using two networks. That is, pretrain an initial classifier and then, following an adversarial training procedure, one network is trying to confuse the classifier and the other one to maximize its accuracy. Using this formulation, the authors report state-of-the-art results for salience map extraction.

SUMMARY/OVERALL COMMENTS
The authors present a simple and effective way to produce classifier-agnostic saliency maps. The argument for the approach is well justified and the results seem convincing on a first read. However, the novelty of the method is a concern given the previous work of Fan et al. (2017), and the manuscript is not upfront about the differences between the two works. The experiments are another cause for concern: Fan et al. should have been tested as a baseline with similar implementation (controlling for architecture and \lambda), and implementation differences in prior works of Table 1 make it difficult to draw conclusions. 


RELATED WORKS
* In the introduction, the authors mention related works but fail to mention the work of Fan et al. (2017) which is clearly the most relevant. The first mention of Fan et al is on page 4 in a very specific discussion the regularization coefficient. The problem formulation in Section 2 and the approach is Section 3 is largely borrowed from Fan et al but not acknowledged until the last page. This introduces bias and confusion to the reader in regards to the novelty of the approach. Please, mention the work of Fan et al. (2017) in the introduction and clearly delineate the differences in the works earlier in the text. (--)

* Du et al. (2018), “Towards Explanation of DNN-based Prediction with Guided Feature Inversion”, use the VGG models for saliency map extraction and achieve a LE of 38.2. Note that Du et al. (2018), suggest that this modification could lead to SOTA results. I would like to see a comparison with this method. (-)

* The work of Kindermans, et al. (2017), “Learning how to explain neural networks: PatternNet and Pattern Attribution”, although they do not aim for weakly supervised localization and thus, they do not present the LE, they produce saliency maps. I would like to see a LE comparison with that method. (minor -)

* In the introduction, p1 (last paragraph) other methods are briefly mentioned (Extracted saliency maps show all the evidence….superpixels), etc.) without references. Please add references when needed. (-)

* The framework presented in this paper was first proposed by Fan et al. (2017). The authors claim four main differences in their approach. In my eyes, not all of them are major or novel - probably the most impactful is removing superpixels as it simplifies the problem and implementation. (+)


APPROACH
* The authors aim for simplicity (strong +)

* The authors justify their approach and present their arguments clearly (strong ++)

* In the algorithm section, the authors first mention the sampling procedure and then their motivation. Please alter the ordering of these to be conceptually easier to understand your approach

* In the first sentence after the equation 6 I guess that “(cf. Alg. 1)” is a typo and should be modified to (Alg. 1)”

* After Equation 6 it is argued that the method resembles the training procedure of GANs (Godfellow et al., 2014) but not the work of Fan et al., 2017. (--)


EXPERIMENTS
* The authors define as their baseline the F thinning strategy (i.e. use only the first classifier) which is a model dependent salience map. While this is a useful comparison against the classifier dependent methods, given the similarity to the work of Fan et al. (2017), experiments comparing the proposed model to Fan et al. are necessary. It is important to control for network architecture (ResNet-50) and choice of \lambda to properly determine if the four changes outlined in Section 6 result in any real improvement over Fan et al. (strong --)

* The authors use the Table 1 (borrowed from Fong and Vedaldi (2017)) to compare their results against other methods. This comparison is problematic as different approaches are using different models as classifiers which may lead to increase or decrease of the LE. (--)

* In Table 2 the authors do not report how many times they run the same experiments to get these values. They also run less experiments with non-shared weights and they report only the LE. In my eyes it looks that the authors are trying to force their argument that the sharing weights helps (probably because it is one of their novelties). Please report the statistics of your experiments and fill the empty entries in the table. (--)

* In Table 3, what does the last row represent?

* Table 1 errors: (1) You write “Localization evaluation using OM, LE and F1 scores”. Please remove the F1 score as you do not report it. Also, correct the first sentence of the “Localization” subsection which states that you use three different metrics to “two different metrics”. (2) The LE from Fong and Vedaldi (2017) should be 43.2 and not 43.1.

* Regarding the unseen classes (section 5): (1) Please report in the appendix the classes that you are using in each subset. Are there classes correlated? (-)  (2) I see that there is a strong correlation between the LE on subset A and E. It looks like you are training on E and you generalize on A.


NOVELTY/IMPACT
* Novelty is a strong concern, given the work of Fan et al. (2017) (strong --). Nevertheless, the authors propose some changes that can be seen as more general, but the effectiveness of the changes is clearly established.

* This paper’s strongest point is the simplicity (conceptually and implementation-wise) of the method, an advantage over previous works (+)


OTHER COMMENTS
* Fan et al. (2017), use an adaptive λ that pushes the mask to 10% of the image whereas you are using a fixed one that pushes the mask to approximately 50% of the image. How can you make sure that this is not the reason that you are getting better results?

If the authors can clearly and fairly demonstrate that the changes they propose over Fan et al (2017) result in improved performance, and the manuscript is adjusted to be more upfront about this prior work, I would consider increasing my rating.
</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">4: Ok but not good enough - rejection</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></main></div>
  </div>
</div>


    <!-- Footer -->
    <footer class="sitemap">
      <div class="container">
        <div class="row hidden-xs">
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/venues">All Venues</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="/contact">Contact</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
    
        <div class="row visible-xs-block">
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/contact">Contact</a></li>
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
      </div>
    </footer>
    
    <footer class="sponsor">
      <div class="container">
        <div class="row">
          <div class="col-sm-10 col-sm-offset-1">
            <p class="text-center">
              OpenReview is created by the <a href="http://www.iesl.cs.umass.edu/" target="_blank">Information Extraction and Synthesis Laboratory</a>, College of Information and Computer Science, University of Massachusetts Amherst. We gratefully acknowledge the support of the OpenReview sponsors:  Google,  Facebook, NSF, the University of Massachusetts Amherst Center for Data Science, and Center for Intelligent Information Retrieval, as well as the Google Cloud Platform for donating the computing and networking services on which OpenReview.net runs.
            </p>
          </div>
        </div>
      </div>
    </footer>

  <div id="feedback-modal" class="modal fade" tabindex="-1" role="dialog">
    <div class="modal-dialog">
      <div class="modal-content">
        <div class="modal-header">
          <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button>
          <h3 class="modal-title">Send Feedback</h3>
        </div>
        <div class="modal-body">
          <p>Enter your feedback below and we'll get back to you as soon as possible.</p>
          <form action="/feedback" method="POST">
            <div class="form-group">
              <input type="email" name="from" class="form-control" placeholder="Email" />
            </div>
            <div class="form-group">
              <input type="text" name="subject" class="form-control" placeholder="Subject" />
            </div>
            <div class="form-group">
              <textarea name="message" class="form-control feedback-input" rows="5" placeholder="Message" required=""></textarea>
            </div>
          <ul id="ui-id-2" tabindex="0" class="ui-menu ui-widget ui-widget-content" style="display: none;"></ul></form>
        </div>
        <div class="modal-footer">
          <button type="button" class="btn btn-default" data-dismiss="modal">Cancel</button>
          <button type="button" class="btn btn-primary">Send</button>
        </div>
      </div>
    </div>
  </div>

  <script type="text/javascript" async="" src="https://www.google-analytics.com/analytics.js"></script><script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js"></script>
  <script>window.jQuery || document.write('&lt;script src="/static/js/vendor/jquery-2.2.4.min.js"&gt;&lt;\/script&gt;')</script>

  <script src="/static/dist/vendor.min.js"></script>
  <script src="/static/dist/templates.min.js"></script>
  <script src="/static/dist/openreview.min.js"></script>

    <script>window.legacyScripts = true;</script>


    <script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-108703919-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() { dataLayer.push(arguments); }
      gtag('js', new Date());
      gtag('config', 'UA-108703919-1');
    </script>


<div role="status" aria-live="assertive" aria-relevant="additions" class="ui-helper-hidden-accessible"></div></body></html>
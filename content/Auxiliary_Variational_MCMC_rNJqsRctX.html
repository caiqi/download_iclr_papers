<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" class="no-js"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>Auxiliary Variational MCMC | OpenReview</title>
  <meta name="description" content="" />

      <meta name="citation_title" content="Auxiliary Variational MCMC" />
        <meta name="citation_author" content="Anonymous" />
      <meta name="citation_publication_date" content="2018/09/27" />
      <meta name="citation_online_date" content="2018/09/27" />
      <meta name="citation_pdf_url" content="https://openreview.net/pdf?id=r1NJqsRctX" />
      <meta name="twitter:card" content="summary" />
      <meta name="twitter:site" content="@openreviewnet" />
      <meta name="og:title" content="Auxiliary Variational MCMC" />
      <meta name="og:description" content="We introduce Auxiliary Variational MCMC, a novel framework for learning MCMC kernels that combines recent advances in variational inference with insights drawn from traditional auxiliary variable..." />
      <meta name="og:image" content="https://openreview.net/static/images/openreview_logo_512.png" />

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans:400,400i,700,700i" />

  <link rel="stylesheet" href="/static/css/bootstrap.min.css" />
  <link rel="stylesheet" href="/static/css/jquery-ui.min.css" />
  <link rel="stylesheet" href="/static/css/main.min.css" />
</head>

<body class="forum">
  <nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
  
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand home push-link" href="/"><strong>OpenReview</strong>.net</a>
      </div>
  
      <div id="navbar" class="navbar-collapse collapse">
        <form class="navbar-form navbar-left profile-search" role="search">
          <div class="form-group has-feedback">
            <input id="search_input" type="text" class="form-control ui-autocomplete-input" placeholder="Search ICLR 2019 Conference" autocomplete="off" />
            <span class="glyphicon glyphicon-search form-control-feedback" aria-hidden="true"></span>
          </div>
  
          <input id="search_group" type="hidden" value="ICLR.cc/2019/Conference" />
          <input id="search_content" type="hidden" value="all" />
        <ul id="ui-id-1" tabindex="0" class="ui-menu ui-widget ui-widget-content ui-autocomplete ui-front" style="display: none;"></ul></form>
  
        <ul class="nav navbar-nav navbar-right">
        
            <li id="user-menu"><a href="/login">Login</a></li>
        </ul>
      </div>
  
    </div>
  </nav>

  <div id="or-banner" class="banner" style="">
  <div class="container">
    <div class="row">
      <div class="col-xs-12"><a href="/group?id=ICLR.cc/2019/Conference" title="Venue Homepage"><img class="icon" src="/static/images/arrow_left.svg" /> Go to <strong>ICLR 2019 Conference</strong> homepage</a></div>
    </div>
  </div>
</div>
<div id="flash-message-container" class="alert alert-danger" role="alert" style="display: none;">
  <div class="container">
    <div class="row">
      <div class="col-xs-12">
        <div class="alert-content">
          <button type="button" class="close" aria-label="Close"><span aria-hidden="true">×</span></button>
        </div>
      </div>
    </div>
  </div>
</div>

<div class="container">
  <div class="row">
    <div class="col-xs-12">
      <main id="content" class="clearfix openbanner-visible legacy-styles"><div id="note_r1NJqsRctX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Auxiliary Variational MCMC</a> <a class="note_content_pdf" href="/pdf?id=r1NJqsRctX" title="Download PDF" target="_blank"><img src="/static/images/pdf_icon_blue.svg" /></a> </h2></div><div class="meta_row"><span class="signatures">Anonymous</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">28 Sep 2018 (modified: 06 Nov 2018)</span><span class="item">ICLR 2019 Conference Blind Submission</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span><span class="item"><a class="action-bibtex-modal" data-bibtex="@inproceedings{    &#10;anonymous2019auxiliary,    &#10;title={Auxiliary Variational MCMC},    &#10;author={Anonymous},    &#10;booktitle={Submitted to International Conference on Learning Representations},    &#10;year={2019},    &#10;url={https://openreview.net/forum?id=r1NJqsRctX},    &#10;note={under review}    &#10;}">Show Bibtex</a></span><a class="note_content_pdf item" href="/revisions?id=r1NJqsRctX" target="_blank">Show Revisions</a></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Abstract: </span><span class="note_content_value">We introduce Auxiliary Variational MCMC, a novel framework for learning MCMC kernels that combines recent advances in variational inference with insights drawn from traditional auxiliary variable MCMC methods such as Hamiltonian Monte Carlo. Our framework exploits low dimensional structure in the target distribution in order to learn a more efficient MCMC sampler. The resulting sampler is able to suppress random walk behaviour and mix between modes efficiently, without the need to compute gradients of the target distribution. We test our sampler on a number of challenging distributions, where the underlying structure is known, and on the task of posterior sampling in Bayesian logistic regression. Code to reproduce all experiments is available at <a href="https://github.com/AVMCMC/AuxiliaryVariationalMCMC" target="_blank" rel="nofollow">https://github.com/AVMCMC/AuxiliaryVariationalMCMC</a> .
</span></div><div class="note_contents"><span class="note_content_field">Keywords: </span><span class="note_content_value">MCMC, Variational Inference</span></div><div class="reply_row clearfix"><div class="item" id="reply_count">13 Replies</div></div></div><hr class="small" /><div id="note_children"><div class="note_with_children"><div id="note_HkenO3Ku6m" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Gradient use during training phase of AVS</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=r1NJqsRctX&amp;noteId=HkenO3Ku6m"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">(anonymous)</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">14 Nov 2018</span><span class="item">ICLR 2019 Conference Paper501 Public Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">In the training phase of AVS, we use the reparameterization gradient estimator which requires the gradient of the target distribution (e.g., p wrt to x). Is that understanding correct?</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_S1xI4X5Opm" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Gradients only with respect to the variational parameters</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=r1NJqsRctX&amp;noteId=S1xI4X5Opm"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper501 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">14 Nov 2018</span><span class="item">ICLR 2019 Conference Paper501 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Hi,

thanks for your interest in our paper.  Your suggestion is not quite right.

We want to optimise a KL objective,  KL[p_\theta(a|x) p(x) | q_\phi(x|a) q(a)],  with respect to the parameters of the variational distributions. We are free here to choose the forms of the variational distribution and so have a significant amount of control. The gradients are not taken with respect to the variable x and so the gradient of the target density p(x) is never required even during training.

The re-parameterisation gradient becomes useful when we set q_\phi(x|a) = N(\mu(a), \sigma^2(a)). Here we have set q as a Gaussian whose mean and variance are parameterised by neural networks. We use the re-parameterisation trick to take gradients of expectations with respect to this distribution. In particular we use it to get low variance gradients of the KL stated above.

Hope that clears things up but please feel free to follow up.</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_SkemMdaOa7" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Are you sure?</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=r1NJqsRctX&amp;noteId=SkemMdaOa7"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">(anonymous)</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">14 Nov 2018</span><span class="item">ICLR 2019 Conference Paper501 Public Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">The paper claims to use the reverse KL. Is that a typo?

Computing the gradient of KL[ q_\phi(x|a) q(a) || p_\theta(a|x) p(x)] wrt to the parameters of q_\phi(x | a) using the reparameterization trick requires the gradient of p(x) wrt to x. This is done implicitly by TensorFlow when you take the gradient with a reparameterized x. Are you sure this isn't happening in your code?</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_rkg-CmR5aQ" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>You are correct</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=r1NJqsRctX&amp;noteId=rkg-CmR5aQ"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper501 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">15 Nov 2018</span><span class="item">ICLR 2019 Conference Paper501 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Thanks again for your comment.

Yes we do use the reverse KL, that was indeed a typo in the comment.

Apologies, I didn't fully appreciate your question before. You are right that when we re-parametrise x = \mu_theta + \sigma_theta * \epsilon, there will be an implicit gradient of the target density required during training. This means that presently in the paper we do use the gradient of the log-density during training, though not when sampling. It's worth noting though that it's not strictly necessary to re-parameterise. If the gradient cost was prohibitive, we could take the stochastic gradient, without calculating derivatives of p(x), by using the log-derivative trick. Thank you for highlighting this. We'll amend the paper at the end of section 2.4 to clarify this point.

After training, sampling is unaffected by this observation.</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_rkeKLLVj67" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Thank you for the clarification</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=r1NJqsRctX&amp;noteId=rkeKLLVj67"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">(anonymous)</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">16 Nov 2018</span><span class="item">ICLR 2019 Conference Paper501 Public Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Thank you for the clarification. Agreed that training could be done w/ log-derivative trick, so this doesn't affect the main message of the paper.</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div></div></div></div></div></div></div><div class="note_with_children"><div id="note_ryg3s8BzTX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>A very interesting idea for combining MCMC and VI.</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=r1NJqsRctX&amp;noteId=ryg3s8BzTX"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper501 AnonReviewer4</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">09 Nov 2018</span><span class="item">ICLR 2019 Conference Paper501 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">This paper proposes a clever and sensible approach to using the structure learned by the auxiliary variational method to accelerate random-walk MCMC. The idea is to learn a low-dimensional latent space that explains much of the variation in the original parameter space, then do random-walk sampling in that space (while also updating a state variable in the original state, which is necessary to ensure correctness).

I like this idea and think the paper merits acceptance, although there are some important unanswered questions. For example:
- How does the method work on higher-dimensional target distributions? I would think it would be hard for a low-dimensional auxiliary space to have high mutual information with a much higher-dimensional space. In principle neural networks can do all sorts of crazy things, but phenomena like VAEs with low-dimensional latent spaces generating blurry samples make me suspect that auxiliary dimension should be important.
- How does the method work with hierarchical models, heavy-tailed models, etc.? Rings, MoGs, and flat logistic regressions are already pretty easy targets.
- Is it really so valuable to not need gradients? High-quality automatic differentiation systems are widely available, and variational inference on discrete parameters with neural nets remains a pretty hard problem in general.

Some other comments:

* It’s probably worth citing Ranganath et al. (2015; “Hierarchical Variational Models”), who combine the auxiliary variational method with modern stochastic VI. Also, I wonder if there are connections to approximate Bayesian computation (ABC).

* I think you could prove the validity of the procedure in section 2.1 more succinctly by interpreting it as alternating a Gibbs sampling update for “a” with a Metropolis-Hastings update for “x”. If we treat “a” as an auxiliary variable such that
p(a | x) = \tilde q(a | x)
p(x | a) \propto p(x) \tilde q(a | x)
then the equation (2) is the correct M-H acceptance probability for the proposal
\tilde q(a’, x’) = δ(a’-a) \tilde q(x’ | a).
Alternating between this proposal and a Gibbs update for “a” yields the mixture proposal in section 2.1.

* It’s also possibly worth noting that this procedure will have a strictly lower acceptance rate than the ideal procedure of using the marginal
\tilde q(x’|x)
as a M-H proposal directly. Unfortunately that marginal density usually can’t be computed, which makes this ideal procedure impractical. It might be interesting to try to say something about how large this gap is for the proposed method.

* "We choose not to investigate burn-in since AVS is initialized by the variational distribution and therefore has negligible if any burn-in time.” This claim seems unjustified to me. It’s only true insofar as the variational distribution is an excellent approximation to the posterior (in which case why use MCMC at all?). It’s easy to find examples where an MCMC chain initialized with a sample from a variational distribution takes quite a while to burn in.</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">7: Good paper, accept</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_Skgpobvnam" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Thanks and Response - Part 1 of 2</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=r1NJqsRctX&amp;noteId=Skgpobvnam"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper501 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">16 Nov 2018</span><span class="item">ICLR 2019 Conference Paper501 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Thank you for your review and well considered comments.

&gt;&gt; Review: This paper proposes a clever and sensible approach to using the structure learned by the auxiliary variational method to accelerate random-walk MCMC. The idea is to learn a low-dimensional latent space that explains much of the variation in the original parameter space, then do random-walk sampling in that space (while also updating a state variable in the original state, which is necessary to ensure correctness).

&gt;&gt; I like this idea and think the paper merits acceptance, although there are some important unanswered questions. For example:


&gt;&gt; How does the method work on higher-dimensional target distributions? I would think it would be hard for a low-dimensional auxiliary space to have high mutual information with a much higher-dimensional space. In principle neural networks can do all sorts of crazy things, but phenomena like VAEs with low-dimensional latent spaces generating blurry samples make me suspect that auxiliary dimension should be important.

This is an interesting question and one we think it is hard to give a definitive answer to. The degree to which we can benefit from learning low dimensional structure will depend significantly on the choice of target distribution. It is easy to construct very high dimensional distributions with low dimensional parametrisations and in these cases it is likely the method will work well but it's unclear how many of the posteriors typically encountered in real world Bayesian inference actually have this structure. In practice, we have found the method to perform reasonably well on problems up till 10's of dimensions, which would cover quite a wide range of statistical applications. However, we were not able to get our method (or any of the other neural adaptive samplers tested) to sample reliably from the posterior of a relatively small neural network.

 We would argue that the blurry images often produced by VAEs are more to do with the training objective than the ability of neural nets to discover low-dimensional structure. This is evidenced by the fact that otherwise identical models, when trained with an adversarial objective are able to produce very sharp images.

&gt;&gt;  How does the method work with hierarchical models, heavy-tailed models, etc.? Rings, MoGs, and flat logistic regressions are already pretty easy targets.

This is a fair point and we will try to add one or two more experiments and update the paper.

&gt;&gt; Is it really so valuable to not need gradients? High-quality automatic differentiation systems are widely available, and variational inference on discrete parameters with neural nets remains a pretty hard problem in general.

We take your point but would still argue that the ability to avoid gradient computations could be of benefit, especially in the large data regime.

Though automatic differentiation eases the implementation burden, it doesn't do away with the computational difficulty of calculating gradients which for most Bayesian inference will scale linearly in the size of the data-set and for exact HMC will need to be calculated multiple times per iteration (sometimes even hundreds oft times). It's exactly for this reason that methods such as Stochastic Gradient HMC have been introduced but these methods are derived for continuous time and are not exact in practice.

Furthermore, whilst it's true that discrete neural variational inference (NVI) remains challenging it is an area of very active ongoing research and this method opens up the possibility to translate progress in NVI immediately to MCMC.

&gt;&gt; Some other comments:

&gt;&gt;* It’s probably worth citing Ranganath et al. (2015; “Hierarchical Variational Models”), who combine the auxiliary variational method with modern stochastic VI. Also, I wonder if there are connections to approximate Bayesian computation (ABC).

Thanks for this pointer, we were not aware of this paper and it does indeed use many of the same ingredients. We will add this reference.
</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_HkxClWDnpX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Thanks and Response - Part 2 of 2</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=r1NJqsRctX&amp;noteId=HkxClWDnpX"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper501 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">16 Nov 2018</span><span class="item">ICLR 2019 Conference Paper501 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">&gt;&gt; * I think you could prove the validity of the procedure in section 2.1 more succinctly by interpreting it as alternating a Gibbs sampling update for “a” with a Metropolis-Hastings update for “x”. If we treat “a” as an auxiliary variable such that

&gt;&gt;p(a | x) = \tilde q(a | x)
&gt;&gt;p(x | a) \propto p(x) \tilde q(a | x)
&gt;&gt;then the equation (2) is the correct M-H acceptance probability for the proposal
&gt;&gt;\tilde q(a’, x’) = δ(a’-a) \tilde q(x’ | a).
&gt;&gt;Alternating between this proposal and a Gibbs update for “a” yields the mixture proposal in section 2.1.

We agree that there are perhaps more direct proofs of our method, as has been suggested by another reviewer as well. However, rigorously handling deterministic proposals in Metropolis Hastings is quite an advanced topic and we feel that our proof whilst algebraically more involved is conceptually simpler. We also feel that the extension of the proof as given to multiple auxiliary variables is more straight forward. Unless the reviewers feel very strongly on this point, we would prefer to maintain the proof as is.

&gt;&gt; It’s also possibly worth noting that this procedure will have a strictly lower acceptance rate than the ideal procedure of using the marginal
&gt;&gt;\tilde q(x’|x)
&gt;&gt;as a M-H proposal directly. Unfortunately that marginal density usually can’t be computed, which makes this ideal procedure impractical. It might be interesting to try to say something about how large this gap is for the proposed method.

This is an interesting question and not one we had investigated in detail. We shall think carefully about this and if we have any insights prior to the final deadline shall update the paper.

&gt;&gt; "We choose not to investigate burn-in since AVS is initialized by the variational distribution and therefore has negligible if any burn-in time.” This claim seems unjustified to me. It’s only true insofar as the variational distribution is an excellent approximation to the posterior (in which case why use MCMC at all?). It’s easy to find examples where an MCMC chain initialized with a sample from a variational distribution takes quite a while to burn in.

Perhaps the claim as stated is slightly too strong but it seems plausible to the authors that initialising with a variational distribution will likely start the chain in a region of high target density even if the variational approximation is poor. This in turn will reduce burn-in time relative to a method that is not initialised in a region of high density. Indeed, this is the reason for the common practice of initialising MCMC algorithms by first running an optimisation procedure to find the mode. In any case, all the authors were hoping to convey was that burn-in is relatively fast for AVS and thus not the most interesting point of comparison relative to other methods.

We will amend the text to read: "We choose not to focus our investigation on burn-in time since AVS, being initialized by the variational distribution, often has short burn-in relative to competitive methods.”</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div><div class="note_with_children"><div id="note_rkeocNqY2X" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>The paper contains very interesting novel ideas. Some points must clarified and the state-of-the-art must be improved.</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=r1NJqsRctX&amp;noteId=rkeocNqY2X"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper501 AnonReviewer1</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">02 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper501 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">In my opinion, the paper contains very interesting novel ideas.
However, some parts needs a future clarification and the state-of-the-art must be improved.

- First of all,  Sections 2.3.1 or 2.3.2 can be improved and clarified. For instance, I believe you can create a unique section with title " Choice of Proposal density " and then schematically describe each proposal from the simplest to the more sophisticated one.

- At the beginning of Section 2, please devote more sentence to explain why extending the space and apply the variational inference is good for finding a suitable good proposal density.

- Related  to Section 2 ( theMixture Proposal MCMC contribution), the authors should discuss (in the introduction and also in the related works section) the Multiple Try Metropolis schemes with correlated candidates where, for instance, a path of candidates is generated and one of them is selected and tested with MH-type acceptance probability, in a proper way. This is more general that your scheme but very related. Please see

Qin, Z.S., Liu, J.S., 2001. Multi-point Metropolis method with application to hybrid Monte Carlo. Journal of Computational Physics 172, 827–840.

L. Martino, V. P. Del Olmo, J. Read, "A multi-point Metropolis scheme with generic weight functions", Statistics and Probability Letters, Volume 82, Issue 7, Pages: 1445-1453, 2012.

L. Martino, "A Review of Multiple Try MCMC algorithms for Signal Processing", Digital Signal Processing, Volume 75, Pages: 134-152, 2018.

- Related again with the state-of-the-art description, the references regarding  Adaptive Mixture Metropolis methods are completely missed. If I have properly understood, you also adapt a mixture via variational inference. Please, in Section 4, consider the different works that considers an adapting mixture proposal for a  Metropolis-type algorithm,

P. Giordani and R. Kohn, “Adaptive independent Metropolis-Hastings by fast estimation of mixtures of normals,” Journal of Computational and Graphical Statistics, vol. 19, no. 2, pp. 243–259, September 2010.

Tran, M.-N., M. K. Pitt, and R. Kohn. Adaptive Metropolis–Hastings sampling using reversible dependent mixture proposals. Statistics and Computing, 26, 1–21, 2014.

D. Luengo, L. Martino, "Fully Adaptive Gaussian Mixture Metropolis-Hastings Algorithm", IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP), Vancouver (Canada), 2013.

Roberts, G. O. and J. S. Rosenthal (2009). Examples of adaptive MCMC. Journal of Computational and Graphical Statistics 18, 349–367.


</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">7: Good paper, accept</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_BklskfP36Q" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Thanks and Response</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=r1NJqsRctX&amp;noteId=BklskfP36Q"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper501 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">16 Nov 2018</span><span class="item">ICLR 2019 Conference Paper501 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Thank you for your review and well considered comments.

&gt;&gt; Review: In my opinion, the paper contains very interesting novel ideas.
&gt;&gt; However, some parts needs a future clarification and the state-of-the-art must be improved.


&gt;&gt; First of all,  Sections 2.3.1 or 2.3.2 can be improved and clarified. For instance, I believe you can create a unique section with title " Choice of Proposal density " and then schematically describe each proposal from the simplest to the more sophisticated one.

Thanks for the feedback. As we edit the paper to include other changes we'll bear this in mind. We'd hoped this was what we had done already but will try to make it clearer.

&gt;&gt; At the beginning of Section 2, please devote more sentence to explain why extending the space and apply the variational inference is good for finding a suitable good proposal density.

We believe that this was made clear in sections 2.3.1 and 2.3.2. In particular the discussion immediately following equation (9) tries to make this point. However, we can add a further sentence emphasising this at the start of section 2 as well. 

&gt;&gt; Related  to Section 2 ( theMixture Proposal MCMC contribution), the authors should discuss (in the introduction and also in the related works section) the Multiple Try Metropolis schemes with correlated candidates were, for instance, a path of candidates is generated and one of them is selected and tested with MH-type acceptance probability, in a proper way. This is more general that your scheme but very related. Please see

&gt;&gt; Qin, Z.S., Liu, J.S., 2001. Multi-point Metropolis method with application to hybrid Monte Carlo. Journal of Computational Physics 172, 827–840.

&gt;&gt; L. Martino, V. P. Del Olmo, J. Read, "A multi-point Metropolis scheme with generic weight functions", Statistics and Probability Letters, Volume 82, Issue 7, Pages: 1445-1453, 2012.

&gt;&gt;L. Martino, "A Review of Multiple Try MCMC algorithms for Signal Processing", Digital Signal Processing, Volume 75, Pages: 134-152, 2018.

Thanks for the pointers to these papers. We are aware of Multiple Try Metropolis (MTM) but many of the references you provided below were new to us. Whilst we acknowledge that MTM is a powerful tool in the MCMC arsenal, we felt that it was quite different to our method and really offers an orthogonal direction for improvement. We don't attempt a thorough review of the state-of-the-art in MCMC, which we feel is beyond the scope here, but instead try to focus our discussion on other neural adaptive samplers such as L2HMC and A-NICE-MCMC.


&gt;&gt; related again with the state-of-the-art description, the references regarding  Adaptive Mixture Metropolis methods are completely missed. If I have properly understood, you also adapt a mixture via variational inference. Please, in Section 4, consider the different works that considers an adapting mixture proposal for a  Metropolis-type algorithm,

Thanks for the pointers to these papers. These were mostly new to us and do seem very related. After reading the papers more closely we will try to include them in our references. 

&gt;&gt;P. Giordani and R. Kohn, “Adaptive independent Metropolis-Hastings by fast estimation of mixtures of normals,” Journal of Computational and Graphical Statistics, vol. 19, no. 2, pp. 243–259, September 2010.

&gt;&gt;Tran, M.-N., M. K. Pitt, and R. Kohn. Adaptive Metropolis–Hastings sampling using reversible dependent mixture proposals. Statistics and Computing, 26, 1–21, 2014.

&gt;&gt;D. Luengo, L. Martino, "Fully Adaptive Gaussian Mixture Metropolis-Hastings Algorithm", IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP), Vancouver (Canada), 2013.

&gt;&gt;Roberts, G. O. and J. S. Rosenthal (2009). Examples of adaptive MCMC. Journal of Computational and Graphical Statistics 18, 349–367</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div><div class="note_with_children"><div id="note_B1xDvf7FnX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Interesting paper, though results are slightly weak.</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=r1NJqsRctX&amp;noteId=B1xDvf7FnX"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper501 AnonReviewer3</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">02 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper501 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">This paper proposes an auxiliary variable MCMC scheme involving variational inference for efficient MCMC. Given a target distribution p(x), the authors introduce an auxiliary variable a, and learn conditional distributions p(a|x) and q(a|x) by minimizing the KL divergence between p(x)p(a|x) and q(a)q(x|a), with q(a) something simple (the authors use Gaussian). A MH proposal step involves simulating x givea the current MCMC sample x (from p(a|x), taking a step in A-space, and then returning back to the X space (using q(x|a)).  The authors show how to calculate the acceptance probability. 

I think the idea is nice and useful (I'm surprised people haven't thought of this before), though I think the paper presents this in a less clear way (as an extension of ideas from Agakov and Barber's "Auxiliary variational method"). While this is correct and perhaps more general, in my mind it slightly obscures the main idea, as well as the strong ties with variational autoencoders: express a complex distribution as a (learnt) transformation of a simple distribution (this is the actual approach taken in the experiments). 

The motivation of the approach is that the nonlinear encoding network can transform the complex p(x) into a simpler q(a). 
For this reason, I think an important baseline is the independent MH sampler from equation 8 (I think this essentially uses a trained VAE generative model as a proposal distribution). The authors talk about how producing independent proposals can be sub-optimal, yet it seems to me that if the encoder and decoder neural networks are powerful enough, this should do a good job. I think excluding this baseline hurts the paper a bit.

The proof of correctness while correct is a bit unclear, can perhaps be simplified if you view the MCMC algorithm as operating on an augmented space (x,a,x') with stationary distribution p(x)q(a|x)q(x'|a) (writing writing q for \tilde(q)). This clearly has the right distribution over x. Each MCMC iteration starts with x and proceeds as follow:
  1) Given x, sample a and x' from q(a|x) and q(x'|a)
  2) Make a deterministic proposal on the augmented space to swap (x,x'). The acceptance probability is now equation 2.
  3) Discard a,x'.

In figure 4, the authors use HMC as an "improved MCMC algorithm", yet this is not an algorithm that deals with multimodality well. More useful would be to include some tempering algorithm like serial or parallel tempering.

While I like the idea, I unfortunately don't think the experiments are very convincing (and the authors barely discuss their results). Other than mixture of Gaussians, HMC (which involves no training) appears to be superior. With some tempering, I expect it to outperform the proposed method for the MoG case

Table 2 left: since HMC involves no training, does this mean that, taking training time into account, HMC is 5-6 orders of magnitude more efficient. L?ke I mentioned earlier, these results need more discussion. 

It would also help to provide absolute training and run times, so the reader can better understand whether the proposed method of ANICE is better.

Figure 3: why don't the authors also plot the histogram of values in the auxiliary space, p(a). It would be interesting to see how Gaussian this is (this is what variational inference is trying to achieve). Also, does Figure 3(a) mean that conditioned on x, p(a|x) is basically a delta function? This would suggest that the encoder is basically learning a deterministic transformation to a simpler low-dimensional space? There is some work in this direction in the statistics literature, e.g. 
"Variable transformation to obtain geometric ergodicity in the random-walk Metropolis algorithm"

The authors some refers to the distribution of a|x as q(a|x) sometimes (in section 2.1) and sometimes as p(a|x) which is a bit confusing.

Figure 2: the labels are wrong.</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">7: Good paper, accept</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_rJgjUgvn6X" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Thanks and Response - Part 1 of 2</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=r1NJqsRctX&amp;noteId=rJgjUgvn6X"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper501 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">16 Nov 2018</span><span class="item">ICLR 2019 Conference Paper501 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Thank you for your review and well considered comments.

&gt;&gt;This paper proposes an auxiliary variable MCMC scheme involving variational inference for efficient MCMC. Given a target distribution p(x), the authors introduce an auxiliary variable a, and learn conditional distributions p(a|x) and q(a|x) by minimizing the KL divergence between p(x)p(a|x) and q(a)q(x|a), with q(a) something simple (the authors use Gaussian). A MH proposal step involves simulating x givea the current MCMC sample x (from p(a|x), taking a step in A-space, and then returning back to the X space (using q(x|a)).  The authors show how to calculate the acceptance probability.

&gt;&gt;I think the idea is nice and useful (I'm surprised people haven't thought of this before), though I think the paper presents this in a less clear way (as an extension of ideas from Agakov and Barber's "Auxiliary variational method"). While this is correct and perhaps more general, in my mind it slightly obscures the main idea, as well as the strong ties with variational autoencoders: express a complex distribution as a (learnt) transformation of a simple distribution (this is the actual approach taken in the experiments).

We did consider presenting the exposition in this way but in the end decided to err on the side of generality. Ultimately, we think that there are really two main ideas in the paper: 1) A quite general framework for construction of MH proposals that can exploit structure 2) A VAE-inspired black-box instantiation of that structure.

Though we primarily investigated the neural-net version of our sampler, we do think that there are likely other ways to construct valid samplers that may be more efficient on a problem specific basis and wanted to expose this possibility to the research community.


&gt;&gt;The motivation of the approach is that the nonlinear encoding network can transform the complex p(x) into a simpler q(a). 
&gt;&gt;For this reason, I think an important baseline is the independent MH sampler from equation 8 (I think this essentially uses a trained VAE generative model as a proposal distribution). The authors talk about how producing independent proposals can be sub-optimal, yet it seems to me that if the encoder and decoder neural networks are powerful enough, this should do a good job. I think excluding this baseline hurts the paper a bit.

We think this is a fair point and will run this experiment and update the results.

&gt;&gt;The proof of correctness while correct is a bit unclear, can perhaps be simplified if you view the MCMC algorithm as operating on an augmented space (x,a,x') with stationary distribution p(x)q(a|x)q(x'|a) (writing writing q for \tilde(q)). This clearly has the right distribution over x. Each MCMC iteration starts with x and proceeds as follow:
&gt;&gt;  1) Given x, sample a and x' from q(a|x) and q(x'|a)
&gt;&gt;  2) Make a deterministic proposal on the augmented space to swap (x,x'). The acceptance probability is now equation 2.
&gt;&gt;  3) Discard a,x'.

This point was also made by another reviewer who suggested a slightly different approach that was also valid. As we said to them, we agree that there are perhaps more direct proofs of our method. However, rigorously handling deterministic proposals in Metropolis Hastings is quite an advanced topic and we feel that our proof whilst algebraically more involved is conceptually simpler. Unless the reviewers feel very strongly on this point, the authors would prefer to maintain the proof as is.


&gt;&gt;In figure 4, the authors use HMC as an "improved MCMC algorithm", yet this is not an algorithm that deals with multimodality well. More useful would be to include some tempering algorithm like serial or parallel tempering.

In retrospect the inclusion of HMC here is maybe a little distracting. The point was not to demonstrate superiority over advanced methods but simply to demonstrate the ability of our sampler to find low dimensional structure when we know it is present. Perhaps the main reason we chose to include this example though, was because the inability of HMC to mix between modes was a key problem investigated in the L2HMC paper, which we benchmark against. The authors would happily remove this example if the reviewer feels it adds little.</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_rJgRC1whTm" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Thanks and Response - Part 2 of 2 </a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=r1NJqsRctX&amp;noteId=rJgRC1whTm"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper501 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">16 Nov 2018 (modified: 17 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper501 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">
&gt;&gt;While I like the idea, I unfortunately don't think the experiments are very convincing (and the authors barely discuss their results). Other than mixture of Gaussians, HMC (which involves no training) appears to be superior. With some tempering, I expect it to outperform the proposed method for the MoG case

&gt;&gt;Table 2 left: since HMC involves no training, does this mean that, taking training time into account, HMC is 5-6 orders of magnitude more efficient. Like I mentioned earlier, these results need more discussion.


&gt;&gt;It would also help to provide absolute training and run times, so the reader can better understand whether the proposed method of ANICE is better.

The reviewer is correct that, presently, if training time is included HMC significantly outperforms not just the method proposed in this paper but all of the learned samplers explored thus far. The size of the difference is dramatic here because the data-sets used are small but as the size of the data-set grows we expect the computational cost of HMC to grow much faster than the learned samplers. This is because HMC will require many gradients of the log-density per iteration and the cost of each of these scales linearly in the size of the data. Whilst calculating acceptance ratios also scales linearly in data-size, it only needs to be performed once per iteration. HMC, on the other hand, will often require 10s or 100s of gradients per iteration. Another point that we'd emphasise is that although there is an increased computational time for these methods, because they are black-box they potentially save on much more vital human time, HMC being quite tricky to tune.

We will update the paper to include absolute training times. To give the reviewer an indication here of the difference in absolute training times (in seconds) we provide preliminary figures taken from the last batch of experiments we ran:

Ring/   Mog/   Logistic Regression/

ANICE:  120/ 1290 / 3310

AVS: 70 / 2  /   2

L2HMC: 3310/ 2620 / 4590 

We will try to expand the discussion of the results, their brevity was primarily a result of space restrictions.

&gt;&gt;Figure 3: why don't the authors also plot the histogram of values in the auxiliary space, p(a). It would be interesting to see how Gaussian this is (this is what variational inference is trying to achieve).

We agree that this might be interesting but felt that in the limited space given it wasn't central to our argument.

&gt;&gt; Also, does Figure 3(a) mean that conditioned on x, p(a|x) is basically a delta function? This would suggest that the encoder is basically learning a deterministic transformation to a simpler low-dimensional space? There is some work in this direction in the statistics literature, e.g.

In this case, yes the conditional became close to a delta-function though its not clear how often this will be the case.

&gt;&gt;"Variable transformation to obtain geometric ergodicity in the random-walk Metropolis algorithm"

Thanks also for the pointer to this paper. We were not aware of it but it seems highly relevant. We'll try to add it to our discussion after we study it in more detail.

&gt;&gt;The authors some refers to the distribution of a|x as q(a|x) sometimes (in section 2.1) and sometimes as p(a|x) which is a bit confusing.

Thanks this was a mistake and will be corrected.

&gt;&gt;Figure 2: the labels are wrong.

Thanks again, we will correct this.</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div></div></main></div>
  </div>
</div>


    <!-- Footer -->
    <footer class="sitemap">
      <div class="container">
        <div class="row hidden-xs">
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/venues">All Venues</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="/contact">Contact</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
    
        <div class="row visible-xs-block">
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/contact">Contact</a></li>
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
      </div>
    </footer>
    
    <footer class="sponsor">
      <div class="container">
        <div class="row">
          <div class="col-sm-10 col-sm-offset-1">
            <p class="text-center">
              OpenReview is created by the <a href="http://www.iesl.cs.umass.edu/" target="_blank">Information Extraction and Synthesis Laboratory</a>, College of Information and Computer Science, University of Massachusetts Amherst. We gratefully acknowledge the support of the OpenReview sponsors:  Google,  Facebook, NSF, the University of Massachusetts Amherst Center for Data Science, and Center for Intelligent Information Retrieval, as well as the Google Cloud Platform for donating the computing and networking services on which OpenReview.net runs.
            </p>
          </div>
        </div>
      </div>
    </footer>

  <div id="feedback-modal" class="modal fade" tabindex="-1" role="dialog">
    <div class="modal-dialog">
      <div class="modal-content">
        <div class="modal-header">
          <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button>
          <h3 class="modal-title">Send Feedback</h3>
        </div>
        <div class="modal-body">
          <p>Enter your feedback below and we'll get back to you as soon as possible.</p>
          <form action="/feedback" method="POST">
            <div class="form-group">
              <input type="email" name="from" class="form-control" placeholder="Email" />
            </div>
            <div class="form-group">
              <input type="text" name="subject" class="form-control" placeholder="Subject" />
            </div>
            <div class="form-group">
              <textarea name="message" class="form-control feedback-input" rows="5" placeholder="Message" required=""></textarea>
            </div>
          <ul id="ui-id-2" tabindex="0" class="ui-menu ui-widget ui-widget-content" style="display: none;"></ul></form>
        </div>
        <div class="modal-footer">
          <button type="button" class="btn btn-default" data-dismiss="modal">Cancel</button>
          <button type="button" class="btn btn-primary">Send</button>
        </div>
      </div>
    </div>
  </div>

  <script type="text/javascript" async="" src="https://www.google-analytics.com/analytics.js"></script><script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js"></script>
  <script>window.jQuery || document.write('&lt;script src="/static/js/vendor/jquery-2.2.4.min.js"&gt;&lt;\/script&gt;')</script>

  <script src="/static/dist/vendor.min.js"></script>
  <script src="/static/dist/templates.min.js"></script>
  <script src="/static/dist/openreview.min.js"></script>

    <script>window.legacyScripts = true;</script>


    <script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-108703919-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() { dataLayer.push(arguments); }
      gtag('js', new Date());
      gtag('config', 'UA-108703919-1');
    </script>


<div role="status" aria-live="assertive" aria-relevant="additions" class="ui-helper-hidden-accessible"></div></body></html>
<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" class="no-js"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>Estimating Heterogeneous Treatment Effects Using Neural Networks With The Y-Learner | OpenReview</title>
  <meta name="description" content="" />

      <meta name="citation_title" content="Estimating Heterogeneous Treatment Effects Using Neural Networks With The Y-Learner" />
        <meta name="citation_author" content="Bradly C. Stadie" />
        <meta name="citation_author" content="Sören R. Künzel" />
        <meta name="citation_author" content="Nikita Vemuri" />
        <meta name="citation_author" content="Jasjeet S. Sekhon" />
      <meta name="citation_publication_date" content="2018/09/27" />
      <meta name="citation_online_date" content="2018/09/27" />
      <meta name="citation_pdf_url" content="https://openreview.net/pdf?id=ryxnDoRcK7" />
      <meta name="twitter:card" content="summary" />
      <meta name="twitter:site" content="@openreviewnet" />
      <meta name="og:title" content="Estimating Heterogeneous Treatment Effects Using Neural Networks..." />
      <meta name="og:description" content="We develop the Y-learner for estimating heterogeneous treatment effects in experimental and observational studies. The Y-learner is designed to leverage the abilities of neural networks to optimize..." />
      <meta name="og:image" content="https://openreview.net/static/images/openreview_logo_512.png" />

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans:400,400i,700,700i" />

  <link rel="stylesheet" href="/static/css/bootstrap.min.css" />
  <link rel="stylesheet" href="/static/css/jquery-ui.min.css" />
  <link rel="stylesheet" href="/static/css/main.min.css" />
</head>

<body class="forum">
  <nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
  
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand home push-link" href="/"><strong>OpenReview</strong>.net</a>
      </div>
  
      <div id="navbar" class="navbar-collapse collapse">
        <form class="navbar-form navbar-left profile-search" role="search">
          <div class="form-group has-feedback">
            <input id="search_input" type="text" class="form-control ui-autocomplete-input" placeholder="Search ICLR 2019 Conference" autocomplete="off" />
            <span class="glyphicon glyphicon-search form-control-feedback" aria-hidden="true"></span>
          </div>
  
          <input id="search_group" type="hidden" value="ICLR.cc/2019/Conference" />
          <input id="search_content" type="hidden" value="all" />
        <ul id="ui-id-1" tabindex="0" class="ui-menu ui-widget ui-widget-content ui-autocomplete ui-front" style="display: none;"></ul></form>
  
        <ul class="nav navbar-nav navbar-right">
        
            <li id="user-menu"><a href="/login">Login</a></li>
        </ul>
      </div>
  
    </div>
  </nav>

  <div id="or-banner" class="banner" style="">
  <div class="container">
    <div class="row">
      <div class="col-xs-12"><a href="/group?id=ICLR.cc/2019/Conference" title="Venue Homepage"><img class="icon" src="/static/images/arrow_left.svg" /> Go to <strong>ICLR 2019 Conference</strong> homepage</a></div>
    </div>
  </div>
</div>
<div id="flash-message-container" class="alert alert-danger" role="alert" style="display: none;">
  <div class="container">
    <div class="row">
      <div class="col-xs-12">
        <div class="alert-content">
          <button type="button" class="close" aria-label="Close"><span aria-hidden="true">×</span></button>
        </div>
      </div>
    </div>
  </div>
</div>

<div class="container">
  <div class="row">
    <div class="col-xs-12">
      <main id="content" class="clearfix openbanner-visible legacy-styles"><div id="note_ryxnDoRcK7" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Estimating Heterogeneous Treatment Effects Using Neural Networks With The Y-Learner</a> <a class="note_content_pdf" href="/pdf?id=ryxnDoRcK7" title="Download PDF" target="_blank"><img src="/static/images/pdf_icon_blue.svg" /></a> </h2></div><div class="meta_row"><span class="signatures"><a href="/profile?email=bstadie%40berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="bottom" title="" data-original-title="bstadie@berkeley.edu">Bradly C. Stadie</a>, <a href="/profile?email=srk%40berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="bottom" title="" data-original-title="srk@berkeley.edu">Sören R. Künzel</a>, <a href="/profile?email=nikitavemuri%40berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="bottom" title="" data-original-title="nikitavemuri@berkeley.edu">Nikita Vemuri</a>, <a href="/profile?email=sekhon%40berkeley.edu" class="profile-link" data-toggle="tooltip" data-placement="bottom" title="" data-original-title="sekhon@berkeley.edu">Jasjeet S. Sekhon</a></span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">28 Sep 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Withdrawn Submission</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Abstract: </span><span class="note_content_value">We develop the Y-learner for estimating heterogeneous treatment effects in experimental and observational studies. The Y-learner is designed to leverage the abilities of neural networks to optimize multiple objectives and continually update, which allows for better pooling of underlying feature information between treatment and control groups. We evaluate the Y-learner on three test problems: (1) A set of six simulated data benchmarks from the literature. (2) A real-world large-scale experiment on voter persuasion. (3) A task from the literature that estimates artificially generated treatment effects on MNIST didgits. The Y-learner achieves state of the art results on two of the three tasks. On the MNIST task, it gets the second best results. </span></div><div class="note_contents"><span class="note_content_field">Keywords: </span><span class="note_content_value">causal inference, CATE estimation, ITE, deep learning</span></div><div class="note_contents"><span class="note_content_field">TL;DR: </span><span class="note_content_value">We develop a CATE estimation strategy that takes advantage some of the intriguing properties of neural networks. </span></div><div class="reply_row clearfix"><div class="item" id="reply_count">4 Replies</div></div></div><hr class="small" /><div id="note_children"><div class="note_with_children"><div id="note_SyluiQUC37" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Submission Withdrawn by the Authors</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=ryxnDoRcK7&amp;noteId=SyluiQUC37"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper298 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">06 Nov 2018</span><span class="item">ICLR 2019 Conference Paper298 Withdraw Submission</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Withdrawal confirmation: </span><span class="note_content_value">I have read and agree with the withdrawal statement on behalf of myself and my co-authors.</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_r1l4-3i5nQ" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>interesting idea</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=ryxnDoRcK7&amp;noteId=r1l4-3i5nQ"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper298 AnonReviewer3</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">03 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper298 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">multi-objective learning is known to regularize estimation and improve optimization. the authors excellently bring this idea to causal inference, in particular learning conditional average treatment effect. I see the main contribution of the paper experimental: the authors demonstrate that their methods achieve good results on different tasks.

the causal setting it operates under is the classical one: under strong ignorability and overlap. the contribution is in causal estimation, rather than causal identification.

while the authors claim the results are all state-of-the art, in several cases, it seems the S-learner is a very competitive and seemingly favorable competitor; in simulation 4,5,6 of fig 3 for example. and fig 6.

could the authors please clarify in their understanding of the empirical performance? in what scenario/data patterns will the Y-learner often outperform? when does it perform the best compared to its competitors. it could help to give intuitions of why and when the proposal work. it could help future users decide when to use it.</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">5: Marginally below acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">3: The reviewer is fairly confident that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_BJgCColc2X" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>More experimental evaluations can improve the paper</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=ryxnDoRcK7&amp;noteId=BJgCColc2X"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper298 AnonReviewer1</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">03 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper298 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">Summary
This paper proposed to estimate the conditional average treatment effect (CATE) in counterfactual inference by modifying an existing approach, called X-learner, in the following ways. First, both the treatment response function and the control response function were modeled as neural networks, denoted as f_theta, rather than random forest. The imputed treatment effect can be computed. Second, the mapping from the imputed treatment effect to the CATE were also modeled as neural networks, denoted as f_tau. Therefore, f_theta and f_tau can be jointly optimized through backpropagation. Experimental results on a simulated dataset showed that the co-training of f_tau and f_theta contributed most to the improvement of Y-learner compared to the X-learner. Experimental results on six simulated datasets, the VOTE dataset, and MNIST dataset showed the proposed Y-learner can outperform its competing alternatives, including T-leaner, S-learner, R-learner, X-learner, on a subset of all datasets.

Comments
This work aimed to estimate the conditional average treatment effect. The related work section contains relevant work from the statistics and economics community. Did the author try to implement and compare against some strong baselines commonly used in the machine learning community, such as the Bayesian additive regression trees (BART, Hill 2011), the counterfactual regression with integral probability metrics (Shalit et al. ICML 2017), counterfactual multiple-task Gaussian process (Alaa et al. NIPS 2017)?

Why didn't the MSE of X-learner (Figure3: Simulation 3) and T-learner (Figure 3: Simulation 1, Figure 5) monotonically decrease w.r.t. the number of samples?

Were the confidence intervals shown in Figure 2,3 generated by simulating those synthetic datasets multiple times? Could the authors explain why the confidence interval of the Y-learner is very small when the number of samples used is quite small?

What were the network architectures and detailed hyper-parameter settings used for f_theta and f_tau? Were the results sensitive to the choice of those parameters? For the competing baselines (T-leaner, S-learner, R-learner, X-learner), which model were used as the function approximator, neural network or random forest?</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">5: Marginally below acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_HylJweBI2m" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Interesting idea, but both writing and experiments need further improvement</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=ryxnDoRcK7&amp;noteId=HylJweBI2m"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper298 AnonReviewer2</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">31 Oct 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper298 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">In this submission, the authors propose the Y-learner to estimate conditional average treatment effect(CATE), which simultaneously updates the parameters of the outcome functions and the CATE estimator. The co-learning strategy idea is interesting, but the details of the method are not well explained and the experiment results seem not convincing. The detailed comments are as follows:

First, the motivation of Y-learner is not well presented. As mentioned in the paper, Y-learner is an improvement of X-learner, so the authors need to clearly illustrate the deficiency of X-learner. Also, whether the Y-learner can keep the advantages of X-learners and overcome its disadvantages?

Second, in section 3, the authors mention the importance of the learning rate in the training of GAN as an analogy to explain why co-learning can achieve better performance. However, it doesn’t convince me well, and the reasons are as follows: in GAN, the generator and discriminator have the adversarial relationship, but this relationship is no longer exist in Y-learner as the outcome prediction networks (f_{\theta_0}, f_{\theta_1}) and CATE estimation network (f_{\tau}) are complementary. Whether the phenomenon observed in the GAN training can be an analogy to explain the superiority of co-learning is still doubtful. The authors should give more detailed explanations.

Third, I have some questions about the results (figure 2) of the experiment which aims to test the importance of co-learning in the Y-learner. (1) Which category (method with co-learning or without co-learning) the method Y-learner with no backpropagation belongs to? Is the method Y-learner with no backpropagation the same as Algorithm 1 excluding the line 3 and 7? (2) In figure 2, the method Y-learner with no backpropagation achieves similar performance with the full Y-learner. Why does this happen? Whether the method Y-learner with no backpropagation can replace the Y-learner? Why the authors design the full backpropagation through f_{\theta_0}, f_{\theta_1} when training f_{\tau} in the Y-learner?

Forth, whether the machine learning methods adopted in R, S, T, X-learners are all neural networks when conducting the experiment on the simulated data as well as the GET-OUT-THE-VOTE dataset? 

Fifth, the experiment results are not convincing. In the introduction, the authors claim that Y-learner can achieve state of the art performance with only a fraction of the data on several CATE estimation tasks. However, the results on six simulated datasets and the MNIST task don’t support this claim: (1) In the simulated datasets, only in dataset 2 (complex linear case), the Y-learner has better performance with fewer training samples, and in the other five datasets, there always exits some baselines that perform better than Y-learner. (2) In the MNIST task, the baseline method S-learner performs much better than the proposed method, and also S-learner requires much less training sample to learn good CATE estimator compared with Y-learner. 

Sixth, the analysis of the experiment results are missing. For example, the authors should explain why the proposed method doesn’t perform as well as S-learners in MNIST task. 

Minor question: the notations \pi_{\theta_0}, \pi_{\theta_1}, and \pi_{\tau} in Figure 1 are not explained. Are they typos? Or they should be f_{\theta_0}, f_{\theta_1} and f_{\tau} instead of \pi?
</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">4: Ok but not good enough - rejection</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></main></div>
  </div>
</div>


    <!-- Footer -->
    <footer class="sitemap">
      <div class="container">
        <div class="row hidden-xs">
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/venues">All Venues</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="/contact">Contact</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
    
        <div class="row visible-xs-block">
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/contact">Contact</a></li>
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
      </div>
    </footer>
    
    <footer class="sponsor">
      <div class="container">
        <div class="row">
          <div class="col-sm-10 col-sm-offset-1">
            <p class="text-center">
              OpenReview is created by the <a href="http://www.iesl.cs.umass.edu/" target="_blank">Information Extraction and Synthesis Laboratory</a>, College of Information and Computer Science, University of Massachusetts Amherst. We gratefully acknowledge the support of the OpenReview sponsors:  Google,  Facebook, NSF, the University of Massachusetts Amherst Center for Data Science, and Center for Intelligent Information Retrieval, as well as the Google Cloud Platform for donating the computing and networking services on which OpenReview.net runs.
            </p>
          </div>
        </div>
      </div>
    </footer>

  <div id="feedback-modal" class="modal fade" tabindex="-1" role="dialog">
    <div class="modal-dialog">
      <div class="modal-content">
        <div class="modal-header">
          <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button>
          <h3 class="modal-title">Send Feedback</h3>
        </div>
        <div class="modal-body">
          <p>Enter your feedback below and we'll get back to you as soon as possible.</p>
          <form action="/feedback" method="POST">
            <div class="form-group">
              <input type="email" name="from" class="form-control" placeholder="Email" />
            </div>
            <div class="form-group">
              <input type="text" name="subject" class="form-control" placeholder="Subject" />
            </div>
            <div class="form-group">
              <textarea name="message" class="form-control feedback-input" rows="5" placeholder="Message" required=""></textarea>
            </div>
          <ul id="ui-id-2" tabindex="0" class="ui-menu ui-widget ui-widget-content" style="display: none;"></ul></form>
        </div>
        <div class="modal-footer">
          <button type="button" class="btn btn-default" data-dismiss="modal">Cancel</button>
          <button type="button" class="btn btn-primary">Send</button>
        </div>
      </div>
    </div>
  </div>

  <script type="text/javascript" async="" src="https://www.google-analytics.com/analytics.js"></script><script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js"></script>
  <script>window.jQuery || document.write('&lt;script src="/static/js/vendor/jquery-2.2.4.min.js"&gt;&lt;\/script&gt;')</script>

  <script src="/static/dist/vendor.min.js"></script>
  <script src="/static/dist/templates.min.js"></script>
  <script src="/static/dist/openreview.min.js"></script>

    <script>window.legacyScripts = true;</script>


    <script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-108703919-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() { dataLayer.push(arguments); }
      gtag('js', new Date());
      gtag('config', 'UA-108703919-1');
    </script>


<div role="status" aria-live="assertive" aria-relevant="additions" class="ui-helper-hidden-accessible"></div></body></html>
<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" class="no-js"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>Learning to Generate Parameters from Natural Languages for Graph Neural Networks | OpenReview</title>
  <meta name="description" content="" />

      <meta name="citation_title" content="Learning to Generate Parameters from Natural Languages for Graph Neural Networks" />
        <meta name="citation_author" content="Anonymous" />
      <meta name="citation_publication_date" content="2018/09/27" />
      <meta name="citation_online_date" content="2018/09/27" />
      <meta name="citation_pdf_url" content="https://openreview.net/pdf?id=SkgzYiRqtX" />
      <meta name="twitter:card" content="summary" />
      <meta name="twitter:site" content="@openreviewnet" />
      <meta name="og:title" content="Learning to Generate Parameters from Natural Languages for Graph..." />
      <meta name="og:description" content="Recently, progress has been made towards improving relational reasoning in machine learning field. Among existing models, graph neural networks (GNNs) is one of the most effective approaches for..." />
      <meta name="og:image" content="https://openreview.net/static/images/openreview_logo_512.png" />

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans:400,400i,700,700i" />

  <link rel="stylesheet" href="/static/css/bootstrap.min.css" />
  <link rel="stylesheet" href="/static/css/jquery-ui.min.css" />
  <link rel="stylesheet" href="/static/css/main.min.css" />
</head>

<body class="forum">
  <nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
  
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand home push-link" href="/"><strong>OpenReview</strong>.net</a>
      </div>
  
      <div id="navbar" class="navbar-collapse collapse">
        <form class="navbar-form navbar-left profile-search" role="search">
          <div class="form-group has-feedback">
            <input id="search_input" type="text" class="form-control ui-autocomplete-input" placeholder="Search ICLR 2019 Conference" autocomplete="off" />
            <span class="glyphicon glyphicon-search form-control-feedback" aria-hidden="true"></span>
          </div>
  
          <input id="search_group" type="hidden" value="ICLR.cc/2019/Conference" />
          <input id="search_content" type="hidden" value="all" />
        <ul id="ui-id-1" tabindex="0" class="ui-menu ui-widget ui-widget-content ui-autocomplete ui-front" style="display: none;"></ul></form>
  
        <ul class="nav navbar-nav navbar-right">
        
            <li id="user-menu"><a href="/login">Login</a></li>
        </ul>
      </div>
  
    </div>
  </nav>

  <div id="or-banner" class="banner" style="">
  <div class="container">
    <div class="row">
      <div class="col-xs-12"><a href="/group?id=ICLR.cc/2019/Conference" title="Venue Homepage"><img class="icon" src="/static/images/arrow_left.svg" /> Go to <strong>ICLR 2019 Conference</strong> homepage</a></div>
    </div>
  </div>
</div>
<div id="flash-message-container" class="alert alert-danger" role="alert" style="display: none;">
  <div class="container">
    <div class="row">
      <div class="col-xs-12">
        <div class="alert-content">
          <button type="button" class="close" aria-label="Close"><span aria-hidden="true">×</span></button>
        </div>
      </div>
    </div>
  </div>
</div>

<div class="container">
  <div class="row">
    <div class="col-xs-12">
      <main id="content" class="clearfix openbanner-visible legacy-styles"><div id="note_SkgzYiRqtX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Learning to Generate Parameters from Natural Languages for Graph Neural Networks</a> <a class="note_content_pdf" href="/pdf?id=SkgzYiRqtX" title="Download PDF" target="_blank"><img src="/static/images/pdf_icon_blue.svg" /></a> </h2></div><div class="meta_row"><span class="signatures">Anonymous</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">28 Sep 2018 (modified: 11 Oct 2018)</span><span class="item">ICLR 2019 Conference Blind Submission</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span><span class="item"><a class="action-bibtex-modal" data-bibtex="@inproceedings{    &#10;anonymous2019learning,    &#10;title={Learning to Generate Parameters from Natural Languages for Graph Neural Networks},    &#10;author={Anonymous},    &#10;booktitle={Submitted to International Conference on Learning Representations},    &#10;year={2019},    &#10;url={https://openreview.net/forum?id=SkgzYiRqtX},    &#10;note={under review}    &#10;}">Show Bibtex</a></span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Abstract: </span><span class="note_content_value">Recently, progress has been made towards improving relational reasoning in machine learning field. Among existing models, graph neural networks (GNNs) is one of the most effective approaches for multi-hop relational reasoning. In fact, multi-hop relational reasoning is indispensable in many natural language processing tasks such as relation extraction. In this paper, we propose to generate the parameters of graph neural networks (GP-GNNs) according to natural language sentences, which enables GNNs to process relational reasoning on unstructured text inputs. We verify GP-GNNs in relation extraction from text. Experimental results on a human-annotated dataset and two distantly supervised datasets show that our model achieves significant improvements compared to state-of-the-art baselines. We also perform a qualitative analysis to demonstrate that our model could discover more accurate relations by multi-hop relational reasoning.</span></div><div class="note_contents"><span class="note_content_field">Keywords: </span><span class="note_content_value">Graph Neural Networks, Relational Reasoning</span></div><div class="note_contents"><span class="note_content_field">TL;DR: </span><span class="note_content_value">A graph neural network model with parameters generated from natural languages, which can perform multi-hop reasoning. </span></div><div class="reply_row clearfix"><div class="item" id="reply_count">3 Replies</div></div></div><hr class="small" /><div id="note_children"><div class="note_with_children"><div id="note_HkekMdOihm" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Review</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=SkgzYiRqtX&amp;noteId=HkekMdOihm"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper424 AnonReviewer1</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">04 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper424 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">
This paper proposes a new model based on graph neural networks for relation extraction and evaluates it on multiple benchmarks and demonstrates its ability to do some level of “multi-hop relational reasoning”.

Although the empirical results look good and the paper might present some interesting and effective ideas, I find the paper very difficult to follow and many concepts are confusing (and even misleading).

Section 3-4:

- “l” is not defined -- I assume it denotes the number of tokens in the sentence but |s| is used in other places.
- Are “entires” and “entities” the same?
- a series of tokens =&gt; a sequence of tokens.
- Equation (5): “n” is not defined on the right of equation. Does this mean that different layers have LSTMs/MLPs with separate sets of parameters? If it is the case, why do you need the word embeddings at all the layers to construct the transition matrices? Please clarify. 
- Does BiLSTM return one vector or a sequence of l vectors? Even MLP needs to be defined.

In general I find the concept of “generated parameters” even confusing. How would traditional GNNs work in this context? Isn’t the novelty that parameterizing word/positional information in the transition matrix which enables a graph-based neural network working?

It would be very important to explain the intuition of this model and make the presentation clear and understandable. I don’t recommend this paper to be accepted in the current format.

The empirical results also make me wonder whether this model outperforms other models because the other models work on a single pair of entities while this model attempts to work on all pairs of entities at the same time so that it enables some level of reasoning at the entity level (e.g., language + cast member -&gt; language spoken in Figure 1). If this is the real contribution, the paper has to make it clear enough. 

Another related paper that needs to be cited:

- Zhang et al, 2018: Graph Convolution over Pruned Dependency Trees Improves Relation Extraction. EMNLP.




</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">4: Ok but not good enough - rejection</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_BJelhSgoh7" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>The paper describes a Graph NN method for information extraction from sentences. Some interesting innovations in the paper. The evaluation analysis and the comparison with other models are still preliminary.</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=SkgzYiRqtX&amp;noteId=BJelhSgoh7"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper424 AnonReviewer3</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">03 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper424 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">The paper describes a Graph NN method for information extraction from sentences. The objective is to label couples of entities (token or multiple tokens)  according to a given set of relations. The GNN processes token representations through one or more layers and a final classification layer scores the relations between entity couples in the sentence. Parameters of GNN – transition matrices between layers operating on node representations – are learned from the data.  Experiments are performed on different variants of an extraction corpus, for the task consisting in extracting all the relations between identified token couples in a sentence. 

The description is clear. The main original contribution is the scheme used for learning the transition matrices between layers from the text input.  Overall, the proposed system is a new mechanism for classifying relations between items in a sentence using GNN. Note that the current title is misleading w.r.t. this goal.
The authors claim that the model allows relational reasoning on text. This is somewhat exaggerated, the model performs relation classification and that’s it. There is nothing indicating any form of reasoning and this argument could be removed without reducing the value of the paper.

The experiments show that the proposed model outperforms, on this classification task baselines, including a recent model. The analysis here should be developed and improved: as it is, it does not provide much information.
Below are some questions concerning this evaluation.
Why not using mono sentence evaluation on the two distantly labeled datasets? 
The performance of the two CNN baselines on the hand labeled dataset are extremely low, what is the reason for that?
The improved performance of the proposed model w.r.t. the baselines is attributed to the “reasoning” potential of the model, but this explanation falls short. There is no fact in the paper to support this idea, and the Context-aware RE model making use of sentence attention has also the potential of exploiting contextual information and thus might also infer more complex relations. The reason for the improvement has to be found somewhere else.
Overall, there is some interesting innovation in the paper. The evaluation analysis and the comparison with other models are still preliminary.
</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">6: Marginally above acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">3: The reviewer is fairly confident that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_BJlOlHzcnm" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Good results, some questions</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=SkgzYiRqtX&amp;noteId=BJlOlHzcnm"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper424 AnonReviewer2</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">03 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper424 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">This work proposes a method for parametrising relation matrices in graph neural networks (GNNs) using text. The model is applied in a relation extraction task, and specific dataset subsections are identified to test and analyse “hopping” behaviour: a model’s ability to combine multiple relations for inferring a new one.

Strengths
- strong results
- testing on both bag-level / single-level relation extraction
- Insights via multiple ablations — variation of the number of layers, exploring densely connected data subsections with cycles to identify examples for multi-hop inference
- evaluation on new, human-annotated test set


Issues
- evaluation only on one task, and one dataset (although, with more detail).
- unclear how/why the specific result metrics and their particular range of precision are chosen. Why is F1/Acc only reported for the human-labelled part, but not for the distantly labelled part? Why is precision cut off at ~25% recall? A comprehensive aggregate measure across all levels of recall would be more informative, e.g. PR-AUC., and consistently applied in all experiments.
- task varies from previous versions of the task, posing a potential problem with comparability. What is the motivation behind augmenting the dataset with “NA” labels? Why is the task from previous work altered to predicting relationships between _every_ entity pair? Also unclear: is predicting “NA” actually part of the training loss, and of the evaluation? Is training of the previous “baseline” models adapted accordingly?
- some claims appear too bold and vague — see below.
- comparatively small modelling innovation
- There is similar prior work to this, most prominently Schlichtkrull et al. 2017 [<a href="https://arxiv.org/pdf/1703.06103.pdf]" target="_blank" rel="nofollow">https://arxiv.org/pdf/1703.06103.pdf]</a> who evaluate on Fb15k-237, but also De Cao et al. 2018 [https://arxiv.org/pdf/1808.09920.pdf, published within 1 month before ICLR submission deadline] who evaluate on Wikihop. These previous methods in fact do the following: “Most existing GNNs only process multi-hop relational reasoning on pre-defined graphs and cannot be directly applied in natural language relational reasoning.” It would be good to work out differences to these previous models in more detail, especially to Schlichtkrull et al. 2017.
- unclear how big the specific contribution of the language-generated matrices is. I would normally not obsess about such a baseline, but it seems that the “generate using NL” aspect is a core to the paper (even in the title), and this isn’t worked out clearly.


More comments / questions:
- “multi-hop relational reasoning is indispensable in many natural language processing tasks such as relation extraction”. This isn’t clear to me, “indispensable” is a very strong wording.
- “state-of-the-art baselines”. SOTA defines the best previous work. How can there be several baselines (plural) which are all best? What does SOTA mean when a slight redefinition of the task is proposed, as in this work?
- “Relation extraction from text is a classic natural language relational reasoning task” — reference would be useful. 
- not a big issue, though this does sound somewhat contradictory: 1) “the number of layers K is chosen to be of the order of the graph diameter”. 2) “We treat K as a hyperparameter”
- not clear: is LSTM indeed exactly the same as GP-GNN with K=1? I assume there is a difference, as the LSTM encodes the entire sentence at once, conditioning entity representations on their local context, whereas in GP-GNN this would not be the case.
- The distinction to Context-Aware RE (CARE) is not clear. The authors argue that CARE models co-occurrence of multiple relations, but is this not what a multi-hop relation extraction _should_ learn? It is also not clear how GP-GNN differs in this respect.
- It would be interesting to compare with a model which does not use language to define relation matrices (A), but learns them directly as parameters (independently from the text). 
- It would be interesting to see an analysis of the matrices A_{i,j}. What does the text generate, and how can one find this out? </span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">6: Marginally above acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></main></div>
  </div>
</div>


    <!-- Footer -->
    <footer class="sitemap">
      <div class="container">
        <div class="row hidden-xs">
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/venues">All Venues</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="/contact">Contact</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
    
        <div class="row visible-xs-block">
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/contact">Contact</a></li>
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
      </div>
    </footer>
    
    <footer class="sponsor">
      <div class="container">
        <div class="row">
          <div class="col-sm-10 col-sm-offset-1">
            <p class="text-center">
              OpenReview is created by the <a href="http://www.iesl.cs.umass.edu/" target="_blank">Information Extraction and Synthesis Laboratory</a>, College of Information and Computer Science, University of Massachusetts Amherst. We gratefully acknowledge the support of the OpenReview sponsors:  Google,  Facebook, NSF, the University of Massachusetts Amherst Center for Data Science, and Center for Intelligent Information Retrieval, as well as the Google Cloud Platform for donating the computing and networking services on which OpenReview.net runs.
            </p>
          </div>
        </div>
      </div>
    </footer>

  <div id="feedback-modal" class="modal fade" tabindex="-1" role="dialog">
    <div class="modal-dialog">
      <div class="modal-content">
        <div class="modal-header">
          <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button>
          <h3 class="modal-title">Send Feedback</h3>
        </div>
        <div class="modal-body">
          <p>Enter your feedback below and we'll get back to you as soon as possible.</p>
          <form action="/feedback" method="POST">
            <div class="form-group">
              <input type="email" name="from" class="form-control" placeholder="Email" />
            </div>
            <div class="form-group">
              <input type="text" name="subject" class="form-control" placeholder="Subject" />
            </div>
            <div class="form-group">
              <textarea name="message" class="form-control feedback-input" rows="5" placeholder="Message" required=""></textarea>
            </div>
          <ul id="ui-id-2" tabindex="0" class="ui-menu ui-widget ui-widget-content" style="display: none;"></ul></form>
        </div>
        <div class="modal-footer">
          <button type="button" class="btn btn-default" data-dismiss="modal">Cancel</button>
          <button type="button" class="btn btn-primary">Send</button>
        </div>
      </div>
    </div>
  </div>

  <script type="text/javascript" async="" src="https://www.google-analytics.com/analytics.js"></script><script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js"></script>
  <script>window.jQuery || document.write('&lt;script src="/static/js/vendor/jquery-2.2.4.min.js"&gt;&lt;\/script&gt;')</script>

  <script src="/static/dist/vendor.min.js"></script>
  <script src="/static/dist/templates.min.js"></script>
  <script src="/static/dist/openreview.min.js"></script>

    <script>window.legacyScripts = true;</script>


    <script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-108703919-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() { dataLayer.push(arguments); }
      gtag('js', new Date());
      gtag('config', 'UA-108703919-1');
    </script>


<div role="status" aria-live="assertive" aria-relevant="additions" class="ui-helper-hidden-accessible"></div></body></html>
<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" class="no-js"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>Deterministic Variational Inference for Robust Bayesian Neural Networks | OpenReview</title>
  <meta name="description" content="" />

      <meta name="citation_title" content="Deterministic Variational Inference for Robust Bayesian Neural Networks" />
        <meta name="citation_author" content="Anonymous" />
      <meta name="citation_publication_date" content="2018/09/27" />
      <meta name="citation_online_date" content="2018/09/27" />
      <meta name="citation_pdf_url" content="https://openreview.net/pdf?id=B1l08oAct7" />
      <meta name="twitter:card" content="summary" />
      <meta name="twitter:site" content="@openreviewnet" />
      <meta name="og:title" content="Deterministic Variational Inference for Robust Bayesian Neural..." />
      <meta name="og:description" content="Bayesian neural networks (BNNs) hold great promise as a flexible and principled solution to deal with uncertainty when learning from finite data. Among approaches to realize probabilistic inference..." />
      <meta name="og:image" content="https://openreview.net/static/images/openreview_logo_512.png" />

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans:400,400i,700,700i" />

  <link rel="stylesheet" href="/static/css/bootstrap.min.css" />
  <link rel="stylesheet" href="/static/css/jquery-ui.min.css" />
  <link rel="stylesheet" href="/static/css/main.min.css" />
</head>

<body class="forum">
  <nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
  
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand home push-link" href="/"><strong>OpenReview</strong>.net</a>
      </div>
  
      <div id="navbar" class="navbar-collapse collapse">
        <form class="navbar-form navbar-left profile-search" role="search">
          <div class="form-group has-feedback">
            <input id="search_input" type="text" class="form-control ui-autocomplete-input" placeholder="Search ICLR 2019 Conference" autocomplete="off" />
            <span class="glyphicon glyphicon-search form-control-feedback" aria-hidden="true"></span>
          </div>
  
          <input id="search_group" type="hidden" value="ICLR.cc/2019/Conference" />
          <input id="search_content" type="hidden" value="all" />
        <ul id="ui-id-1" tabindex="0" class="ui-menu ui-widget ui-widget-content ui-autocomplete ui-front" style="display: none;"></ul></form>
  
        <ul class="nav navbar-nav navbar-right">
        
            <li id="user-menu"><a href="/login">Login</a></li>
        </ul>
      </div>
  
    </div>
  </nav>

  <div id="or-banner" class="banner" style="">
  <div class="container">
    <div class="row">
      <div class="col-xs-12"><a href="/group?id=ICLR.cc/2019/Conference" title="Venue Homepage"><img class="icon" src="/static/images/arrow_left.svg" /> Go to <strong>ICLR 2019 Conference</strong> homepage</a></div>
    </div>
  </div>
</div>
<div id="flash-message-container" class="alert alert-danger" role="alert" style="display: none;">
  <div class="container">
    <div class="row">
      <div class="col-xs-12">
        <div class="alert-content">
          <button type="button" class="close" aria-label="Close"><span aria-hidden="true">×</span></button>
        </div>
      </div>
    </div>
  </div>
</div>

<div class="container">
  <div class="row">
    <div class="col-xs-12">
      <main id="content" class="clearfix openbanner-visible legacy-styles"><div id="note_B1l08oAct7" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Deterministic Variational Inference for Robust Bayesian Neural Networks</a> <a class="note_content_pdf" href="/pdf?id=B1l08oAct7" title="Download PDF" target="_blank"><img src="/static/images/pdf_icon_blue.svg" /></a> </h2></div><div class="meta_row"><span class="signatures">Anonymous</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">28 Sep 2018 (modified: 19 Nov 2018)</span><span class="item">ICLR 2019 Conference Blind Submission</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span><span class="item"><a class="action-bibtex-modal" data-bibtex="@inproceedings{    &#10;anonymous2019fixing,    &#10;title={Fixing Variational Bayes: Deterministic Variational Inference for Bayesian Neural Networks},    &#10;author={Anonymous},    &#10;booktitle={Submitted to International Conference on Learning Representations},    &#10;year={2019},    &#10;url={https://openreview.net/forum?id=B1l08oAct7},    &#10;note={under review}    &#10;}">Show Bibtex</a></span><a class="note_content_pdf item" href="/revisions?id=B1l08oAct7" target="_blank">Show Revisions</a></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Abstract: </span><span class="note_content_value">Bayesian neural networks (BNNs) hold great promise as a flexible and principled solution to deal with uncertainty when learning from finite data. Among approaches to realize probabilistic inference in deep neural networks, variational Bayes (VB) is theoretically grounded, generally applicable, and computationally efficient. With wide recognition of potential advantages, why is it that variational Bayes has seen very limited practical use for BNNs in real applications? We argue that variational inference in neural networks is fragile: successful implementations require careful initialization and tuning of prior variances, as well as controlling the variance of Monte Carlo gradient estimates. We provide two innovations that aim to turn VB into a robust inference tool for Bayesian neural networks: first, we introduce a novel deterministic method to approximate moments in neural networks, eliminating gradient variance; second, we introduce a hierarchical prior for parameters and a novel Empirical Bayes procedure for automatically selecting prior variances. Combining these two innovations, the resulting method is highly efficient and robust. On the application of heteroscedastic regression we demonstrate good predictive performance over alternative approaches.</span></div><div class="note_contents"><span class="note_content_field">Keywords: </span><span class="note_content_value">Bayesian neural network, variational inference, variational bayes, variance reduction, empirical bayes</span></div><div class="note_contents"><span class="note_content_field">TL;DR: </span><span class="note_content_value">A method for eliminating gradient variance and automatically tuning priors for effective training of bayesian neural networks</span></div><div class="reply_row clearfix"><div class="item" id="reply_count">6 Replies</div></div></div><hr class="small" /><div id="note_children"><div class="note_with_children"><div id="note_H1eOIrXYhm" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>An interesting paper </a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=B1l08oAct7&amp;noteId=H1eOIrXYhm"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper220 AnonReviewer3</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">02 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper220 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">The authors propose a new approach to perform deterministic variational inference for feed-forward BNN with specific nonlinear activation functions by approximating layerwise moments. Under certain conditions, the authors show that the proposed method achieves better performance than existing Monte Carlo variational inference. This paper is interesting since most of the existing works focus on Monte Carlo variational inference. The main contribution of this paper is to perform Gaussian approximation. The authors show that for specific activation functions, the Gaussian approximation is reasonable. The main concern is the cumulative error due to the Gaussian approximation. Since the authors argue that the proposed method fixes the issues of stochastic VI for BNN, the authors should also investigate/clarify the following cases. 
(1)  A deep BNN to show that the cumulative error is negligible as the number of the hidden layers increases 
(2)  Small latent dimension since CLT may not hold
(3)  A heavy-tailed variational distribution since the second moment may not be finite 
(4)  Other nonlinear activations since the Gaussian approximation may not be accurate due to (generalized) Berry-Esseen theorem
(5) A BNN with skip connections  since a Bayesian multiplayer perceptron with skip connections is also a feed-forward BNN
 
Among these cases, I am eager to see some results on a deep thin BNN. For example, a BNN with 5 hidden layers, where the latent dimension at each layer is less than 32. 
Furthermore, I would like to see some empirical comparison on real-world datasets between DVI and MCVI under a *fixed* prior since such comparison demonstrates the approximation accuracy of DVI and rule out the confounding factor introduced by the empirical Bayes approach.

</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">6: Marginally above acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">3: The reviewer is fairly confident that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_rJex4YNeCQ" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Revisions to address requests</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=B1l08oAct7&amp;noteId=rJex4YNeCQ"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper220 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">19 Nov 2018</span><span class="item">ICLR 2019 Conference Paper220 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Thank you for your great recommendations for additional studies. We created some new sections when replying to your questions that are good improvements to the paper:

&gt; (1) A deep BNN to show that the cumulative error is negligible as the number of the hidden layers increases
&gt; (2) Small latent dimension since CLT may not hold … I am eager to see some results on a deep thin BNN. For example, a BNN with 5 hidden layers, where the latent dimension at each layer is less than 32

We have added a new Appendix C that studies deeper neural networks:
To address request (1), we studied a 5-layer, 125-unit network, and we observe good fits to data and qualitatively good agreement of our Gaussian approximation with Monte Carlo (MC) simulation using 20k samples (see the new figure 6a)
To address request (2) we additionally study a 5-layer, 25-unit network, and we again see good fits and qualitatively reasonable performance of our approximation (figure 6b). For completeness, we include an extreme case: 5-layers, 5-units. In this extreme case we do see we see significantly non-Gaussian output distributions in MC simulation due to failure of the central limit theorem underlying our approximations. Since such narrow networks are not of significant practical importance, we do not see this as a major problem with our method.
We thank the reviewer for recommending these studies – including a demonstration that failure cases only arise in impractically narrow architectures helps to justify our use of the CLT.

&gt; (3) A heavy-tailed variational distribution since the second moment may not be finite

The reviewer is correct that our method relies on a variational distribution with finite first and second moments, for which the CLT holds. We have added clarification of these necessary conditions in the text. Note that *only* the first and second moments of the variational distribution are required to compute the reconstruction log-probability in the ELBO (i.e. only &lt;W&gt; and Cov(W,W) appear in equation 3). The precise form of the variational distribution is only required to evaluate the KL term in the ELBO, and therefore it is easy to apply our method to any variational family with finite moments which has a closed form KL with a suitable prior.

&gt; (4) Other nonlinear activations since the Gaussian approximation may not be accurate due to (generalized) Berry-Esseen theorem

We provide results on the Heaviside and ReLU nonlinearities. Other useful and commonly deployed nonlinearities are (generally speaking) “softened” and translated versions of either a Heaviside or ReLU nonlinearity (e.g. tanh is a soft Heaviside and elu is a soft ReLU). Note that the nonlinearity only appears in equations 4 and 5, where it is being convolved with the Gaussian activation distribution. Since this convolution already softens the hard nonlinearities (e.g. see the smooth functions plotted in figure 2), changes in the intrinsic the softness of the underlying nonlinearity are qualitatively equivalent to using a hard nonlinearity and adjusting the convolving Gaussian covariance. For this reason, we do not think there will be considerable benefit from exploring other nonlinearities. We believe that any gain is likely not worth the considerable work required to find closed form approximations for the integrals in 4 and 5 for arbitrary nonlinearities.

&gt; (5) A BNN with skip connections since a Bayesian multiplayer perceptron with skip connections is also a feed-forward BNN

This was fairly simple to add to our method, and we thank the reviewer for suggesting this nice addition. Specifically, we have added derivations of the integral results required to implement a network with skip connections in a new Appendix C.1 and include a figure showing that our approximation works in a deep network with skip connections in Fig 6d.

&gt; I would like to see some empirical comparison on real-world datasets between DVI and MCVI under a *fixed* prior since such comparison demonstrates the approximation accuracy of DVI and rule out the confounding factor introduced by the empirical Bayes approach.

We have added section D.1 and Table 5 to the appendix to give an ablation study corresponding to all combinations of DVI or MCVI with fixed or EB priors. Note that when running with a fixed prior, we select the best prior variance by a separate hyperparameter sweep on each dataset (cf. figure 5). Besides eliminating this tuning overhead, EB maintains a small performance advantage over manual tuning because it automatically finds different prior variances for each weight matrix, whereas we only manually tune the global fixed prior variance.
</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div><div class="note_with_children"><div id="note_H1g0a1ir2Q" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Fixing Variational Bayes: Deterministic Variational Inference for Bayesian Neural Networks</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=B1l08oAct7&amp;noteId=H1g0a1ir2Q"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper220 AnonReviewer1</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">30 Oct 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper220 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">This paper considers a purely deterministic approach to learning variational posterior approximations for Bayesian neural networks.  Variational lower bound gradients are obtained by approximating the lower bound using Gaussian approximations and moment propagation for network activations, and using a closed form expression for the variational expectation of the log-likelihood, the latter being available for the models considered in the paper.  

This is an interesting paper.  The Gaussian approximations and moment propagation approximations are clever and highly original although the derivation is rather heuristic.  There is some empirical support that the approximations work well.  The paper is generally well written and clearly motivated in the context of the existing literature.

The approximations work well for the examples presented in the paper.  The experiments are for rather small datasets and for the DVI method if I understand correctly only models with a single hidden layer are considered.  I wonder if the Gaussian and moment propagation approximations cause difficulty when applied repeatedly in deeper networks.  Are the problems with MCVI and high gradient variance most serious for large datasets and more complex models?  If so a comparison of DVI with MCVI in a more complex example is of interest.  The empirical Bayes approximations are interesting - I would have thought similar approximations been used in the literature before, in addition to the work you mention in Section 5?  I don't feel there is much to compare the proposed EB approximations to, although a comparison with manual tuning is given in Section 6.  

</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">7: Good paper, accept</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">3: The reviewer is fairly confident that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_HJxcV9EgRX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Response to review questions</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=B1l08oAct7&amp;noteId=HJxcV9EgRX"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper220 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">19 Nov 2018</span><span class="item">ICLR 2019 Conference Paper220 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Thank you for your kind review and suggestions for additional studies. We address specific questions below with reference to new sections in the paper.

&gt; I wonder if the Gaussian and moment propagation approximations cause difficulty when applied repeatedly in deeper networks

We have added a new Appendix C that studies deeper neural networks. We also include a 5-layer, 125-unit network (“deep, wide”), 5-layer, 25-unit network (“deep, narrow”) and a 5-layer, 5-unit network (“deep and impractically narrow”). For the practically relevant 25- and 125-unit cases, we observe good fits to data and qualitatively good agreement of our approximation with Monte Carlo (MC) simulation using 20k samples. For the extremely narrow 5-unit case we see significantly non-Gaussian output distributions in MC simulation due to failure of the central limit theorem underlying our approximations. These experiments cover the range of behaviour expected in our method and demonstrate that our method does work for deep networks in the practically relevant regime where at least a few tens of hidden units are used. In addition, we have derived the required results to incorporate skip connections into our method to help training on even deeper networks. All of these results are summarized in figure 6.

&gt; Are the problems with MCVI and high gradient variance most serious for large datasets and more complex models? If so a comparison of DVI with MCVI in a more complex example is of interest.

Our evaluation focuses on assessing the robustness of the new methods and how automatic they are. The experiments do consider nine different datasets (containing up to 45k examples), in accordance with established practice for evaluating new approximate inference methods for BNNs (see e.g. [1,2,3]). Crucially we evaluate the proposed methods using many different model variants (hetero vs homoscedastic, MC vs different deterministic approximations, different prior settings, various methods for parameterising the variance, etc.). In this way we have prioritized a comprehensive assessment of the myriad design decisions, rather than assessing a relatively small number of design decisions on a larger number of datasets. Whilst we acknowledge that since the benchmarks are relatively simple this work is just a first step of a completely comprehensive evaluation, we believe that the experiments provide a solid foundation for this longer-term enterprise. 

&gt; I don't feel there is much to compare the proposed EB approximations to, although a comparison with manual tuning is given in Section 6.

To complement our comparison with manual tuning, we have added section D.1 and Table 5 to the appendix to give an ablation study corresponding to all combinations of DVI or MCVI with fixed or EB priors. Note that when running with a fixed prior, we select the best prior variance by a separate hyperparameter sweep on each dataset (cf. figure 5). Besides eliminating this tuning overhead, EB maintains a small performance advantage over manual tuning because it automatically finds different prior variances for each weight matrix, whereas we only manually tune the global fixed prior variance.

[1] Deep Gaussian Processes for Regression using Approximate Expectation Propagation. Thang Bui, José Miguel Hernández-Lobato, Yingzhen Li, Daniel Hernández-Lobato, and Rich Turner 
ICML 2016 
[2] Black-box alpha-divergence minimization José Miguel Hernández-Lobato, Yingzhen Li, Mark Rowland, Daniel Hernández-Lobato, Thang Bui, and Rich Turner 
ICML 2016
[3] Simple and Scalable Predictive Uncertainty Estimation using Deep Ensembles Balaji Lakshminarayanan, Alexander Pritzel, Charles Blundell, NIPS 2017
</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div><div class="note_with_children"><div id="note_rJexO5ZynQ" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Two advances for variational Bayes on neural networks. Expectations are done deterministically (as in PBP), not by Monte Carlo, thus reducing variance. The weight prior is learned with length scales by empirical Bayes. Both should make VB training more robust, but experiments do not show that.</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=B1l08oAct7&amp;noteId=rJexO5ZynQ"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper220 AnonReviewer2</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">25 Oct 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper220 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">Summary:

This work is tackling two difficulties in current VB applied to DNNs ("Bayes by backprop"). First, MC approximations of intractable expectations are replaced by deterministic approximations. While this has been done before, the solution here is new and very interesting. Second, a Gaussian prior with length scales is learned by VB empirical Bayes alongside the normal training, which is also very useful.

The term "fixing VB" and some of the intro is not really supported by the rather weak experiments, done on small datasets and networks, where much older work like Barber&amp;Bishop would apply without any problems. While interesting and potentially very useful novelties are presented, and the writing is excellent, both experiments and motivation can be improved.

- Quality: Extremely well written paper, I learned a lot from it. Approximations are
   tested, great figures to explain things. And the major technical novelty, the
   expression for &lt;h_j h_l&gt;, is really interesting and useful.
- Clarity: Excellent writing until it comes to the experiments. Here, important
   details are just missing, for example what q(w) is (fully factorized Gaussian?).
   Very nice literature review, also historical.
- Originality: The idea of matching Gaussian moments along the network graph is
   previously done in PBP (Lobato, Adams), as acknowledged here. Porting this from
   ADF to VB gives dDVI. PBP also has the property that a DL system gives you the
   gradients. Having said that, I think dDVI may be more useful than PBP.
   While Barber&amp;BIshop 98 is cited, they miss the expression for &lt;h_j h_l&gt; in
   there. Now, what is done here, is more elegant, does not need 1D quadrature.
- Significance: Judging from the existing experiments, the significance may be
   rather small, *if one only looks at test log likelihood*. I'd still give this the
   benefit of the doubt, as in particular dDVI could be really interesting at large
   scale as well. But the authors may tone down their language a bit.
   To increase significance, I recommend to comment beyond just test log
   likelihood scores. For example:
   - Does the optimization become simpler, less tuning required, more automatic?
      Would one not expect so, given you make a big point out of reducing variance?
      Does it converge faster?
   - Can you do something with your posterior that normal DNN methods cannot
      do? Better decisions (bandits, active learning, HPO)? Continual learning?
      In the end, who really cares about test log likelihood?

Experiments:
- What is the q(w) family being used here? Fully factorized Gaussian? I
   suppose so for dDVI. But for DVI? Not said anywhere, in main paper or
   Appendix
- A bit disappointing. Why not evaluate at least dDVI with diagonal q(w) on
   some much larger models and datasets? Why not quote numbers on speed
   and robustness of learning, etc? Show what you really gain by reducing the
   variance.
- Experiments are OK, but on pretty small datasets, and for single hidden
   layer NNs. On such data and models, the Barber&amp;Bishop 98 method could
   be run as well
- Was MCVI run with re-parameterization? This is really important. If not,
   this would be an important missing comparison. Please be clear in the main
   text
- Advantages over MCVI are not very large. At least, dDVI should be faster to
   converge than MCVI.
   Can you say something about robustness of training? Is it easier to train
   dDVI than MCVI?
- Why not show the PBP-1 results, comparing to dDVI, in the main text? Are they
   obtained with the same model? dDVI is doing better.

Other points:
- Please acknowledge the &lt;h_j h_l&gt; expression in Barber&amp;Bishop 98. Yours is
   more elegant and faster (does not need 1D quadrature)
- Relation to PBP: Note that dDVI has an advantage in practice. With PBP, I need
   to compute gradients for every datapoint. In dDVI, I can do mini-batch
   updates.
- I just *love* the header "Wild approximations". I tend to refer to this kind of work
   as "weak analogies". Why do you not also compare against this, and show it really
   does not work?
</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">7: Good paper, accept</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_HyeV1yHgAm" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Response to reviewer questions</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=B1l08oAct7&amp;noteId=HyeV1yHgAm"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper220 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">19 Nov 2018</span><span class="item">ICLR 2019 Conference Paper220 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Thank you for your detailed and enthusiastic review. We have updated the paper and address specific questions below

&gt; The term "fixing VB" and some of the intro is not really supported… the authors may tone down their language a bit.

We have removed “fixing VB” from the title and removed strong phrases in the abstract and introduction.

&gt; While Barber&amp;BIshop 98 is cited, they miss the expression for &lt;h_j h_l&gt; in there. Now, what is done here, is more elegant, does not need 1D quadrature.

We have added these comments to our related work section.

&gt; Can you do something with your posterior that normal DNN methods cannot do?

Standard training of DNNs which returns point-parameter estimates (i) results in poorly calibrated predictive uncertainty estimates (notably predictions are often confidently wrong), (ii) does not support model-based sequential decision making (e.g. active learning), and (iii) suffers from catastrophic forgetting when trained in the continual learning setting. BNNs have been shown to substantially improve upon standard models / training in these three settings (see e.g. [1,2,3]). The new innovations proposed in this paper will be applied to these areas in future work. In the second two application areas – sequential decision making and continual learning – approximate Bayesian inference must be run as an inner loop of a larger algorithm. This requires a robust and automated version of BNN training: this is precisely where we believe the innovations in this paper will have large impact since they pave the way to automated and robust deployment of BBNs that do not involve an expert in-the-loop. We have included these points as motivational future work items in the paper conclusion.

&gt; what is q(w) [the variational family used in the experiments]?

Our method is not limited to fully factorized Gaussian variational distributions (any distribution with a tractable first and second moment could be used). However, for computational simplicity, our experiments do use a fully factorized Gaussian q(w). We have added this detail to the experimental section.

&gt; Why not evaluate at least dDVI with diagonal q(w) on some much larger models and datasets? 

We have added an appendix C that evaluates the performance of DVI in larger models including deep networks with skip connections. Regarding larger datasets, our evaluation focuses on assessing the robustness of the new methods and how automatic they are. The experiments do consider nine different datasets, following established practice for evaluating new approximate inference methods for BNNs (see e.g. [4,5,6]). We evaluate the proposed methods using many of different model variants (hetero vs homoscedastic, MC vs different deterministic approximations, different prior settings, various methods for parameterising the variance, etc.). In this way we have prioritized a comprehensive assessment of the myriad design decisions, rather than assessing a relatively small number of design decisions on a larger number of datasets. Whilst we acknowledge that since the benchmarks are relatively simple this work is just a first step of a completely comprehensive evaluation, we believe that the experiments provide a solid foundation for this longer-term enterprise. 

&gt; Was MCVI run with re-parameterization? 

We run vanilla MCVI, and re-parameterization is discussed in section E of the appendix and results using re-parameterization appear in Table 3. We have added this clarification and pointers to section E in the main text.

&gt; Relation to PBP: Note that dDVI has an advantage in practice… Why not show the PBP-1 results, comparing to dDVI, in the main text? Are they obtained with the same model? dDVI is doing better.

Table 3 is too large to be included in the main text and although we perform comparison with PBP using the same model, we don’t want to move the results to the main text because our method has clear qualitative advantages over PBP as you highlight: 1) we handle batches of data and do not have to process one data point at a time, 2) we account for correlations in the forward pass and in the posterior distribution and 3) we can account for heteroskedastic noise. We have clarified these advantages in the related work section.

&gt; Compare against [dropout-like methods], and show it really does not work?

Our extended results table (Table 3) in the appendix includes results using dropout.

[1] Known Unknowns: Uncertainty Quality in BNNs, R Oliveira et al., NIPS BDL workshop 2016 
[2] Deep Bayesian Active Learning with Image Data, Y Gal et al., PMLR 70:1183-1192, 2017
[3] Variational Continual Learning CV Nguyen et al. ICLR 2018
[4] Deep Gaussian Processes for Regression using Approximate Expectation Propagation. T Bui, et al. ICML 2016 
[5] Black-box alpha-divergence minimization JM Hernández-Lobato et al., ICML 2016
[6] Simple and Scalable Predictive Uncertainty Estimation using Deep Ensembles B Lakshminarayanan, et al., NIPS 2017</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div></div></main></div>
  </div>
</div>


    <!-- Footer -->
    <footer class="sitemap">
      <div class="container">
        <div class="row hidden-xs">
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/venues">All Venues</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="/contact">Contact</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
    
        <div class="row visible-xs-block">
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/contact">Contact</a></li>
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
      </div>
    </footer>
    
    <footer class="sponsor">
      <div class="container">
        <div class="row">
          <div class="col-sm-10 col-sm-offset-1">
            <p class="text-center">
              OpenReview is created by the <a href="http://www.iesl.cs.umass.edu/" target="_blank">Information Extraction and Synthesis Laboratory</a>, College of Information and Computer Science, University of Massachusetts Amherst. We gratefully acknowledge the support of the OpenReview sponsors:  Google,  Facebook, NSF, the University of Massachusetts Amherst Center for Data Science, and Center for Intelligent Information Retrieval, as well as the Google Cloud Platform for donating the computing and networking services on which OpenReview.net runs.
            </p>
          </div>
        </div>
      </div>
    </footer>

  <div id="feedback-modal" class="modal fade" tabindex="-1" role="dialog">
    <div class="modal-dialog">
      <div class="modal-content">
        <div class="modal-header">
          <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button>
          <h3 class="modal-title">Send Feedback</h3>
        </div>
        <div class="modal-body">
          <p>Enter your feedback below and we'll get back to you as soon as possible.</p>
          <form action="/feedback" method="POST">
            <div class="form-group">
              <input type="email" name="from" class="form-control" placeholder="Email" />
            </div>
            <div class="form-group">
              <input type="text" name="subject" class="form-control" placeholder="Subject" />
            </div>
            <div class="form-group">
              <textarea name="message" class="form-control feedback-input" rows="5" placeholder="Message" required=""></textarea>
            </div>
          <ul id="ui-id-2" tabindex="0" class="ui-menu ui-widget ui-widget-content" style="display: none;"></ul></form>
        </div>
        <div class="modal-footer">
          <button type="button" class="btn btn-default" data-dismiss="modal">Cancel</button>
          <button type="button" class="btn btn-primary">Send</button>
        </div>
      </div>
    </div>
  </div>

  <script type="text/javascript" async="" src="https://www.google-analytics.com/analytics.js"></script><script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js"></script>
  <script>window.jQuery || document.write('&lt;script src="/static/js/vendor/jquery-2.2.4.min.js"&gt;&lt;\/script&gt;')</script>

  <script src="/static/dist/vendor.min.js"></script>
  <script src="/static/dist/templates.min.js"></script>
  <script src="/static/dist/openreview.min.js"></script>

    <script>window.legacyScripts = true;</script>


    <script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-108703919-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() { dataLayer.push(arguments); }
      gtag('js', new Date());
      gtag('config', 'UA-108703919-1');
    </script>


<div role="status" aria-live="assertive" aria-relevant="additions" class="ui-helper-hidden-accessible"></div></body></html>
<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" class="no-js"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>Auto-Encoding Knockoff Generator for FDR  Controlled Variable Selection | OpenReview</title>
  <meta name="description" content="" />

      <meta name="citation_title" content="Auto-Encoding Knockoff Generator for FDR  Controlled Variable Selection" />
        <meta name="citation_author" content="Anonymous" />
      <meta name="citation_publication_date" content="2018/09/27" />
      <meta name="citation_online_date" content="2018/09/27" />
      <meta name="citation_pdf_url" content="https://openreview.net/pdf?id=rkxfjjA5Km" />
      <meta name="twitter:card" content="summary" />
      <meta name="twitter:site" content="@openreviewnet" />
      <meta name="og:title" content="Auto-Encoding Knockoff Generator for FDR  Controlled Variable..." />
      <meta name="og:description" content="A new statistical procedure (Candès,2018) has provided a way to identify important factors using any supervised learning method controlling for FDR. This line of research has shown great potential..." />
      <meta name="og:image" content="https://openreview.net/static/images/openreview_logo_512.png" />

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans:400,400i,700,700i" />

  <link rel="stylesheet" href="/static/css/bootstrap.min.css" />
  <link rel="stylesheet" href="/static/css/jquery-ui.min.css" />
  <link rel="stylesheet" href="/static/css/main.min.css" />
</head>

<body class="forum">
  <nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
  
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand home push-link" href="/"><strong>OpenReview</strong>.net</a>
      </div>
  
      <div id="navbar" class="navbar-collapse collapse">
        <form class="navbar-form navbar-left profile-search" role="search">
          <div class="form-group has-feedback">
            <input id="search_input" type="text" class="form-control ui-autocomplete-input" placeholder="Search ICLR 2019 Conference" autocomplete="off" />
            <span class="glyphicon glyphicon-search form-control-feedback" aria-hidden="true"></span>
          </div>
  
          <input id="search_group" type="hidden" value="ICLR.cc/2019/Conference" />
          <input id="search_content" type="hidden" value="all" />
        <ul id="ui-id-1" tabindex="0" class="ui-menu ui-widget ui-widget-content ui-autocomplete ui-front" style="display: none;"></ul></form>
  
        <ul class="nav navbar-nav navbar-right">
        
            <li id="user-menu"><a href="/login">Login</a></li>
        </ul>
      </div>
  
    </div>
  </nav>

  <div id="or-banner" class="banner" style="">
  <div class="container">
    <div class="row">
      <div class="col-xs-12"><a href="/group?id=ICLR.cc/2019/Conference" title="Venue Homepage"><img class="icon" src="/static/images/arrow_left.svg" /> Go to <strong>ICLR 2019 Conference</strong> homepage</a></div>
    </div>
  </div>
</div>
<div id="flash-message-container" class="alert alert-danger" role="alert" style="display: none;">
  <div class="container">
    <div class="row">
      <div class="col-xs-12">
        <div class="alert-content">
          <button type="button" class="close" aria-label="Close"><span aria-hidden="true">×</span></button>
        </div>
      </div>
    </div>
  </div>
</div>

<div class="container">
  <div class="row">
    <div class="col-xs-12">
      <main id="content" class="clearfix openbanner-visible legacy-styles"><div id="note_rkxfjjA5Km" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Auto-Encoding Knockoff Generator for FDR  Controlled Variable Selection</a> <a class="note_content_pdf" href="/pdf?id=rkxfjjA5Km" title="Download PDF" target="_blank"><img src="/static/images/pdf_icon_blue.svg" /></a> </h2></div><div class="meta_row"><span class="signatures">Anonymous</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">28 Sep 2018 (modified: 19 Nov 2018)</span><span class="item">ICLR 2019 Conference Blind Submission</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span><span class="item"><a class="action-bibtex-modal" data-bibtex="@inproceedings{    &#10;anonymous2019auto-encoding,    &#10;title={Auto-Encoding Knockoff Generator for FDR  Controlled Variable Selection},    &#10;author={Anonymous},    &#10;booktitle={Submitted to International Conference on Learning Representations},    &#10;year={2019},    &#10;url={https://openreview.net/forum?id=rkxfjjA5Km},    &#10;note={under review}    &#10;}">Show Bibtex</a></span><a class="note_content_pdf item" href="/revisions?id=rkxfjjA5Km" target="_blank">Show Revisions</a></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Abstract: </span><span class="note_content_value">A new statistical procedure (Candès,2018) has provided a way to identify important factors using any supervised learning method controlling for FDR. This line of research has shown great potential to expand the horizon of machine learning methods beyond the task of prediction, to serve the broader need for scientific researches for interpretable findings. However, the lack of a practical and flexible method to generate knockoffs remains the major obstacle for wide application of  Model-X procedure. This paper fills in the gap by proposing a model-free knockoff generator which approximates the correlation structure between features through latent variable representation. We demonstrate our proposed method can achieve FDR control and better power than two existing methods in various simulated settings and a real data example for finding mutations associated with drug resistance in HIV-1 patients.

</span></div><div class="note_contents"><span class="note_content_field">Keywords: </span><span class="note_content_value">Model-X Knockoff Generator, model-free FDR control, variable selection</span></div><div class="note_contents"><span class="note_content_field">TL;DR: </span><span class="note_content_value">This paper provide model free method for generating Knockoffs, which is critical step in Model-X procedure to choose important variables with any supervised learning method under rigorous FDR control.</span></div><div class="reply_row clearfix"><div class="item" id="reply_count">10 Replies</div></div></div><hr class="small" /><div id="note_children"><div class="note_with_children"><div id="note_SyeHB4cKnm" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>The presentation of this paper can be improved. The notation is not very clear. </a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=rkxfjjA5Km&amp;noteId=SyeHB4cKnm"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper602 AnonReviewer3</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">02 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper602 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">This paper proposes a new approach to construct model-X knockoffs based on VAE, which can be used for controlling the false discovery rate. Both numerical simulations and real-data experiments are provided to corroborate the proposed method.  

Although the problem of generating knockoffs based on VAE is novel, the paper presentation is not easy to follow and the notation seems confusing. Moreover, the main idea of this paper seems not entirely novel. The proposed method is based on combining the analysis in ''Robust inference with knockoffs'' by Barber et. al. and the VAE.  

Detailed comments:

1. The presentation of the main results is a bit short. Section 2, the proposed method, only takes 2 pages. It would be better to present the main results with more details. 

2. The method works under the assumption that there exists a random variable $Z$ such that $X_j$'s are mutually independent conditioning on $Z$. Is this a strong assumption? It seems better to illustrate when this assumption holds and fails.

3. The notation of this paper seems confusing. For example, the authors did not introduce what $(X_j, X_{-j}, \tilde X_j, \tilde X_{-j} )$ means. Moreover, in Algorithm 1, what is $\hat \theta$ and $\hat f$. 

4. I think there might be a typo in the proof of Theorem 2.1. In the main equation, why $\tilde Z$ and $\tilde X$ did not appear? They should show up somewhere in the probabilities.

5. In Theorem 2.2, how strong is the assumption that $\sup_{z,x} | log (density ratio)| $ is smaller than $\alpha_n$? Usually, we might only achieve nonparametric rate for estimating the likelihood ratios. But here you also take a supremum, which might sacrifice the rate. The paper suggested that $\alpha_n$ can be o( (n \log p)^{-1/2}). When can we achieve such a rate?

6. Novelty. Theorem 2.2 seems to be an application of the result in Barber et. al. Compared with that work, this paper seems to use VAE to construct the distribution $ P_{\tilde X| X}$ and its analysis seems hinges on the assumptions in Theorem 2.2 that might be stringent.

7. In Figure 1 and 2, what is the $x$-axis?

8. A typo: Page 2, last paragraph. "In this paper, we relaxes the ..."</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">3: Clear rejection</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_ryxnMxhg0m" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Point-by-point response and clarification of the contribution</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=rkxfjjA5Km&amp;noteId=ryxnMxhg0m"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper602 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">20 Nov 2018</span><span class="item">ICLR 2019 Conference Paper602 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value"> ``This paper proposes a new approach to construct model-X knockoffs based on VAE, which can be used for controlling the false discovery rate. Both numerical simulations and real-data experiments are provided to corroborate the proposed method.   Although the problem of generating knockoffs based on VAE is novel, the paper presentation is not easy to follow and the notation seems confusing. Moreover, the main idea of this paper seems not entirely novel. The proposed method is based on combining the analysis in ''Robust inference with knockoffs'' by Barber et. al. and the VAE. '' 

Response:
We disagree with the judgement that our method is a combination of ''Robust inference with knockoffs'' by Barber et. al. and the VAE. '', thus it is not novel.  One can also argue in the same way that for example, the KnockoffGAN combines GAN and the model X knockoff framework, thus it is not novel. The author of this paper thinks both our work, and other deep learning based knockoff generator are novel and make great contribution to the field.  The contribution of work should be judged more by its originally to propose a  suitable and practical solution to an important problem, regardless of the technically difficulty. Indeed, a simpler model maybe more likely to be used by domain scientist who will make use of the generator and Model-X for scientific discoveries.

How to generate Model-X knockoff is a largely unsolved when we start this work. And this paper together with two other independent papers (one is also a submitted paper KnockoffGAN for ICLR 2019, the other appears in arXiv which we omit the reference for double blind review)  contribute to provide the first deep learning solutions to generate knockoffs.  Our work/ framework is unique in the way that we propose to generate knockoffs based on latent variable $Z$ which captures the correlation structure of $X$. This provide a great generalization from the existing knockoff generation methods for HMM and mixture Gaussian to (but not limited to) Hidden Markov Random Field. The contribution of this paper has two folds: first, we tackles the problem of generating Model-X knockoffs for any data set by proposing and justifying a framework based on latent variable $Z$; second, the proposed framework is a novel application for variational auto encoder and its variants. Compared with other deep learning architecture to generate knockoff, the proposed framework has the advantage in less computational complexity and easier to be implemented by domain scientists.
We added this claim of contribution to the end of second paragraph in the introduction section. And we marked the revised content in red.

Detailed comments:
1. ``The presentation of the main results is a bit short. Section 2, the proposed method, only takes 2 pages. It would be better to present the main results with more details. ''
Response: 
Thanks for the comment. For the readers to digest the idea of the paper, we have extended the presentation of the methods into 4 pages (excluding numerical results) in the revision. We added more motivation for the proposed framework and include a figure of Hidden Markov Random Field as a general example where a latent $Z$ can help generating $X$.  Section 3.1 to explain and discuss the existence of $Z$. Section 4 to explain the general strategy to evaluate generated knockoffs.

2. ``The method works under the assumption that there exists a random variable $Z$ such that $X_j$'s are mutually independent conditioning on $Z$. Is this a strong assumption? It seems better to illustrate when this assumption holds and fails.''
Response:
Thanks for the comment. We now added section 3.1 to discuss this in details. In fact, such $Z$ always exists for any $X$, one can take $Z=X$ or $Z=f(X)$, such that $f$ is an one-on-one mapping between $X$ and $Z$.  However, to generate powerful knockoff, we want smaller mutual information between $\tilde{X}_j$ and $X_j$, which means that we need large variation of $X|Z$, or at least conditional densities, $p(X|Z)$ is not degenerated. 

Generally speaking,   this is a very mild assumption that it always exist when $X$ is categorical variables and $Z$ exist under mild assumption for continuous $Z$. We presented many general examples that this assumption holds, however, we cannot find a concrete example that we can prove there does not exist $Z$.  Although our method propose a nature method to generate $X$ from Hidden Markov Random Field. We illustrates that the desired $Z$ exist even for distribution of $X$ not from Markov Random Field.  See Section 3.1 for further answer to this question. 


</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_S1lM5g2lC7" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Point-by-Point Responses-Continued</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=rkxfjjA5Km&amp;noteId=S1lM5g2lC7"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper602 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">20 Nov 2018</span><span class="item">ICLR 2019 Conference Paper602 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">3. ``The notation of this paper seems confusing. For example, the authors did not introduce what $(X_j, X_{-j}, \tilde X_j, \tilde X_{-j} )$ means. Moreover, in Algorithm 1, what is $\hat \theta$ and $\hat f$."
Response:
We now have added more explanation for the notations. We moved the notation explanation that appears inside Algorithm 1 to a separate paragraph: paragraph 4 section 3.2.

4. I think there might be a typo in the proof of Theorem 2.1. In the main equation, why $\tilde Z$ and $\tilde X$ did not appear? They should show up somewhere in the probabilities.
Response:
We did not find a typo in the proof of Theorem 2.1 (now 3.1). \tilde X does appear as \tilde X_j and \tilde X_{-j};  We considers \tilde Z  from distribution of Z|X, and argues that \tilde X generated from X|Z, with Z take the value of the generate \tilde Z, satisfies the knockoff's definition.

5. In Theorem 2.2, how strong is the assumption that $\sup_{z,x} | log (density ratio)| $ is smaller than $\alpha_n$? Usually, we might only achieve nonparametric rate for estimating the likelihood ratios. But here you also take a supremum, which might sacrifice the rate. The paper suggested that $\alpha_n$ can be o( (n \log p)^{-1/2}). When can we achieve such a rate?
Response: 
Yes, this is a strong assumption. And as far as I know, there is no theory to guarantee that the variational encoder and decoder from VAE algorithm would satisfy this rate in general.  Beyond restrict assumption for $X$, theoretical justification for deep generative models are hard to derive.  Our motivation to include Theorem 2.2 (now 3.2), is to provide some link of this method with asymptotic bound for FDR. And also contribute to conceptually understand how this method would control for FDR.

However, the lack of  theoretical guarantee is not a weakness of our work. It is indeed a common problem for any deep learning method to generate knockoffs.  For a relevant discussion of this problem, see also the response to reviewer 1.
There are two approaches to validate the knockoffs.  One evaluation approach proposed by Candes 2018,  is to estimate the empirical FDR for simulated $Y$ and $X$ of the real data, and compare the power and FDR control performance of knockoffs from various generator. Then the scientists will be able to feel certain about the feature selected by our approach in the sense that if the true signals are of similar structure of the simulated settings, then FDR is controlled. The other approach proposed by a most recent preprint (omitted the name for double blinded review purpose), is to compose some goodness of fit metrics based on the distributional discrepancy between $(X,\tilde{X})$ and $(X,\tilde{X})_{swap}$.   Both approaches offer gears to compare and choose the best knockoff generator for each specific real data applications.

And in addition to the metrics shared with the other knockoff generators, our framework has an unique measurement for goodness of fit, which is that $X|Z$ are independent. Specifically, if the $q_\epsilon$ is assumed to be additive error, i.e. $\tilde{X_j} = \hat{f_j}(\tilde{Z})+\epsilon_j$. The mutual independence of the residuals $X-\hat{f}(\tilde{Z})$, which is the difference of  the real data $X$ and its fitted means,  indicate good model fitting.
 In numerical studies, we focus on the first evaluation strategy which is based on FDR control for simulated $Y$. We include preliminary graphical check for the independence criterion in Appendix C and some further discussion in Section 7 .  For the real data example,  the graphical diagnostic for independence of the fitted X|Z, demonstrate great attenuation of the X's correlation by conditioning $Z$.

</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_SkgmRghgAX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Point-by-Point Reponse to Comments </a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=rkxfjjA5Km&amp;noteId=SkgmRghgAX"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper602 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">20 Nov 2018</span><span class="item">ICLR 2019 Conference Paper602 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">6. Novelty. Theorem 2.2 seems to be an application of the result in Barber et. al. Compared with that work, this paper seems to use VAE to construct the distribution $ P_{\tilde X| X}$ and its analysis seems hinges on the assumptions in Theorem 2.2 that might be stringent.
Response: 
We do not consider Theorem 2.2 (now 3.2) to be the most important component to justify the contribution and novelty of this work. As in the response earlier. The contribution and novelty of this work is that it is one of the earliest work on proposing knockoff generators with deep learning models. We proposed a unique framework based on latent $Z$. It has the advantage of lighter computational cost because it focus on reconstruction of X from Z, instead of the more complex distributional discrepancy between X and \tilde X. 
We demonstrate through simulation and real data application that this framework is a promising methods with reasonable FDR control in various settings.


7. In Figure 1 and 2, what is the $x$-axis?
Response:
It is the signal magnitude. We describe it in the text. And now we added the explanation in the title of the figure.

8. A typo: Page 2, last paragraph. "In this paper, we relaxes the ..."
Thanks for the catch, we have revised and will continue to revise typos until the revision deadline.

We would appreciate your letting us know if you are satisfied with the response to your question and concerns. We will provide more clarification if there are other concerns.

Thanks
</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div></div></div></div></div><div class="note_with_children"><div id="note_r1xr9_8v2X" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>A reasonable but unfortunately flawed approach to FDR control in feature selection combining neural networks and the knockoff</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=rkxfjjA5Km&amp;noteId=r1xr9_8v2X"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper602 AnonReviewer2</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">01 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper602 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">This manuscript tackles an important problem, namely, generating the knockoff procedure for FDR-controlled feature selection so that it can work on any data, rather than only for data generated from a Gaussian (as in the original work) or several specific other cases (mixtures of Gaussians or HMMs).  The basic idea is to exploit ideas from variational autoencoders to create a generic knockoff generation mechanism. Specifically, the main idea of the paper is to map the input covariates X into latent variable Z using a variational auto-encoder, generate the knockoffs \tilde{Z} in the latent space, and then map \tilde{Z} back to the input space to get the knockoffs \tilde{X}. The authors claim that their contribution in threefold: 

(1) Given the assumption is valid that X is mutually independent conditional on Z, the generated knockoffs \tilde{X} is proved to be valid in terms of satisfying the necessary swap condition. 

(2) Given (1) holds, and given that the discrepancy (measured by KL-divergence) between the true conditional probability Q(Z|X) and its estimate using variational auto-encoder is bounded by o((nlogp)^{-1/2}), the FDR is also bounded.

(3) The proposed knockoffs generating procedure can achieve controlled FDR and better power. 

In agreement with the above intuition, I have major concerns about the correctness of the paper.

The cornerstone of the proof in contribution (1) relies on the assumption that X is mutually independent conditional on Z. However, this assumption is invalid if there are dependencies between x_i and x_j. Therefore, the proposed knockoffs \tilde{X} cannot be proved valid by Theorem 2.1.

The erroneous proof in contribution (1) leads to the failure of contribution (2) stated in Theorem 2.2. The FDR is no longer controlled. Intuitively, according to algorithm 1, \tilde{Z} and \tilde{X} are expected to have the same distribution as Z and X, respectively; therefore, the FDR cannot be controlled.

The experimental results are suspicious. In general, it seems fishy that the proposed VAE approach outperforms Model X in the fully Gaussian case.  In this setting, Model X should have an advantage, since it is specifically designed for Gaussian generated data.  Related to this, the text is confusing: "Since the data were not Gaussian, the second-order matching method has the lowest power. The assumptions of the Fixed knockoff generations holds for the Gaussian cases, …" In the figure, the second-order matching method has low power even in the Gaussian case.

Minor comments:

p. 2: The exposition should explain the motivation for Knockoff+.

The manuscript contains numerous grammatical errors, a few examples of which are below:

p. 1: "biological linked" -&gt; "biologically linked"

p. 1: "associated certain" -&gt; "associated with a certain"

p. 1: "showed light" -&gt; "shed light"

p. 1: "which has very limited" -&gt; "which has limited"

p. 1: "leveraging on the power of of" -&gt; "leveraging the power of"


</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">4: Ok but not good enough - rejection</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_r1gahXwA2X" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Clarification</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=rkxfjjA5Km&amp;noteId=r1gahXwA2X"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper602 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">06 Nov 2018</span><span class="item">ICLR 2019 Conference Paper602 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Thanks for the review and many constructive suggestions. I will write the formal point to point response latter. However, I found there is a major concern for the theoretical results about the proof of contribution (1) that I want to discuss ahead and  to make sure we understand the concern. 

"The cornerstone of the proof in contribution (1) relies on the assumption that X is mutually independent conditional on Z. However, this assumption is invalid if there are dependencies between x_i and x_j. Therefore, the proposed knockoffs \tilde{X} cannot be proved valid by Theorem 2.1."

Even if two variables X_i and X_j are not independent. Conditional on Z, X_i and X_j can be independent. 
For example, Z is a standard normal variable,  e1 and e2 are two independent error variables (e1 and e2 are independent, and they are independent of Z).  Generate  X_1=Z+ e1, X2=Z+e2.  Then X_1 and X_2 are independent conditional on Z.   

Our proposed method relies on 'X_i is independent of X_j conditional on Z'.    Indeed we are using the VAE for approximate the latent Z that de-correlates X's.  There are some works in pre-prints that actually point out in the informatics theory, VAE is targeting to find the Z that de-correlates X. <a href="https://arxiv.org/pdf/1802.05822.pdf" target="_blank" rel="nofollow">https://arxiv.org/pdf/1802.05822.pdf</a>

Does this clarification solve the concern about 1)?  

Admittedly, we should move the proofs to the appendix and so to have  a longer introduction and results discussion. Sorry for the confusion it caused.
For the major concerns about our simulation results.  'In this setting, Model X should have an advantage, since it is specifically designed for Gaussian generated data.' I understand this sentence as describing the Fixed X Knockoff method in Barber 2014.  It is proposed for Gaussian outcomes with fixed X. 
'Since the data were not Gaussian, the second-order matching method has the lowest power.' We wanted to express is that the X's in this setting are not generated from Gaussian distribution, but the model X (with second order matching) is proposed for X that generated from Gaussian distribution.
'The assumptions of the Fixed knockoff generations holds for the Gaussian cases, …" is to say the Fixed-X method is proposed for when the outcomes are generated from Gaussian. (linear regression models) Sorry for the confusion.

 We will revise for a better  presentation of the paper.  And meanwhile, I would appreciate your letting us know if I have misunderstood your concerns and if there are other concerns you may have for our paper.

Thanks.
</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_rJlPs5tyTX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>we need to be sure that such a Z_j exists for each X_j</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=rkxfjjA5Km&amp;noteId=rJlPs5tyTX"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper602 AnonReviewer2</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">07 Nov 2018</span><span class="item">ICLR 2019 Conference Paper602 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">No, this does not address the concern.  The paper you mention indeed points out that the VAE is aiming to find the Z that de-correlates X. But for the proof to hold, we need to be sure that such a Z_j exists for each X_j. This may not be the case in general.
</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_Bklxsap1CQ" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Revision uploaded to address this question</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=rkxfjjA5Km&amp;noteId=Bklxsap1CQ"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper602 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">19 Nov 2018</span><span class="item">ICLR 2019 Conference Paper602 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Thanks much for the clarification.

Now we have uploaded a revision to address this question.

In the current revision, we devoted one page (section 3.1 on page 3) to address the question of the existence of $Z$. Notice that $Z$ always exist, if $Z=X$ or there is a one-on-one mapping between $X$ and $Z$.  However,  we are interested in $Z$ where $X|Z$ is not degenerated, to generate knockoffs different from $X$.  We showed the desired $Z$ exist for any categorical $X$ and continuous $X$ with mild assumption, we provide many general examples in the revision and the example we present includes but not limited to Hidden Markov Random Field. We have not found one counter example where we can show $Z$ does not exist. In practice, we can think of this approach to approximate $X$ with the general distribution of $X$ where the desired $Z$ exist. 

There are two simultaneous independent works on generating knockoffs with deep learning. Their frameworks assumes the knockoff is  a function of $X$ and a random noise $E$.  
Like the other works on these topic, our paper does not theoretically showed  $X$ generated from our approach will be guaranteed to be true knockoffs. But we propose a reasonable way to generate knockoffs. The simulation and real data experiment demonstrates its promising performance in FDR controlled variable selection.  The area will latter grow by comparing these methods in real data scenarios in their performance of simulated Y which the true model is known, and by the knockoff diagnostic metrics. Our approach is computationally easier to be implemented than the other two methods with the cost that one has to make the assumption the latent variable model can reconstruct $X$ good enough.

All added explanations and content are marked in red.
In this revision we provide more explanation on why we propose a  framework to generate knockoffs based on latent variable $Z$.  We include a new figure of Hidden Markov Random Field to make this idea more intuitive.   We also make changes in correspondence to Reviewer 1's concern about the gap between theory and practice in a new section 4 Goodness of fit, the revised discussion section and in Appendix C I include some preliminary results for graphical check of whether the fitted $X|Z$ is close to independence.

We fixed the typos and will continue for grammatical check until revision deadline. I revised the problematic sentences in the simulation part, and revised the figure's title for the simulation results and name it after 'Linear Regression' and 'Logistic Regression', to avoid the confusion with the Gaussian outcomes and predictors.

At your convenience, would you let you know whether this revision would clear out some doubt about this framework to generate knockoffs and if there are other concerns about this work. We will be able to address these concerns until this Friday.

Thanks much
</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div></div></div></div></div><div class="note_with_children"><div id="note_HyxbhZTpom" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Good results, but a slight gap between theory and practice.</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=rkxfjjA5Km&amp;noteId=HyxbhZTpom"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper602 AnonReviewer1</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">24 Oct 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper602 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">In the paper , the authors proposed the use of autoencoder for Model-X knockoffs. The authors proved that, if there exists latent factors, and if the encoders and the decoders can approximate conditional distributions well, the autoencoder can be used for approximating Model-X knockoff random variables: one can find relevant features while controlling FDR (Theorem 2.2).

I think the theoretical part is good, and the experimental results seem to be promising.

My concern is the gap between theory and practice. In the manuscript, the authors used VAE for approximating conditional distributions. The question is how we can confirm that the trained encoder and decoder satisfy the assumptions in Theorem 2.2. If the trained models violate the assumptions, the control of FDR is no longer guaranteed, which may lead to false discoveries. As long as this gap remains unfilled, we cannot use the procedure reliably: we always need to doubt whether the encoders and decoders are trained appropriately or not. I think this gap is unfavorable for scientific discovery where only rigid procedures are accepted.
How we can use the proposed procedure reliably, e.g. for scientific discovery? Is there any way to confirm that the encoders and decoders are appropriate? Or, is there any way to bypass the gap so that we can guarantee the FDR control even for inappropriate models?</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">6: Marginally above acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">3: The reviewer is fairly confident that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_rJxAnSreAm" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Revision uploaded to discuss more about the gap between theory and practice</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=rkxfjjA5Km&amp;noteId=rJxAnSreAm"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper602 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">19 Nov 2018</span><span class="item">ICLR 2019 Conference Paper602 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Thanks for your comment.

We agree that we can not prove from the theoretical point of view that the FDR can be controlled, because there is no theoretical guarantee that VAE will estimate the conditional distributions with the rate Theorem 3.2 (previous 2.2) requires. 

This is a common problem for any deep learning approach to generate knockoffs without strong assumptions on the $X$'s distribution. In the revision we extend some discussion in the previous version and provide a more thorough discussion on this matter. We add a new section 4 to discuss the Goodness of fit, we also discuss it further in section 7,  and present some preliminary results of graphical diagnostic in Appendix C.  

There are two approaches to validate the knockoffs.  One evaluation approach proposed by Candes 2018,  is to estimate the empirical FDR for simulated $Y$ and $X$ of the real data, and compare the power and FDR control performance of knockoffs from various generator. Then the scientists will be able to feel certain about the feature selected by our approach in the sense that if the true signals are of similar structure of the simulated settings, then FDR is controlled. The other approach proposed by a most recent preprint (omitted the name for double blinded review purpose), is to compose some goodness of fit metrics based on the distributional discrepancy between $(X,\tilde{X})$ and $(X,\tilde{X})_{swap}$.   Both approaches offers gears to compare and choose the best knockoff generator for each specific real data applications.

And in addition to the metrics shared with the other knockoff generators, our framework has an unique measurement for goodness of fit, which is that $X|Z$ are independent. Specifically, if the $q_\epsilon$ is assumed to be additive error, i.e. $\tilde{X_j} = \hat{f_j}(\tilde{Z})+\epsilon_j$. The mutual independence of the residuals $X-\hat{f}(\tilde{Z})$, which is the difference of  the real data $X$ and its fitted means,  indicate good model fitting.

 In numerical studies, we focus on the first evaluation strategy which is based on FDR control for simulated $Y$. We include preliminary graphical check for the independence criterion in Appendix C and some further discussion in Section 7 .  For the real data example,  the graphical diagnostic for independence of the fitted X|Z, demonstrate great attenuation of the X's correlation by conditioning $Z$.

Whether theory for a bound in FDR can be derived from these empirical metrics for goodness of fit is an open problem for all the deep knockoff generators and beyond the scope of this paper. And it remains future work to investigate if modification of  VAE's objective by penalizing dependence of $X|Z$ can enhance the performance of our proposed framework.

Besides the above mentioned revision to address your question. We also add more motivation and intuitive explanation for introducing of $Z$ to generate $X$, and extensive discussion about the existence of $Z$, see more details in the comments for Reviewer 2 and in section 3.1.

At your convenience, would you let you know whether this revision offers a satisfying answer to address your concern and if there are other concerns about the work . We will be able to address these concerns until this Friday.

Thanks much</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div></div></main></div>
  </div>
</div>


    <!-- Footer -->
    <footer class="sitemap">
      <div class="container">
        <div class="row hidden-xs">
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/venues">All Venues</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="/contact">Contact</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
    
        <div class="row visible-xs-block">
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/contact">Contact</a></li>
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
      </div>
    </footer>
    
    <footer class="sponsor">
      <div class="container">
        <div class="row">
          <div class="col-sm-10 col-sm-offset-1">
            <p class="text-center">
              OpenReview is created by the <a href="http://www.iesl.cs.umass.edu/" target="_blank">Information Extraction and Synthesis Laboratory</a>, College of Information and Computer Science, University of Massachusetts Amherst. We gratefully acknowledge the support of the OpenReview sponsors:  Google,  Facebook, NSF, the University of Massachusetts Amherst Center for Data Science, and Center for Intelligent Information Retrieval, as well as the Google Cloud Platform for donating the computing and networking services on which OpenReview.net runs.
            </p>
          </div>
        </div>
      </div>
    </footer>

  <div id="feedback-modal" class="modal fade" tabindex="-1" role="dialog">
    <div class="modal-dialog">
      <div class="modal-content">
        <div class="modal-header">
          <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button>
          <h3 class="modal-title">Send Feedback</h3>
        </div>
        <div class="modal-body">
          <p>Enter your feedback below and we'll get back to you as soon as possible.</p>
          <form action="/feedback" method="POST">
            <div class="form-group">
              <input type="email" name="from" class="form-control" placeholder="Email" />
            </div>
            <div class="form-group">
              <input type="text" name="subject" class="form-control" placeholder="Subject" />
            </div>
            <div class="form-group">
              <textarea name="message" class="form-control feedback-input" rows="5" placeholder="Message" required=""></textarea>
            </div>
          <ul id="ui-id-2" tabindex="0" class="ui-menu ui-widget ui-widget-content" style="display: none;"></ul></form>
        </div>
        <div class="modal-footer">
          <button type="button" class="btn btn-default" data-dismiss="modal">Cancel</button>
          <button type="button" class="btn btn-primary">Send</button>
        </div>
      </div>
    </div>
  </div>

  <script type="text/javascript" async="" src="https://www.google-analytics.com/analytics.js"></script><script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js"></script>
  <script>window.jQuery || document.write('&lt;script src="/static/js/vendor/jquery-2.2.4.min.js"&gt;&lt;\/script&gt;')</script>

  <script src="/static/dist/vendor.min.js"></script>
  <script src="/static/dist/templates.min.js"></script>
  <script src="/static/dist/openreview.min.js"></script>

    <script>window.legacyScripts = true;</script>


    <script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-108703919-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() { dataLayer.push(arguments); }
      gtag('js', new Date());
      gtag('config', 'UA-108703919-1');
    </script>


<div role="status" aria-live="assertive" aria-relevant="additions" class="ui-helper-hidden-accessible"></div></body></html>
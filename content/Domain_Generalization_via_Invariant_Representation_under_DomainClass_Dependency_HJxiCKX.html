<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" class="no-js"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>Domain Generalization via Invariant Representation under Domain-Class Dependency | OpenReview</title>
  <meta name="description" content="" />

      <meta name="citation_title" content="Domain Generalization via Invariant Representation under Domain-Class Dependency" />
        <meta name="citation_author" content="Anonymous" />
      <meta name="citation_publication_date" content="2018/09/27" />
      <meta name="citation_online_date" content="2018/09/27" />
      <meta name="citation_pdf_url" content="https://openreview.net/pdf?id=HJx38iC5KX" />
      <meta name="twitter:card" content="summary" />
      <meta name="twitter:site" content="@openreviewnet" />
      <meta name="og:title" content="Domain Generalization via Invariant Representation under..." />
      <meta name="og:description" content="Learning domain-invariant representation is a dominant approach for domain generalization, where we need to build a classifier that is robust toward domain shifts induced by change of users..." />
      <meta name="og:image" content="https://openreview.net/static/images/openreview_logo_512.png" />

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans:400,400i,700,700i" />

  <link rel="stylesheet" href="/static/css/bootstrap.min.css" />
  <link rel="stylesheet" href="/static/css/jquery-ui.min.css" />
  <link rel="stylesheet" href="/static/css/main.min.css" />
</head>

<body class="forum">
  <nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
  
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand home push-link" href="/"><strong>OpenReview</strong>.net</a>
      </div>
  
      <div id="navbar" class="navbar-collapse collapse">
        <form class="navbar-form navbar-left profile-search" role="search">
          <div class="form-group has-feedback">
            <input id="search_input" type="text" class="form-control ui-autocomplete-input" placeholder="Search ICLR 2019 Conference" autocomplete="off" />
            <span class="glyphicon glyphicon-search form-control-feedback" aria-hidden="true"></span>
          </div>
  
          <input id="search_group" type="hidden" value="ICLR.cc/2019/Conference" />
          <input id="search_content" type="hidden" value="all" />
        <ul id="ui-id-1" tabindex="0" class="ui-menu ui-widget ui-widget-content ui-autocomplete ui-front" style="display: none;"></ul></form>
  
        <ul class="nav navbar-nav navbar-right">
        
            <li id="user-menu"><a href="/login">Login</a></li>
        </ul>
      </div>
  
    </div>
  </nav>

  <div id="or-banner" class="banner" style="">
  <div class="container">
    <div class="row">
      <div class="col-xs-12"><a href="/group?id=ICLR.cc/2019/Conference" title="Venue Homepage"><img class="icon" src="/static/images/arrow_left.svg" /> Go to <strong>ICLR 2019 Conference</strong> homepage</a></div>
    </div>
  </div>
</div>
<div id="flash-message-container" class="alert alert-danger" role="alert" style="display: none;">
  <div class="container">
    <div class="row">
      <div class="col-xs-12">
        <div class="alert-content">
          <button type="button" class="close" aria-label="Close"><span aria-hidden="true">×</span></button>
        </div>
      </div>
    </div>
  </div>
</div>

<div class="container">
  <div class="row">
    <div class="col-xs-12">
      <main id="content" class="clearfix openbanner-visible legacy-styles"><div id="note_HJx38iC5KX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Domain Generalization via Invariant Representation under Domain-Class Dependency</a> <a class="note_content_pdf" href="/pdf?id=HJx38iC5KX" title="Download PDF" target="_blank"><img src="/static/images/pdf_icon_blue.svg" /></a> </h2></div><div class="meta_row"><span class="signatures">Anonymous</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">28 Sep 2018 (modified: 14 Nov 2018)</span><span class="item">ICLR 2019 Conference Blind Submission</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span><span class="item"><a class="action-bibtex-modal" data-bibtex="@inproceedings{    &#10;anonymous2019learning,    &#10;title={Learning Domain-Invariant Representation under Domain-Class Dependency},    &#10;author={Anonymous},    &#10;booktitle={Submitted to International Conference on Learning Representations},    &#10;year={2019},    &#10;url={https://openreview.net/forum?id=HJx38iC5KX},    &#10;note={under review}    &#10;}">Show Bibtex</a></span><a class="note_content_pdf item" href="/revisions?id=HJx38iC5KX" target="_blank">Show Revisions</a></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Abstract: </span><span class="note_content_value">Learning domain-invariant representation is a dominant approach for domain generalization, where we need to build a classifier that is robust toward domain shifts induced by change of users, acoustic or lighting conditions, etc. However, prior domain-invariance-based methods overlooked the underlying dependency of classes (target variable) on source domains during optimization, which causes the trade-off between classification accuracy and domain-invariance, and often interferes with the domain generalization performance. This study first provides the notion of domain generalization under domain-class dependency and elaborates on the importance of considering the dependency by expanding the analysis of Xie et al. (2017). We then propose a method, invariant feature learning under optimal classifier constrains (IFLOC), which explicitly considers the dependency and maintains accuracy while improving domain-invariance. Specifically, the proposed method regularizes the representation so that it has as much domain information as the class labels, unlike prior methods that remove all domain information. Empirical validations show the superior performance of IFLOC to baseline methods, supporting the importance of the domain-class dependency in domain generalization and the efficacy of the proposed method for overcoming the issue.</span></div><div class="note_contents"><span class="note_content_field">Keywords: </span><span class="note_content_value">domain generalization, adversarial learning, invariant feature learning</span></div><div class="note_contents"><span class="note_content_field">TL;DR: </span><span class="note_content_value">Address the trade-off caused by the dependency of classes on domains in domain generalization</span></div><div class="reply_row clearfix"><div class="item" id="reply_count">10 Replies</div></div></div><hr class="small" /><div id="note_children"><div class="note_with_children"><div id="note_SygAAIO3n7" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>This paper lacks sufficient novelty</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HJx38iC5KX&amp;noteId=SygAAIO3n7"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper209 AnonReviewer2</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">04 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper209 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">In this paper, the author(s) propose a method, invariant feature learning under optimal classifier constrains (IFLOC), which maintains accuracy while improving domain-invariance. Here is a list of suggestions that will help the author(s) to improve this paper.
1.The paper explains the necessity and effectiveness of the method from the theoretical and experimental aspects, but the paper does not support the innovation point enough, and the explanation is too simple.
2.In this paper, Figure3-(b) shows that the classification accuracy of IFLOC-abl method decreases a lot when γ is taken to 0. Figure3-(c) shows that the domain invariance of IFLOC-abl method becomes significantly worse when γ is 10. The author(s) should explain the reasons in detail.
3. The lack of analysis on domain-class dependency of each dataset makes the analysis of experimental results weak.
</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">4: Ok but not good enough - rejection</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_H1lur28F6m" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Response to Reviewer 2 [1/2]</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HJx38iC5KX&amp;noteId=H1lur28F6m"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper209 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">14 Nov 2018</span><span class="item">ICLR 2019 Conference Paper209 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Thank you for your critical feedback.
We hope to clarify and address your concerns and questions.
We respond in detail to each comment below.


### Reply to comment 1

Regarding this comment, we would very much appreciate if you could give us more details so that we could exactly address your concerns and improve the paper.
For example, we would like to know (1) why you think "the paper does not support the innovation point enough" and (2) which parts of "the explanation is too simple" and why simple is a weak point.

Here, we would like to clarify three innovation points of the paper we think.
(1) We elaborate on the trade-off problem under domain-class dependency, both theoretically (Sec.4.1.1) and experimentally (1st-paragraph of Sec.5.4), for the first time in domain generalization context.
Here, note that domain generalization is different from domain adaptation in that we cannot obtain input and label data from target domain(s), but has been attracting considerable attention in recent years.
(2) We propose to maximize domain-invariance within a range that does not interfere with classification accuracy and provide the theoretical analysis which derives the novel approach (i.e., to regularize latent representation so that H(d|y)=H(d|h) holds) to address the aforementioned problem in Sec.4.1.2.
(3) We confirm the efficacy of the proposed approch with the novel algorighm (IFLOC) in Sec.5.4.


Moreover, we have added the below contents to the updated paper in order to clarify the inovation points.

1. To make it clear that domain generalization differs from domain adaptation, we have added the following sentence:
```
(Sec.2, para.2)  Domain generalization has been attracting considerable attention in recent years (Blanchard et al. (2011); Muandet et al. (2013); Shankar et al. (2018)). Note that it is different from domain adaptation in that we cannot obtain input and label data from target domain(s).
```

2. To make it clear that domain-class dependency (p(y|d) \neq p(y)) is a novel and important problem setting in domain generalization, we compare it with conditional probability shift (p(y|x) and p(x) change across domains) and showed that domain-class dependency is a root cause of the trade-off problem:
```
(Sec.1, para.3) Domain-class dependency might be similar to the situation where p(y|x) and p(x) change across domains due to the causal structure y → x (Zhang et al. (2013); Gong et al. (2016) in domain adaptation and Li et al. (2018c) in domain generalization), which we call conditional probability shift. However, the shift does not cause the trade-off as long as y and d are independent (Figure 1-left), so it is necessary to focus on the relationship between y and d.
(Sec.2, para.5) There are several kinds of distributional shifts other than domain-class dependency, such as conditional probability shift. Although the distinction between that shift and domain-class dependency is important, it has been received less attention. For example, Li et al. (2018c) claimed that conditional probability shift might harm the performance of domain-invariance-based methods, but our analysis in Sec.4.1.1 suggests that the root cause of the performance degradation is not it but domain-class dependency.
```</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_ByeXo2UY6m" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Response to Reviewer 2 [2/2]</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HJx38iC5KX&amp;noteId=ByeXo2UY6m"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper209 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">14 Nov 2018</span><span class="item">ICLR 2019 Conference Paper209 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">
### Reply to comment 2.

#### About Figure3-(b):
We acknowledge that we lack the explanation on it, so we investigated and considered the reasons as below.

(1) Firstly, we do not intend to claim that "IFLOC and IFLOC-Abl always outperform DAN when γ becomes strong", but we just observed that IFLOC and IFLOC-Abl tends to outperform DAN when γ = 10, i.e., the regularizer becomes strong, in Figure 2-(a, b) and 3-(a, b).
We provided one possible explanation of this observation that "the regularizers of IFLOC and IFLOC-Abl is KLD and thus bounded by 0, in contrast to that of DAN that can increase to infinity and destabilize the traininig".
However, since the regularization terms of IFLOC-Abl and DAN are intended to achive the same equilibrium and they do not have clear superiority or inferiority in theory, we do not intend to exclude the possibility that DAN outperforms IFLOC-Abl on a certain hyperparameter (and of course to show the superiority of IFLOC-Abl over DAN is not the main purpose of the paper).

(2) Secondly, we acknowledge that "the classification accuracy of IFLOC-abl method decreases a lot when γ is taken from 0.1 to 1".
However, the range of the accuracy reduction is roughly the same with those in &lt;DAN, γ changes from 1 to 10, Figure 3-(a)&gt; and (2) &lt;DAN, γ changes from 1 to 10, Figure 3-(a)&gt;.
This suggests that the range of accuracy reduction you concern is not so exceptional for the two domain-invariance-based methods in the WISDM experiment.


Based on the above discussions, we modified the paper to clarity that "IFLOC and IFLOC-Abl tends to but not always outperform DAN when γ becomes strong" as follows:
```
The training of IFLOC tends to be more stable than that of DAN when the regularizer becomes strong. Figures 2-(a,b) and 3-(a,b) show that IFLOC and IFLOC-Abl could achieve higher Y-Acc than DAN when γ = 1 or 10, i.e., the regularization is strong, except for IFLOC-Abl with γ=1 in Figure 3-(b).
This tendency might be because the regularizer of IFLOC is KLD and thus bounded by 0, in contrast to that of DAN that can increase to infinity and destabilize the traininig.
```


#### About Figure3-(c):
We agree that this should be explained, and we already explained it to some extent as follows:
```
(Sec. 5.4, 2nd para.) That high D-Acc might be because the validation accuracy achieved the highest value before the domain-invariance matured. (Recall that the more the representation becomes invariant, the lower the accurary becomes under the trade-off).
```
So we would appreciate if you could specify what kind of analysis would improve the paper more.


### Reply to comment 3.

We agree that “analysis on domain-class dependency of each dataset” is important, and some analysis is already done in the paper.
So we would very appreciate if you could specify what kind of analysis would improve the paper more.
Below are the analyses we already did in the paper.

1. BMNISTR is the synthetic dataset which we created by modifying MNISTR. As noted in Sec.5.1, BMNISTRs have several types of domain-class dependency, and the reason for the each type is noted in Sec.5.1. Also, the performances of IFLOC on each dependency type are discussued in the 1st-paragraph in Sec.5.4.

2. PACS has the dependency probably because samples in some &lt;domain, class&gt; pairs are difficult to obtain, as noted in Sec.5.1. The reasons why some &lt;domain, class&gt; pairs become difficult to obtain is discussed in Sec.1 (data characteristics and data-collection errors).

3. WISDM has the dependency due to the reason discussed in Sec.1.


Also, we have added the below discussion regarding the datasets.

1. We have added the table of the concrete sample sizes for each &lt;domain, class&gt; pair in PACS and WISDM dataset to Appendix.

2. The reason why WISDM has the dependency was already noted in Sec.1, but we have added it to Sec.5.1 again.

3. We have provided the concrete example of domain-class dependency in PACS as follows:
```
(Sec.5.1, para.2) For example, p(y = person|d = Phot) is much higher than p(y = person|d = Sketch), which indicates that photos of person are easier to obtain than those of animals, but sketches of persons are more difficult to obtain than those of animals in the wild.
```

4. We have cited Zhang+2013 to support the fact that that domain-class dependency often happens in real-world dataset as follows:
```
(Sec.1, para.4) Unfortunately, domain-class dependency is common in real-world datasets as shown in Zhang et al. (2013).
```</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div></div></div><div class="note_with_children"><div id="note_SkeHjnHch7" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Simple and effective idea, good experiment design</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HJx38iC5KX&amp;noteId=SkeHjnHch7"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper209 AnonReviewer1</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">03 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper209 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">This paper proposed to address domain generalization under inter-dependence of domains and classes. It motivates a new regularization term by analyzing an existing work, DAN. It shows that this term can improve the generalization performance when the classes and domains are not independent. Experiments are extensive and supportive. 

I do not have many comments about this paper. It was a joy to read. The proposed idea is well motivated. It is simple and seems like effective. Experiments are extensive. 

While the regularization term is motivated by analyzing DAN, it would be nice to discuss its application to other domain adaptation/generalization methods. What is even better is to show its effectiveness on another method in the experiments.</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">7: Good paper, accept</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_HkxHep8Y67" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Response to Reviewer 1</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HJx38iC5KX&amp;noteId=HkxHep8Y67"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper209 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">14 Nov 2018</span><span class="item">ICLR 2019 Conference Paper209 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Thank you for your positive review.
We really appreciate the remarks that our “idea is well motivated” and “experiments are extensive and supportive”.

### Reply to “to discuss its application to other domain adaptation/generalization methods and to show its effectiveness on another method in the experiments” would improve the paper.

Thank you for the suggestion. As you pointed out, the regularization term is motivated by analyzing DAN. So we acknowledge that its application to other domain adaptation/generalization methods is not trivial and discussing it would improve the paper. One possible direction is to modify conditional VAE (Louizos+2015) or CrossGrad (Shankar+2018) to make H(d|h) = H(d|y) holds and to use it in domain generalization. These methods have clear and tractable data generating process but assume the independence of y and d, so we hope we can somehow modify it to H(d|h) = H(d|y) holds. However, we unfortunately might not have time to develop concrete methods and conduct experiments, so we have added the above discussion to the paper.

### References

Christos Louizos, Kevin Swersky, Yujia Li, Max Welling, and Richard S. Zemel. The variational fair autoencoder. ICLR2016
Shiv Shankar, Vihari Piratla, Soumen Chakrabarti, Siddhartha Chaudhuri, Preethi Jyothi, and Sunita Sarawagi. Generalizing across domains via cross-gradient training. ICLR2018
</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div><div class="note_with_children"><div id="note_SylAH62FhQ" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>The proposed problem seems similar to traditional conditional distribution matching problem. </a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HJx38iC5KX&amp;noteId=SylAH62FhQ"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper209 AnonReviewer3</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">02 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper209 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">The paper proposed a problem that most prior methods overlooked the underlying dependency of classes on domains, namely p (y|d) \= p(y).   Figure 1 is used to illustrate this issue. 

If the conditional probability of source domain and target domain is not equal (i.e., p(y|x_S) \= p(y|x_T)  ), the optimal invariance can lead the same generalization problem.   Unfortunately, a lot of works has been done [1,2] in matching domain classifier or conditional probability.  It is desirable to discuss the difference between these two problems and compared with the missing references in experiments. 

It is also suggested to conduct the analysis of why the datasets satisfy the assumption of the dependence of class and domains. 

Reference:
[1] Flexible Transfer Learning under Support and Model Shift, NIPS 2014.
[2]Conditional Adversarial Domain Adaptation, NIPS 2018</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">5: Marginally below acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_Hkei6C8FpX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Response to Reviewer 3 [1/4]</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HJx38iC5KX&amp;noteId=Hkei6C8FpX"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper209 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">14 Nov 2018</span><span class="item">ICLR 2019 Conference Paper209 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Thank you for your critical feedback.
We hope to clarify and address your concerns and questions.
We respond in detail to each comment below.


### Reply to “it is desirable to discuss the difference between these two problems”

In our understanding, your main concern is the novelty of our problem setting, i.e., “is domain generalization under domain-class dependency (p(y|d) \neq p(y)) is different from domain adaptation under p(y|x_S) \neq p(y|x_T) ?”
We acknowledge that we lack the discussion about the difference between these two (though they are indeed considerably different problems), so we have added the below discussion to the paper and emphasized the novelty of our problem setting.

Firstly, the paper addresses {\em domain generalization}, not domain adaptation, as noted in abstract, Sec.1, etc.
These two have different assumptions and purposes.
Concretely, domain adaptation methods require either labeled or unlabeled data from the target domain at training time.
In contrast, domain generalization methods do not require any data from target domains during training but instead, require labeled data from several source domains.
Then the methods collectively exploit them so that the trained system can handle new domains without any adaptation step.

Due to the difference, domain adaptation methods are not always applicable to domain generalization.
For example, Wang+2014, which you suggested for us, transform unlabeled target data so that they can correct distributional shift, but in domain generalization, target data are unavailable.
Also, please note that we care about the shifts within source domains, because domain generalization methods are agnostic on the target domain.
So we think p(y|x_S) \neq p(y|x_T) should be rewritten as p(y|x, d) \neq p(y|x) (we call it conditional probability shift) in domain generalization, so that clarify we focus on the shift within source domains (not between S and T).

Secondly, conditional probability shift (p(y|x, d) \neq p(y|x)), which is often caused by the causal structure y -&gt; x, is not a sufficient condition for p(y|d) \neq p(y).
While conditional probability shift was previously addressed by Li+2018 in domain generalization context, domain-class dependency has been overlooked.
The relation between these two problems is illustrated in Figure 1 in our updated paper.

Thirdly and most importantly, in domain generalization, conditional probability shift does not cause the trade-off problem as long as the domain-class dependency does not exist.
In other words, p(y|x, d) \neq p(y|x) is not a root cause of the trade-off problem, but domain-class dependency is, so it is essential to consider and address domain-class dependency problem.
Again the relation between these two problems is illustrated in Figure 1 in our updated paper.
</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_SJg4xkvKaQ" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Response to Reviewer 3 [2/4]</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HJx38iC5KX&amp;noteId=SJg4xkvKaQ"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper209 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">14 Nov 2018</span><span class="item">ICLR 2019 Conference Paper209 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">
Based on the above discussion (Response to Reviewer 3 [1/4]), we have updated the paper. Below are the details.

1. To make it clear that our purpose is improving {\em domain generalization performance}, we have changed the title of the paper to ”domain generalization via invariant representation under domain-class dependency.”

2. To make it clear that domain generalization differs from domain adaptation, We have added the following sentences:
```
(Sec.2, para.2) Domain generalization has been attracting considerable attention in recent years (Blanchard et al. (2011); Muandet et al. (2013); Shankar et al. (2018)). Note that it is different from domain adaptation in that we cannot obtain input and label data from the target domain(s).
(Sec.2, para.5) In domain adaptation, Zhang et al. (2013); Gong et al. (2016) address the situation where p(y) changes across source and target domains by estimating p(y) change using unlabeled target data. However, this approach is not applicable (or necessary) to domain generalization because our problem setting is different from theirs in that we are agnostic on target domain and aim to care about p(y) change within source domains instead.
```

3. To make it clear that conditional probability shift (p(y|x, d) \neq p(y|x)) and domain-class dependency (p(y|d) \neq p(y)) are different problems, and the latter is the root cause of the trade-off problem, we have added the following sentences:
```
(Sec.1, para.3) We define domain-class dependency as the situation where domain and class labels are statistically dependent due to some common latent factor (z) of y and d (Figure 1-right).
(Sec.1, para.3) Domain-class dependency might be similar to the situation where p(y|x) and p(x) change across domains due to the causal structure y → x (Zhang et al. (2013); Gong et al. (2016) in domain adaptation and Li et al. (2018c) in domain generalization), which we call conditional probability shift. However, the shift does not cause the trade-off as long as y and d are independent (Figure 1-left), so it is necessary to focus on the relationship between y and d.
(Sec.2, para.5) There are several kinds of distributional shifts other than domain-class dependency, such as conditional probability shift. Although the distinction between that shift and domain-class dependency is important, it has been received less attention. For example, Li et al. (2018c) claimed that conditional probability shift might harm the performance of domain-invariance-based methods, but our analysis in Sec.4.1.1 suggests that the root cause of the performance degradation is not it but domain-class dependency.
```

4. To show why conditional probability shift does not cause the trade-off problem and why domain-class dependency is important, we added the following sentence:
```
(Sec.4.1.1, the last para.) It is worth noting that although Li et al. (2018c) claimed that conditional probability shift (the causal structure y → x) could harm the domain generalization performance of invariance-based methods, this analysis suggests that it does not harm DAN as long as domain and class are independent. It can be confirmed by considering Eq.7 and Eq.10; even when the shift occurs, i.e., H(y|x, d) &lt; H(y|x) holds and then H(y|h, d) ≤ H(y|h) holds, it does not conflict with H(d|h) = H(d|y) = H(d) as long as H(d|y) = H(d) holds. In other words, we only need to infer latent variable h that satisfies the causal structure y → h → x to avoid the trade-off. Although Gong et al. (2016) showed a similar result in domain adaptation context, it has been overlooked in domain generalization.
```</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_HyxnMJwKT7" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Response to Reviewer 3 [3/4]</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HJx38iC5KX&amp;noteId=HyxnMJwKT7"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper209 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">14 Nov 2018</span><span class="item">ICLR 2019 Conference Paper209 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">
### Reply to “it is desirable to compare with the missing references in experiments”

Thank you for introducing two important works.
These works greatly help us re-consider the novelty of our work.

However, currently, we do not plan to conduct comparative experiments with them for two reasons.
Firstly, both Wang+2014 and Long+2018 address domain adaptation, so their methods are not directly applicable to our setting (domain generalization).
Secondly, as we discussed in reply to comment 1, p(y|x, d) \neq p(y|x) is not a sufficient condition for p(y|d) \neq p(y), and this paper addresses the trade-off problem caused by the latter.
More specifically, we acknowledge that comparing our method with methods invented for addressing p(y|x, d) \neq p(y|x) is very interesting research direction, but is out of scope of this paper, given our three contributions: the novel problem setting (domain generalization under domain-class dependency); the theoretical analysis which derives the novel approach to address the problem (to regularize latent representation so that H(d|y)=H(d|h) holds); and to confirm the efficacy of the proposed approach with the novel algorithm (IFLOC).


Below are the detailed comments to each paper.

Wang+2014: They consider domain adaptation under a general case where both the support and the model (p(y|x)) change across domains. They proposed to transform both X and Y by a location-scale shift to achieve transfer between domains. Our paper differs from theirs in that we focus on domain generalization (while they focus on domain adaptation), we focus on p(y|d) \neq p(y) (they focus on p(y|x, d) \neq p(y|x)), we focus on classification (they focus on regression), and we use DNN to extract latent features (they use location-scale shift to transform target data into source data).

Long+2018: They address two issues in domain adaptation: (1) when data distributions embody complex multimode structures, adversarial domain adaptation may fall into mode collapse; (2) adversarial adaptation of a particular layer is not sufficient to bridge the domain shifts. To address these issues, they proposed to conditioning domain discriminator on the middle layer and output layer of the classifier. Our paper differs from theirs in that we focus on domain generalization (while they focus on domain adaptation), we focus on p(y|d) \neq p(y) (they do not mention the type of distributional shift), and we avoid removing all domain information from latent features.
(Also, please note that the NIPS version of the paper is unavailable now.)</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_ryg7wJvK67" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Response to Reviewer 3 [4/4]</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HJx38iC5KX&amp;noteId=ryg7wJvK67"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper209 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">14 Nov 2018</span><span class="item">ICLR 2019 Conference Paper209 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">
### Reply to “It is also suggested to conduct the analysis of why the datasets satisfy the assumption of the dependence of class and domains”

We agree that “the analysis of why the datasets satisfy the assumption of the dependence of class and domains” would improve the paper, and some analysis is already done in the paper.
So we would very appreciate if you could specify what kind of analysis would improve the paper more.
Below are the analyses we already did in the paper.

1. BMNISTR is the synthetic dataset which we created by modifying MNISTR. As noted in Sec.5.1., BMNISTRs have several types of domain-class dependency, and the reason for each type is noted in Sec.5.1. Also, the performances of IFLOC in each dependency type are discussed in the 1st-paragraph in Sec.5.4.

2. PACS has the dependency probably because samples in some &lt;domain, class&gt; pairs are difficult to obtain, as noted in Sec.5.1. The reasons why some &lt;domain, class&gt; pairs become difficult to obtain is discussed in Sec.1 (data characteristics and data-collection errors).

3. WISDM has the dependency due to the reason discussed in Sec.1.


Also, we have added the below discussion regarding the datasets.

1. We have added the table of the concrete sample sizes for each &lt;domain, class&gt; pair in PACS and WISDM dataset to Appendix.

2. The reason why WISDM has the dependency was already noted in Sec.1, but we have added it to Sec.5.1 again.

3. We have provided the concrete example of domain-class dependency in PACS as follows:
```
(Sec.5.1, para.2) For example, p(y = person|d = Phot) is much higher than p(y = person|d = Sketch), which indicates that photos of person are easier to obtain than those of animals, but sketches of persons are more difficult to obtain than those of animals in the wild.
```

4. We have cited Zhang+2013 to support the fact that that domain-class dependency often happens in real-world dataset as follows:
```
(Sec.1, para.4) Unfortunately, domain-class dependency is common in real-world datasets as shown in Zhang et al. (2013).
```

### References

Kun Zhang, Bernhard Scholkopf, Krikamol Muandet, Zhikun Wang, “Domain Adaptation under Target and Conditional Shift”, ICML2013
Xuezhi Wang, Jeff Schneider, “Flexible Transfer Learning under Support and Model Shift”, NIPS2014
Mingsheng Long, Zhangjie Cao, Jianmin Wang, Michael I. Jordan, “Conditional Adversarial Domain Adaptation”, NIPS2018
Ya Li, Mingming Gong, Xinmei Tian, Tongliang Liu, Dacheng Tao, “Domain Generalization via Conditional Invariant Representations”, AAAI2018
</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div></div></div></div></div></div></div></div></main></div>
  </div>
</div>


    <!-- Footer -->
    <footer class="sitemap">
      <div class="container">
        <div class="row hidden-xs">
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/venues">All Venues</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="/contact">Contact</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
    
        <div class="row visible-xs-block">
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/contact">Contact</a></li>
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
      </div>
    </footer>
    
    <footer class="sponsor">
      <div class="container">
        <div class="row">
          <div class="col-sm-10 col-sm-offset-1">
            <p class="text-center">
              OpenReview is created by the <a href="http://www.iesl.cs.umass.edu/" target="_blank">Information Extraction and Synthesis Laboratory</a>, College of Information and Computer Science, University of Massachusetts Amherst. We gratefully acknowledge the support of the OpenReview sponsors:  Google,  Facebook, NSF, the University of Massachusetts Amherst Center for Data Science, and Center for Intelligent Information Retrieval, as well as the Google Cloud Platform for donating the computing and networking services on which OpenReview.net runs.
            </p>
          </div>
        </div>
      </div>
    </footer>

  <div id="feedback-modal" class="modal fade" tabindex="-1" role="dialog">
    <div class="modal-dialog">
      <div class="modal-content">
        <div class="modal-header">
          <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button>
          <h3 class="modal-title">Send Feedback</h3>
        </div>
        <div class="modal-body">
          <p>Enter your feedback below and we'll get back to you as soon as possible.</p>
          <form action="/feedback" method="POST">
            <div class="form-group">
              <input type="email" name="from" class="form-control" placeholder="Email" />
            </div>
            <div class="form-group">
              <input type="text" name="subject" class="form-control" placeholder="Subject" />
            </div>
            <div class="form-group">
              <textarea name="message" class="form-control feedback-input" rows="5" placeholder="Message" required=""></textarea>
            </div>
          <ul id="ui-id-2" tabindex="0" class="ui-menu ui-widget ui-widget-content" style="display: none;"></ul></form>
        </div>
        <div class="modal-footer">
          <button type="button" class="btn btn-default" data-dismiss="modal">Cancel</button>
          <button type="button" class="btn btn-primary">Send</button>
        </div>
      </div>
    </div>
  </div>

  <script type="text/javascript" async="" src="https://www.google-analytics.com/analytics.js"></script><script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js"></script>
  <script>window.jQuery || document.write('&lt;script src="/static/js/vendor/jquery-2.2.4.min.js"&gt;&lt;\/script&gt;')</script>

  <script src="/static/dist/vendor.min.js"></script>
  <script src="/static/dist/templates.min.js"></script>
  <script src="/static/dist/openreview.min.js"></script>

    <script>window.legacyScripts = true;</script>


    <script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-108703919-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() { dataLayer.push(arguments); }
      gtag('js', new Date());
      gtag('config', 'UA-108703919-1');
    </script>


<div role="status" aria-live="assertive" aria-relevant="additions" class="ui-helper-hidden-accessible"></div></body></html>
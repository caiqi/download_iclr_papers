<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" class="no-js"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>Dataset Distillation | OpenReview</title>
  <meta name="description" content="" />

      <meta name="citation_title" content="Dataset Distillation" />
        <meta name="citation_author" content="Anonymous" />
      <meta name="citation_publication_date" content="2018/09/27" />
      <meta name="citation_online_date" content="2018/09/27" />
      <meta name="citation_pdf_url" content="https://openreview.net/pdf?id=Sy4lojC9tm" />
      <meta name="twitter:card" content="summary" />
      <meta name="twitter:site" content="@openreviewnet" />
      <meta name="og:title" content="Dataset Distillation" />
      <meta name="og:description" content="Model distillation aims to distill the knowledge of a complex model into a simpler one.  In this paper, we consider an alternative formulation called {\em dataset distillation}: we keep the model..." />
      <meta name="og:image" content="https://openreview.net/static/images/openreview_logo_512.png" />

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans:400,400i,700,700i" />

  <link rel="stylesheet" href="/static/css/bootstrap.min.css" />
  <link rel="stylesheet" href="/static/css/jquery-ui.min.css" />
  <link rel="stylesheet" href="/static/css/main.min.css" />
</head>

<body class="forum">
  <nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
  
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand home push-link" href="/"><strong>OpenReview</strong>.net</a>
      </div>
  
      <div id="navbar" class="navbar-collapse collapse">
        <form class="navbar-form navbar-left profile-search" role="search">
          <div class="form-group has-feedback">
            <input id="search_input" type="text" class="form-control ui-autocomplete-input" placeholder="Search ICLR 2019 Conference" autocomplete="off" />
            <span class="glyphicon glyphicon-search form-control-feedback" aria-hidden="true"></span>
          </div>
  
          <input id="search_group" type="hidden" value="ICLR.cc/2019/Conference" />
          <input id="search_content" type="hidden" value="all" />
        <ul id="ui-id-1" tabindex="0" class="ui-menu ui-widget ui-widget-content ui-autocomplete ui-front" style="display: none;"></ul></form>
  
        <ul class="nav navbar-nav navbar-right">
        
            <li id="user-menu"><a href="/login">Login</a></li>
        </ul>
      </div>
  
    </div>
  </nav>

  <div id="or-banner" class="banner" style="">
  <div class="container">
    <div class="row">
      <div class="col-xs-12"><a href="/group?id=ICLR.cc/2019/Conference" title="Venue Homepage"><img class="icon" src="/static/images/arrow_left.svg" /> Go to <strong>ICLR 2019 Conference</strong> homepage</a></div>
    </div>
  </div>
</div>
<div id="flash-message-container" class="alert alert-danger" role="alert" style="display: none;">
  <div class="container">
    <div class="row">
      <div class="col-xs-12">
        <div class="alert-content">
          <button type="button" class="close" aria-label="Close"><span aria-hidden="true">×</span></button>
        </div>
      </div>
    </div>
  </div>
</div>

<div class="container">
  <div class="row">
    <div class="col-xs-12">
      <main id="content" class="clearfix openbanner-visible legacy-styles"><div id="note_Sy4lojC9tm" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Dataset Distillation</a> <a class="note_content_pdf" href="/pdf?id=Sy4lojC9tm" title="Download PDF" target="_blank"><img src="/static/images/pdf_icon_blue.svg" /></a> </h2></div><div class="meta_row"><span class="signatures">Anonymous</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">28 Sep 2018 (modified: 11 Oct 2018)</span><span class="item">ICLR 2019 Conference Blind Submission</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span><span class="item"><a class="action-bibtex-modal" data-bibtex="@inproceedings{    &#10;anonymous2019dataset,    &#10;title={Dataset Distillation},    &#10;author={Anonymous},    &#10;booktitle={Submitted to International Conference on Learning Representations},    &#10;year={2019},    &#10;url={https://openreview.net/forum?id=Sy4lojC9tm},    &#10;note={under review}    &#10;}">Show Bibtex</a></span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Abstract: </span><span class="note_content_value">Model distillation aims to distill the knowledge of a complex model into a simpler one.  In this paper, we consider an alternative formulation called {\em dataset distillation}: we keep the model fixed and instead attempt to distill the knowledge from a large training dataset into a small one.  The idea is to {\em synthesize} a small number of data points that do not need to come from the correct data distribution, but will, when given to the learning algorithm as training data, approximate the model trained on the original data.  For example, we show that it is possible to compress $60,000$ MNIST training images into just $10$ synthetic {\em distilled images} (one per class) and achieve close to original performance with only a few steps of gradient descent, given a particular fixed network initialization. Apart from being an interesting new way to think about distillation, this approach could potentially open up several applications, such as fast domain adaptation and effective data poisoning attacks.</span></div><div class="note_contents"><span class="note_content_field">Keywords: </span><span class="note_content_value">knowledge distillation, deep learning, few-shot learning, adversarial attack</span></div><div class="note_contents"><span class="note_content_field">TL;DR: </span><span class="note_content_value">We propose to distill a large dataset into a small set of synthetic data , so networks can achieve close to original performance when trained on these data.</span></div><div class="reply_row clearfix"><div class="item" id="reply_count">7 Replies</div></div></div><hr class="small" /><div id="note_children"><div class="note_with_children"><div id="note_S1gcr_G5hm" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>An algorithm to reduce datatset size for  NNs</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=Sy4lojC9tm&amp;noteId=S1gcr_G5hm"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper593 AnonReviewer1</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">03 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper593 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">The paper presents an algorithm for compressing the size of entire training data into a few synthetic training samples. The method is based on neural networks and is applied on image datsets. The authors comment two possible applications of their method domain adaptation and effective data poisoning attack.

The proposed technique seems to be limited to neural networks since it seems that is linked to the initialization of the networks. In this aspect, it could be interesting to have a more general method.

There are related works that are not commented, for instance :

Olvera-López, J. Arturo, et al. "A review of instance selection methods." Artificial Intelligence Review 34.2 (2010): 133-143.


Experimental section is weak. Few datasets are considered, other problems should be added. Additionally, related methods should be included to  compare the performance of the proposal. Some comments about the computational cost should be inserted. In this aspect, the experimental section should be improved following these recommendations.</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">5: Marginally below acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_S1xVvuOLh7" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Original problem and well written paper, but that lacks comparisons to baselines</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=Sy4lojC9tm&amp;noteId=S1xVvuOLh7"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper593 AnonReviewer3</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">31 Oct 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper593 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">This paper presents an approach to compress a dataset into a much smaller number of synthetic samples that are optimized to yield as good performance as possible when a given model is trained on that smaller dataset. This is done by unrolling the gradient descent procedure of training such a model to allow for gradient-based optimization of synthetic samples themselves as well as the used learning rates.

In summary, my evaluation is as follow:

*Pros*
- Pretty original problem formulation
- Generally well written paper

*Cons*
- Lack of comparison with simple baselines in basic dataset distillation setting
- Use in practical applications (domain adaptation, data poisoning) yet to be convincingly demonstrated
- Possibly a mistake in the theoretical analysis of the linear case

Indeed, I found the paper to be generally quite clear and enjoyed reading it. One minor thing I struggled a bit with is the distinction between "SG steps" and "Epochs" (I believe the former corresponds to when the synthetic samples are different between GD steps, whereas the later corresponds to the number of times the method repeatedly cycles over these samples) so I would perhaps encourage the authors to emphasize that difference. 

I also find the problem statement that proposed to be interesting and thought provoking, and the solution that's proposed seems quite appropriate and well thought out.

That said, I'm worried about the following:

- Unless I misunderstood, in the basic dataset distillation setting a comparison is never provided with training on a randomly selected subset of the training set. Presumably the results are worse, but I think these results should be in the paper. I would also argue for having another baseline, which would try to (approximately) optimize the choice of which training examples are put in the subset. A very simple approach would be to take the 200 runs already performed for the random selection and select the subset providing the best accuracy on the full training set and only report the performance of that subset (instead of the mean and std of all 200 runs). In short, this would help determine to what extent there is value to synthesizing entirely new samples. Moreover, I think a simple alternative baseline for creating synthesized samples should be considered. Specifically, I'd personally would like to know the performance of using per-class k-means clustering and training on the cluster centroids as the distilled dataset.

- While I appreciate that the authors identify potential applications and report some results on them, I think they currently fall short of convincing the reader of the potential of dataset distillation for these applications. For domain adaptation, no actual domain adaptation baseline is compared against (a good candidate would be method from Daume III 2007, at the very least). For data poisoning, I find that the assumptions for attacks are pretty strong, i.e. that a) you have access to the parameters of the pre-trained models to attack and b) that the model is doing additional updates *only* on the synthesized data. If there are reasons to think that such assumptions are reasonable, I'd at least expect the paper to motivate why that is. 

- In the analysis of the simple linear case, in Equation 7, there appears to be a mistake, specifically some missing parentheses:

d^Td( (I-\eta/M d^Td)\theta_0 + \eta/M \tilde{d}^T\tilde{t}) = d^T t

i.e. there should be parentheses right after "d^Td" and right before "=". This is from replacing \theta^* by the expression for \theta_1 in Equation 6, which is what I think Equation 7 is supposed to be doing. This possibly doesn't affect some of the conclusions taken from this section, but I'd like to see this potential mistake discussed/addressed.


That said, if the authors can sufficiently address the 3 points above, I'd be willing to increase my rating for this paper.

Finally, I have a few other more minor (nice-to-have) points:
- Having in the related work a discussion on the relationship with coreset methods would be nice
- Experiments showing how well the distilled datasets transfer to different network architectures than those used in training would be interesting? Even other ML algorithms would be quite interesting?
- "We often find that the number of distilled images required to achieve good performance is an informative indicator of the dataset diversity" =&gt; I'm not sure what in the paper actually justifies / demonstrates this statement.
- Figure 4 is presented as an "Ablation study", but an ablation study is where you remove certains parts of a model or algorithm and see what happens, which isn't the case here. I think it's better described as a hyper-parameter sensitivity study. 
- Some typos:
   * the below objective =&gt; the objective below
   * w.r.t. to =&gt; w.r.t
   * the discrete part rather =&gt; the discrete parts rather
   * necesary =&gt; necessary
</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">5: Marginally below acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_S1lPGgNVs7" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Interesting approach, not fully mature yet</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=Sy4lojC9tm&amp;noteId=S1lPGgNVs7"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper593 AnonReviewer2</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">17 Oct 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper593 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">The paper addresses the interesting problem of generating a small number of synthetic examples that can be used to train a classifier, replacing a larger dataset. 

The paper is clearly written, the approach makes sense, and the experiments are interesting. 
My major concerns are regarding to previous literature, analysis of the algorithm, and details of the experiment. Overall, I expect an ICLR paper to go deeper (rather than wide). I recommend presenting strong convincing evidence on one front. 


Specific comments: 
(1)  I'm missing analysis of the proposed procedure. It wasn't fully clear which Loss it minimizes and if it indeed guaranteed to converge to the minimum of that loss. 

(2)  The topic of learning from few samples is presented as completely new. It is well known that for classical linear algorithms like the Perceptron and SVM, the weights are a weighted sum of (label-weighted) samples, hence by definition of these algorithm, there is a single sample that can be used to "train" the model in one step. I'd expect some discussion of how the proposed approach relate to these classical approaches. 
There is also existing literature on a related problem of selecting samples (Teaching dimension Goldman&amp;Kearns) that could be somewhat relevant here. 

(3) Motivation. The paper provide several motivations for dataset distillation. I support the first motivation of scientific understanding what data is actually needed for a classifier, and this means that deeper analysis is needed. The practical motivations are less convincing, because (a) domain adaptation experiments are not compared with real baselines (b) robustness of poisoning with a single sample is not studied/discussed.

(4) experiments: The intro states that training with 10 images reaches 94% accuracy, but this does not seem consistent with the results in Table 1. The caption of figure 2 suggests that accuracy is between 12% and 94% which means the stated 94% is not representative or typical. Could you clarify? 
For domain adaptation. The baseline (random images) are very weak, and still perform almost   comparably to the proposed approach. More robust experiments are needed here: stronger baselines, decent hyper-parameter search etc.

(5) Writing and exposition: The paper addresses two issues: (a) learning with few synthetic samples, and (b) learning with few gradient steps. The intro tends to mix the two, and it is not clear why learning with a single gradient step is important. I recommend to separate the two topics more clearly. 
</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">5: Marginally below acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_SJxQBk_4qm" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Question about hyperparameters</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=Sy4lojC9tm&amp;noteId=SJxQBk_4qm"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">(anonymous)</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">05 Oct 2018</span><span class="item">ICLR 2019 Conference Paper593 Public Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">I'm trying to reproduce your results in Sec. 4, but had some questions about the hyperparameters in Algorithm 1:

1) What is a reasonable size for the minibatch of real samples (i.e., 'n' on line 3)?
2) What is a reasonable number of \theta_0 samples (i.e., how many time is the loop on line 5 run)?
3) What is a reasonable number of outer optimization steps (i.e., 'T' on line 2)?

Thanks!</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_SJxZo-Y4qX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Re: Question about hyperparameters</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=Sy4lojC9tm&amp;noteId=SJxZo-Y4qX"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper593 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">05 Oct 2018</span><span class="item">ICLR 2019 Conference Paper593 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Hi, 

Thanks for your interest in our paper! I will reply to your questions below:

1) What is a reasonable size for the minibatch of real samples (i.e., 'n' on line 3)?

We used minibatch of 1024 real samples to generate the results in paper. We also tried 256 and 512 some time when working on the project. It didn't seem to make much difference.

2) What is a reasonable number of \theta_0 samples (i.e., how many time is the loop on line 5 run)?

In the experiments, we used 4~16 samples per iteration, depending on the distributed training set-up. In my experience, even 1 sample per iteration can yield reasonable results.

3) What is a reasonable number of outer optimization steps (i.e., 'T' on line 2)?

For datasets other than USPS, we iterate over the training set 150 times. for USPS, we iterate 200 times.

Hope that this helps!</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_Syg9BHEHcX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Few more questions</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=Sy4lojC9tm&amp;noteId=Syg9BHEHcX"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">(anonymous)</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">06 Oct 2018</span><span class="item">ICLR 2019 Conference Paper593 Public Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">This helps - thanks! Just a couple more clarifications -- what do you use for \alpha and \eta_0?</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_S1gktV8BcX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Re: Few more questions</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=Sy4lojC9tm&amp;noteId=S1gktV8BcX"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper593 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">06 Oct 2018</span><span class="item">ICLR 2019 Conference Paper593 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">In most of our experiments, we initialize the \eta for all steps to be `0.001, and use \alpha with initial value 0.01 and exponentially decay with a factor of 0.5 every 23 epochs (sweeps over the training dataset) for USPS and 30 epochs for other datasets. The fast data-poisoning attack experiments use uses initial \eta 0.02 and initial \alpha 0.02. 

There is no particular reason about the difference. In my experience, reasonable values about that range work fine. 

I plan to clean-up and release our code when it is ready. You are more than welcome to try it out when that happens! Unfortunately, for anonymity reasons, this may take a while.  </span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div></div></div></div></div></div></main></div>
  </div>
</div>


    <!-- Footer -->
    <footer class="sitemap">
      <div class="container">
        <div class="row hidden-xs">
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/venues">All Venues</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="/contact">Contact</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
    
        <div class="row visible-xs-block">
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/contact">Contact</a></li>
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
      </div>
    </footer>
    
    <footer class="sponsor">
      <div class="container">
        <div class="row">
          <div class="col-sm-10 col-sm-offset-1">
            <p class="text-center">
              OpenReview is created by the <a href="http://www.iesl.cs.umass.edu/" target="_blank">Information Extraction and Synthesis Laboratory</a>, College of Information and Computer Science, University of Massachusetts Amherst. We gratefully acknowledge the support of the OpenReview sponsors:  Google,  Facebook, NSF, the University of Massachusetts Amherst Center for Data Science, and Center for Intelligent Information Retrieval, as well as the Google Cloud Platform for donating the computing and networking services on which OpenReview.net runs.
            </p>
          </div>
        </div>
      </div>
    </footer>

  <div id="feedback-modal" class="modal fade" tabindex="-1" role="dialog">
    <div class="modal-dialog">
      <div class="modal-content">
        <div class="modal-header">
          <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button>
          <h3 class="modal-title">Send Feedback</h3>
        </div>
        <div class="modal-body">
          <p>Enter your feedback below and we'll get back to you as soon as possible.</p>
          <form action="/feedback" method="POST">
            <div class="form-group">
              <input type="email" name="from" class="form-control" placeholder="Email" />
            </div>
            <div class="form-group">
              <input type="text" name="subject" class="form-control" placeholder="Subject" />
            </div>
            <div class="form-group">
              <textarea name="message" class="form-control feedback-input" rows="5" placeholder="Message" required=""></textarea>
            </div>
          <ul id="ui-id-2" tabindex="0" class="ui-menu ui-widget ui-widget-content" style="display: none;"></ul></form>
        </div>
        <div class="modal-footer">
          <button type="button" class="btn btn-default" data-dismiss="modal">Cancel</button>
          <button type="button" class="btn btn-primary">Send</button>
        </div>
      </div>
    </div>
  </div>

  <script type="text/javascript" async="" src="https://www.google-analytics.com/analytics.js"></script><script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js"></script>
  <script>window.jQuery || document.write('&lt;script src="/static/js/vendor/jquery-2.2.4.min.js"&gt;&lt;\/script&gt;')</script>

  <script src="/static/dist/vendor.min.js"></script>
  <script src="/static/dist/templates.min.js"></script>
  <script src="/static/dist/openreview.min.js"></script>

    <script>window.legacyScripts = true;</script>


    <script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-108703919-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() { dataLayer.push(arguments); }
      gtag('js', new Date());
      gtag('config', 'UA-108703919-1');
    </script>


<div role="status" aria-live="assertive" aria-relevant="additions" class="ui-helper-hidden-accessible"></div></body></html>
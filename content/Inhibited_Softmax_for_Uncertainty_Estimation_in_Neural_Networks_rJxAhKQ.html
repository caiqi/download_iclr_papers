<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" class="no-js"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>Inhibited Softmax for Uncertainty Estimation in Neural Networks | OpenReview</title>
  <meta name="description" content="" />

      <meta name="citation_title" content="Inhibited Softmax for Uncertainty Estimation in Neural Networks" />
        <meta name="citation_author" content="Anonymous" />
      <meta name="citation_publication_date" content="2018/09/27" />
      <meta name="citation_online_date" content="2018/09/27" />
      <meta name="citation_pdf_url" content="https://openreview.net/pdf?id=rJxA-h05KQ" />
      <meta name="twitter:card" content="summary" />
      <meta name="twitter:site" content="@openreviewnet" />
      <meta name="og:title" content="Inhibited Softmax for Uncertainty Estimation in Neural Networks" />
      <meta name="og:description" content="We present a new method for uncertainty estimation and out-of-distribution detection in neural networks with softmax output. We extend softmax layer with an additional constant input. The..." />
      <meta name="og:image" content="https://openreview.net/static/images/openreview_logo_512.png" />

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans:400,400i,700,700i" />

  <link rel="stylesheet" href="/static/css/bootstrap.min.css" />
  <link rel="stylesheet" href="/static/css/jquery-ui.min.css" />
  <link rel="stylesheet" href="/static/css/main.min.css" />
</head>

<body class="forum">
  <nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
  
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand home push-link" href="/"><strong>OpenReview</strong>.net</a>
      </div>
  
      <div id="navbar" class="navbar-collapse collapse">
        <form class="navbar-form navbar-left profile-search" role="search">
          <div class="form-group has-feedback">
            <input id="search_input" type="text" class="form-control ui-autocomplete-input" placeholder="Search ICLR 2019 Conference" autocomplete="off" />
            <span class="glyphicon glyphicon-search form-control-feedback" aria-hidden="true"></span>
          </div>
  
          <input id="search_group" type="hidden" value="ICLR.cc/2019/Conference" />
          <input id="search_content" type="hidden" value="all" />
        <ul id="ui-id-1" tabindex="0" class="ui-menu ui-widget ui-widget-content ui-autocomplete ui-front" style="display: none;"></ul></form>
  
        <ul class="nav navbar-nav navbar-right">
        
            <li id="user-menu"><a href="/login">Login</a></li>
        </ul>
      </div>
  
    </div>
  </nav>

  <div id="or-banner" class="banner" style="">
  <div class="container">
    <div class="row">
      <div class="col-xs-12"><a href="/group?id=ICLR.cc/2019/Conference" title="Venue Homepage"><img class="icon" src="/static/images/arrow_left.svg" /> Go to <strong>ICLR 2019 Conference</strong> homepage</a></div>
    </div>
  </div>
</div>
<div id="flash-message-container" class="alert alert-danger" role="alert" style="display: none;">
  <div class="container">
    <div class="row">
      <div class="col-xs-12">
        <div class="alert-content">
          <button type="button" class="close" aria-label="Close"><span aria-hidden="true">×</span></button>
        </div>
      </div>
    </div>
  </div>
</div>

<div class="container">
  <div class="row">
    <div class="col-xs-12">
      <main id="content" class="clearfix openbanner-visible legacy-styles"><div id="note_rJxA-h05KQ" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Inhibited Softmax for Uncertainty Estimation in Neural Networks</a> <a class="note_content_pdf" href="/pdf?id=rJxA-h05KQ" title="Download PDF" target="_blank"><img src="/static/images/pdf_icon_blue.svg" /></a> </h2></div><div class="meta_row"><span class="signatures">Anonymous</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">28 Sep 2018 (modified: 11 Oct 2018)</span><span class="item">ICLR 2019 Conference Blind Submission</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span><span class="item"><a class="action-bibtex-modal" data-bibtex="@inproceedings{    &#10;anonymous2019inhibited,    &#10;title={Inhibited Softmax for Uncertainty Estimation in Neural Networks},    &#10;author={Anonymous},    &#10;booktitle={Submitted to International Conference on Learning Representations},    &#10;year={2019},    &#10;url={https://openreview.net/forum?id=rJxA-h05KQ},    &#10;note={under review}    &#10;}">Show Bibtex</a></span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Abstract: </span><span class="note_content_value">We present a new method for uncertainty estimation and out-of-distribution detection in neural networks with softmax output. We extend softmax layer with an additional constant input. The corresponding additional output is able to represent the uncertainty of the network. The proposed method requires neither additional parameters nor multiple forward passes nor input preprocessing nor out-of-distribution datasets. We show that our method performs comparably to more computationally expensive methods and outperforms baselines on our experiments from image recognition and sentiment analysis domains.</span></div><div class="note_contents"><span class="note_content_field">Keywords: </span><span class="note_content_value">uncertainty  estimation, out-of-distribution detection, inhibited softmax</span></div><div class="note_contents"><span class="note_content_field">TL;DR: </span><span class="note_content_value">Uncertainty estimation in a single forward pass without additional learnable parameters.</span></div><div class="reply_row clearfix"><div class="item" id="reply_count">3 Replies</div></div></div><hr class="small" /><div id="note_children"><div class="note_with_children"><div id="note_S1gLGUZ_37" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Inhibited Softmax for Uncertainty Estimation in Neural Networks</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=rJxA-h05KQ&amp;noteId=S1gLGUZ_37"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1224 AnonReviewer2</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">01 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper1224 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">Paper claims that the modified version of softmax known as inhibited softmax can be used to calculate uncertainty.

Inhibited softmax can be thought of as having an extra output, i.e if there were 3 classes then normal softmax would have 3 nodes at the output but inhibited softmax can be thought of as having the 4th node with a constant output(value of constant is hyperparameter).

The output of this extra node in inhibited softmax is used to quantify uncertainty.


Pros
- The method requires only one forward pass, unlike popular Bayesian methods.
- seems to work for out of distribution detection.

Cons
- No mathematical intuition as to why the output of the extra node can be taken as a measure for uncertainty.
- In cases where final output is not a softmax (i.e regression) then the method is not applicable in its current form. (This and other cons have been acknowledged in the paper)

My concerns
- the method does some modifications such as turning off bias in the penultimate layer etc. What if we do all those changes and keep the softmax layer as it is? This might help to figure out if the advantage was due to inhibited softmax alone or the engineering tricks done to make it work.
</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">4: Ok but not good enough - rejection</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_SyePN76DhQ" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Review</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=rJxA-h05KQ&amp;noteId=SyePN76DhQ"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1224 AnonReviewer3</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">01 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper1224 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value"># Summary

The paper proposes a new method for computing output uncertainty estimates in DNNs for classification problems. The authors claim that replacing the softmax output layer for an Inhibit Softmax layer (a modified softmax with an additional constant additive term in the denominator, proposed in Saito et al., 2016) matches the state-of-the-art methods for uncertainty estimation an outperforms them in out-of-distribution detection tasks.  While the original idea is simple, the final method is convoluted, including several modifications (section 3.1.) to deal with an ill-behaved optimization objective, making it difficult to evaluate why the method works in the end. Finally, the experimental section needs to be extended. The proposed metrics are presented as the gold standard to measure uncertainty calibration; however, it is known that this is itself an open problem due to the fact that ground truth labels about uncertainty are not available. The paper should be extended with experiments that use a simulated data to gain a further understanding of what kind of uncertainty it is capture by the model, as well as considering additional metrics like the brier score, histograms of predictive entropy, …. Also, several state-of-the-art inference methods for BNNs that improve the results of the original backprop paper are missing in the experimental section.

# Details

The key idea is to use an Inhibited softmax output layer (instead the classical softmax) to get a better estimation of the output uncertainty (epistemic, aleatoric and distributional). They claim that the method matches other state-of-the-art methods in the field and outperform them in out-of-distribution detection tasks. However, the reason why this may be true is unclear and the experimental section needs to be strengthen. 

Regarding the inhibited softmax layer, they propose to decompose the log-likelihood in two term: the log-likelihood of the classical softmax plus a term modeling a certainty score that is maximized. What the method is doing is adding a term to all the probabilities which effectively is a simple smoothing of the output probabilities, leaving out some probability for when the test data is far from the training one. This value is fix as a hyper-parameter.  In particular “c” dictates the probability of the instance belonging to a new class, and so, fixing it ad-hoc means that you determine how far a test data should be from the training set in order to consider it out-of-distribution. It seems then a bad idea to fix this with independence of the dataset/model we are looking at. The paper would benefit from a deeper analysis of the method and connections with other methods in the literature, e.g. connections to the open world classification problem would be of interest.

Authors should elaborate on Section 3.1.. This section summarized 4 modifications that seems to be needed in order for the proposed method to work. Each of these modifications are explained in just a short paragraph, and it seems that choosing correctly these values is critical for the final performance of the algorithm. The number of hyper-parameters to tune increases making more difficult to understand why the method works (despite the analysis in the appendix). 

In the experimental section, I would encourage the authors to propose some experiments using synthetic data where they have more control about the uncertainty of the generated data. These experiments would allow to visualize several properties of the uncertainty estimator and offer more insights to the reader. I would also like to see how the current method performs in the low data regime: when you have a small training set and an over parameterized DNN. In this case, I would expect that the method overfit since all the uncertainty of the lower levels is collapsed before reaching the output. Finally, in recent years, several advances in variational inference have been proposed that improve upon the basic version of Backprop (Blundell et al., 2015), e.g., <a href="https://arxiv.org/pdf/1703.01961.pdf," target="_blank" rel="nofollow">https://arxiv.org/pdf/1703.01961.pdf,</a> https://arxiv.org/pdf/1511.06233.pdf … that should be included in the experimental section.
</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">4: Ok but not good enough - rejection</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">3: The reviewer is fairly confident that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_ByeB27683m" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Interesting idea, but needs more careful analysis.</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=rJxA-h05KQ&amp;noteId=ByeB27683m"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1224 AnonReviewer1</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">31 Oct 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper1224 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">The authors present inhibited softmax, a modification of the softmax through adding a constant activation which under a particular interpretation provides a measure for uncertainty. The method has no learnable parameter, works with only a single forward operation, does not need additional data for training, and does no input "preprocessing."  The authors present experiments on vision problems and sentiment analysis.

The idea is to add a constant pre-softmax class activation c. In section 3 the authors explain why this "serves as an uncertainty estimator." I read this paragraph several times, I do not see how they reach this conclusion. They point out that "P_c(x) is maximized only for cases from training distribution." Unless we have a reasonable justification that P_c(x) would emit small values on the other samples, assuming this alone does not tell us anything useful.

The authors chose to split the new formulation to S(x)_i times P_c(x) in equation (2). If we keep the original equation and expand the cross-entropy term we get:

L_i = - x_(y_i) + log(sum(exp(x_i))+exp(c)).

What c does, is that it puts a lower bound on the true class activation and an upper bound on the incorrect class activation. The first term increases the activation of the true class, the second term cancels the first term once x_(y_i) &gt;&gt; c. The second term also decreases the other classes' activations if they are &gt;&gt; c and &gt; x_(y_i)), but once they go below c they are no longer penalized. If we instead write the softmax as a hard max, it becomes more clear why this is the case.

L_i = - x_(y_i) + max({x_i}+{c})

Unlike the original cross-entropy loss that squashes other probabilities to 0 and the correct class to 1, the inhibited softmax would be happy if the other probabilities are less than some threshold t &gt; 0 (which is a function of c) and the correct class probability &gt; t.

From this perspective, this approach is just another way to penalize the predictions similar to [1] in which the authors penalize the negative entropy of the prediction to encourage a more uniform prediction. That method also has no additional learnable parameters, works with only a single forward pass, requires no more out-of-distribution data, and has no input "preprocessing." 

In section 3.1 the authors:
- (i) Propose to remove the bias in the final layer of the neural network to eliminate data-independency. Removing the bias from the final layer should have minimal effect on the ability of network in inducing data-independent bias -- the bias of the final layer can be directly absorbed in the bias of the layer immediate before that.
- (ii) the second paragraph that discusses replacing the penultimate layer with a kernel function is not clear. 
- (iii) The assertion that x_i increases boundlessly is wrong. Adding a constant value to all of x_i's does not change the loss of the original cross-entropy term -- it cancels out in the probability; furthermore, the gradient of - log P_c converges to zero quickly when max(x_i) &gt;&gt; c. If we expand the term - log P_c  to - log(sum(exp(x_i))) + log(sum(exp(x_i))+exp(c)), and then simplify it to - max(x_i) + max({x_i}+{c}), we'll see that when x_i is sufficiently larger than c, the first term and the second term cancel out. This cancelling effect happens immediately with a hard max when max(x_i)&gt;c, but for a softmax, it is more gradual, but quick nonetheless. Therefore the x_i's should not be increasing boundlessly.
- (iv) Applying l2 regularization only on the weights of the final layer merely pushes the high-magnitude activation to the layer immediate before it. Unless we regularize all the layers, this should have minimal effect.

It seems, empirically, that the deeper the network, the more the overconfidence problem [2]. The overconfidence makes the detection of out-of-distribution samples in modern neural networks particularly more difficult. The first matter that concerns me in the evaluation of this work is that the networks under study, in addition to being non-standard, are much shallower than the common neural networks that are used for evaluation of out-of-distribution samples. For instance, (Wide)-ResNets are commonly used in previous work such as [3] to evaluate the method for OOD detection. The OOD problem in the shallow networks is a relatively easier problem than the OOD detection in deep networks. The second concern is that the set of chosen datasets for in-distribution and out-of-distribution are far from challenging: the datasets are so different that a linear classifier based on the local image statistics can separate them. Some more challenging datasets that appear in the OOD detection literature are CIFAR100, TinyImageNet, and SUN.

Quality. The provided theoretical analysis are either incomplete or need a more careful review by the authors. See above.

Clarity. The paper is overall easy to follow and understand. However, there are a few instances that should be clarified. The paragraph that provides intuition on why inhibited softmax serves as an uncertainty estimator could be improved. The paragraph explaining the adjustment by using a kernel activation function is not clear. The explanation of the experiments (the three bullet points in section 4) can be improved by adding more details. Specifically, the measures should be explained properly.

Originality. The three main contributions are, (i) the mathematical explanation, which as discussed earlier is not clear (to me) and seems insufficient by itself. (ii) The additional adjustments, which as discussed earlier were not convincing, and (iii) the benchmarks comparing the proposed idea with some of the recent methods that I believe do not reflect a conclusive picture because of the two stated concerns. The idea of inhibited softmax itself comes from another publication (Saito et al. in the paper).

I would be happy to change my rating if I have misunderstood parts of the paper or have made a mistake in my review.

References.
[1] G. Pereyra, G. Tucker, J. Chorowski, Ł. Kaiser, and G. Hinton, “Regularizing Neural Networks by Penalizing Confident Output Distributions,” ICLR Work., 2017
[2] C. Guo, G. Pleiss, Y. Sun, and K. Q. Weinberger, “On Calibration of Modern Neural Networks,” ICML, 2017.
[3] S. Liang, Y. Li, and R. Srikant, “Enhancing The Reliability of Out-of-distribution Image Detection in Neural Networks,” ICLR, 2018.
</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">3: Clear rejection</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></main></div>
  </div>
</div>


    <!-- Footer -->
    <footer class="sitemap">
      <div class="container">
        <div class="row hidden-xs">
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/venues">All Venues</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="/contact">Contact</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
    
        <div class="row visible-xs-block">
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/contact">Contact</a></li>
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
      </div>
    </footer>
    
    <footer class="sponsor">
      <div class="container">
        <div class="row">
          <div class="col-sm-10 col-sm-offset-1">
            <p class="text-center">
              OpenReview is created by the <a href="http://www.iesl.cs.umass.edu/" target="_blank">Information Extraction and Synthesis Laboratory</a>, College of Information and Computer Science, University of Massachusetts Amherst. We gratefully acknowledge the support of the OpenReview sponsors:  Google,  Facebook, NSF, the University of Massachusetts Amherst Center for Data Science, and Center for Intelligent Information Retrieval, as well as the Google Cloud Platform for donating the computing and networking services on which OpenReview.net runs.
            </p>
          </div>
        </div>
      </div>
    </footer>

  <div id="feedback-modal" class="modal fade" tabindex="-1" role="dialog">
    <div class="modal-dialog">
      <div class="modal-content">
        <div class="modal-header">
          <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button>
          <h3 class="modal-title">Send Feedback</h3>
        </div>
        <div class="modal-body">
          <p>Enter your feedback below and we'll get back to you as soon as possible.</p>
          <form action="/feedback" method="POST">
            <div class="form-group">
              <input type="email" name="from" class="form-control" placeholder="Email" />
            </div>
            <div class="form-group">
              <input type="text" name="subject" class="form-control" placeholder="Subject" />
            </div>
            <div class="form-group">
              <textarea name="message" class="form-control feedback-input" rows="5" placeholder="Message" required=""></textarea>
            </div>
          <ul id="ui-id-2" tabindex="0" class="ui-menu ui-widget ui-widget-content" style="display: none;"></ul></form>
        </div>
        <div class="modal-footer">
          <button type="button" class="btn btn-default" data-dismiss="modal">Cancel</button>
          <button type="button" class="btn btn-primary">Send</button>
        </div>
      </div>
    </div>
  </div>

  <script type="text/javascript" async="" src="https://www.google-analytics.com/analytics.js"></script><script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js"></script>
  <script>window.jQuery || document.write('&lt;script src="/static/js/vendor/jquery-2.2.4.min.js"&gt;&lt;\/script&gt;')</script>

  <script src="/static/dist/vendor.min.js"></script>
  <script src="/static/dist/templates.min.js"></script>
  <script src="/static/dist/openreview.min.js"></script>

    <script>window.legacyScripts = true;</script>


    <script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-108703919-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() { dataLayer.push(arguments); }
      gtag('js', new Date());
      gtag('config', 'UA-108703919-1');
    </script>


<div role="status" aria-live="assertive" aria-relevant="additions" class="ui-helper-hidden-accessible"></div></body></html>
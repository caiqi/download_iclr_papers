<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" class="no-js"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>Low Latency Privacy Preserving Inference | OpenReview</title>
  <meta name="description" content="" />

      <meta name="citation_title" content="Low Latency Privacy Preserving Inference" />
        <meta name="citation_author" content="Anonymous" />
      <meta name="citation_publication_date" content="2018/09/27" />
      <meta name="citation_online_date" content="2018/09/27" />
      <meta name="citation_pdf_url" content="https://openreview.net/pdf?id=rJl8viCqKQ" />
      <meta name="twitter:card" content="summary" />
      <meta name="twitter:site" content="@openreviewnet" />
      <meta name="og:title" content="Low Latency Privacy Preserving Inference" />
      <meta name="og:description" content="Using machine learning in domains such as medicine and finance requires tools that can preserve privacy and confidentiality. In this work, we focus on private inference with neural networks...." />
      <meta name="og:image" content="https://openreview.net/static/images/openreview_logo_512.png" />

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans:400,400i,700,700i" />

  <link rel="stylesheet" href="/static/css/bootstrap.min.css" />
  <link rel="stylesheet" href="/static/css/jquery-ui.min.css" />
  <link rel="stylesheet" href="/static/css/main.min.css" />
</head>

<body class="forum">
  <nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
  
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand home push-link" href="/"><strong>OpenReview</strong>.net</a>
      </div>
  
      <div id="navbar" class="navbar-collapse collapse">
        <form class="navbar-form navbar-left profile-search" role="search">
          <div class="form-group has-feedback">
            <input id="search_input" type="text" class="form-control ui-autocomplete-input" placeholder="Search ICLR 2019 Conference" autocomplete="off" />
            <span class="glyphicon glyphicon-search form-control-feedback" aria-hidden="true"></span>
          </div>
  
          <input id="search_group" type="hidden" value="ICLR.cc/2019/Conference" />
          <input id="search_content" type="hidden" value="all" />
        <ul id="ui-id-1" tabindex="0" class="ui-menu ui-widget ui-widget-content ui-autocomplete ui-front" style="display: none;"></ul></form>
  
        <ul class="nav navbar-nav navbar-right">
        
            <li id="user-menu"><a href="/login">Login</a></li>
        </ul>
      </div>
  
    </div>
  </nav>

  <div id="or-banner" class="banner" style="">
  <div class="container">
    <div class="row">
      <div class="col-xs-12"><a href="/group?id=ICLR.cc/2019/Conference" title="Venue Homepage"><img class="icon" src="/static/images/arrow_left.svg" /> Go to <strong>ICLR 2019 Conference</strong> homepage</a></div>
    </div>
  </div>
</div>
<div id="flash-message-container" class="alert alert-danger" role="alert" style="display: none;">
  <div class="container">
    <div class="row">
      <div class="col-xs-12">
        <div class="alert-content">
          <button type="button" class="close" aria-label="Close"><span aria-hidden="true">×</span></button>
        </div>
      </div>
    </div>
  </div>
</div>

<div class="container">
  <div class="row">
    <div class="col-xs-12">
      <main id="content" class="clearfix openbanner-visible legacy-styles"><div id="note_rJl8viCqKQ" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Low Latency Privacy Preserving Inference</a> <a class="note_content_pdf" href="/pdf?id=rJl8viCqKQ" title="Download PDF" target="_blank"><img src="/static/images/pdf_icon_blue.svg" /></a> </h2></div><div class="meta_row"><span class="signatures">Anonymous</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">28 Sep 2018 (modified: 11 Oct 2018)</span><span class="item">ICLR 2019 Conference Blind Submission</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span><span class="item"><a class="action-bibtex-modal" data-bibtex="@inproceedings{    &#10;anonymous2019low,    &#10;title={Low Latency Privacy Preserving Inference},    &#10;author={Anonymous},    &#10;booktitle={Submitted to International Conference on Learning Representations},    &#10;year={2019},    &#10;url={https://openreview.net/forum?id=rJl8viCqKQ},    &#10;note={under review}    &#10;}">Show Bibtex</a></span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Abstract: </span><span class="note_content_value">Using machine learning in domains such as medicine and finance requires tools that can preserve privacy and confidentiality. In this work, we focus on private inference with neural networks. Following the work of Dowlin et al. (2016), we use Homomorphic Encryption (HE) to allow neural networks to be applied to encrypted data and therefore make predictions while preserving privacy. We present 90x improvement in latency and 7x improvement in throughput compared to prior attempts. The improved performance is achieved via a modern implementation of the encryption scheme and a collection of methods to better represent the data during the computation. We also apply the method of transfer learning to provide private inference services using deep networks. We demonstrate the efficacy of our methods on several computer vision tasks.</span></div><div class="note_contents"><span class="note_content_field">Keywords: </span><span class="note_content_value">privacy, classification, homomorphic encryption, neural networks</span></div><div class="note_contents"><span class="note_content_field">TL;DR: </span><span class="note_content_value">This work presents methods, combining neural-networks and encryptions, to make predictions while preserving the privacy of the data owner with low latency</span></div><div class="reply_row clearfix"><div class="item" id="reply_count">8 Replies</div></div></div><hr class="small" /><div id="note_children"><div class="note_with_children"><div id="note_SyxpMdlha7" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Incremental improvements or poor motivation. Writing needs improvement. </a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=rJl8viCqKQ&amp;noteId=SyxpMdlha7"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper264 AnonReviewer4</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">16 Nov 2018</span><span class="item">ICLR 2019 Conference Paper264 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">This paper proposes several improvements to cryptonet proposed in Dowlin et al, 2016. The contributions include: 
1. Better implementation to improve speed and throughput. 
2. Modified architecture (LoLa) to reduce latency. 
3. Using features from a deep network rather than raw input. 
Contribution 1 is better engineering with modern libraries and more efficient parallelism. This has limited academic novelty. Contribution 2 seems interesting, but is poorly explained. What is the cause of this improvement? What are some guidelines of latency-bandwidth trade-off in homomorphic deep networks? Contribution 3 seems to eliminate the need for remote classification service itself. Users need classification services because they do not have the computation resources, or do not have enough data to train classifiers successfully. If the users need to generate good representations such that classification becomes linearly separable, then why don’t they just train the last linear layer themselves? Is there any computation or statistical reason to use any remote service?

The biggest problem with the paper is that it is hard to read and has several writing issues:
1. It is not self contained. I had to refer to Dowlin et al, 2016 to understand what the authors are referring to. 
2. Notations are used but not defined. For example, I couldn’t find any definition several symbols in section 3.
3. The narration is too long and detailed: the authors report a laundry list of the things they did, details that should go into the appendix. It’s hard to find what the main contributions are. 

</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">4: Ok but not good enough - rejection</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">3: The reviewer is fairly confident that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_HklEFpAa2Q" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Low latency version of CryptoNet</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=rJl8viCqKQ&amp;noteId=HklEFpAa2Q"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper264 AnonReviewer3</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">05 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper264 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">This paper proposes a low latency data representation / network architecture to operate on encrypted data. This work is based on CryptoNet, but uses a different data representation. How to apply machine learning on confidential data is important in many practical applications.

I recommend to give a brief review of HE before Section 3, to be more friendly.</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">6: Marginally above acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_Hkgb8VNGhm" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Potential to advance the area, but the paper should be improved</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=rJl8viCqKQ&amp;noteId=Hkgb8VNGhm"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper264 AnonReviewer2</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">28 Oct 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper264 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">The paper proposes improvements on the area of neural network inference with homomorphically encrypted data, where a major drawback in current applications is the high computational cost.

The paper makes several minor contributions and, in my opinion, it fails to provide an unified message to the reader. The arguably independent contributions are:
1. the use of the faster SAEL 3.2.1 over CryptoNet — not really an innovation per se
2. flexible representation of message space — the main contribution
3. a much more complex network than CryptoNet for an experiment on CIFAR10 — minor contribution/application of 2
4. using pre-trained model for embedding images before encryption — minor contribution

I think the authors should refocus this work on point 2 and 3 only. 1 could simply be a note in the paper, as not a a real contribution and 4 may be even excluded as it goes toward a different direction.

I will mainly focus on the central contribution of the paper — the data representation — which in my opinion has the potential to progress this area further. Unfortunately, the current quality of presentation is suboptimal. The choices on architecture and intermediate representations of LoLa in Section 4 are hard to follow, and it is not clear to me when the authors are making a choice or satisfying a constraint. That is, for example when we aim to vs. we have to use one representation in place of another? Since this is the main contribution, I suggest the author to help the presentation with diagrams and formulae in this Section. Each component should be presented in modular fashion. In fact, this is what the authors did in Section 3. Yet, towards reuse of these concepts for machine learning applications, the authors could present their improvements as applied to *neural network layers*. E.g. responding to answers such as: what are the most efficient data representation in input and output if we want to compute a convolutional layer? It would be also interesting to break down cost requirements for each intermediate computation, to highlight bottlenecks and compare alternative choices.

Incidentally, LoLa-Conv improvements appear to be simply due to the use of a conv vs. dense layer as input.

Section 6 explains the use of a pre-trained AlexNet to embed data for learning a linear model (HE-aware) for Caltech 101. In the context of application of HE, the idea is novel to my knowledge, although it is a rather common practice in deep learning. The number reported in this section have no baseline to compare with and therefore it’s hard to evaluate their significance.

A missing reference is [A].

Minors
* section 4: “this saves a processing step which saves"
* typos in section 6: “a networks”, “in medical imagine"
* footnote 4: “convinient"

[A] TAPAS: Tricks to Accelerate (encrypted) Prediction As a Service.</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">5: Marginally below acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_Syl2KCLsi7" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Missed a very relevant recent published paper</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=rJl8viCqKQ&amp;noteId=Syl2KCLsi7"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">(anonymous)</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">22 Oct 2018</span><span class="item">ICLR 2019 Conference Paper264 Public Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Hi,
I do not see the mention of [1] at all in the paper. The paper was presented in the last ICML and I think should be a part of the literature review and comparisons.

[1] TAPAS: Tricks to Accelerate (encrypted) Prediction As a Service. <a href="http://proceedings.mlr.press/v80/sanyal18a.html" target="_blank" rel="nofollow">http://proceedings.mlr.press/v80/sanyal18a.html</a></span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_HJxnfS7Jhm" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Thanks for the reference</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=rJl8viCqKQ&amp;noteId=HJxnfS7Jhm"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper264 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">25 Oct 2018</span><span class="item">ICLR 2019 Conference Paper264 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Thank you for the reference, we will add it to the paper since it adds significant insights. The paper you pointed to argues that CryptoNets, and other similar solutions, leak information about the structure of the network the provider uses via the encryption parameters [1]. Therefore, they propose a new approach that uses a different encryption scheme that is capable of relatively fast bootstrapping but is limited to work with only binary values. To accommodate that, they use Binary Neural Networks (BNNs). After applying various techniques, they manage to perform a single prediction in 37 **hours** that is predicted to reduce to 2.41 **hours** if 16 servers are used in parallel to perform the prediction.

In contrast, the approach we present here can make a prediction on a single machine in 2.2 **seconds**. Indeed, it leaks some information on the structure of the network, a point that we mention in the Conclusions section (Section 7). One thing to note, is that the TAPAS approach (the approach presented in the recent ICML paper) does leak information about the structure of the network too. For example, computation time varies with the network size, as can be seen in Table 2 in the reference paper that shows that the computation time is different for different tasks. Moreover, since the service allows an adversary to get predictions on its data-points, the adversary can use this to build a labeled dataset and train a model on it that will replicate the predictions the service provides. 

To conclude, we think that this is an important reference and we will include it in the paper. However, the problem they address is different and therefore it does not stand in direct comparison with the solutions we propose.


[1] It is important to note that the information that leaks is only about the layout of the network and not about the data that was used for training or the data that was supplied for predictions.
</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_H1xqJa8knX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Precise Summary!</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=rJl8viCqKQ&amp;noteId=H1xqJa8knX"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">(anonymous)</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">25 Oct 2018</span><span class="item">ICLR 2019 Conference Paper264 Public Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">I believe this is a very good summary of the paper. I would want to add that not leaking information through the encryption parameters also allows you to update the model continuously without informing the client. It's a small point but that might be very useful in the real world.</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div></div></div><div class="note_with_children"><div id="note_S1lLBKLssQ" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>The contribution</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=rJl8viCqKQ&amp;noteId=S1lLBKLssQ"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">(anonymous)</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">22 Oct 2018</span><span class="item">ICLR 2019 Conference Paper264 Public Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">What's your technical contribution compared with CryptoNet? It seems the only difference
comes from the used homomorphic library?</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_rke0USG1hm" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>The main contribution is in using alternative representation methods that result in &gt;10x performance gain</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=rJl8viCqKQ&amp;noteId=rke0USG1hm"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper264 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">25 Oct 2018</span><span class="item">ICLR 2019 Conference Paper264 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">
Replacing the homomorphic encryption library gives a speedup of about 8x, from 205 seconds to 24.8 seconds. However, the techniques presented in this work give an additional 11x speedup, down to 2.2 seconds per prediction for the MNIST dataset. The main difference between the approach we take here and CryptoNets is that CryptoNets encrypt every node in the network as a message while we encrypt entire layers. We show that this allows us to use HE’s ability to perform vector operations. We show that there are multiple ways to represent vectors in this scheme and to get low latency it is better to use a diverse set of representations.

The difference between the approach we propose and CryptoNets is demonstrated again in section 5 when we try to apply secure predictions to the CIFAR dataset. Since the network used is more complicated, CryptoNets’ approach fails to execute since the amount of memory needed is in the order of 100’s of GBs, whereas our solution executes in 12 minutes (and uses only several GBs of RAM).

In section 6 we push the idea of representations even further and show that if you use standard networks, such as AlexNet, to encrypt the image in a deep representation, you can obtain predictions in a fraction of a second. In contrast, if we were to apply the same network on the pixel level data as CryptoNets does, it will fail both because of memory requirements and lengthy computation.

</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div></div></main></div>
  </div>
</div>


    <!-- Footer -->
    <footer class="sitemap">
      <div class="container">
        <div class="row hidden-xs">
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/venues">All Venues</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="/contact">Contact</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
    
        <div class="row visible-xs-block">
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/contact">Contact</a></li>
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
      </div>
    </footer>
    
    <footer class="sponsor">
      <div class="container">
        <div class="row">
          <div class="col-sm-10 col-sm-offset-1">
            <p class="text-center">
              OpenReview is created by the <a href="http://www.iesl.cs.umass.edu/" target="_blank">Information Extraction and Synthesis Laboratory</a>, College of Information and Computer Science, University of Massachusetts Amherst. We gratefully acknowledge the support of the OpenReview sponsors:  Google,  Facebook, NSF, the University of Massachusetts Amherst Center for Data Science, and Center for Intelligent Information Retrieval, as well as the Google Cloud Platform for donating the computing and networking services on which OpenReview.net runs.
            </p>
          </div>
        </div>
      </div>
    </footer>

  <div id="feedback-modal" class="modal fade" tabindex="-1" role="dialog">
    <div class="modal-dialog">
      <div class="modal-content">
        <div class="modal-header">
          <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button>
          <h3 class="modal-title">Send Feedback</h3>
        </div>
        <div class="modal-body">
          <p>Enter your feedback below and we'll get back to you as soon as possible.</p>
          <form action="/feedback" method="POST">
            <div class="form-group">
              <input type="email" name="from" class="form-control" placeholder="Email" />
            </div>
            <div class="form-group">
              <input type="text" name="subject" class="form-control" placeholder="Subject" />
            </div>
            <div class="form-group">
              <textarea name="message" class="form-control feedback-input" rows="5" placeholder="Message" required=""></textarea>
            </div>
          <ul id="ui-id-2" tabindex="0" class="ui-menu ui-widget ui-widget-content" style="display: none;"></ul></form>
        </div>
        <div class="modal-footer">
          <button type="button" class="btn btn-default" data-dismiss="modal">Cancel</button>
          <button type="button" class="btn btn-primary">Send</button>
        </div>
      </div>
    </div>
  </div>

  <script type="text/javascript" async="" src="https://www.google-analytics.com/analytics.js"></script><script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js"></script>
  <script>window.jQuery || document.write('&lt;script src="/static/js/vendor/jquery-2.2.4.min.js"&gt;&lt;\/script&gt;')</script>

  <script src="/static/dist/vendor.min.js"></script>
  <script src="/static/dist/templates.min.js"></script>
  <script src="/static/dist/openreview.min.js"></script>

    <script>window.legacyScripts = true;</script>


    <script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-108703919-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() { dataLayer.push(arguments); }
      gtag('js', new Date());
      gtag('config', 'UA-108703919-1');
    </script>


<div role="status" aria-live="assertive" aria-relevant="additions" class="ui-helper-hidden-accessible"></div></body></html>
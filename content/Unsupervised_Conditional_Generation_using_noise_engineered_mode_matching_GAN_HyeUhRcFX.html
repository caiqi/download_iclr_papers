<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" class="no-js"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>Unsupervised Conditional Generation using noise engineered mode matching GAN | OpenReview</title>
  <meta name="description" content="" />

      <meta name="citation_title" content="Unsupervised Conditional Generation using noise engineered mode matching GAN" />
        <meta name="citation_author" content="Anonymous" />
      <meta name="citation_publication_date" content="2018/09/27" />
      <meta name="citation_online_date" content="2018/09/27" />
      <meta name="citation_pdf_url" content="https://openreview.net/pdf?id=HyeU1hRcFX" />
      <meta name="twitter:card" content="summary" />
      <meta name="twitter:site" content="@openreviewnet" />
      <meta name="og:title" content="Unsupervised Conditional Generation using noise engineered mode..." />
      <meta name="og:description" content="Conditional generation refers to the process of sampling from an unknown distribution conditioned on semantics of the data. This can be achieved by augmenting the generative model with the desired..." />
      <meta name="og:image" content="https://openreview.net/static/images/openreview_logo_512.png" />

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans:400,400i,700,700i" />

  <link rel="stylesheet" href="/static/css/bootstrap.min.css" />
  <link rel="stylesheet" href="/static/css/jquery-ui.min.css" />
  <link rel="stylesheet" href="/static/css/main.min.css" />
</head>

<body class="forum">
  <nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
  
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand home push-link" href="/"><strong>OpenReview</strong>.net</a>
      </div>
  
      <div id="navbar" class="navbar-collapse collapse">
        <form class="navbar-form navbar-left profile-search" role="search">
          <div class="form-group has-feedback">
            <input id="search_input" type="text" class="form-control ui-autocomplete-input" placeholder="Search ICLR 2019 Conference" autocomplete="off" />
            <span class="glyphicon glyphicon-search form-control-feedback" aria-hidden="true"></span>
          </div>
  
          <input id="search_group" type="hidden" value="ICLR.cc/2019/Conference" />
          <input id="search_content" type="hidden" value="all" />
        <ul id="ui-id-1" tabindex="0" class="ui-menu ui-widget ui-widget-content ui-autocomplete ui-front" style="display: none;"></ul></form>
  
        <ul class="nav navbar-nav navbar-right">
        
            <li id="user-menu"><a href="/login">Login</a></li>
        </ul>
      </div>
  
    </div>
  </nav>

  <div id="or-banner" class="banner" style="">
  <div class="container">
    <div class="row">
      <div class="col-xs-12"><a href="/group?id=ICLR.cc/2019/Conference" title="Venue Homepage"><img class="icon" src="/static/images/arrow_left.svg" /> Go to <strong>ICLR 2019 Conference</strong> homepage</a></div>
    </div>
  </div>
</div>
<div id="flash-message-container" class="alert alert-danger" role="alert" style="display: none;">
  <div class="container">
    <div class="row">
      <div class="col-xs-12">
        <div class="alert-content">
          <button type="button" class="close" aria-label="Close"><span aria-hidden="true">×</span></button>
        </div>
      </div>
    </div>
  </div>
</div>

<div class="container">
  <div class="row">
    <div class="col-xs-12">
      <main id="content" class="clearfix openbanner-visible legacy-styles"><div id="note_HyeU1hRcFX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Unsupervised Conditional Generation using noise engineered mode matching GAN</a> <a class="note_content_pdf" href="/pdf?id=HyeU1hRcFX" title="Download PDF" target="_blank"><img src="/static/images/pdf_icon_blue.svg" /></a> </h2></div><div class="meta_row"><span class="signatures">Anonymous</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">28 Sep 2018 (modified: 20 Nov 2018)</span><span class="item">ICLR 2019 Conference Blind Submission</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span><span class="item"><a class="action-bibtex-modal" data-bibtex="@inproceedings{    &#10;anonymous2019unsupervised,    &#10;title={Unsupervised Conditional Generation using noise engineered mode matching GAN},    &#10;author={Anonymous},    &#10;booktitle={Submitted to International Conference on Learning Representations},    &#10;year={2019},    &#10;url={https://openreview.net/forum?id=HyeU1hRcFX},    &#10;note={under review}    &#10;}">Show Bibtex</a></span><a class="note_content_pdf item" href="/revisions?id=HyeU1hRcFX" target="_blank">Show Revisions</a></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Abstract: </span><span class="note_content_value">Conditional generation refers to the process of sampling from an unknown distribution conditioned on semantics of the data. This can be achieved by augmenting the generative model with the desired semantic labels, albeit it is not straightforward in an unsupervised setting where the semantic label of every data sample is unknown. In this paper, we address this issue by proposing a method that can generate samples conditioned on the properties of a latent distribution engineered in accordance with a certain data prior. In particular, a latent space inversion network is trained in tandem with a generative adversarial network such that the modal properties of the latent space distribution are induced in the data generating distribution. We demonstrate that our model despite being fully unsupervised, is effective in learning meaningful representations through its mode matching property. We validate our method on multiple unsupervised tasks such as conditional generation, dataset attribute discovery and inference using three real world image datasets namely MNIST, CIFAR-10 and CELEB-A and show that the results are comparable to the state-of-the-art methods. </span></div><div class="note_contents"><span class="note_content_field">Keywords: </span><span class="note_content_value">Noise engineered GAN, Latent space engineering, Mode matching, Unsupervised learning</span></div><div class="note_contents"><span class="note_content_field">TL;DR: </span><span class="note_content_value">A GAN model where an inversion mapping from the generated data space to an engineered latent space is learned such that properties of the data generating distribution are matched to those of the latent distribution.</span></div><div class="reply_row clearfix"><div class="item" id="reply_count">7 Replies</div></div></div><hr class="small" /><div id="note_children"><div class="note_with_children"><div id="note_r1gpI2JA67" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Thanks for the insightful reviews.</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HyeU1hRcFX&amp;noteId=r1gpI2JA67"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper990 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">18 Nov 2018</span><span class="item">ICLR 2019 Conference Paper990 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">We are thankful to the reviewers for the constructive feedback and comments. It has helped us in improving the quality of the paper and understanding the work better. We shall address all the concerns of the reviewers one by one through suggested experiments and revisions. </span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_rJxVyZR0h7" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Modification to GAN construction which induces bias to encourage mode matching between latent and data space.</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HyeU1hRcFX&amp;noteId=rJxVyZR0h7"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper990 AnonReviewer3</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">06 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper990 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">This paper presents a GAN construction which encourages the latent space to mode-match the data distribution.  This allows for unsupervised class-label inference (experimentally verified for two tasks).

I think the paper is of low significance, but the approach outlined is interesting.

Unfortunately, I think the work is slightly let down by the presentation (there are many typos, and the first couple of sections could do with a rewrite), as well as a lack of rigorous experimentation.  I believe that the paper is also missing references to the conditional VAE literature, which shares many similarities (at least in application) with the described approach.

Pros:
- Some theoretical justification for the approach taken.
- Early evidence that the method allows for latent space class separation, given a prior on number of classes.

Cons:
- A little more experimental evidence would be welcome.  E.g. why is the result for CIFAR 10 not shown---hard to understand how helpful the inductive bias is for a general problem.
- No discussion of conditional VAEs (which were designed with a very similar goal in mind).
- No discussion of why decomposing h in the manner in which they did was appropriate.
- Would be nice to see a more detailed study of how adding supervision + varying the strength of the inductive bias affects performance.

</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">5: Marginally below acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">3: The reviewer is fairly confident that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_HkeyPwV63X" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>A well-written paper; would be appreciated if the motivation were clearer and the method more principle</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HyeU1hRcFX&amp;noteId=HkeyPwV63X"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper990 AnonReviewer1</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">05 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper990 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">This paper is concerned with the so-called conditional generation, which was descried as the task of sampling from an unknown distribution conditioned on semantics of the data. This proposed method aims at achieving this by using a latent distribution engineered according to a certain data prior. Experimental results showed that the proposed method seems to produce good results.

I have several questions about the motivation and the method in the paper. First, it is not clear to me how the "semantics" of the data was defined. Is it given by visual inspection? Is it possible to find it with some automated method? Second, the authors seem to advocate the idea that data of a k-mode distribution should be generated from a k-mode latent distribution. It might be useful in certain scenarios; however, it is not clear why the transformation from the latent to the observed does not change the number of modes or why keeping the same number of modes would endow the latent distribution a "semantics" meaning. We know that a k-mode distribution can be obtained by applying a smooth nonlinear transformation to a Gaussian or uniform distribution and, similarly, a k-mode distribution can be transformed to a single-mode distribution with a smooth mapping. So I am not sure why engineering the latent distribution this way can give it a "semantics" meaning. Should we try to enforce a kind of smoothness of the transformation, by, say, penalizing high derivative values? Third, the experimental results seem nice, but the lack of comparisons blurs the advantage of the proposed method. How is the result produced by GAN compared to the reported one? How did the original GAN with the engineering latent distribution work? It would be appreciated if the authors could address these issues more clearly.</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">5: Marginally below acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">3: The reviewer is fairly confident that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_ryx9eWzApQ" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Response to Reviewer #1 (part 2 of 2)</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HyeU1hRcFX&amp;noteId=ryx9eWzApQ"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper990 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">18 Nov 2018 (modified: 20 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper990 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Q3. Why keeping the same number of modes would endow the latent distribution a "semantics" meaning. So I am not sure why engineering the latent distribution this way can give it a "semantics" meaning. Should we try to enforce a kind of smoothness of the transformation, by, say, penalizing high derivative values? 

Ans: As discussed while answering the first question, semantics refer to the modes in the true data. Latent space engineering alone wouldn’t endow semantics in the observed space but training an inversion network in tandem would, in the sense that the number (and the properties) of modes in the observed space will be same as that in the latent space (which is assumed to be same as the true data space). 

While enforcing a smooth transformation on the generator might produce a multi modal distribution, it is not guaranteed. However, a multimodal latent space in tandem with an inversion mapping from the data back to a multimodal distribution does so (Please refer to Proposition 1 and 2). 

Q4. The experimental results seem nice, but the lack of comparisons blurs the advantage of the proposed method. How is the result produced by GAN compared to the reported one? How did the original GAN with the engineering latent distribution work? It would be appreciated if the authors could address these issues more clearly.

Ans: Thank you for this suggestion. We have added new experiments with a conventional GAN trained with the engineered latent space. Please refer to Appendix E (Figure 19) for details. The below are the observations. 

We took 2 MNIST digits (3 and 5) with a skew of 30:70 and trained a conventional GAN with a bimodal latent space with a modal mass of 30:70. It was observed that the conventional GAN could not separate the modes and most of the samples drawn are from the dominant mode. On the contrary, it is shown in the paper that our model can separate out the modes.

Mode counting results for stacked MNIST dataset and FID values are included in Table 1 and 2 of the current version of the paper, respectively.</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_HkxeyR-CaX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Response to Reviewer #1 (part 1 of 2)</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HyeU1hRcFX&amp;noteId=HkxeyR-CaX"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper990 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">18 Nov 2018</span><span class="item">ICLR 2019 Conference Paper990 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">We thank the reviewer for the insightful comments and below are our responses for the concerns raised. We are happy to answer further questions, if any. 

Q1.  First, it is not clear to me how the "semantics" of the data was defined. Is it given by visual inspection? Is it possible to find it with some automated method?

Ans: By semantics of the data we refer to the modes in the data distribution. Further, the modes are defined as disjoint connected open subsets in the support of the distribution of the data (Please refer to the opening paragraph of section 2). These modes may correspond to ‘natural’ classes in the data (as in MNIST data where every mode correspond to a digit) or separable attributes in data space (like smile with teeth versus no teeth in the CelebA dataset). It is akin in spirit to the concept of ‘clusters’ in any unsupervised task wherein the idea of a cluster depends on the task at hand in which case the semantics (modes) are implicitly defined.

Our claim is that the properties of the latent space are imposed on the generated data space and hence ‘semantics’ (also called the modes or disjoint connected open subsets) similar to that of the latent space are enforced on the generated space. We do NOT claim that these modes (or semantics) in the generated data are always visually interpretable. However, if the true data space has visually interpretable modes, then so is the generated data space. For example, we have shown experimentally that each of the 10 modes in the generated MNIST dataset correspond to a digit type, without any mixup. 

To drive home this point, we have conducted further experiments where we consider only a single digit type from the MNIST dataset and train a NEMGAN with a discrete uniform latent space with 10 modes. It is observed (and reported in the revised version of the paper) that the generated data space has exactly 10 distinct modes. Further, while the data from each mode exhibits some level of separation (for instance when we consider digit 7, one of the modes contains 7s with the vertical line slit), not all of them are visually interpretable. Please refer to the Appendix C of the paper for the figures from this experiment. 

In summary, conceptually by semantics we mean the modal properties of the true data space which is obtained (or assumed) by the prior information that one has about the data. The following text has been added to the introduction - 
“The proposed model thus preserves the semantics of the data in the sense that each mode in the generated space correspond to a certain data semantic”. 

Q2: The authors seem to advocate the idea that data of a k-mode distribution should be generated from a k-mode latent distribution. It might be useful in certain scenarios; however, it is not clear why the transformation from the latent to the observed does not change the number of modes.  We know that a k-mode distribution can be obtained by applying a smooth nonlinear transformation to a Gaussian or uniform distribution and, similarly, a k-mode distribution can be transformed to a single-mode distribution with a smooth mapping.

Ans:  As pointed out rightly, a unimodal distribution can be transformed into multimodal distribution and vice versa. Ideally, a neural network (the GAN generator), being a non linear transformation is supposed to transform a unimodal latent distribution to a multimodal distribution but it has been found practically that this often does not happen. It is a well-known fact that a GAN tends to collapse the modes in the observed space even though the true data space has multiple modes. 

Also, if the latent space is a union of k non-empty disjoint connected open subsets, no continuous function could map it to a set with more than k disjoint subsets (Proposition 1). Based on this, our aim in this work is to propose a method which enforces a GAN to produce a distribution with multiple modes (disjoint open subsets) and thus avoiding mode collapse. We achieve so by training an inversion network which maps the observed data space back to a multimodal latent space, in tandem with a regular GAN, by using Proposition 1 twice  (once on the latent to data mapping and once on the data to latent mapping). It is noteworthy that in all  our experiments the latent space is designed to be a union of k non-empty disjoint connected open subsets.

In summary, owing to the fact that neural networks are deterministic continuous functions, we have shown (in Proposition 1 and 2) that if there exists a mapping from the observed data space back to the latent space, the observed space is deemed to have as many modes as in the latent space. It is this inversion (with the KL-loss) which ensures that the transformation from the latent to the observed does not change the number of modes. </span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div><div class="note_with_children"><div id="note_r1lKzjkq2Q" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Review</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HyeU1hRcFX&amp;noteId=r1lKzjkq2Q"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper990 AnonReviewer2</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">02 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper990 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">The paper proposes simple modifications to GAN architecture for unsupervised conditional image generation. The authors achieve this by making the distribution of noise z dependent on variable y that can depend on the label distribution when available. This involves learning to predict the input noise z as well as y from the generated image. The qualitative results shown for unsupervised conditional image generations using the approach are convincing. 

Pros:
	- The paper is well written and easy to follow.
	- The simple modification to the noise distribution leads to good results on unsupervised conditional image generation.
	- Minimizes loss terms exactly instead of lower bound as is commonly done in other similar unsupervised approaches.
	- Theoretical justifications for the approach are convincing.

Cons:
	- The paper can be strengthened by including ablation studies on the loss term for the z reconstruction.
	- How will InfoGAN and VEEGAN compare with similar loss terms for the z reconstruction added to their objective?
	- It will be useful to show FID and other similar scores to better evaluate the learned generative model. Including mode counting, experiments will strengthen the paper.
	- ACGAN can suffer from the issue of generating images where it is easy to infer y [1]. This leads to mode collapse within each category/class. Will the proposed approach suffer from similar issues?

[1] Shu, Rui, Hung Bui, and Stefano Ermon. "AC-GAN Learns a Biased Distribution."</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">6: Marginally above acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_Hyxm3CqxAm" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Response to Reviewer #2</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HyeU1hRcFX&amp;noteId=Hyxm3CqxAm"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper990 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">20 Nov 2018</span><span class="item">ICLR 2019 Conference Paper990 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">We thank the reviewer for the constructive feedback and comments. Below are our responses for the concerns raised. We are happy to answer further questions, if any.

Q1. The paper can be strengthened by including ablation studies on the loss term for the z reconstruction.

Ans: Thank you for this suggestion. We have now included the ablation studies in the experimental section. The following are the observations - 

Our model involves two reconstruction stages for the latent space ($h_1$ and $h_2$). In this section, to study the effect of individual components of the model, we perform the following ablation studies -  (a) training a NEMGAN without the $h_1$ network, (b) training a NEMGAN without the $h_2$ network, (c) training a conventional GAN with noise engineering. Experiment (a) and (b) are conducted on the MNIST dataset and the output images are shown in Fig 9. It can be seen that the absence of the KL-loss ($h_1$) results in the mixing of classes within each mode and the absence of norm-loss ($h_2$) results in lack of variety within each mode. For example, 1's with serifs are not generated in absence of $h_2$. Results for the experiment (c) is depicted in the Appendix E which suggests that a conventional GAN with latent space engineering cannot separate out the modes. These experiments suggest that the inclusion of the norm-based reconstruction term encourages the model to avoid the intraclass mode collapse unlike the case of supervised conditional GANs [1]. 

Q2. How will InfoGAN and VEEGAN compare with similar loss terms for the z reconstruction added to their objective?

Ans: VEEGAN  by construction has a latent space reconstruction term in it. We included the z reconstruction term in the official implementation of the InfoGAN and found that it is unable to produce the MNIST images. We believe that this might be because of the fact that the Q network, which is used to maximize the mutual information, is made a part of the discriminator. Thus, performing a joint task of maximizing mutual information between the categorical code and the generated images as well as reconstructing the noise term is not feasible. That is perhaps the reason authors of InfoGAN terms ‘z’ as the irreducible noise. On the contrary, our architecture has the discriminator and the latent reconstructor decoupled which is the reason our method performs multiple tasks such as conditional generation, data inference etc. 

Q3. It will be useful to show FID and other similar scores to better evaluate the learned generative model. Including mode counting, experiments will strengthen the paper.

Ans: Thank you again for this suggestion. We have included the FID values in Table 2 of the current version of the paper and compared with the existing methods. We have also included the mode counting experiments on standard stacked MNIST data and a toy 8 component GMM data in Appendix D. Mode counting results are summarized in Table 1 of the current version of the paper and it is found that NEMGAN captures the most number of modes. 

Q4. ACGAN can suffer from the issue of generating images where it is easy to infer y [1]. This leads to mode collapse within each category/class. Will the proposed approach suffer from similar issues?

Ans: This is precisely the reason we broke down the z-reconstruction loss into two parts - KL and norm-based. The below paragraph (from Sec. 2 of the paper) summarizes the idea - 

Using proposition 1 and 2, one can make the data generating distribution to be bimodal, however, produced modes might be degenerated in the sense that $\sX_i$'s  reduce to singletons (intramode collapse).  To avoid this degenerative case, we propose to decompose  $h$  as a composite of two mappings $h_1:{\sX}\rightarrow \hat{\sZ}$ and $h_2:\hat{\sZ}\rightarrow \hat{\sY}$. Further, minimizing a norm distance between samples of $\sZ$ and $\hat{\sZ}$ will prevent degenerative modes in $P_X$. This is because $h_2$ will enforce unique reconstruction of every sample of $\rvz$ which in turn ensures that a unique sample of $\rvx$ is generated by a unique sample of $\rvz$. 

These ideas are reconciled with the ablation experiments (Sec. 5.4) where the inclusion of norm-based loss is seen to avoid the intraclass mode collapse. This point has been brought out in the current version of the paper. 

[1] Shu, Rui, Hung Bui, and Stefano Ermon. "AC-GAN Learns a Biased Distribution."</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div></div></main></div>
  </div>
</div>


    <!-- Footer -->
    <footer class="sitemap">
      <div class="container">
        <div class="row hidden-xs">
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/venues">All Venues</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="/contact">Contact</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
    
        <div class="row visible-xs-block">
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/contact">Contact</a></li>
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
      </div>
    </footer>
    
    <footer class="sponsor">
      <div class="container">
        <div class="row">
          <div class="col-sm-10 col-sm-offset-1">
            <p class="text-center">
              OpenReview is created by the <a href="http://www.iesl.cs.umass.edu/" target="_blank">Information Extraction and Synthesis Laboratory</a>, College of Information and Computer Science, University of Massachusetts Amherst. We gratefully acknowledge the support of the OpenReview sponsors:  Google,  Facebook, NSF, the University of Massachusetts Amherst Center for Data Science, and Center for Intelligent Information Retrieval, as well as the Google Cloud Platform for donating the computing and networking services on which OpenReview.net runs.
            </p>
          </div>
        </div>
      </div>
    </footer>

  <div id="feedback-modal" class="modal fade" tabindex="-1" role="dialog">
    <div class="modal-dialog">
      <div class="modal-content">
        <div class="modal-header">
          <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button>
          <h3 class="modal-title">Send Feedback</h3>
        </div>
        <div class="modal-body">
          <p>Enter your feedback below and we'll get back to you as soon as possible.</p>
          <form action="/feedback" method="POST">
            <div class="form-group">
              <input type="email" name="from" class="form-control" placeholder="Email" />
            </div>
            <div class="form-group">
              <input type="text" name="subject" class="form-control" placeholder="Subject" />
            </div>
            <div class="form-group">
              <textarea name="message" class="form-control feedback-input" rows="5" placeholder="Message" required=""></textarea>
            </div>
          <ul id="ui-id-2" tabindex="0" class="ui-menu ui-widget ui-widget-content" style="display: none;"></ul></form>
        </div>
        <div class="modal-footer">
          <button type="button" class="btn btn-default" data-dismiss="modal">Cancel</button>
          <button type="button" class="btn btn-primary">Send</button>
        </div>
      </div>
    </div>
  </div>

  <script type="text/javascript" async="" src="https://www.google-analytics.com/analytics.js"></script><script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js"></script>
  <script>window.jQuery || document.write('&lt;script src="/static/js/vendor/jquery-2.2.4.min.js"&gt;&lt;\/script&gt;')</script>

  <script src="/static/dist/vendor.min.js"></script>
  <script src="/static/dist/templates.min.js"></script>
  <script src="/static/dist/openreview.min.js"></script>

    <script>window.legacyScripts = true;</script>


    <script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-108703919-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() { dataLayer.push(arguments); }
      gtag('js', new Date());
      gtag('config', 'UA-108703919-1');
    </script>


<div role="status" aria-live="assertive" aria-relevant="additions" class="ui-helper-hidden-accessible"></div></body></html>
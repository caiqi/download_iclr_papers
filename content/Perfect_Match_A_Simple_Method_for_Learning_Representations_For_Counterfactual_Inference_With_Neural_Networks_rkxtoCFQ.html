<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" class="no-js"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>Perfect Match: A Simple Method for Learning Representations For Counterfactual Inference With Neural Networks | OpenReview</title>
  <meta name="description" content="" />

      <meta name="citation_title" content="Perfect Match: A Simple Method for Learning Representations For Counterfactual Inference With Neural Networks" />
        <meta name="citation_author" content="Anonymous" />
      <meta name="citation_publication_date" content="2018/09/27" />
      <meta name="citation_online_date" content="2018/09/27" />
      <meta name="citation_pdf_url" content="https://openreview.net/pdf?id=rkxt8oC9FQ" />
      <meta name="twitter:card" content="summary" />
      <meta name="twitter:site" content="@openreviewnet" />
      <meta name="og:title" content="Perfect Match: A Simple Method for Learning Representations For..." />
      <meta name="og:description" content="Learning representations for counterfactual inference from observational data is of high practical relevance for many domains, such as healthcare, public policy and economics. Counterfactual..." />
      <meta name="og:image" content="https://openreview.net/static/images/openreview_logo_512.png" />

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans:400,400i,700,700i" />

  <link rel="stylesheet" href="/static/css/bootstrap.min.css" />
  <link rel="stylesheet" href="/static/css/jquery-ui.min.css" />
  <link rel="stylesheet" href="/static/css/main.min.css" />
</head>

<body class="forum">
  <nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
  
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand home push-link" href="/"><strong>OpenReview</strong>.net</a>
      </div>
  
      <div id="navbar" class="navbar-collapse collapse">
        <form class="navbar-form navbar-left profile-search" role="search">
          <div class="form-group has-feedback">
            <input id="search_input" type="text" class="form-control ui-autocomplete-input" placeholder="Search ICLR 2019 Conference" autocomplete="off" />
            <span class="glyphicon glyphicon-search form-control-feedback" aria-hidden="true"></span>
          </div>
  
          <input id="search_group" type="hidden" value="ICLR.cc/2019/Conference" />
          <input id="search_content" type="hidden" value="all" />
        <ul id="ui-id-1" tabindex="0" class="ui-menu ui-widget ui-widget-content ui-autocomplete ui-front" style="display: none;"></ul></form>
  
        <ul class="nav navbar-nav navbar-right">
        
            <li id="user-menu"><a href="/login">Login</a></li>
        </ul>
      </div>
  
    </div>
  </nav>

  <div id="or-banner" class="banner" style="">
  <div class="container">
    <div class="row">
      <div class="col-xs-12"><a href="/group?id=ICLR.cc/2019/Conference" title="Venue Homepage"><img class="icon" src="/static/images/arrow_left.svg" /> Go to <strong>ICLR 2019 Conference</strong> homepage</a></div>
    </div>
  </div>
</div>
<div id="flash-message-container" class="alert alert-danger" role="alert" style="display: none;">
  <div class="container">
    <div class="row">
      <div class="col-xs-12">
        <div class="alert-content">
          <button type="button" class="close" aria-label="Close"><span aria-hidden="true">×</span></button>
        </div>
      </div>
    </div>
  </div>
</div>

<div class="container">
  <div class="row">
    <div class="col-xs-12">
      <main id="content" class="clearfix openbanner-visible legacy-styles"><div id="note_rkxt8oC9FQ" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Perfect Match: A Simple Method for Learning Representations For Counterfactual Inference With Neural Networks</a> <a class="note_content_pdf" href="/pdf?id=rkxt8oC9FQ" title="Download PDF" target="_blank"><img src="/static/images/pdf_icon_blue.svg" /></a> </h2></div><div class="meta_row"><span class="signatures">Anonymous</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">28 Sep 2018 (modified: 15 Nov 2018)</span><span class="item">ICLR 2019 Conference Blind Submission</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span><span class="item"><a class="action-bibtex-modal" data-bibtex="@inproceedings{    &#10;anonymous2019perfect,    &#10;title={Perfect Match: A Simple Method for Learning Representations For Counterfactual Inference With Neural Networks},    &#10;author={Anonymous},    &#10;booktitle={Submitted to International Conference on Learning Representations},    &#10;year={2019},    &#10;url={https://openreview.net/forum?id=rkxt8oC9FQ},    &#10;note={under review}    &#10;}">Show Bibtex</a></span><a class="note_content_pdf item" href="/revisions?id=rkxt8oC9FQ" target="_blank">Show Revisions</a></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Abstract: </span><span class="note_content_value">Learning representations for counterfactual inference from observational data is of high practical relevance for many domains, such as healthcare, public policy and economics. Counterfactual inference enables one to answer "What if...?" questions, such as "What would be the outcome if we gave this patient treatment $t_1$?". However, current methods for training neural networks for counterfactual inference on observational data are either overly complex, limited to settings with only two available treatment options, or both. Here, we present Perfect Match (PM), a method for training neural networks for counterfactual inference that is easy to implement, compatible with any architecture, does not add computational complexity or hyperparameters, and extends to any number of treatments. PM is based on the idea of augmenting samples within a minibatch with their propensity-matched nearest neighbours. Our experiments demonstrate that PM outperforms a number of more complex state-of-the-art methods in inferring counterfactual outcomes across several real-world and semi-synthetic datasets.</span></div><div class="reply_row clearfix"><div class="item" id="reply_count">8 Replies</div></div></div><hr class="small" /><div id="note_children"><div class="note_with_children"><div id="note_B1gT2MScTm" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Revised manuscript uploaded</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=rkxt8oC9FQ&amp;noteId=B1gT2MScTm"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper192 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">15 Nov 2018</span><span class="item">ICLR 2019 Conference Paper192 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">We thank the reviewers for their helpful and constructive feedback. We uploaded a revised draft to implement the suggested improvements and to address the concerns of the reviewers. 

In addition, while performing the additional experiments requested by the reviewers, we discovered a small error in the code for the experiments for the "+ on X" and "+ MLP" ablations that could in some cases deactivate matching when it was supposed to be active. We have fixed the error and revised the reported numbers for the "+ on X" and "+ MLP" ablations in Tables 3 and 4. The "+ MLP" and "+ on X" ablations are now more competitive with PM on IHDP. The overall conclusions have not changed since both ablations still suffer from the curse of dimensionality in higher-dimensional datasets if not accounted for by, e.g., matching on a low-dimensional representation of X (see the rebuttal to R2; or p.8 paragraph "Counterfactual Inference.").  To ensure other results were not affected, we have also re-run all other experiments that used batch matching.</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_HygsMMPq2X" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Review: Interesting paper and impressive results; why novel vs. standard PSM?</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=rkxt8oC9FQ&amp;noteId=HygsMMPq2X"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper192 AnonReviewer1</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">03 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper192 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">========= Summary =========

The authors propose a novel method for counterfactual inference (i.e. individual/heterogeneous treatment effect, as well as average treatment effect) with neural networks. They perform propensity score matching within each minibatch in order to match the covariate distributions during training, which leads to a doubly robust model.

PM is evaluated on several standard semi-synthetic datasets (jobs, IHDP, TCGA) and PM shows state-of-the-art performance on some datasets, and overall looks quite promising. 

======= Comments =======

The paper is well-written, presents a novel method of some interest to the community, and shows quite good performance across a range of relevant benchmarks.

I have one major issue with this work: I don't see why propensity-score matching *within* a minibatch should provide a substantial improvement over propensity-score matching across the dataset (Ho et al 2011). I find the cursory explanation given ("it ensures that every gradient step is done in a way that is approximately unbiased") unconvincing, since (a) proper SGD training should be robust to per-batch biases during training (the expected loss is identical for both methods, correct?), and (b) biases should go away in the limit of large batch sizes. If indeed SGD required unbiased *minibatches* then standard minibatch SGD wouldn't work at all.

Looking at the experimental details in the appendix, it appears that the MatchIt package was used to do PSM, rather than a careful comparison under the same conditions. Are the exact matching procedure, PS estimator model, choosing "one of 6 closest  matches by propensity score", batch size, etc. the same between your PM implementation and MatchIt? I'd be very curious to see the results of a controlled comparison between Alg S1 and S2 under the same conditions (i.e. run your PM implementation on the whole dataset), and perhaps even some more clever experiments illustrating why matching within a minibatch is important. 

Another hypothesis for why PM is better than PSM is that the matching distribution for PM changes at each epoch (at least due to the randomization among the 6 closest matches). Could it be that the advantage of PM is that it actually provides a randomized rather than constant distribution of matched points?

Can the authors provide more motivation for why PM should outperform PSM? Or some more careful comparison of these methods isolating the benefits of PM? I think a convincing justification and comparison here could change my opinion, as I like the paper otherwise. Thanks!

Detailed Comments:

- There is insufficient explanation of the PM method in the main text. The method is only mentioned in a single sentence buried in the middle of a long paragraph "In PM, we match every sample within a minibatch...". This should be made more clear, e.g. by moving Algorithm S1 to the main text.
- The discussion on Model Selection and the argument for nearest-neighbor PEHE is clever and well-supported by the experiments.
- In Table 3 and 4, it's not clear which numbers are reported by the original authors and which were replicated by the authors.</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">5: Marginally below acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">3: The reviewer is fairly confident that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_Skxizc4q6m" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Rebuttal Reviewer 1</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=rkxt8oC9FQ&amp;noteId=Skxizc4q6m"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper192 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">15 Nov 2018</span><span class="item">ICLR 2019 Conference Paper192 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">
We thank Reviewer 1 for the helpful and constructive feedback. We address the feedback below. 

R1: "Looking at the experimental details in the appendix, it appears that the MatchIt package was used to do PSM, rather than a careful comparison under the same conditions. (...) I'd be very curious to see the results of a controlled comparison between Alg S1 and S2 (...), and perhaps even some more clever experiments illustrating why matching within a minibatch is important. "

We thank R1 for these insightful and important comments. In the latest revision, we have added the requested baseline that performs PSM using the PM matching procedure on the dataset level (called PSM_PM) . The old PSM baseline that used the "MatchIt" package is now referred to as PSM_MI. Although PSM_PM indeed performed better than PSM_MI, PM still consistently, with the exception of Jobs, outperformed PSM_PM (Tables 3 and 4). To further elucidate why this is the case, we added a new experiment for which we compared the training dynamics of PM, PSM_PM and PSM_MI (Fig. 6, and p.9 second to last paragraph).

R1: "I have one major issue with this work: I don't see why propensity-score matching *within* a minibatch should provide a substantial improvement over propensity-score matching across the dataset (Ho et al 2011)."
R1: "(a) proper SGD training should be robust to per-batch biases during training (the expected loss is identical for both methods, correct?)"

R1 is correct in that the expected observed factual loss is identical for both methods. However, when learning counterfactual representations from observational data, we are interested in reducing the unobserved counterfactual error using the observed factual loss. In observational data, we do not have direct access to the counterfactual error, and a gradient step that improves the factual error may not necessarily improve the counterfactual error. In fact, in practice, we often see the opposite, undesired behavior of the factual error decreasing and the counterfactual error increasing as the network overfits to the properties of the treated group (see Fig. 6 - PSM_MI for an illustration of this behavior).

As we have outlined in the manuscript, it is possible to implicitly optimise the unobserved counterfactual error using the observed factual samples if (1) we manage to break the dependence of treatment assignment on $X$, and (2) we observe all relevant variables. The results in Fig. 6 show that attempting to ensure that each individual batch conforms to (1) has a significant variance-reducing effect compared to sampling batches that may not necessarily conform to (1) as well from a pre-balanced dataset. This indicates that PM effectively minimises either the number or magnitude of undesired steps that improve the factual error but do not improve (or worsen) the counterfactual error.

R1: "(b) biases should go away in the limit of large batch sizes."

R1 is correct that the performance advantage of PM over PSM_PM would disappear in the limit case - when the batch size equals the number of samples in the training set. However, we are not aware of any prior works that have shown that either very large batch sizes or matching within batches may be necessary to effectively learn counterfactual representations with neural networks when using PSM with SGD, nor that ensuring that each individual batch is balanced has a significant variance-reducing effect. In addition, the use of minibatching may be a necessity when the entire dataset does not fit in memory.

R1: "(...) Could it be that the advantage of PM is that it actually provides a randomized rather than constant distribution of matched points?"

We thank R1 for this feedback. We added new experiments to the latest revision in order to determine the impact of the randomisation introduced by matching to one of the k nearest neighbours at random (Table S1). We found no significant differences in performance both between using randomisation and not using randomisation (k=1), and between variants of PM that used different choices of $k$ ranging from 3-15. We therefore conclude that randomisation is not an essential component of PM.

We also thank R1 for the detailed comments and suggested improvements, which we have implemented in the revised manuscript.

R1: "- There is insufficient explanation of the PM method in the main text. (...) This should be made more clear, e.g. by moving Algorithm S1 to the main text."

We have moved Algorithm 1 to the main text in the revised manuscript.

R1: "- In Table 3 and 4, it's not clear which numbers are reported by the original authors and which were replicated by the authors."

We have added detailed documentation on the origins of the reported performance numbers in Appendix I.

</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div><div class="note_with_children"><div id="note_B1e3G21qhm" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Simple idea, the presentation of the method and experiment results can be improved</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=rkxt8oC9FQ&amp;noteId=B1e3G21qhm"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper192 AnonReviewer3</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">02 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper192 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">Summary:
This paper proposed to extend TARNET (Shalit et al. 2017), a representation learning approach for counterfactual inference, in the following ways.

First, to extend TARNET to multiple treatment setting, k head networks (instead of 2) were constructed following the shared MLP layers, where each head network modeled the outcome of one treatment. This extension seemed quite straightforward.

Second, during training, for every sample in a minibatch, find its nearest neighbors from all other treatments and add them to the minibatch. The distance was measured by the propensity score, which was defined the probability of a sample being assigned to a treatment group and could be learned by a classification model (such as support vector machine used in this work). Therefore, 1) the augmented minibatch would contain the same number of samples for each treatment group; 2) different treatment group were balanced.

Third, a model selection strategy was proposed by estimating the PEHE using nearest neighbor search.

Comments:
This paper is well motivated. The key challenges in counterfactual inference is how to adjust for the bias in treatment assignment and the associated discrepancies in the distribution of different treatment groups. 

The main idea of this paper, i.e., augmenting the minibatch through propensity score matching for each sample, is well explained in Section 3. However, it could be better if the introduction of model architecture (in Appendix F) was presented in the method section.

Did the author need to train (k choose 2) SVMs to compute the propensity scores for samples from k treatment groups?

When comparing different approaches, as were shown in Table 3, 4 and Figure 3,4, did the author run any statistical test, such as t-test, to confirm the difference between those distributions were significant? The standard deviations of those errors seemed quite large so the difference could be non-significant.

Could the author provide more explanations on why the proposed approach, i.e., minibatch augmentation using propensity score matching, can outperform the TARNET? In TARNET, each sample it only used to update the head network corresponding to the sample's treatment assignment, why would balancing samples in the minibatch can improve the estimation of treatment effect?</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">5: Marginally below acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_SklykqV9a7" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Rebuttal Reviewer 3</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=rkxt8oC9FQ&amp;noteId=SklykqV9a7"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper192 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">15 Nov 2018</span><span class="item">ICLR 2019 Conference Paper192 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">
We thank Reviewer 3 for the helpful and constructive feedback. We address the feedback below in order. 

R3: "However, it could be better if the introduction of model architecture (in Appendix F) was presented in the method section."

We thank R3 for this feedback. We have moved the architectural details to the method section in the revised draft.

R3: "Did the author need to train (k choose 2) SVMs to compute the propensity scores for samples from k treatment groups?"

No, only one multi-class SVM - one entry in the output vector for each treatment option - was necessary (see Algorithm 1).

R3: "(...) did the author run any statistical test, such as t-test, to confirm the difference between those distributions were significant?"

We have added the requested statistical significance test results (alpha &lt; 0.05) to Tables 3 and 4. With few exceptions, most results on IHDP and News-2/4/8/16 were significantly different to PM due to the large number of repeated experiments. However, we found that on Jobs, where PM had the second best result after GANITE, and on News-4, where PM had the second best result after PD, those results were not significantly different. 

R3: "Could the author provide more explanations on why the proposed approach, i.e., minibatch augmentation using propensity score matching, can outperform the TARNET? In TARNET, each sample it only used to update the head network corresponding to the sample's treatment assignment, why would balancing samples in the minibatch can improve the estimation of treatment effect?"

We thank R3 for this comment. In TARNET, the shared lower layers are trained on all samples (see p.4 last paragraph, or Shalit et al. 2017) and are therefore subject to the treatment assignment bias present in observational data. The TARNET architecture by itself therefore does not address treatment assignment bias. PM is orthogonal to TARNET, and improves upon the performance of TARNET by controlling for treatment assignment bias.</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div><div class="note_with_children"><div id="note_rkxxZ8nwnm" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Overall a good paper</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=rkxt8oC9FQ&amp;noteId=rkxxZ8nwnm"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper192 AnonReviewer2</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">01 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper192 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">This paper proposes an augmentation of traditional neural network learning to allow for the inference of causal effects. Specifically, they modify the data sampling procedure of SGD during training to use matched samples that are paired via propensity score matching. Experimental results on a number of dataset show that the proposed methodology is comparable to alternative machine learning based causal inference methods. 

Overall, I think this is a nice idea. I have two main concerns: 
(1) The use of small batches for matching. Figure 2 does alleviate this concern to an extent, but there is a large literature in statistics and the social sciences on the effect that the quality of matches have on the final causal estimand. It is quite possible that this particular dataset is more amenable to PSM. It is also worth noting that while there is bias reduction shown in figure 2, it is not overwhelming. 

(2) The use of propensity scores for matching. One of the insights from the heterogeneous treatment effect literature is that it is not difficult to find cases where the propensity of treatment is identical for two sets of covariates that otherwise do not obey any real balance. This can lead to large biases in the final estimate. Given that PSM is still a relatively widely used practice, I don’t think that its use is a ground for rejection in itself, but given that neural networks are often used to estimate complex causal relations when they are used and this paper is interested in individual treatment effects it is worth noting. 

I found the experimental setup to do a very good job in covering large portions of the behavior of the algorithm. The final results are a little underwhelming–the proposed method does not appear to clearly define a new state of the art for the tasks it is applied to–but it is often competitive and the paper presents an interesting idea.
</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">6: Marginally above acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_B1euHY4q67" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Rebuttal Reviewer 2</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=rkxt8oC9FQ&amp;noteId=B1euHY4q67"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper192 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">15 Nov 2018</span><span class="item">ICLR 2019 Conference Paper192 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">We thank Reviewer 2 for the helpful and constructive feedback. We address the feedback below in order. 

R2: "I have two main concerns: (1) The use of small batches for matching. (...)"

We believe R2 may have missed this detail in the manuscript: PM does not use small batches for matching. All samples from the whole training set are used for matching (see p. 3, bottom, and Algorithm 1). 

R2: "It is quite possible that this particular dataset is more amenable to PSM."

We evaluated PM on four different datasets (IHDP, Jobs, News-2/4/8/16 and TCGA) that cover a wide range of characteristics (Table 2), and the performance of PM was consistently either state-of-the-art or highly competitive with the respective state-of-the-art (Tables 3 and 4). The consistently strong performance of PM in our experiments shows that PM performs well across multiple datasets with varying characteristics.

R2: "(2) The use of propensity scores for matching. (...)"

We thank R2 for this comment. In the most recent revision of the manuscript, we have updated the "+ on X" ablation to use a low-dimensional representation of X for matching (obtained via PCA, 50 principal components) on the News dataset. The results show that matching on a low-dimensional representation is as effective as matching on the propensity score (Tables 3 and 4; p. 8 last paragraph). This indicates that PM is effective with any low-dimensional balancing score, not just the propensity score.

R2: "The final results are a little underwhelming–the proposed method does not appear to clearly define a new state of the art (...)"

Across the four evaluated datasets, PM consistently achieved either the best or a highly competitive performance in the relevant metrics for ITE estimation (PEHE, R_{Pol}). It is important that a method achieves good results consistently across many different datasets with varying characteristics, because we, in general, do not have access to the counterfactual error in practice, i.e. for a given real-world observational dataset we would not know whether a non-consistent method is operating at its best or its worst.

Finally, independently of performance metrics, we would additionally like to stress that PM is easy to implement, compatible with any architecture, does not add computational complexity or hyperparameters, and extends to any number of treatments. This is in stark contrast to the limitations and complexities added by existing state-of-the-art methods (Table 1).</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div></div></main></div>
  </div>
</div>


    <!-- Footer -->
    <footer class="sitemap">
      <div class="container">
        <div class="row hidden-xs">
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/venues">All Venues</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="/contact">Contact</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
    
        <div class="row visible-xs-block">
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/contact">Contact</a></li>
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
      </div>
    </footer>
    
    <footer class="sponsor">
      <div class="container">
        <div class="row">
          <div class="col-sm-10 col-sm-offset-1">
            <p class="text-center">
              OpenReview is created by the <a href="http://www.iesl.cs.umass.edu/" target="_blank">Information Extraction and Synthesis Laboratory</a>, College of Information and Computer Science, University of Massachusetts Amherst. We gratefully acknowledge the support of the OpenReview sponsors:  Google,  Facebook, NSF, the University of Massachusetts Amherst Center for Data Science, and Center for Intelligent Information Retrieval, as well as the Google Cloud Platform for donating the computing and networking services on which OpenReview.net runs.
            </p>
          </div>
        </div>
      </div>
    </footer>

  <div id="feedback-modal" class="modal fade" tabindex="-1" role="dialog">
    <div class="modal-dialog">
      <div class="modal-content">
        <div class="modal-header">
          <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button>
          <h3 class="modal-title">Send Feedback</h3>
        </div>
        <div class="modal-body">
          <p>Enter your feedback below and we'll get back to you as soon as possible.</p>
          <form action="/feedback" method="POST">
            <div class="form-group">
              <input type="email" name="from" class="form-control" placeholder="Email" />
            </div>
            <div class="form-group">
              <input type="text" name="subject" class="form-control" placeholder="Subject" />
            </div>
            <div class="form-group">
              <textarea name="message" class="form-control feedback-input" rows="5" placeholder="Message" required=""></textarea>
            </div>
          <ul id="ui-id-2" tabindex="0" class="ui-menu ui-widget ui-widget-content" style="display: none;"></ul></form>
        </div>
        <div class="modal-footer">
          <button type="button" class="btn btn-default" data-dismiss="modal">Cancel</button>
          <button type="button" class="btn btn-primary">Send</button>
        </div>
      </div>
    </div>
  </div>

  <script type="text/javascript" async="" src="https://www.google-analytics.com/analytics.js"></script><script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js"></script>
  <script>window.jQuery || document.write('&lt;script src="/static/js/vendor/jquery-2.2.4.min.js"&gt;&lt;\/script&gt;')</script>

  <script src="/static/dist/vendor.min.js"></script>
  <script src="/static/dist/templates.min.js"></script>
  <script src="/static/dist/openreview.min.js"></script>

    <script>window.legacyScripts = true;</script>


    <script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-108703919-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() { dataLayer.push(arguments); }
      gtag('js', new Date());
      gtag('config', 'UA-108703919-1');
    </script>


<div role="status" aria-live="assertive" aria-relevant="additions" class="ui-helper-hidden-accessible"></div></body></html>
<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" class="no-js"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>Deep learning generalizes because the parameter-function map is biased towards simple functions | OpenReview</title>
  <meta name="description" content="" />

      <meta name="citation_title" content="Deep learning generalizes because the parameter-function map is biased towards simple functions" />
        <meta name="citation_author" content="Anonymous" />
      <meta name="citation_publication_date" content="2018/09/27" />
      <meta name="citation_online_date" content="2018/09/27" />
      <meta name="citation_pdf_url" content="https://openreview.net/pdf?id=rye4g3AqFm" />
      <meta name="twitter:card" content="summary" />
      <meta name="twitter:site" content="@openreviewnet" />
      <meta name="og:title" content="Deep learning generalizes because the parameter-function map is..." />
      <meta name="og:description" content="Deep neural networks generalize remarkably well without explicit regularization even in the strongly over-parametrized regime. This success suggests that some form of implicit regularization must..." />
      <meta name="og:image" content="https://openreview.net/static/images/openreview_logo_512.png" />

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans:400,400i,700,700i" />

  <link rel="stylesheet" href="/static/css/bootstrap.min.css" />
  <link rel="stylesheet" href="/static/css/jquery-ui.min.css" />
  <link rel="stylesheet" href="/static/css/main.min.css" />
</head>

<body class="forum">
  <nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
  
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand home push-link" href="/"><strong>OpenReview</strong>.net</a>
      </div>
  
      <div id="navbar" class="navbar-collapse collapse">
        <form class="navbar-form navbar-left profile-search" role="search">
          <div class="form-group has-feedback">
            <input id="search_input" type="text" class="form-control ui-autocomplete-input" placeholder="Search ICLR 2019 Conference" autocomplete="off" />
            <span class="glyphicon glyphicon-search form-control-feedback" aria-hidden="true"></span>
          </div>
  
          <input id="search_group" type="hidden" value="ICLR.cc/2019/Conference" />
          <input id="search_content" type="hidden" value="all" />
        <ul id="ui-id-1" tabindex="0" class="ui-menu ui-widget ui-widget-content ui-autocomplete ui-front" style="display: none;"></ul></form>
  
        <ul class="nav navbar-nav navbar-right">
        
            <li id="user-menu"><a href="/login">Login</a></li>
        </ul>
      </div>
  
    </div>
  </nav>

  <div id="or-banner" class="banner" style="">
  <div class="container">
    <div class="row">
      <div class="col-xs-12"><a href="/group?id=ICLR.cc/2019/Conference" title="Venue Homepage"><img class="icon" src="/static/images/arrow_left.svg" /> Go to <strong>ICLR 2019 Conference</strong> homepage</a></div>
    </div>
  </div>
</div>
<div id="flash-message-container" class="alert alert-danger" role="alert" style="display: none;">
  <div class="container">
    <div class="row">
      <div class="col-xs-12">
        <div class="alert-content">
          <button type="button" class="close" aria-label="Close"><span aria-hidden="true">Ã—</span></button>
        </div>
      </div>
    </div>
  </div>
</div>

<div class="container">
  <div class="row">
    <div class="col-xs-12">
      <main id="content" class="clearfix openbanner-visible legacy-styles"><div id="note_rye4g3AqFm" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Deep learning generalizes because the parameter-function map is biased towards simple functions</a> <a class="note_content_pdf" href="/pdf?id=rye4g3AqFm" title="Download PDF" target="_blank"><img src="/static/images/pdf_icon_blue.svg" /></a> </h2></div><div class="meta_row"><span class="signatures">Anonymous</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">28 Sep 2018 (modified: 11 Oct 2018)</span><span class="item">ICLR 2019 Conference Blind Submission</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span><span class="item"><a class="action-bibtex-modal" data-bibtex="@inproceedings{    &#10;anonymous2019deep,    &#10;title={Deep learning generalizes because the parameter-function map is biased towards simple functions},    &#10;author={Anonymous},    &#10;booktitle={Submitted to International Conference on Learning Representations},    &#10;year={2019},    &#10;url={https://openreview.net/forum?id=rye4g3AqFm},    &#10;note={under review}    &#10;}">Show Bibtex</a></span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Abstract: </span><span class="note_content_value">Deep neural networks generalize remarkably well without explicit regularization even in the strongly over-parametrized regime. This success suggests that some form of implicit regularization must be at work. In this paper we argue that a strong intrinsic bias in the parameter-function map helps explain the success of deep neural networks. We provide evidence that the parameter-function map results in a heavily biased prior over functions, if we assume that the training algorithm samples parameters close to uniformly within the zero-error region. The PAC-Bayes theorem then guarantees good expected generalization for target functions producing high-likelihood training sets.
We exploit connections between deep neural networks and Gaussian processes to estimate the marginal likelihood, finding remarkably good agreement between Gaussian processes and neural networks for small input sets.  Using approximate marginal likelihood calculations we produce nontrivial generalization PAC-Bayes error bounds which correlate well with the true error on realistic datasets such as MNIST and CIFAR and for architectures including convolutional and fully connected networks.
As predicted by recent arguments based on algorithmic information theory, we find that the prior probability drops exponentially with linear increases in several measures of descriptional complexity of the target function. As target functions in many real problems are expected to be highly structured, this simplicity bias offers an insight into why deep networks generalize well on real world problems, but badly on randomized data.</span></div><div class="note_contents"><span class="note_content_field">Keywords: </span><span class="note_content_value">generalization, deep learning theory, PAC-Bayes, Gaussian processes, parameter-function map, simplicity bias</span></div><div class="note_contents"><span class="note_content_field">TL;DR: </span><span class="note_content_value">The parameter-function map of deep networks is hugely biased; this can explain why they generalize. We use PAC-Bayes and Gaussian processes to obtain nonvacuous bounds.</span></div><div class="reply_row clearfix"><div class="item" id="reply_count">3 Replies</div></div></div><hr class="small" /><div id="note_children"><div class="note_with_children"><div id="note_SyxXKMG937" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>A fresh study to the generalization capabilities of (deep) neural networks, with the help of the PAC-Bayesian learning theory and empirically backed intuitions.</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=rye4g3AqFm&amp;noteId=SyxXKMG937"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1066 AnonReviewer2</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">03 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper1066 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">The paper brings a fresh study to the generalization capabilities of (deep) neural networks, with the help of an original use of PAC-Bayesian learning theory and some empirically backed intuitions.

Expressing the prior over the input-output function space generated by the neural network is very interesting. This provides an original analysis compared to the common PAC-Bayesian analysis of neural networks that express the prior over network parameters space. The theoretical study here appears simple (noteworthy, it is based one of the very first PAC-Bayesian theorems of McAllester that is not the most used nowadays), and the study is conducted mainly by empirical observation. Nevertheless, the experiments leading to these observations are cleverly designed, and I think it gives great insights and might open the way to other interesting studies.

Overall, the paper is enjoyable to read. I also appreciate the completeness of the supplementary material. I recommend the paper acceptance, but I would like the authors to consider the concerns I rise below:
- The paper title is a bit presumptuous. The paper presents a conjunction backed by empirical evidence on some not-so-deep neural networks. Even if I consider it as an important piece of work, it does not provide any definitive answer to the generalization puzzle. 
- Many peer-reviewed publications are cited as arXiv preprints. Please carefully complete the bibliography. Some papers are referenced by the name, title and year only (Smith and Le 2018; Zhang et al, 2017)
- I recommend adding to the learning curves of Figures 2 and 3 the loss on the training set. 

Other minor comments and typos:
- Intro: Please define "parameter-function" map 
- Page 4: Missing parentheses around Mand et al. (2017)
- SGD has not had time ==&gt; SGD did not have time
- Please refers to the definition in the supplementary material/information the first time you mention Lempel-Ziv complexity.
- Please mention that SI stands for Supplementary Information
</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">7: Good paper, accept</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_SkgdeIbqh7" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Interesting perspective but most relevant experiments are on very tiny networks</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=rye4g3AqFm&amp;noteId=SkgdeIbqh7"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1066 AnonReviewer1</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">03 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper1066 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">This paper propose an interesting perspective to explain the generalization behaviors of large over-parameterized neural networks by saying that the parameter-function map in neural networks are biased towards "simple" functions, and through a PAC-Bayes argument, the generalization behavior will be good if the target concept is also "simple". I like the perspective of view that combines the "complexity" of both the algorithm bias and the target concept in the view of generalization. However, the implementation and presentation of the paper could be improved.

First of all, the paper is a bit difficult to follow as some important information is either missing or only available in the appendix. For example, in Section 2, to measure the properties of the parameter-function mapping, a simple boolean neural network is explored. However, it is not clear how the sampling procedure is carried out. There is also a 'training set of 64 examples', and it not obvious to the reader how this training set is used in this sample of neural network parameters.

Following that, the paper uses Gaussian Process and Expectation-Propagation to approximately compute P(U). But the description is brief and vague (to non-expert in GP or EP). As one of the main contribution stated in the introduction, it would be better if more details are included.

Moreover, the generalization bound is derived with the assumption that the learning algorithm uniformly sample from the set of all hypothesis that is consistent with a given training set. It is unlikely that this is what SGD is doing. But explicit experiments to verify how close is the real-world behavior to the hypothetical behavior would be helpful.

The experiment in section 6 that verify the 'complexity' of 'high-probability' functions in the given prior is very interesting. It would be good if some kind of measurements more directly on the real world tasks could be done, which will better support the argument made in the paper.
</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">5: Marginally below acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">3: The reviewer is fairly confident that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_BJlNf4D827" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>not surprising</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=rye4g3AqFm&amp;noteId=BJlNf4D827"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1066 AnonReviewer3</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">31 Oct 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper1066 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">
The authors make a case that deep networks are biased
toward fitting data with simple functions.

The start by examining the priors on classifiers obtained by sampling
the weights of a neural network according to different distributions.  They do this
in two ways.  First, they examine properties of the distribution
on binary-valued functions on seven boolean inputs obtained by
sampling the weights of a small neural network.  They also empirically compare
the labelings obtained by sampling the weights of a network with
labelings obtained from a Gaussian process model arising from earlier
work.

Next, they analyze the complexity of the functions produced, using
different measures of the complexity of boolean functions.  A
favorite of theirs is something that they call Lempel-Ziv complexity,
which is measured by choosing an arbitrarily ordering of the
domain, writing the outputs of the function in that ordering,
and looking at how well the Lempel-Ziv algorithm compresses this
sequence.  I am not convinced that this is the most meaningful
and fundamental measure of the complexity of functions.
(In the supplementary material, they examine some others.
They show plots relating the different measures in the body
of the paper.  None of the measures is specified in detail in the
body of the paper. They provide plots relating these complexity
measures, but they don't demonstrate a very close connection.)

The authors then evaluate the generalization bound obtained by
applying a PAC Bayes bound, together with the assumption that
the training process produces weights sampled from the distribution
obtained by conditioning weights chosen according to the random
initialization on the event that they fit they fit the training
data perfectly.  They do this for small networks and simple datasets.
They bounds are loose, but not vacuous, and follow the same order
of difficulty on a handful of datasets as the true generalization
error.

In all of their experiments, they stop training when the training
accuracy reaches 100%, where papers like <a href="https://arxiv.org/pdf/1706.08947.pdf" target="_blank" rel="nofollow">https://arxiv.org/pdf/1706.08947.pdf</a>
have found that continuing training past this point further improves test
accuracy.  The experiments all use architectures that are
quite dissimilar to what is commonly used in practice, and
achieve much worse accuracy, so that a reader is concerned
that the results differ qualitatively in other respects.

I do not find it surprising that randomly sampling parameters
of deep networks leads to simple functions.

Papers like the Soudry, et al paper cited in this submission are
inconsistent with the assumption in the paper that SGD samples
parameters uniformly.

It is not clear to me how many hidden layers were used for the
results in Table 1 (is it four?).  

I did find it interesting to see exactly how concentrated the
distribution of functions obtained in their 7-input experiment
was, and also found results on the agreement of the Gaussian process
models with the randomly sampled weight interesting, as far as they
went.  Overall, I am not sure that this paper provided enough
fundamental new insight to be published in ICLR.
</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">4: Ok but not good enough - rejection</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></main></div>
  </div>
</div>


    <!-- Footer -->
    <footer class="sitemap">
      <div class="container">
        <div class="row hidden-xs">
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/venues">All Venues</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="/contact">Contact</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
    
        <div class="row visible-xs-block">
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/contact">Contact</a></li>
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
      </div>
    </footer>
    
    <footer class="sponsor">
      <div class="container">
        <div class="row">
          <div class="col-sm-10 col-sm-offset-1">
            <p class="text-center">
              OpenReview is created by the <a href="http://www.iesl.cs.umass.edu/" target="_blank">Information Extraction and Synthesis Laboratory</a>, College of Information and Computer Science, University of Massachusetts Amherst. We gratefully acknowledge the support of the OpenReview sponsors:  Google,  Facebook, NSF, the University of Massachusetts Amherst Center for Data Science, and Center for Intelligent Information Retrieval, as well as the Google Cloud Platform for donating the computing and networking services on which OpenReview.net runs.
            </p>
          </div>
        </div>
      </div>
    </footer>

  <div id="feedback-modal" class="modal fade" tabindex="-1" role="dialog">
    <div class="modal-dialog">
      <div class="modal-content">
        <div class="modal-header">
          <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">Ã—</span></button>
          <h3 class="modal-title">Send Feedback</h3>
        </div>
        <div class="modal-body">
          <p>Enter your feedback below and we'll get back to you as soon as possible.</p>
          <form action="/feedback" method="POST">
            <div class="form-group">
              <input type="email" name="from" class="form-control" placeholder="Email" />
            </div>
            <div class="form-group">
              <input type="text" name="subject" class="form-control" placeholder="Subject" />
            </div>
            <div class="form-group">
              <textarea name="message" class="form-control feedback-input" rows="5" placeholder="Message" required=""></textarea>
            </div>
          <ul id="ui-id-2" tabindex="0" class="ui-menu ui-widget ui-widget-content" style="display: none;"></ul></form>
        </div>
        <div class="modal-footer">
          <button type="button" class="btn btn-default" data-dismiss="modal">Cancel</button>
          <button type="button" class="btn btn-primary">Send</button>
        </div>
      </div>
    </div>
  </div>

  <script type="text/javascript" async="" src="https://www.google-analytics.com/analytics.js"></script><script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js"></script>
  <script>window.jQuery || document.write('&lt;script src="/static/js/vendor/jquery-2.2.4.min.js"&gt;&lt;\/script&gt;')</script>

  <script src="/static/dist/vendor.min.js"></script>
  <script src="/static/dist/templates.min.js"></script>
  <script src="/static/dist/openreview.min.js"></script>

    <script>window.legacyScripts = true;</script>


    <script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-108703919-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() { dataLayer.push(arguments); }
      gtag('js', new Date());
      gtag('config', 'UA-108703919-1');
    </script>


<div role="status" aria-live="assertive" aria-relevant="additions" class="ui-helper-hidden-accessible"></div></body></html>
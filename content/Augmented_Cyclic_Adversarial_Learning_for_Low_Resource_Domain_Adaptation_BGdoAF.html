<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" class="no-js"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>Augmented Cyclic Adversarial Learning for Low Resource Domain Adaptation | OpenReview</title>
  <meta name="description" content="" />

      <meta name="citation_title" content="Augmented Cyclic Adversarial Learning for Low Resource Domain Adaptation" />
        <meta name="citation_author" content="Anonymous" />
      <meta name="citation_publication_date" content="2018/09/27" />
      <meta name="citation_online_date" content="2018/09/27" />
      <meta name="citation_pdf_url" content="https://openreview.net/pdf?id=B1G9doA9F7" />
      <meta name="twitter:card" content="summary" />
      <meta name="twitter:site" content="@openreviewnet" />
      <meta name="og:title" content="Augmented Cyclic Adversarial Learning for Low Resource Domain..." />
      <meta name="og:description" content="Training a model to perform a task typically requires a large amount of data from the domains in which the task will be applied.&#10;  However, it is often the case that data are abundant in some domains..." />
      <meta name="og:image" content="https://openreview.net/static/images/openreview_logo_512.png" />

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans:400,400i,700,700i" />

  <link rel="stylesheet" href="/static/css/bootstrap.min.css" />
  <link rel="stylesheet" href="/static/css/jquery-ui.min.css" />
  <link rel="stylesheet" href="/static/css/main.min.css" />
</head>

<body class="forum">
  <nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
  
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand home push-link" href="/"><strong>OpenReview</strong>.net</a>
      </div>
  
      <div id="navbar" class="navbar-collapse collapse">
        <form class="navbar-form navbar-left profile-search" role="search">
          <div class="form-group has-feedback">
            <input id="search_input" type="text" class="form-control ui-autocomplete-input" placeholder="Search ICLR 2019 Conference" autocomplete="off" />
            <span class="glyphicon glyphicon-search form-control-feedback" aria-hidden="true"></span>
          </div>
  
          <input id="search_group" type="hidden" value="ICLR.cc/2019/Conference" />
          <input id="search_content" type="hidden" value="all" />
        <ul id="ui-id-1" tabindex="0" class="ui-menu ui-widget ui-widget-content ui-autocomplete ui-front" style="display: none;"></ul></form>
  
        <ul class="nav navbar-nav navbar-right">
        
            <li id="user-menu"><a href="/login">Login</a></li>
        </ul>
      </div>
  
    </div>
  </nav>

  <div id="or-banner" class="banner" style="">
  <div class="container">
    <div class="row">
      <div class="col-xs-12"><a href="/group?id=ICLR.cc/2019/Conference" title="Venue Homepage"><img class="icon" src="/static/images/arrow_left.svg" /> Go to <strong>ICLR 2019 Conference</strong> homepage</a></div>
    </div>
  </div>
</div>
<div id="flash-message-container" class="alert alert-danger" role="alert" style="display: none;">
  <div class="container">
    <div class="row">
      <div class="col-xs-12">
        <div class="alert-content">
          <button type="button" class="close" aria-label="Close"><span aria-hidden="true">×</span></button>
        </div>
      </div>
    </div>
  </div>
</div>

<div class="container">
  <div class="row">
    <div class="col-xs-12">
      <main id="content" class="clearfix openbanner-visible legacy-styles"><div id="note_B1G9doA9F7" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Augmented Cyclic Adversarial Learning for Low Resource Domain Adaptation</a> <a class="note_content_pdf" href="/pdf?id=B1G9doA9F7" title="Download PDF" target="_blank"><img src="/static/images/pdf_icon_blue.svg" /></a> </h2></div><div class="meta_row"><span class="signatures">Anonymous</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">28 Sep 2018 (modified: 18 Nov 2018)</span><span class="item">ICLR 2019 Conference Blind Submission</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span><span class="item"><a class="action-bibtex-modal" data-bibtex="@inproceedings{    &#10;anonymous2019augmented,    &#10;title={Augmented Cyclic Adversarial Learning for Domain Adaptation},    &#10;author={Anonymous},    &#10;booktitle={Submitted to International Conference on Learning Representations},    &#10;year={2019},    &#10;url={https://openreview.net/forum?id=B1G9doA9F7},    &#10;note={under review}    &#10;}">Show Bibtex</a></span><a class="note_content_pdf item" href="/revisions?id=B1G9doA9F7" target="_blank">Show Revisions</a></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Abstract: </span><span class="note_content_value">Training a model to perform a task typically requires a large amount of data from the domains in which the task will be applied.
However, it is often the case that data are abundant in some domains but scarce in others. Domain adaptation deals with the challenge of adapting a model trained from a data-rich source domain to perform well in a data-poor target domain. In general, this requires learning plausible mappings between domains. CycleGAN is a powerful framework that efficiently learns to map inputs from one domain to another using adversarial training and a cycle-consistency constraint. However, the conventional approach of enforcing cycle-consistency via reconstruction may be overly restrictive in cases where one or more domains have limited training data. In this paper, we propose an augmented cyclic adversarial learning model that enforces the cycle-consistency constraint via an external task specific model, which encourages the preservation of task-relevant content as opposed to exact reconstruction. We explore digit classification in a low-resource setting in supervised, semi and unsupervised situation, as well as high resource unsupervised. In low-resource supervised setting, the results show that our approach improves absolute performance by 14% and 4% when adapting SVHN to MNIST and vice versa, respectively, which outperforms unsupervised domain adaptation methods that require high-resource unlabeled target domain. Moreover, using only few unsupervised target data, our approach can still outperforms many high-resource unsupervised models. Our model also outperforms on USPS to MNIST and synthetic digit to SVHN for high resource unsupervised adaptation. In speech domains, we similarly adopt a speech recognition model from each domain as the task specific model. Our approach improves absolute performance of speech recognition by 2% for female speakers in the TIMIT dataset, where the majority of training samples are from male voices.</span></div><div class="note_contents"><span class="note_content_field">Keywords: </span><span class="note_content_value">Domain adaptation, generative adversarial network, cyclic adversarial learning, speech</span></div><div class="note_contents"><span class="note_content_field">TL;DR: </span><span class="note_content_value">A new cyclic adversarial learning augmented with auxiliary task model which improves domain adaptation performance in low resource supervised and unsupervised situations </span></div><div class="reply_row clearfix"><div class="item" id="reply_count">7 Replies</div></div></div><hr class="small" /><div id="note_children"><div class="note_with_children"><div id="note_ByxZHgYCam" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>General Response</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=B1G9doA9F7&amp;noteId=ByxZHgYCam"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper380 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">18 Nov 2018</span><span class="item">ICLR 2019 Conference Paper380 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">We appreciate all reviewers for providing insightful comments on technical aspect  of the proposed method.
Below, we summarize the revision briefly. Detailed responses to each reviewer/comment are followed based on each reviewer feedback.
- Additional experiment is performed to compare the performance of our model on low-resource unsupervised domain with CyCADA model (see Figure 2)
- Table 2 (low-resource supervised experiment) in the previous version is now replaced with Figure 3 (bar plot), where additional baselines are added, to emphasize the significance of domain adaptation in our model in comparison to state of the art models.
- Table 3 (Speech experiments): The updated acronyms in this table are now consistent with those in visual adaptation section.We further added additional CycleGAN results to provide mores baselines for comparison between models. 
- The new title for the work is “Augmented Cyclic Adversarial Learning for Low Resource Domain Adaptation”
- The acronym for the proposed model is changed from “Augmented-Cyc” to “ACAL” and “Relaxed-Cyc” to “RCAL”
- In all experiments, Tables and Figures, number of samples are per class, whether supervised or unsupervised
- All changes are highlighted in the paper
- We have used the official CyCADA open-source code to reproduce its results and get the performance on low-resource unsupervised adaptation in Figure 2. 
CyCADA code: <a href="https://github.com/jhoffman/cycada_release" target="_blank" rel="nofollow">https://github.com/jhoffman/cycada_release</a>


Clarification on Novelty:
In this paper, we address the problem of domain adaptation for low resource situation in supervised, semi and unsupervised situations. We emphasize the necessity of using two cycle in tackling this problem. As evident from our experiments (see results in Table 1 and Figure 2), current one-cycle based models (such as CyCADA) or conventional two-cycle method (CycleGAN) fail in stable and good adaptation in low-resource situation.
</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_HklKo3NW6Q" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Interesting paper</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=B1G9doA9F7&amp;noteId=HklKo3NW6Q"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper380 AnonReviewer1</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">08 Nov 2018</span><span class="item">ICLR 2019 Conference Paper380 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">
I am putting "weak accept" because I think the paper addresses an important problem (domain adaptation) and has an interesting approach.  As the other reviewers pointed out, it's maybe not *super* novel.  But it's still interesting, and pretty readable for the most part.  

I do question the statistical significance of the TIMIT experiments: TIMIT has a very tiny test set to start with, and by focusing on the female portion only you are further reducing the amount.

Small point: I don't think GANs are technically nonparametric, as the neural nets do have parameters.

I am a little skeptical that this method would have as general applicability or usefulness as the authors seem to think.  The reason is that, since the cycle constraint no longer exists, there is nothing to stop the network from just figuring out the class label of the input (say) image, and treating all the rest of the  information in that image as noise the same way a regular non-cyclic GAN would treat it.  Of course, one wouldn't expect a convolutional network to behave like this, but in theory it could happen in general cases.  This is just speculation though.  Personally I would have tended to accept the paper, but I'm not going to argue with the other reviewers, who are probably more familiar with GAN literature than me.</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">6: Marginally above acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_SylfAxKCpQ" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Response to AnonReviewer1 comments and suggestions</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=B1G9doA9F7&amp;noteId=SylfAxKCpQ"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper380 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">18 Nov 2018</span><span class="item">ICLR 2019 Conference Paper380 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">- Comment on “statistical significance on TIMIT experiments”:
We have chosen TIMIT dataset because of its inherent low-resource domain for different genders. As shown in Table 3, when using only Male speech for training the network, testing on female genders results in a large margin (11% on phoneme error recognition), compared to baseline. However by using only “Male-&gt;Female” data in training of proposed model, this gap can be reduced by ~10% for 124 voices in validation and 64 voices in test set for female domain.

 - Comment on “Whether GAN’s are parametric or non-parametrics”:
Here we refer to the classical parametric models for modeling data distribution. In this sense, the generator in GAN implicitly models the true distribution. Therefore, we categorize GAN as a non-parametric density estimation model since it does not assume any form of distribution.

- Comment on general applicability of the proposed domain adaptation model:
Since for any sample, whether target or source, there are two classifier in the cycle to preserve the class label information during transformation across domains, we believe that this implicit enforcement of content preservation will hold in broader applications. If the model is able to figure out which part is important for a certain class and ignore other parts, that is a desired behavior, since only those parts are important for the task in mind. 
</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div><div class="note_with_children"><div id="note_rkgVnNv52Q" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Review</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=B1G9doA9F7&amp;noteId=rkgVnNv52Q"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper380 AnonReviewer2</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">03 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper380 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">The authors propose an extension of cycle-consistent adversarial adaptation methods in order to tackle domain adaptation in settings where a limited amount of supervised target data is available (though they also validate their model in the standard unsupervised setting as well). The method appears to be a natural generalization/extension of CycleGAN/CyCADA. It uses the ideas of the semantic consistency loss and training on adapted data from CyCADA, but "fills out" the model by applying these techniques in both directions (whereas CyCADA only applied them in the source-to-target direction).

The writing in this paper is a little awkward at times (many omitted articles such as "the" or "a'), but, with a few exceptions, it is generally easy to understand what the authors are saying. They provide experiments in a variety of settings in order to validate their model, including both visual domain adaptation and speech domain adaptation. The experiments show that their model is effective both in low-resource supervised adaptation settings as well as high-resource unsupervised adaptation settings. An ablation study, provided in Section 4.1, helps to understand how well the various instantiations of the authors' model perform, indicating that enforcing consistency in both methods is crucial to achieving performance beyond the simple baselines.

It's a little hard to understand how this method stands in comparison to existing work. Table 3 helps to show that the model can scale up to the high-resource setting, but it would also be nice to see the reverse: comparisons against existing work run in the limited data setting, to better understand how much limited data negatively impacts the performance of models that weren't designed with this setting in mind.

I would've also liked to see more comparisons against the simple baseline of a classifier trained exclusively on the available supervised target data, or with the source and target data together—in my experience, these baselines can prove to be surprisingly strong, and would give a better sense of how effective this paper's contributions are. This corresponds to rows 2 and 3 of Table 1, and inspection of the numbers in that table shows that the baseline performance is quite strong even relative to the proposed method, so it would be nice to see these numbers in Table 2 as well, since that table is intended to demonstrate the model's effectiveness across a variety of different domain shifts.

While it's nice that the model is experimentally validated on the speech domain, the experiment itself is not explained well. The speech experiments are hard to understand—it's unclear what the various training sets are, such as "Adapted Male" or "All Data," making it hard to understand exactly what numbers should be compared. Why is there no CycleGAN result for "Female + Adapted Male," or "All Data + Adapted Male," for example? The paper would greatly benefit from a more careful explanation and analysis of this experimental setting.

Ultimately, I think the idea is a nice generalization of previous work, and the experiments seem to indicate that the model is effective, but the limited scope of the experiments prevent me from being entirely convinced. The inclusion of additional baselines and a great deal of clarification on the speech experiments would improve the quality of this paper enormously.
</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">3: Clear rejection</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_H1gOeZtCpQ" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Response to AnonReviewer2 comments and suggestions </a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=B1G9doA9F7&amp;noteId=H1gOeZtCpQ"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper380 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">18 Nov 2018</span><span class="item">ICLR 2019 Conference Paper380 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Comment on “low-resource supervised adaptation, Table 2”:
To provide more baseline results on low-resource supervised adaptation, we ran additional experiments and replaced table 2 with bar plots in Figure 3. Baselines include classifier trained on low-resource target data, and including source data, with no adaptation. As shown in Figure 3, Augmented-Cyc algorithm outperforms FADA model and the two baselines.

Comment on “comparing with existing works on low-resource unsupervised adaptation”:
We added experiments on low-resource unsupervised adaptation to compare with CyCADA, and the results are shown in Figure 2. This experiment  investigates the effectiveness and robustness of using two cycle with semantic consistency enforced by auxiliary task loss, compared to CyCADA, where semantic consistency is enforced by reconstruction loss. As shown in Figure 2, CyCADA model fails to learn a good adaptation, where target domain contains few unsupervised data. Additionally, CyCADA model shows high instability in low-resource situation. Our model achieves more robust and better performance. We think this is attributed to proper use of source classifier to enforce consistency and robustness that we get by using two cycles (also shown in ablation study in Table 1).

Comment on speech domain experiments:
 We have edited the speech experiment section for more clarification. To mention some, “Adapted Male” is changed to “Male-&gt; Female” to preserve consistency in notation. “All Data” refers to “Male+Female” with no adaption. CycleGAN results are added for"Female + Adapted Male," or "All Data + Adapted Male,”</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div><div class="note_with_children"><div id="note_HJxHpfhH2m" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Well-motivated approach, but limited novelty and experiments</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=B1G9doA9F7&amp;noteId=HJxHpfhH2m"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper380 AnonReviewer3</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">30 Oct 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper380 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">This paper introduces a domain adaptation approach based on the idea of Cyclic GAN. Two different algorithms are proposed. The first one incorporates a semantic consistency loss based on domain-specific classifiers acting on full cycles of the of the generators. The second one also makes use of domain-specific classifiers, but acting either directly on the training samples or on the data mapped from one domain to the other.

Strengths:
- The different terms in the proposed loss functions are well justified.
- The results on low-resources supervised domain adaptation indicate that the method works better than the that of Motiian et al. 2017.

Weaknesses:
- Novelty is limited: The two algorithms are essentially small modification of the semantic consistency term used in Hoffman et al. 2018. They involve making use of both the source and target classifiers, instead of only the source one, and, for the relaxed version, making use of complete cycles instead of just one mapping from one domain to the other. While the modifications are justified, I find this a bit weak for ICLR.

- It is not clear to me why it is worth presenting the relaxed cycle-consistency object, since it always yields worse results than the augmented one. In fact, at first, I though both objectives would be combined in a single loss, and was thus surprised not to see Eq. 5 appear in Algorithm 1. It only became clear when reading the experiments that the authors were treating the two objectives as two different algorithms. Note that, in addition to not performing as well as the augmented version, it is also unclear how the relaxed one could work in the unsupervised scenario.

- Experiments:
* In 4.1, the authors mention that 10 samples per class are available in the target domain. Are they labeled or unlabeled? If labeled, are additional unlabeled samples also used?
* In Table 1, and in Table 3, is there a method that corresponds to CyCADA? I feel that this comparison would be useful considering the similarity. That said, I also understand that CyCADA uses both a reconstruction term (as in Eq. 4) and a semantic consistency one, whereas here only a semantic reconstruction term is used. I therefore suggest the authors to also compare with a baseline that replaces their objective with the semantic consistency one of CyCADA, i.e., CyCADA without reconstruction term.
* In 4.2, it is again not entirely clear if the authors use only the few labeled samples, or if this is complemented with additional unlabeled samples. In any event, does this reproduce the setting used by Motiian et al. 2017?
* As the argument is that the proposed loss is better than the reconstruction one and that of Hoffman et al. 2018 for low-resource supervised adaptation, it would be worth demonstrating this empirically in Table 2.

Summary:
The proposed objective functions are well motivated, but I feel that novelty is too limited and the current set of experiments not sufficient to warrant publication at ICLR.
</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">4: Ok but not good enough - rejection</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_B1xgX-Y0am" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Response to AnonReviewer3 comments and suggestions</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=B1G9doA9F7&amp;noteId=B1xgX-Y0am"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper380 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">18 Nov 2018</span><span class="item">ICLR 2019 Conference Paper380 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Comment on Weakness, and similarity to CyCADA model:
To differentiate between our model and CyCADA, below is the detail of two models and how they perform semantic consistency, and enforcing style adaptation
CyCADA: 
semantic (content) consistency is enforced by two loss; reconstruction loss (CycleGAN); and additionally using reconstruction at feature level.
Style adaptation is enforced using adversarial learning on pixel (observation) and feature (hidden) space. Therefore, it need to learn additional model for representing data in feature space. 

Augmented-Cyc:
semantic consistency is shown to be achieved by only using auxiliary task loss for each cycle. 
Style adaptation is achieved by using adversarial learning on pixel (observation) space only.
We use cycles in both direction to achieve robust performance in low resource (either supervised or unsupervised) setting.

Therefor, CyCADA requires an additional adversarial learning at feature space, while our model achieve this by only adaptation at observation space. Moreover, to compare the performance of the two model on variable-size target domain, we added more experiments for low resource unsupervised adaptation (see Figure 2). It is evident that CyCADA model fails to provide suitable adaptation, while our model outperforms by large margin, when target domain data is small
Note: Both our ablation (see Table 1) and additional experiments (see Figure 2) suggest the benefit of using two cycles for low resource situation, whether supervised or unsupervised. Therefore, we think this is an important aspect for robust domain adaptation under resource constraint.

Comment on relaxed cycle consistency:
The main purpose of presenting relaxed-consistency results in ablation study is to demonstrate the effectiveness of using auxiliary task loss in any or both cycles, rather than L1 reconstruction loss. We have only evaluated relaxed-consistency in low-resource supervised setting, and it is not evaluated for unsupervised adaptation. In unsupervised setting, we are using source classifier M_{S} as pseudo-labeler of target samples. 

Note: In this setting, if we turn off using task model M_{T} to be trained using source data, this is similar to using relaxed version in unsupervised adaptation 


Comments on Experiments:

For all low resource target domain experiment, only the denoted number of samples are used, irrespective if they are labeled or not. For example, in supervised case, 10 labeled sample per class means we only use 10 labeled samples per class in the target domain is used and no other data is used in the target domain. Similarly for unsupervised case, 5 samples per class means only used 5 unsupervised samples from target domain.

- Section 4.1:  we only used 10 labeled sample per class. In this experiment, NO unlabeled data is used. 

- Table 1: this table is intended for ablation of our model. 

- Table 3: we have added CyCADA results in this table for comparison. To directly compare our model with CyCADA, we added new experiments on variable-size target domain which is presented in Figure 2. 

- Section 4.2: Table 2 is replaced with Figure 3, for low-resource supervised adaptation. In this experiment, no unlabeled data is used, and it is a direct comparison between our model and FADA (Motiian et al. 2017)

In Figure 2, we have shown the benefit of the proposed auxiliary task-specific loss to reconstruction loss (CyCADA) on low-resource unsupervised domain adaptation.</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div></div></main></div>
  </div>
</div>


    <!-- Footer -->
    <footer class="sitemap">
      <div class="container">
        <div class="row hidden-xs">
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/venues">All Venues</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="/contact">Contact</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
    
        <div class="row visible-xs-block">
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/contact">Contact</a></li>
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
      </div>
    </footer>
    
    <footer class="sponsor">
      <div class="container">
        <div class="row">
          <div class="col-sm-10 col-sm-offset-1">
            <p class="text-center">
              OpenReview is created by the <a href="http://www.iesl.cs.umass.edu/" target="_blank">Information Extraction and Synthesis Laboratory</a>, College of Information and Computer Science, University of Massachusetts Amherst. We gratefully acknowledge the support of the OpenReview sponsors:  Google,  Facebook, NSF, the University of Massachusetts Amherst Center for Data Science, and Center for Intelligent Information Retrieval, as well as the Google Cloud Platform for donating the computing and networking services on which OpenReview.net runs.
            </p>
          </div>
        </div>
      </div>
    </footer>

  <div id="feedback-modal" class="modal fade" tabindex="-1" role="dialog">
    <div class="modal-dialog">
      <div class="modal-content">
        <div class="modal-header">
          <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button>
          <h3 class="modal-title">Send Feedback</h3>
        </div>
        <div class="modal-body">
          <p>Enter your feedback below and we'll get back to you as soon as possible.</p>
          <form action="/feedback" method="POST">
            <div class="form-group">
              <input type="email" name="from" class="form-control" placeholder="Email" />
            </div>
            <div class="form-group">
              <input type="text" name="subject" class="form-control" placeholder="Subject" />
            </div>
            <div class="form-group">
              <textarea name="message" class="form-control feedback-input" rows="5" placeholder="Message" required=""></textarea>
            </div>
          <ul id="ui-id-2" tabindex="0" class="ui-menu ui-widget ui-widget-content" style="display: none;"></ul></form>
        </div>
        <div class="modal-footer">
          <button type="button" class="btn btn-default" data-dismiss="modal">Cancel</button>
          <button type="button" class="btn btn-primary">Send</button>
        </div>
      </div>
    </div>
  </div>

  <script type="text/javascript" async="" src="https://www.google-analytics.com/analytics.js"></script><script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js"></script>
  <script>window.jQuery || document.write('&lt;script src="/static/js/vendor/jquery-2.2.4.min.js"&gt;&lt;\/script&gt;')</script>

  <script src="/static/dist/vendor.min.js"></script>
  <script src="/static/dist/templates.min.js"></script>
  <script src="/static/dist/openreview.min.js"></script>

    <script>window.legacyScripts = true;</script>


    <script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-108703919-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() { dataLayer.push(arguments); }
      gtag('js', new Date());
      gtag('config', 'UA-108703919-1');
    </script>


<div role="status" aria-live="assertive" aria-relevant="additions" class="ui-helper-hidden-accessible"></div></body></html>
<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" class="no-js"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>Attention, Learn to Solve Routing Problems! | OpenReview</title>
  <meta name="description" content="" />

      <meta name="citation_title" content="Attention, Learn to Solve Routing Problems!" />
        <meta name="citation_author" content="Anonymous" />
      <meta name="citation_publication_date" content="2018/09/27" />
      <meta name="citation_online_date" content="2018/09/27" />
      <meta name="citation_pdf_url" content="https://openreview.net/pdf?id=ByxBFsRqYm" />
      <meta name="twitter:card" content="summary" />
      <meta name="twitter:site" content="@openreviewnet" />
      <meta name="og:title" content="Attention, Learn to Solve Routing Problems!" />
      <meta name="og:description" content="The recently presented idea to learn heuristics for combinatorial optimization problems is promising as it can save costly development. However, in order to push this idea towards practical..." />
      <meta name="og:image" content="https://openreview.net/static/images/openreview_logo_512.png" />

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans:400,400i,700,700i" />

  <link rel="stylesheet" href="/static/css/bootstrap.min.css" />
  <link rel="stylesheet" href="/static/css/jquery-ui.min.css" />
  <link rel="stylesheet" href="/static/css/main.min.css" />
</head>

<body class="forum">
  <nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
  
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand home push-link" href="/"><strong>OpenReview</strong>.net</a>
      </div>
  
      <div id="navbar" class="navbar-collapse collapse">
        <form class="navbar-form navbar-left profile-search" role="search">
          <div class="form-group has-feedback">
            <input id="search_input" type="text" class="form-control ui-autocomplete-input" placeholder="Search ICLR 2019 Conference" autocomplete="off" />
            <span class="glyphicon glyphicon-search form-control-feedback" aria-hidden="true"></span>
          </div>
  
          <input id="search_group" type="hidden" value="ICLR.cc/2019/Conference" />
          <input id="search_content" type="hidden" value="all" />
        <ul id="ui-id-1" tabindex="0" class="ui-menu ui-widget ui-widget-content ui-autocomplete ui-front" style="display: none;"></ul></form>
  
        <ul class="nav navbar-nav navbar-right">
        
            <li id="user-menu"><a href="/login">Login</a></li>
        </ul>
      </div>
  
    </div>
  </nav>

  <div id="or-banner" class="banner" style="">
  <div class="container">
    <div class="row">
      <div class="col-xs-12"><a href="/group?id=ICLR.cc/2019/Conference" title="Venue Homepage"><img class="icon" src="/static/images/arrow_left.svg" /> Go to <strong>ICLR 2019 Conference</strong> homepage</a></div>
    </div>
  </div>
</div>
<div id="flash-message-container" class="alert alert-danger" role="alert" style="display: none;">
  <div class="container">
    <div class="row">
      <div class="col-xs-12">
        <div class="alert-content">
          <button type="button" class="close" aria-label="Close"><span aria-hidden="true">Ã—</span></button>
        </div>
      </div>
    </div>
  </div>
</div>

<div class="container">
  <div class="row">
    <div class="col-xs-12">
      <main id="content" class="clearfix openbanner-visible legacy-styles"><div id="note_ByxBFsRqYm" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Attention, Learn to Solve Routing Problems!</a> <a class="note_content_pdf" href="/pdf?id=ByxBFsRqYm" title="Download PDF" target="_blank"><img src="/static/images/pdf_icon_blue.svg" /></a> </h2></div><div class="meta_row"><span class="signatures">Anonymous</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">28 Sep 2018 (modified: 15 Nov 2018)</span><span class="item">ICLR 2019 Conference Blind Submission</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span><span class="item"><a class="action-bibtex-modal" data-bibtex="@inproceedings{    &#10;anonymous2019attention,,    &#10;title={Attention, Learn to Solve Routing Problems!},    &#10;author={Anonymous},    &#10;booktitle={Submitted to International Conference on Learning Representations},    &#10;year={2019},    &#10;url={https://openreview.net/forum?id=ByxBFsRqYm},    &#10;note={under review}    &#10;}">Show Bibtex</a></span><a class="note_content_pdf item" href="/revisions?id=ByxBFsRqYm" target="_blank">Show Revisions</a></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Abstract: </span><span class="note_content_value">The recently presented idea to learn heuristics for combinatorial optimization problems is promising as it can save costly development. However, in order to push this idea towards practical implementation, we need better models and better ways of training. We contribute in both directions: we propose a model based entirely on attention layers with benefits over the Pointer Network and we show how to train this model using REINFORCE with a simple baseline based on a deterministic greedy rollout, which we find is much more efficient than using a value function. We significantly improve over recent learned heuristics for the Travelling Salesman Problem (TSP), getting close to optimal results for problems up to 100 nodes. With the same hyperparameters, we learn strong heuristics for two variants of the Vehicle Routing Problem (VRP), the Orienteering Problem (OP) and (a stochastic variant of) the Prize Collecting TSP (PCTSP), outperforming a wide range of baselines and getting results close to highly optimized and specialized algorithms. The ability to construct a tour in order is beneficial in the online (stochastic) setting. We make code publicly available.</span></div><div class="note_contents"><span class="note_content_field">Keywords: </span><span class="note_content_value">learning, routing problems, heuristics, attention, reinforce, travelling salesman problem, vehicle routing problem, orienteering problem, prize collecting travelling salesman problem</span></div><div class="note_contents"><span class="note_content_field">TL;DR: </span><span class="note_content_value">Attention based model trained with REINFORCE with greedy rollout baseline to learn heuristics with competitive results on TSP and other routing problems</span></div><div class="reply_row clearfix"><div class="item" id="reply_count">6 Replies</div></div></div><hr class="small" /><div id="note_children"><div class="note_with_children"><div id="note_Bke7cL5jnX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>A good paper; missing comparison to very relevant work</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=ByxBFsRqYm&amp;noteId=Bke7cL5jnX"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper444 AnonReviewer1</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">04 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper444 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">This paper proposes an alternative deep learning model for use in combinatorial optimization. The attention model is inspired by the Transformer architecture of Vaswani et al. (2017). Given a distribution over problem instances (e.g. TSP), the REINFORCE update is used to train the attention model. Interestingly, the baseline used in the REINFORCE update is based on greedy rollout using the current model. Experimentally, four different routing problems are considered. The authors show that the proposed method often outperforms some other learning-based methods and is competitive with existing (non-learned) heuristics.

Overall, this is a good piece of work. Next, I will touch on some strengths and weaknesses which I hope the authors can address/take into account. My main concern is the lack of comparison with Deudon et al. (2018).

Strengths:
- Writing: beautifully written and precise even with respect to tiny technical details; great job!

- Versatility: the experimental evaluation on four different routing problems with different kinds of objectives and constraints, different baseline heuristics, etc., is quite impressive (irrespective of the results). The fact that the proposed model can be easily adapted to different problems is encouraging, since many real-world operational problems may be different from textbook TSP/VRP, and hard to design algorithms for; a learned algorithm can greatly expedite the process. This versatility is shared with the model in Dai et al. (2017) which applied to different graph optimization problems.

- Choice of baseline: the use of the greedy policy is definitely the right thing to do here, as one wants to beat "simpler" baselines.

- Results: the proposed method performs very well and does not seem hard to tune, in that the same model hyperparameters work well across different problems.

Weaknesses:
- Comparison to Deudon et al. (2018): I believe the authors should do more work to compare against Deudon et al. (2018). This includes expanding the sentence in related work, describing the differences in more detail; perhaps a side-by-side graphical comparison of the two models in the appendix would help; reporting results from or running the code of that paper for the relevant problems (TSP?). This is crucial, since that paper also builds on the Transformer architecture, attention, etc. Its code is also online and seems to have been up for a while (<a href="https://github.com/MichelDeudon/encode-attend-navigate)." target="_blank" rel="nofollow">https://github.com/MichelDeudon/encode-attend-navigate).</a> There is quite some overlap, and the reader should be able to understand how the two models/papers differ.

- Intuition: One thing that is lacking here is some intuitive explanation of *why* this particular attention model is a reasonable choice for guiding a combinatorial algorithm. For instance, earlier work such as Pointer networks or S2V-DQN each addressed certain issues with other models of the time (e.g. capturing graph structure in S2V-DQN). If the choice of the model is purely performance-driven, that is completely fine, but then it makes sense to walk the reader through the process that got you to the final model. You do some of that in the ablation study in 5.2, for the baseline. Additionally, I am wondering about why this attention model is good for a combinatorial problem.

Questions/suggestions:
- Performance metric: if I understand correctly, Table 1 reports objective values. Could you additionally report optimality gaps compared to the best solution found *across* methods (including Gurobi, especially when it solves to optimality for the smaller problems/all of TSP)? Otherwise, it is very hard to interpret the differences in absolute objective values across methods.

- Baseline: could you use a non-learned baseline (e.g. 2-opt for the case of TSP) at the beginning of the training (then go to your learned but greedy baseline)? Might this give a stronger baseline at the beginning and accelerate training?</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">6: Marginally above acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_SkePlW15aQ" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Paper updated to include comparison to Deudon et al. (2018) and intuition about attention model</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=ByxBFsRqYm&amp;noteId=SkePlW15aQ"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper444 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">15 Nov 2018</span><span class="item">ICLR 2019 Conference Paper444 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Thank you for reviewing and appreciating our paper! Please let us address your concerns; we have updated the paper according to your suggestions.

- Comparison to Deudon et al. 
We would like to emphasize that Deudon et al. (2018) is *concurrent* work that actually appeared *after* we released an early version (as online preprint) of this paper. However, we agree that to the reader the comparison is relevant and we have updated the paper to include an explanation of the differences. Also, since results in their paper are not directly comparable, we ran their code with the same number of iterations and samples as we do (this improved the results). We have added the numbers in Table 1. 

- Intuition
Thank you for this helpful suggestion (which was also mentioned by R3). Focusing on the technical parts of the paper and the results this is indeed something that we overlooked. We have added this to the discussion section.

- Results as percentages
Not reporting the percentages was merely a practical matter to keep things clear and save space. We have added the percentages in the updated paper and allocated more space for the table to keep things as clear as possible.  

- Baseline
Indeed, using a known algorithm as baseline is a good suggestion. This is an interesting direction for future work.</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div><div class="note_with_children"><div id="note_rJeXVEsdnm" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Simple application of attention + reinforce to routing problems, scalability is unclear</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=ByxBFsRqYm&amp;noteId=rJeXVEsdnm"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper444 AnonReviewer3</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">02 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper444 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">The paper presents an attention-based approach to learning a policy for solving TSP and other routing-type combinatorial optimization problems. An encoder network computes an embedding vector for each node in the input problem instance (e.g., a city in a TSP map), as well as a global embedding for the problem instance. The encoder architecture incorporates multi-head attention layers to compute the embeddings. The decoder network then uses those embeddings to output a permutation of the nodes which is used as the solution to the optimization problem. The encoder and decoder are trained using REINFORCE to maximize solution quality. Results are shown for four problem types -- TSP, vehicle routing, orienteering problem, and stochastic prize collecting TSP. 

Positive aspects of the paper: The problem of learning combinatorial optimization algorithms is definitely an important one as it promises the possibility of automatically generating special purpose optimizers. Showing experimental results for different problem types is useful as it gives evidence for broad applicability. The paper is well-written, the related work section is nice, and the background material is explained well enough to make it a self-sufficient read. 

I have two main criticisms:
1. Scalability of the approach: Focusing on the TSP experiments, the problem sizes of 20, 50, and 100 are really trivial for a state-of-the-art exact solver like Concorde or heuristic algorithm like LKH. And there have already been many papers showing that RL can be used for small-scale TSP and other problems (many are cited in this paper). At this point the interesting question is whether an RL approach can scale to much bigger problem instances, both in terms of solution quality as well as inference running time. For example, the DIMACS TSP Challenge problem instances have sizes up to 10^7 cities. New heuristics used with LKH (e.g. POPMUSIC) can scale to such sizes and empirically show complexity that is nearly linear with respect to the number of cities. It seems that the proposed approach would have quadratic complexity, which would not scale to much bigger problem instances. Table 2 also suggests that the solution quality (optimality gap) becomes worse for bigger sizes. If there was strong evidence that the approach could scale to much larger instances, that would have added to the novelty of the paper.

2. Insufficient comparisons: 
a. The comparison to Gurobi's running time in Table 1 is misleading because in addition to outputting a solution, it also outputs a certificate of optimality. It is possible that Gurobi finds the optimal solution very quickly but then spends a large amount of time proving optimality. Since RL approaches don't prove optimality, it would be more fair to report Gurobi's time to first reach the optimal solution (and disregard proving time). This may turn out to be much smaller than the times reported in Table 1. 
b. It would be good to compare against the state-of-the-art TSP-specific algorithms (Concorde, LKH) as well. Even if a general-purpose RL approach does not beat them, it would be good to assess how much worse it is compared to the best expert-designed custom algorithms so that the tradeoff between human expertise and solution quality / running time is clear. 

It would also be useful to give insight into what does attention buy for the kinds of problems considered. Why do we expect attention to be helpful, and do the results match those expectations?
</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">6: Marginally above acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_Bye8WGJcaX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Comments on scalability, paper updated with additional comparisons and added intuition about attention model</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=ByxBFsRqYm&amp;noteId=Bye8WGJcaX"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper444 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">15 Nov 2018</span><span class="item">ICLR 2019 Conference Paper444 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Thank you for seeing the importance of the problem and the value of showing the broad applicability. Please let us address you concerns.

- Scalability
Scalability is indeed a very important direction for further research. We think that the way that heuristics (like you mention) scale almost linearly is by considering the problem locally, e.g. by local search or by limiting the set of edges for nodes (e.g. consider a sparse graph). A very promising approach would be to combine these ideas with learning, e.g. by learning how to perform local search (rather than a construction as we do here) on a sparse graph. We think our work is a step in this direction by using an architecture that could be extended to operate (potentially locally) on a (sparse) graph structure, and a powerful algorithm to train with the rollout baseline.

- Insufficient comparisons
a.
You are right that Gurobi may spend significant time to prove optimality after finding the solution. However, we are not sure if reporting the time the solution is found as if it were the run time is the right thing to do: the algorithm cannot stop (without sacrificing performance) at this time since it has no way to know that the current solution is optimal. By the same argument, we could also report the time a solution was first found (or sampled) in a heuristic search procedure, but this is a measure 'in hindsight' which does not constitute a practical algorithm.
Nevertheless, it's a good point that Gurobi may find good solutions early, which we can use 'heuristically' by setting a time limit or increasing the MIP gap (stop when the solution is proven within x % of optimal). We found that increasing the MIP gap (to as much as 5%) for TSP reduced running time at most 20%. A time limit of 1s makes no difference for TSP20/50 but results in no feasible solution being found in some cases for TSP100. A larger timelimit has no effect. For the OP and the PCTSP, however, we can tradeoff time for performance, but with limited success for larger instances (we added results for 1s, 10s and 30s time limit to the paper).
b.
We thought Concorde/LKH would not add much as Gurobi already finds optimal solutions very quickly. However, following your suggestions we ran the experiments and added the results, being that Concorde is slower for smaller instances but 6x faster for TSP100. LKH empirically finds optimal results but takes slightly longer than Gurobi.

- What does attention buy
Thank you for this suggestion (which was also noted by R1), this is indeed something that was missing which we have added to the discussion section of the paper.</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div><div class="note_with_children"><div id="note_BkeH3bYNn7" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>A nice contribution to neural combinatorial optimisation</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=ByxBFsRqYm&amp;noteId=BkeH3bYNn7"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper444 AnonReviewer2</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">29 Oct 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper444 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">This paper is one of a sequence of works trying to learn heuristics for solving combinatorial optimisation problems. Compared to its predecessors, its contributions are three-fold. First, it introduces a tweak on the REINFORCE learning algorithm, outperforming more complicated methods. Second, it introduces a new model for combinatorial tasks which delivers interesting results on several tasks which are varied though related. Finally, it evaluates this model on many tasks.

****Quality and clarity****
This is a very high-quality paper. 
The writing is clear and sharp, and the reading experience is quite enjoyable (the witty first paragraph sets the tone for what is to follow), even if the text is at times a bit verbose. 
Another point to commend is the honesty of the paper (see e.g. the comment on the performance of the model on TSP vs specialised solvers such as Concord).
The related work section is complete and well documented.
Finally, the experimental results are clearly presented and well-illustrated.

****Originality and significance****
On the theoretical side, the contributions of this paper are interesting but not ground-breaking. The REINFORCE tweak is close to other algorithms that have been tried in the last few years (such as indeed the one presented in Rennie et al, 2016). The model architecture, while successful, is not a large departure from the Transformer presented in Vaswani et al, 2017.

More significant is the complete set of experiments on a varied subset of combinatorial tasks, which showcases one of the promises of using machine learning for combinatorial optimisation: reusability of a single model for many tasks.

****Conclusion****
Overall, this is a nice, very well-written paper. Its contributions, though not ground-breaking, are significant to the field, and constitute another step in the right direction.

Pros
- high-quality writing
- very clear
- complete experiments on a variety of tasks, some of which do not have optimal solvers
- honest assessment of the model

Cons
- the theoretical contributions are not ground-breaking (either the the tweak on REINFORCE or the model architecture)
- the model is still far from obtaining meaningful results on TSP (although it's interesting to compare to previous learned models, only solving problems with 100 nodes also illustrates how far we have to go...)

Details
- Dai et al has been published at NIPS and is no longer an arxiv preprint
- the comparison to AlphaGo should either be expanded upon or scratched. Although it could be quite interesting, as it is it's not very well motivated.</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">7: Good paper, accept</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_HkgKKfy56m" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Motivation of reusing part of Transformer architecture, paper updated for detailed comments</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=ByxBFsRqYm&amp;noteId=HkgKKfy56m"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper444 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">15 Nov 2018</span><span class="item">ICLR 2019 Conference Paper444 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Thank you for appreciating our paper!

- Please let us motivate why we reuse a large part of the Transformer architecture. We think one of the successes of Deep Learning is the reduction of the need for manual feature engineering. We would like to avoid replacing feature engineering by task specific model engineering. Since the encoder has the generic task of learning node representations, we borrow the powerful Transformer architecture (interpreting it as an instance of a graph neural network). The decoder however is different and suitably adapted to the problem at hand.
- Thank you for the detailed suggestions: we updated the Dai et al. reference and expanded on the AlphaGo comparison in the updated paper.</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div></div></main></div>
  </div>
</div>


    <!-- Footer -->
    <footer class="sitemap">
      <div class="container">
        <div class="row hidden-xs">
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/venues">All Venues</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="/contact">Contact</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
    
        <div class="row visible-xs-block">
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/contact">Contact</a></li>
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
      </div>
    </footer>
    
    <footer class="sponsor">
      <div class="container">
        <div class="row">
          <div class="col-sm-10 col-sm-offset-1">
            <p class="text-center">
              OpenReview is created by the <a href="http://www.iesl.cs.umass.edu/" target="_blank">Information Extraction and Synthesis Laboratory</a>, College of Information and Computer Science, University of Massachusetts Amherst. We gratefully acknowledge the support of the OpenReview sponsors:  Google,  Facebook, NSF, the University of Massachusetts Amherst Center for Data Science, and Center for Intelligent Information Retrieval, as well as the Google Cloud Platform for donating the computing and networking services on which OpenReview.net runs.
            </p>
          </div>
        </div>
      </div>
    </footer>

  <div id="feedback-modal" class="modal fade" tabindex="-1" role="dialog">
    <div class="modal-dialog">
      <div class="modal-content">
        <div class="modal-header">
          <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">Ã—</span></button>
          <h3 class="modal-title">Send Feedback</h3>
        </div>
        <div class="modal-body">
          <p>Enter your feedback below and we'll get back to you as soon as possible.</p>
          <form action="/feedback" method="POST">
            <div class="form-group">
              <input type="email" name="from" class="form-control" placeholder="Email" />
            </div>
            <div class="form-group">
              <input type="text" name="subject" class="form-control" placeholder="Subject" />
            </div>
            <div class="form-group">
              <textarea name="message" class="form-control feedback-input" rows="5" placeholder="Message" required=""></textarea>
            </div>
          <ul id="ui-id-2" tabindex="0" class="ui-menu ui-widget ui-widget-content" style="display: none;"></ul></form>
        </div>
        <div class="modal-footer">
          <button type="button" class="btn btn-default" data-dismiss="modal">Cancel</button>
          <button type="button" class="btn btn-primary">Send</button>
        </div>
      </div>
    </div>
  </div>

  <script type="text/javascript" async="" src="https://www.google-analytics.com/analytics.js"></script><script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js"></script>
  <script>window.jQuery || document.write('&lt;script src="/static/js/vendor/jquery-2.2.4.min.js"&gt;&lt;\/script&gt;')</script>

  <script src="/static/dist/vendor.min.js"></script>
  <script src="/static/dist/templates.min.js"></script>
  <script src="/static/dist/openreview.min.js"></script>

    <script>window.legacyScripts = true;</script>


    <script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-108703919-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() { dataLayer.push(arguments); }
      gtag('js', new Date());
      gtag('config', 'UA-108703919-1');
    </script>


<div role="status" aria-live="assertive" aria-relevant="additions" class="ui-helper-hidden-accessible"></div></body></html>
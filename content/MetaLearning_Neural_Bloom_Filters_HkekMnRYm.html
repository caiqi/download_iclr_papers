<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" class="no-js"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>Meta-Learning Neural Bloom Filters | OpenReview</title>
  <meta name="description" content="" />

      <meta name="citation_title" content="Meta-Learning Neural Bloom Filters" />
        <meta name="citation_author" content="Anonymous" />
      <meta name="citation_publication_date" content="2018/09/27" />
      <meta name="citation_online_date" content="2018/09/27" />
      <meta name="citation_pdf_url" content="https://openreview.net/pdf?id=HkekMnR5Ym" />
      <meta name="twitter:card" content="summary" />
      <meta name="twitter:site" content="@openreviewnet" />
      <meta name="og:title" content="Meta-Learning Neural Bloom Filters" />
      <meta name="og:description" content="There has been a recent trend in training neural networks to replace data structures that have been crafted by hand, with an aim for faster execution, better accuracy, or greater compression.  In..." />
      <meta name="og:image" content="https://openreview.net/static/images/openreview_logo_512.png" />

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans:400,400i,700,700i" />

  <link rel="stylesheet" href="/static/css/bootstrap.min.css" />
  <link rel="stylesheet" href="/static/css/jquery-ui.min.css" />
  <link rel="stylesheet" href="/static/css/main.min.css" />
</head>

<body class="forum">
  <nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
  
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand home push-link" href="/"><strong>OpenReview</strong>.net</a>
      </div>
  
      <div id="navbar" class="navbar-collapse collapse">
        <form class="navbar-form navbar-left profile-search" role="search">
          <div class="form-group has-feedback">
            <input id="search_input" type="text" class="form-control ui-autocomplete-input" placeholder="Search ICLR 2019 Conference" autocomplete="off" />
            <span class="glyphicon glyphicon-search form-control-feedback" aria-hidden="true"></span>
          </div>
  
          <input id="search_group" type="hidden" value="ICLR.cc/2019/Conference" />
          <input id="search_content" type="hidden" value="all" />
        <ul id="ui-id-1" tabindex="0" class="ui-menu ui-widget ui-widget-content ui-autocomplete ui-front" style="display: none;"></ul></form>
  
        <ul class="nav navbar-nav navbar-right">
        
            <li id="user-menu"><a href="/login">Login</a></li>
        </ul>
      </div>
  
    </div>
  </nav>

  <div id="or-banner" class="banner" style="">
  <div class="container">
    <div class="row">
      <div class="col-xs-12"><a href="/group?id=ICLR.cc/2019/Conference" title="Venue Homepage"><img class="icon" src="/static/images/arrow_left.svg" /> Go to <strong>ICLR 2019 Conference</strong> homepage</a></div>
    </div>
  </div>
</div>
<div id="flash-message-container" class="alert alert-danger" role="alert" style="display: none;">
  <div class="container">
    <div class="row">
      <div class="col-xs-12">
        <div class="alert-content">
          <button type="button" class="close" aria-label="Close"><span aria-hidden="true">×</span></button>
        </div>
      </div>
    </div>
  </div>
</div>

<div class="container">
  <div class="row">
    <div class="col-xs-12">
      <main id="content" class="clearfix openbanner-visible legacy-styles"><div id="note_HkekMnR5Ym" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Meta-Learning Neural Bloom Filters</a> <a class="note_content_pdf" href="/pdf?id=HkekMnR5Ym" title="Download PDF" target="_blank"><img src="/static/images/pdf_icon_blue.svg" /></a> </h2></div><div class="meta_row"><span class="signatures">Anonymous</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">28 Sep 2018 (modified: 17 Nov 2018)</span><span class="item">ICLR 2019 Conference Blind Submission</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span><span class="item"><a class="action-bibtex-modal" data-bibtex="@inproceedings{    &#10;anonymous2019meta-learning,    &#10;title={Meta-Learning Neural Bloom Filters},    &#10;author={Anonymous},    &#10;booktitle={Submitted to International Conference on Learning Representations},    &#10;year={2019},    &#10;url={https://openreview.net/forum?id=HkekMnR5Ym},    &#10;note={under review}    &#10;}">Show Bibtex</a></span><a class="note_content_pdf item" href="/revisions?id=HkekMnR5Ym" target="_blank">Show Revisions</a></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Abstract: </span><span class="note_content_value">There has been a recent trend in training neural networks to replace data structures that have been crafted by hand, with an aim for faster execution, better accuracy, or greater compression.  In this setting, a neural data structure is instantiated by training a network over many epochs of its inputs until convergence. In many applications this expensive initialization is not practical, for example streaming algorithms --- where inputs are ephemeral and can only be inspected a small number of times.  In this paper we explore the learning of approximate set membership over a stream of data in one-shot via meta-learning. We propose a novel memory architecture, the Neural Bloom Filter, which we show to be more compressive than Bloom Filters and several existing memory-augmented neural networks in scenarios of skewed data or structured sets.</span></div><div class="note_contents"><span class="note_content_field">Keywords: </span><span class="note_content_value">meta-learning, memory, one-shot learning, bloom filter, set membership, familiarity, compression</span></div><div class="note_contents"><span class="note_content_field">TL;DR: </span><span class="note_content_value">We investigate the space efficiency of memory-augmented neural nets when learning set membership.</span></div><div class="reply_row clearfix"><div class="item" id="reply_count">8 Replies</div></div></div><hr class="small" /><div id="note_children"><div class="note_with_children"><div id="note_S1gCw_-T6X" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Substantial revision - thank you!</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HkekMnR5Ym&amp;noteId=S1gCw_-T6X"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1230 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">17 Nov 2018</span><span class="item">ICLR 2019 Conference Paper1230 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Thank you for reading the paper and leaving your detailed feedback. The unified message from all three of you is that the paper could have done a better job in motivating the model, and describing the training regime. We have perhaps ‘regularized’ the paper’s contents too heavily in the endeavor to be succinct. We provide an updated manuscript with additions to ‘model’, ‘experiments’, and ‘related work’ --- an extra page of text. The proposed architecture is now better explained and the training regime is much more explicit. It’s a much better paper thanks to your comments.

If you think the problem setting has no potential for impact, or if you think there are fundamental flaws in our research approach then we would really appreciate feedback on this (and a rejection). Otherwise we would ask you to read the updated manuscript and update your response. We will also respond to each comment individually.

----

Key changes:

- Re-written ‘model’ section with a much clearer motivation. Added more specific details (e.g. encoder architecture) to model section, less reliance on appendix.

- Re-written experiments: explained meta-learning training in detail with algorithm box, explained why this is meta-learning / one-shot learning, added space comparison info, less reliance on appendix.

- Added speed comparison benchmarks (some peers were interested in us adding these numbers). The summary of these numbers is the latency of the neural bloom filter is much higher than a bloom filter, but the throughput can be comparable if the model is run on a gpu.
</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_HyeHtaK6pm" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Re: "How is this different to Kraska et al. 2018"</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HkekMnR5Ym&amp;noteId=HyeHtaK6pm"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1230 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">17 Nov 2018</span><span class="item">ICLR 2019 Conference Paper1230 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">One concern that reviewer 2 and 3 raised that we would like to quickly address is, ‘what is the point of this model vs kraska et al. 2018?’ The simple answer is that kraska et al. 2018 learns a set membership classifier by training a feed-forward neural classifier from scratch over many (hundreds to thousands) epochs of the storage set S, and it is compressed into the weights of the network. We propose a method where a neural network learns to produce a classifier with a single pass over S, and the set is represented by an external memory M of compressed activations. 

In the case of a banned URL list, where S may not change very much, it may be tenable to use the kraska et al. 2018 approach with multiple epochs of gradient descent. In the case of databases that uses Bloom Filters (e.g. Google Bigtable, Apache Cassandra, Redis) where one may have thousands of separate bloom filters (one per disk file, say) which are dynamically updating, it is impractical to train thousands of separate networks from scratch. Thus a one-shot approach (our paper) is absolutely necessary, and this paper serves as an existence proof that significant compression can be obtained in this challenging setting.</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div><div class="note_with_children"><div id="note_BkxdWIvphQ" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Unclear paper, difficult to understand how the algorithm works or why</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HkekMnR5Ym&amp;noteId=BkxdWIvphQ"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1230 AnonReviewer1</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">05 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper1230 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">The paper proposes a method whereby a neural network is trained and used as a data structure to assess approximate set membership. Unlike the Bloom filter, which uses hand-constructed hash functions to store data and a pre-specified method for answering queries, the Neural Bloom Filter learns both the Write function and the Read function (both are "soft" values rather than the hard binary values used in the Bloom filter). Experiments show that, when there is structure in the data set, the Neural Bloom Filter can achieve the same false positive rate with less space.

I had a hard time understanding how the model is trained. There is an encoding function, a write function, and a query function. The paper talks about one-shot meta-learning over a stream of data, but doesn't make it clear how those functions are learned. A lot of details are relegated to the Appendix. For instance B.2 talks about the encoder architecture for one of the experiments. But even that does not contain much detail, and it's not obvious how this is related to one-shot learning. Overall, the paper is written from the perspective of someone fully immersed in the details of the area, but who is unable to pop out of the details to explain to people who are not already familiar with the approach how it works. I would suggest rewriting to give an end-to-end picture of how it works, including details, without appendices. The approach sounds promising, but the exposition is not clear at all.</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">3: Clear rejection</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">1: The reviewer's evaluation is an educated guess</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_rJeha6qa6m" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Explanation of training setup and why it's one-shot classification.</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HkekMnR5Ym&amp;noteId=rJeha6qa6m"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1230 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">17 Nov 2018</span><span class="item">ICLR 2019 Conference Paper1230 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Thank you for reading the paper, and we apologize for its opacity upon first pass. We completely agree the paper has mis-judged its audience and was not easy to read straight-through, this feedback is very useful in correcting this. We wrote the paper for someone highly familiar with meta-learning memory-augmented neural networks but not familiar with bloom filters; this left out an important audience.

--- Re. “I had a hard time understanding how the model is trained...”

The model learns in one-shot because it observes a set S = (k1, k2, … kn) and writes it to a memory (or state) M with only one observation of this dataset. It then answers queries “is my query x in S” using the read operation, conditioning on the memory, M. It is the same one-shot classification approach as "Matching Networks" Vinyals et al. 2016 however we focus on classifying familiarity versus image or text class. We have added several paragraphs and an algorithm box with further explanation of the meta-learning training setup. We will just briefly summarize it here. 

We have a collection of sets Strain1, Strain2, , … Strainm reserved for training; and a collection of queries Q = {q1, q2, …, qL} and targets yi = 1 if qi in S and 0 otherwise. In the example of a database we can think of a given set Si = {k1, …, kN} as a set of rowkeys for a given file on disk (e.g. SSTable). We have many sets because we have many files; for training we have reserved some for an offline training routine.

During training we calculate M = fwrite(S), and then we calculate oi = fread(S, qi). We calculate the cross-entropy loss L = \sumi yi log(oi) + (1 - yi)log(1-oi) and backprogate through the network (through the parameters controlling both the read, write, and encoder networks). One can consider the creation of M = fwrite(S) as a fast one-shot learning procedure; the network learns a state which can help it solve the classification problem, “is q in S?”. The slow-moving ‘meta-learning’ process is in the network parameters, which are slowly being optimized over several set membership tasks, i.e. several different sets S1:m, to be effective at one-shot classification. At test time, when we observe a new subset (or stream of elements) we can insert them with fwrite in one-shot and the resulting data-structure is the external memory, M.

-- Re. “A lot of details are relegated to the Appendix. For instance B.2 talks about the encoder architecture for one of the experiments.” 

This is a good point. We have removed B. 2 from the appendix and promoted the details to the model section. Furthermore we have given an example instantiation of the full architecture in the model section, so one does not need to consult the appendix. We have not completely removed the appendix as some details are tangential discussion points (e.g. how to implement the model in sub-linear time) but other details, such as space comparison, are now described in more detail in the experiments section.

We have significantly re-written the paper’s model and experiments section to remedy this --- please take a look and let us know if this addresses concerns.</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div><div class="note_with_children"><div id="note_H1lg3Mjdn7" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Interesting topic, some concerns</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HkekMnR5Ym&amp;noteId=H1lg3Mjdn7"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1230 AnonReviewer3</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">01 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper1230 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">SUMMARY
The paper proposes a neural network based architecture to solve the approximate set membership problem, in the distributional setting where the in-set and out-of-set elements come from two unknown and possibly different distributions.


COMMENTARY
The topic of the paper is interesting, and falls into the popular trend of enhancing classical data structures with learning algorithms. For the approximate set membership problem, this approach was already suggested by (Kraska et al. 2018) and studied further in (Mitzenmacher 2018a,b). The difference in the current paper is that the proposed approach relies on "meta-learning", apparently to facilitate online training and/or learning across multiple sets arising from the same distribution; this is what I gather from the introduction, even though as I write below, I feel this point is not properly explained.

My main issue with the paper is that its conceptual contribution seems limited and unclear. It suggests a specific architecture whose details seem mostly arbitrary, or at least this is the impression the reader is left with, as the paper does rather little in terms of discussing and motivating them or putting them in context. Moreover, since the solution ultimately relies on a backup Bloom Filter as in (Kraska et al. 2018), it is hard to not view it as just an instantiation of the model in (Kraska et al. 2018, Mitzenmacher 2018a) with a different plugging of learning component. It would help to flesh out and highlight what the authors claim are the main insights of the paper.

Another issue I suggest revising pertains to the writing. The problem setting is only loosely sketched but not properly defined. How exactly do different subsets coming into play? Specifically, the term "meta-learning" appears in the title and throughout the paper, but is never defined or explained. The authors should write out what exactly they mean by this notion and what role it plays in the paper. This is important since to my understanding, this is the main point of departure from the aforementioned recent works on learning-enhanced Bloom Filters.

The experiments do not seem to make a strong case for the empirical advantage of the Neural Bloom Filter. They show little to no improvement on the MNIST tasks, and some improvement on a non-standard database related task. One interesting thing to look at would be the workload partition between the learning component and the backup filter, meaning what is the rate of false negatives emitted by the former and caught by the latter, and how the space usage breaks down between them (vis-a-vis the formula in Appendix B). For example, it seems plausible that on the class familiarity task, the learning component simply learns to be a binary classifier for the chosen two MNIST classes and mostly ignores the backup filter, whereas in the uniform distribution setting, the learning component only memorizes a small number of true and false positives and defers almost the entire task to the backup filter. I am not sure what to expect on the intermediate exponential distribution task.

Other comments/questions:
1. For the classical Bloom Filter, do the results reported in the experimental plots reflect the empirical false-positive rate measured in the experiment, or just the analytic bound?
2. On that note, it is worth noting that the false positive rate of the classical Bloom Filter is different than the one you report for the neural-net based architectures. The Bloom Filter FP probability is over its internal randomness (i.e. its hash functions) and is independent of the distribution of queries, which need not be randomized at all. For the neural-net based architectures, the measured FP rate is w.r.t. a specific distribution of queries. See the discussion in (Mitzenmacher 2018a), sections B-C.
3. The works (Mitzenmacher 2018a,b) should probably at least be referenced in the related work section.


CONCLUSION
While I like the overall topic of the paper, I currently find the conceptual contribution to be too thin, raising doubts on novelty and significance. In addition, the presentation is somewhat lacking in clarity, and the practical merit is not well established. Notwithstanding the public nature of ICLR submissions, I would suggest more work on the paper prior to publication.


REFERENCES
M. Mitzenmacher, A Model for Learned Bloom Filters and Related Structures, 2018, see <a href="https://arxiv.org/pdf/1802.00884.pdf." target="_blank" rel="nofollow">https://arxiv.org/pdf/1802.00884.pdf.</a>
M. Mitzenmacher, Optimizing Learned Bloom Filters by Sandwiching, 2018, see https://arxiv.org/pdf/1803.01474.pdf.</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">5: Marginally below acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_BklHAWcapX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>R3 response</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HkekMnR5Ym&amp;noteId=BklHAWcapX"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1230 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">17 Nov 2018</span><span class="item">ICLR 2019 Conference Paper1230 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Thank you for this thoughtful and comprehensive review.

-- We agree the recent Mitzenmacher arxiv posts should have been included in the related works, and they have now been added. 

-- Re. ‘strong empirical case for NBF…’ The fact that an LSTM does well on the MNIST class-based familiarity task is a useful data-point. However we do see a substantial gain for the database task. However the main problem with RNNs such as the LSTM (and DNC) is that they are not scalable. need to be trained to store N items by ingesting the N elements sequentially, and then backpropagating over the entire sequence. For large N this does not end up being scalable; e.g. for the large database task (Table 1) where N = 5,000. Thus we develop a memory model that does not rely on BPTT (alike to memory networks) but is compressive (unlike memory networks). 

The crucial design-point of the model is that it uses a commutative write operation (addition) which is much simpler than the DNC &amp; LSTM write (e.g. no gating, no squashing of the state) and is like a continuous relaxation of the Bloom Filter’s write (logical or). A simple additive write scheme also means the model will produce the same external memory M regardless of the ordering of the inputs (because addition is commutative) which makes sense given that familiarity does not depend upon input ordering, thus we also do not get strange effects where older inputs have much worse performance than newer inputs (which will occur with an RNN).  We discuss the model’s motivation more explicitly in the revised text. 

-- Re. “One interesting thing to look at would be the workload partition between the learning component and the backup filter”. This is a very interesting question you ask here. Your intuition is absolutely pretty well for class-based familiarity, the backup filter is used where the encoder essentially miss-classifies a character (so it is very lightly used). For uniform sampling, the model essentially captures a small random subset of inputs but mostly relies on the backup bloom filter. For the imbalanced data the model appears to store and characterise well the ‘heavy hitter’ i.e. frequent elements in the state memory and uses the backup bloom filter for infrequent elements. 

-- Re. ‘problem setting is loosely sketched…’ - the reviewer is correct, we originally wrote the paper for readers familiar with the recent one-shot memory-augmented meta-learning literature (e.g. matching networks [vinyals et al. 2016], MANN [santoro et al. 2016]) but unfamiliar with Bloom Filters. This was an unfortunate choice, we have thus expanded on what we mean by meta-learning and described how the training regime works. It is the exact same training regime as that in vinyals et al. 2016 and many follow-on works, only the classification problem is set membership, versus image classification. We have added a subsection with further explanation and an algorithm box with a succinct summary of the meta-learning training setup.

We will  just briefly summarize the training setup here. We have a collection of sets {S_1, S_2, , … S_m} reserved for training (each set contains n points to insert); and a collection of queries Q = {q1, q2, …, qL} and targets yi = 1 if qi in S and 0 otherwise. In the example of a database we can think of a given set Si = {k1, …, kN} as a set of rowkeys for a given file on disk (e.g. SSTable). We have many sets because we have many files; for training we have reserved some for an offline training routine.

During training we calculate M = f_write(S), and then we calculate oi = f_read(S, qi), our query responses having observed the set S only once. We calculate the cross-entropy loss L = \sumi yi log(oi) + (1 - yi)log(1-oi) and backprogate through the network (through the parameters controlling both the read, write, and encoder networks). One can consider the creation of M = f_write(S) as a fast one-shot learning procedure; the network learns a state which can help it solve the classification problem, “is q in S?” in one-shot. The slow-moving ‘meta-learning’ process is in the network parameters, which are slowly being optimized over several set membership tasks, i.e. several different sets S_1:m, to be effective at one-shot classification. At test time, when we observe a new subset (or stream of elements) we can insert them with f_write in one-shot and the resulting data-structure is the external memory, M.

-- Re. Bloom Filter space usage, we indeed used the analytical bound. We have clarified this in the text. We feel this is fair as it makes the task of beating a Bloom Filter’s space performance slightly more difficult (as the analytic bound is slightly more compressive than in-practice), and it absolves any dispute over the choice of Bloom Filter library / choice of hash function etc.

-- We have clarified the false positive rate is with respect to the distribution of queries in the text. 
</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div><div class="note_with_children"><div id="note_HJlfcMvI3m" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Details of the architecture not well motivated</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HkekMnR5Ym&amp;noteId=HJlfcMvI3m"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1230 AnonReviewer2</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">31 Oct 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper1230 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">The paper proposes a learnable bloom filter architecture. While the details of the architecture seemed a bit too complicated for me to grasp (see more on this later), via experiments the authors show that the learned bloom filters are more compact that regular bloom filters and can outperform other neural architectures when it comes to retrieving seen items.

A bloom filter is fairly simple, K hash functions hash seen items into K bit vectors. During retrieval, if all of the bits hashed to are 1 then we say we've seen the query. I think there's simpler ways to derive a continuous, differentiable version of this which begs the question why the authors chose a relatively more elaborate architecture involving ZCA transform and first/second moments. Perhaps the authors need to motivate their architecture a bit better.

In their experiments, a simple LSTM seems to perform remarkably well (it is close to the best in 2 (a), (b); and crashes in (c) but the proposed technique is also outperformed by vanilla bloom filters in (c)). This is not surprising to me since LSTMs are remarkably good at remembering patterns. Perhaps the authors would like to comment on why they did not develop the LSTM further to remedy it of its shortcomings. Some of the positive results attained using neural bloom filters is a bit tempered by the fact that the experiments were using a back up bloom filter. Also, the neural bloom filters do well only when there is some sort of querying pattern. All of these details would seem to reduce the applicability of the proposed approach.</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">5: Marginally below acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">3: The reviewer is fairly confident that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_BylFBY5aa7" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Model motivation and applicability.</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HkekMnR5Ym&amp;noteId=BylFBY5aa7"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1230 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">17 Nov 2018</span><span class="item">ICLR 2019 Conference Paper1230 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Thank you for your review, and for your keen eye to detail.

Re. “why not develop further an LSTM”. We are principally interested in whether it is possible to learn a compressive set membership data-structure in one-shot. Because many applications of Bloom Filters are in highly dynamic settings (e.g. databases), the requirement that a network may be able to beat a Bloom Filter with only a single computational pass over the data is quite important. It wasn’t clear from the beginning of this research project (to us and our peers) whether it would be possible, and if so - in what setting. Thus we feel that it would be a worthwhile scientific contribution to show this is the case with any model --- even an LSTM. 

Firstly, it is worth noting the LSTM is non-trivially less efficient for the database task even when the sequence length is quite short. But the real issue with an LSTM and other RNNs (partially covered in the Reviewer 3 response) is that it they are difficult to scale to larger set sizes, because one has to BPTT over the entire input sequence linearly (elements of our storage size S) during training. Say S contains 5,000 elements… One would have to train with sequences of length 5,000, insert all elements sequentially and BPTT over the 5,000 long sequence. Training is way too slow, and the optimization problem becomes intractable (network fails to learn). Furthermore the LSTM has quadratic computation cost with respect to the hidden state size. Since set membership is order-invariant, it seemed preferable to try out a memory architecture which does not rely on sequential computation and BPTT (like a memory network) that is still very compressive (unlike a memory network).

Our mistake in the original exposition, which you rightly point out, is that we have presented our solution (the architecture) without much of the motivation that lead to its incarnation. We have re-written the model section to remedy this. But we will also briefly state the model motivation here: 

- We want a simple write scheme and no BPTT -&gt; additive write. (it’s order-invariant, and alike to the Bloom Filter’s logical-or write).

- We want the network to choose where to write, as well as what to write -&gt; address is a softmax over memory based on content. (alike to the Kanerva Machine Wu et al. (2018))

- We want the network’s network trainable parameters to be small and independent of memory size -&gt; make the addressing matrix A non-trainable.

- We want the addressing to be efficient -&gt; make it sparse (alike to Rae et al. (2016)).

- We found a sparse address led to the network fixating on a subset of memory -&gt; whiten the query vector.

Whitening (or sphering) may appear complex but was only necessary if one adopts the sparse attention for efficiency. We implemented it in four lines of TensorFlow code, so at least it is not too complex from an engineering standpoint. Whitening has been used within deep learning literature before, e.g. “natural neural networks” [1] . An alternative to whitening would be to use a “flow” such as real NVP [2] which actually transforms the query to something which appears to be truly gaussian. Crucially, this was a trick to get sparse attention working, if one wishes to avoid sparse attention and just use the full softmax over memory then this side-detail of whitening can be ignored. 

-- Re. “Also, the neural bloom filters do well only when there is some sort of querying pattern. All of these details would seem to reduce the applicability of the proposed approach.” 

Fortunately the proposed approach does well if there is structure to the query pattern *or* storage set. In the case of the database task, our queries are picked uniformly from the universe --- there is not much structure. However there is structure to the storage sets (which represent row keys in an disk file within a database) and this is why our approach outperforms the classical data-structures so significantly. 

More generally we think the research area of using neural networks to replace data-structures, in this case a bloom filter, is so exciting because (we would argue) they are very rarely applied to data that contains no structure. Using a neural network to exploit redundancy and save space feels like a very impactful thing to do, and thought leaders within Computer Science (e.g. Jeff Dean, a co-author of the kraska et al. 2018 paper) appear to believe so. There are patterns to the rowkey schema that is used within our databases, there are patterns to blacklist URLs and IPs within our firewalls, there are patterns to our search queries. 

We have re-written the model and experiment section to address your concerns!

[1] <a href="https://deepmind.com/research/publications/natural-neural-networks/" target="_blank" rel="nofollow">https://deepmind.com/research/publications/natural-neural-networks/</a>
[2] https://arxiv.org/abs/1605.08803 
</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div></div></main></div>
  </div>
</div>


    <!-- Footer -->
    <footer class="sitemap">
      <div class="container">
        <div class="row hidden-xs">
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/venues">All Venues</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="/contact">Contact</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
    
        <div class="row visible-xs-block">
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/contact">Contact</a></li>
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
      </div>
    </footer>
    
    <footer class="sponsor">
      <div class="container">
        <div class="row">
          <div class="col-sm-10 col-sm-offset-1">
            <p class="text-center">
              OpenReview is created by the <a href="http://www.iesl.cs.umass.edu/" target="_blank">Information Extraction and Synthesis Laboratory</a>, College of Information and Computer Science, University of Massachusetts Amherst. We gratefully acknowledge the support of the OpenReview sponsors:  Google,  Facebook, NSF, the University of Massachusetts Amherst Center for Data Science, and Center for Intelligent Information Retrieval, as well as the Google Cloud Platform for donating the computing and networking services on which OpenReview.net runs.
            </p>
          </div>
        </div>
      </div>
    </footer>

  <div id="feedback-modal" class="modal fade" tabindex="-1" role="dialog">
    <div class="modal-dialog">
      <div class="modal-content">
        <div class="modal-header">
          <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button>
          <h3 class="modal-title">Send Feedback</h3>
        </div>
        <div class="modal-body">
          <p>Enter your feedback below and we'll get back to you as soon as possible.</p>
          <form action="/feedback" method="POST">
            <div class="form-group">
              <input type="email" name="from" class="form-control" placeholder="Email" />
            </div>
            <div class="form-group">
              <input type="text" name="subject" class="form-control" placeholder="Subject" />
            </div>
            <div class="form-group">
              <textarea name="message" class="form-control feedback-input" rows="5" placeholder="Message" required=""></textarea>
            </div>
          <ul id="ui-id-2" tabindex="0" class="ui-menu ui-widget ui-widget-content" style="display: none;"></ul></form>
        </div>
        <div class="modal-footer">
          <button type="button" class="btn btn-default" data-dismiss="modal">Cancel</button>
          <button type="button" class="btn btn-primary">Send</button>
        </div>
      </div>
    </div>
  </div>

  <script type="text/javascript" async="" src="https://www.google-analytics.com/analytics.js"></script><script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js"></script>
  <script>window.jQuery || document.write('&lt;script src="/static/js/vendor/jquery-2.2.4.min.js"&gt;&lt;\/script&gt;')</script>

  <script src="/static/dist/vendor.min.js"></script>
  <script src="/static/dist/templates.min.js"></script>
  <script src="/static/dist/openreview.min.js"></script>

    <script>window.legacyScripts = true;</script>


    <script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-108703919-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() { dataLayer.push(arguments); }
      gtag('js', new Date());
      gtag('config', 'UA-108703919-1');
    </script>


<div role="status" aria-live="assertive" aria-relevant="additions" class="ui-helper-hidden-accessible"></div></body></html>
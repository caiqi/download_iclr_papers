<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" class="no-js"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>Difference-Seeking Generative Adversarial Network | OpenReview</title>
  <meta name="description" content="" />

      <meta name="citation_title" content="Difference-Seeking Generative Adversarial Network" />
        <meta name="citation_author" content="Anonymous" />
      <meta name="citation_publication_date" content="2018/09/27" />
      <meta name="citation_online_date" content="2018/09/27" />
      <meta name="citation_pdf_url" content="https://openreview.net/pdf?id=ryxDUs05KQ" />
      <meta name="twitter:card" content="summary" />
      <meta name="twitter:site" content="@openreviewnet" />
      <meta name="og:title" content="Difference-Seeking Generative Adversarial Network" />
      <meta name="og:description" content="We propose a novel algorithm, Difference-Seeking Generative Adversarial Network (DSGAN), developed from traditional GAN. DSGAN considers the scenario that the training samples of target..." />
      <meta name="og:image" content="https://openreview.net/static/images/openreview_logo_512.png" />

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans:400,400i,700,700i" />

  <link rel="stylesheet" href="/static/css/bootstrap.min.css" />
  <link rel="stylesheet" href="/static/css/jquery-ui.min.css" />
  <link rel="stylesheet" href="/static/css/main.min.css" />
</head>

<body class="forum">
  <nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
  
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand home push-link" href="/"><strong>OpenReview</strong>.net</a>
      </div>
  
      <div id="navbar" class="navbar-collapse collapse">
        <form class="navbar-form navbar-left profile-search" role="search">
          <div class="form-group has-feedback">
            <input id="search_input" type="text" class="form-control ui-autocomplete-input" placeholder="Search ICLR 2019 Conference" autocomplete="off" />
            <span class="glyphicon glyphicon-search form-control-feedback" aria-hidden="true"></span>
          </div>
  
          <input id="search_group" type="hidden" value="ICLR.cc/2019/Conference" />
          <input id="search_content" type="hidden" value="all" />
        <ul id="ui-id-1" tabindex="0" class="ui-menu ui-widget ui-widget-content ui-autocomplete ui-front" style="display: none;"></ul></form>
  
        <ul class="nav navbar-nav navbar-right">
        
            <li id="user-menu"><a href="/login">Login</a></li>
        </ul>
      </div>
  
    </div>
  </nav>

  <div id="or-banner" class="banner" style="">
  <div class="container">
    <div class="row">
      <div class="col-xs-12"><a href="/group?id=ICLR.cc/2019/Conference" title="Venue Homepage"><img class="icon" src="/static/images/arrow_left.svg" /> Go to <strong>ICLR 2019 Conference</strong> homepage</a></div>
    </div>
  </div>
</div>
<div id="flash-message-container" class="alert alert-danger" role="alert" style="display: none;">
  <div class="container">
    <div class="row">
      <div class="col-xs-12">
        <div class="alert-content">
          <button type="button" class="close" aria-label="Close"><span aria-hidden="true">×</span></button>
        </div>
      </div>
    </div>
  </div>
</div>

<div class="container">
  <div class="row">
    <div class="col-xs-12">
      <main id="content" class="clearfix openbanner-visible legacy-styles"><div id="note_ryxDUs05KQ" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Difference-Seeking Generative Adversarial Network</a> <a class="note_content_pdf" href="/pdf?id=ryxDUs05KQ" title="Download PDF" target="_blank"><img src="/static/images/pdf_icon_blue.svg" /></a> </h2></div><div class="meta_row"><span class="signatures">Anonymous</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">28 Sep 2018 (modified: 19 Nov 2018)</span><span class="item">ICLR 2019 Conference Blind Submission</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span><span class="item"><a class="action-bibtex-modal" data-bibtex="@inproceedings{    &#10;anonymous2019difference-seeking,    &#10;title={Difference-Seeking Generative Adversarial Network},    &#10;author={Anonymous},    &#10;booktitle={Submitted to International Conference on Learning Representations},    &#10;year={2019},    &#10;url={https://openreview.net/forum?id=ryxDUs05KQ},    &#10;note={under review}    &#10;}">Show Bibtex</a></span><a class="note_content_pdf item" href="/revisions?id=ryxDUs05KQ" target="_blank">Show Revisions</a></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Abstract: </span><span class="note_content_value">We propose a novel algorithm, Difference-Seeking Generative Adversarial Network (DSGAN), developed from traditional GAN. DSGAN considers the scenario that the training samples of target distribution, $p_{t}$, are difficult to collect.

Suppose there are two distributions  $p_{\bar{d}}$ and $p_{d}$ such that the density of the target distribution can be the differences between the densities of $p_{\bar{d}}$ and $p_{d}$. We show how to learn the target distribution $p_{t}$ only via samples from $p_{d}$ and $p_{\bar{d}}$ (relatively easy to obtain).

DSGAN has the flexibility to produce samples from various target distributions (e.g. the out-of-distribution). Two key applications, semi-supervised learning and adversarial training, are taken as examples to validate the effectiveness of DSGAN. We also provide theoretical analyses about the convergence of DSGAN.</span></div><div class="note_contents"><span class="note_content_field">Keywords: </span><span class="note_content_value">Generative Adversarial Network, Semi-Supervised Learning, Adversarial Training</span></div><div class="note_contents"><span class="note_content_field">TL;DR: </span><span class="note_content_value">We proposed "Difference-Seeking Generative Adversarial Network" (DSGAN) model to learn the target distribution which is hard to collect training data.</span></div><div class="reply_row clearfix"><div class="item" id="reply_count">7 Replies</div></div></div><hr class="small" /><div id="note_children"><div class="note_with_children"><div id="note_rklu4Xex0m" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>We upload the revised manuscript .</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=ryxDUs05KQ&amp;noteId=rklu4Xex0m"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper185 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">19 Nov 2018 (modified: 20 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper185 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Thanks for all the comments.

We list all the modifications as following:

1. We add Sec. 1.1 to describe our motivation and scenario.

2. We reorganize Sec. 2.2 to clarify the main idea of DSGAN through several case studies.

3. We move Sec. 3.1 in the original manuscript to appendix C in the new one.

4. We rephrase Sec. 5.1 for better understanding. Moreover, we replace Tables 4 and 5 in the original manuscript with Figs. 7, 9 and 10 in the new one for more comprehensive evaluation.

5. We have more discussion to our model in Sec. 5.1.2 and Sec. 5.2.2.

6. We add Sec. 6 to discuss related works.</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_SkeKjN28aQ" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Interesting but straightforward idea that needs more development.</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=ryxDUs05KQ&amp;noteId=SkeKjN28aQ"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper185 AnonReviewer1</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">12 Nov 2018</span><span class="item">ICLR 2019 Conference Paper185 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">The paper presents DS-GAN, which aims to learn the difference between any two distributions whose samples are difficult or impossible to collect. To this end they simply model the target distribution such that adding it to one of the distribution results in another, and propose a min-max objective based on it. To show the effectiveness of the proposed DS-GAN, the authors validate it on semi-supervised learning and adversarial training tasks, on which it performs reasonably well in generating the difference between the two distributions. 

Pros
- The idea of learning the difference between two distributions is novel to my knowledge. Similar ideas have been explored in prior work such as [Li et al. 17] but are not doing exactly what the authors try to do. 
- The proposed method works reasonably well on semi-supervised learning and adversarial learning tasks, and thus it seems practically useful. 

Cons
- The proposed model is quite straightforward in its formulation, and since the paper is not addressing the importance of, or any challenges with the problem they are trying to solve, the contribution of this work appears minor. 
- The authors list theoretical results as contributions, but they are rather straightforward replacement of the p_d and p_g terms in the original theorems on optimality in [Goodfellow et al. 14] with the target distributions in this paper, that has nothing to do with what the authors claim in this paper.  Thus they add nothing to the value of the paper.
- The motivation is very unclear when reading the introduction section, and Figure 1 does not do a good job of providing it.  
- The experimental validation is lacking in many aspects. I think the main results should show that the difference-seeking GAN can learn distributional differences but the authors jump straight to the applications. Also, the current experimental section simply reports performances on the two tasks, without much analysis showing why it works well and how it works differently from other models. 

In sum, the idea seems nice and interesting but the model is straightforward and the current results are very weak in analysis in order to make a good paper. I would recommend the authors to perform further analysis of the model either theoretically or experimentally.

</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">5: Marginally below acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_BkgHQNggRQ" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Thanks for your review.</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=ryxDUs05KQ&amp;noteId=BkgHQNggRQ"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper185 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">19 Nov 2018</span><span class="item">ICLR 2019 Conference Paper185 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">We revise the manuscript to answer the comments.

&gt;&gt; “The proposed model is quite straightforward in its formulation, and since the paper is not addressing the importance of, or any challenges with the problem they are trying to solve, the contribution of this work appears minor.” 
&gt;&gt; “The motivation is very unclear when reading the introduction section, and Figure 1 does not do a good job of providing it. “

We add a subsection Sec. 1.1 to emphasize our motivations. Our goal is to generate unseen data, which is absent during training process and is difficult to collect. We show that the proposed DSGAN will have the ability to generate diverse unseen data that is helpful for one-class classification, semi-supervised learning, and adversarial attacks. Those techniques are important and involve many real applications shown in Fig. 8 in the revised manuscript.  


&gt;&gt; “The authors list theoretical results as contributions, but they are rather straightforward replacement of the p_d and p_g terms in the original theorems on optimality in [Goodfellow et al. 14] with the target distributions in this paper, that has nothing to do with what the authors claim in this paper. Thus they add nothing to the value of the paper.”

We rephrase the contribution about theoretical proofs (in Sec. 1.2 in the revised manuscript).  We remove the sentences “when the optimum of the Jensen-Shannon divergence is attained such that the generator distribution is equal to the target distribution,” which has been covered under [Goodfellow et al. 14]. Instead we show that the proposed DSGAN can learn the distribution which support set is difference of support sets of two distributions shown in Proposition 2. 


&gt;&gt; “The experimental validation is lacking in many aspects. I think the main results should show that the difference-seeking GAN can learn distributional differences but the authors jump straight to the applications. Also, the current experimental section simply reports performances on the two tasks, without much analysis showing why it works well and how it works differently from other models. “

We rearrange the figures, where Figs. 2-6 in the revised manuscript illustrate that DSGAN learn distributional difference on both toy-data and MNIST. We also add more discussions to compare our method with other methods in Sec 5.1.2 and Sec 5.2.2, and emphasize the advantages in DSGAN in the last paragraph of Sec. 5.1.2. </span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div><div class="note_with_children"><div id="note_HJlU9T4ph7" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>An interesting problem formulation, but the method doesn't seem innovative and the empirical results not very convincing</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=ryxDUs05KQ&amp;noteId=HJlU9T4ph7"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper185 AnonReviewer3</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">05 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper185 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">- Summary:
This paper considers the problem of learning a GAN to capture a target distribution p_t with only very few training samples from p_t available.

- Good
An interesting problem formulation. 
The proposed approach is not new, but seems to be a sensible and simple solution to the problem formulated in this paper. I would see the contributions of the paper: (1) an interesting problem formulation on how to learn p_t (with a few assumptions) (2) a sensible adaptation of GANs on this problem (with minor modifications to GANs which have been observed/adopted in many GAN literatures in the last two years)
The training appaoches/tricks are rather straightforward and not new as well.

- Suggestions
The main problem of this paper is that it does not provide sufficient results on any real applications that can support its problem&amp;model formulations. 
For example, in which scenarios would the users of the model need to train a GAN to mimic a target distribution p_t which is a difference of another two distributions (with examples available there but unavailable in p_t)? It would be good to show significant results on real applications to show the problem and the method useful.

Two applications on semi-supervised classification and adversarial training are discussed. While both seem to be very artificial IMO if considering the used dataset and designed experiments. The results are also not convincing even for the shown two experiments compared to baselines.

No related works on addressing the similar problems have been discussed nor compared in experiments.

- Theoretical results:
While the authors claim new theoretical results, in fact, I didn't see any contributions here as the theories developed in section 3 are mostly rather straightforward. There have been some similar theories being developed in previous papers where a component in GAN exhibits mixture-modeled forms, such as in TripleGan (Li et al. NIPS'17). So I would not recommend the authors to claim contributions here.

- Writing:
The paper does not seem to be polished. It may not be necessary to exceed 8 pages as many spaces in this paper could be easily squeezed (apparently). The organization could be better; Some parts are vague and difficult to understand;  the writing could be improved to be more clearly demonstrate the contributions of this paper. </span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">4: Ok but not good enough - rejection</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">3: The reviewer is fairly confident that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_rJlhD4gxAm" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Thanks for your review.</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=ryxDUs05KQ&amp;noteId=rJlhD4gxAm"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper185 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">19 Nov 2018</span><span class="item">ICLR 2019 Conference Paper185 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">We revise the manuscript to answer the comments.  


&gt;&gt; “The main problem of this paper is that it does not provide sufficient results on any real applications that can support its problem&amp;model formulations. For example, in which scenarios would the users of the model need to train a GAN to mimic a target distribution p_t which is a difference of another two distributions (with examples available there but unavailable in p_t)? It would be good to show significant results on real applications to show the problem and the method useful.” 
“Two applications on semi-supervised classification and adversarial training are discussed. While both seem to be very artificial IMO if considering the used dataset and designed experiments. The results are also not convincing even for the shown two experiments compared to baselines.”

For responding the suggestions, we add a subsection Sec. 1.1 to emphasize our motivations. Our goal is to generate unseen data, which is absent during training process and is difficult to collect. We show that the proposed DSGAN will have the ability to generate diverse unseen data that is helpful for one-class classification, semi-supervised learning, and adversarial attacks. Those techniques are important and involve many real applications shown in Fig. 8 in the revised manuscript.  


&gt;&gt;”No related works on addressing the similar problems have been discussed nor compared in experiments.”

We also add Sec. 6 in the revised manuscript to discuss related works about generating unseen data. In sum, DSGAN is a simple and effective way for our objective. The results compared with other methods are discussed in Sec. 5.1.2 and 5.2.2 corresponding to the two experiments.


&gt;&gt; “While the authors claim new theoretical results, in fact, I didn't see any contributions here as the theories developed in section 3 are mostly rather straightforward. There have been some similar theories being developed in previous papers where a component in GAN exhibits mixture-modeled forms, such as in TripleGan (Li et al. NIPS'17). So I would not recommend the authors to claim contributions here.”

About the contribution of theoretical proofs (in Sec. 1.2 in the revised manuscript), we remove the sentences “when the optimum of the Jensen-Shannon divergence is attained such that the generator distribution is equal to the target distribution,” which has been covered under [Goodfellow et al. 14]. Instead we show that the proposed DSGAN can learn the distribution which support set is difference of support sets of two distributions shown in Proposition 2. 


&gt;&gt; The paper does not seem to be polished. It may not be necessary to exceed 8 pages as many spaces in this paper could be easily squeezed (apparently). The organization could be better; Some parts are vague and difficult to understand; the writing could be improved to be more clearly demonstrate the contributions of this paper. 

Consequently, in the revised manuscript, we reorganize some sections and rephrase some sentences for better understandings.</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div><div class="note_with_children"><div id="note_BkxL26einQ" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Potentially Interesting Method but the Paper Needs Polishing</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=ryxDUs05KQ&amp;noteId=BkxL26einQ"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper185 AnonReviewer2</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">03 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper185 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">The paper presents a new Generative Adversarial Network (GAN) for learning a  
target distribution that is defined as the difference between two other 
distributions. Applications in semi-supervised learning and adversarial training 
are considered in the experimental evaluation and results are presented in 
computer vision tasks. 

The paper is not very well written and can be hard to follow. One very important 
issue for me was motivation for defining the target distribution as a difference 
between two other distributions. I am not familiar with this area, but reading 
through the introduction it was never clear to me why this is a useful scenario, 
in practice. Furthermore, some statements in the introduction felt quite 
arbitrary. For example, the authors state that PixelCNN "does not have a latent 
representation" in a manner that makes it sound as if that is a bad thing. If 
indeed it is, then why so? It would be very helpful to motivate the setting more 
and to provide a couple of examples of where this method would be useful, in the 
introduction. Also, regarding the MNIST example in the end of page 1, what is 
the "universal set"? This paragraph also felt a bit arbitrary and unclear.

Some comments about the rest of the paper:
  - The theoretical results of section 3 are just stated/listed, but are not 
    connected to algorithm 1. Please connect them to the different parts of the 
    algorithm and state in a couple sentences what they imply for the algorithm.
  - Right after theorem 1, which assumption are you referring to when you say 
    "the assumption in Theorem 1"?
  - The reformulation of section 3.1 is never justified. What led you to use 
    this reformulation and why do you think it is more stable in practice?
  - You should mention in the caption of table 4, what quantity you are 
    computing.

Note that my evaluation for this paper is based mainly on the way it is written 
as, in its current state, it is hard for me to judge what is novel and what is 
useful, and what readers are supposed to take in by reading this paper. The main 
question that the paper definitely needs to answer, but does not do so currently 
(in my opinion) is:

  When is this method useful to readers? For solving which problems and under 
  what conditions? And also, when is this method bad and should not be used?

== Experiments ==

Section 5.1 is hard to follow and I don't quite get how it connects to the rest.

Also, in section 5.1.2 you mention that in comparison to Dai et al. (2017) your 
method does not need to rely on an additional density estimation network. Even 
if that is true, I cannot see how it is a useful remark given that the method of 
Dai et al. seems to always beat your method.

== Style ==

In figure 1, no labels or legends are provided making it hard to figure out 
what's going on at a glance. It would be very helpful to include labels and a 
legend.

Equation 2 is not written correctly. The equals sign only refers to "V(G, D)" 
and not the min-max of that, right? Please make that explicit by first defining 
"V(G, D)" alone.</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">3: Clear rejection</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_SyxWewllA7" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Thanks for your review.</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=ryxDUs05KQ&amp;noteId=SyxWewllA7"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper185 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">19 Nov 2018</span><span class="item">ICLR 2019 Conference Paper185 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">We revise the manuscript to answer the comments.


&gt;&gt; “Some statements in the introduction felt quite arbitrary. For example, the authors state that PixelCNN "does not have a latent representation" in a manner that makes it sound as if that is a bad thing. If indeed it is, then why so? It would be very helpful to motivate the setting more and to provide a couple of examples of where this method would be useful, in the introduction.”
&gt;&gt; “When is this method useful to readers? For solving which problems and under what conditions? And also, when is this method bad and should not be used?”

We rephrase the first paragraph in original paragraph to delete some discussions which may be out-of-scope such as PixelCNN and VAE in this paper. We also add a subsection Sec. 1.1 to emphasize our motivations along with the scenario, where the proposed DSGAN will have the ability to generate diverse unseen data that is helpful for one-class classification, semi-supervised learning, and adversarial attacks. Those techniques are important and involve many real applications shown in Fig. 8 in the revised manuscript. 


&gt;&gt; “The theoretical results of section 3 are just stated/listed, but are not connected to algorithm 1. Please connect them to the different parts of the algorithm and state in a couple sentences what they imply for the algorithm.” 

The theoretical results in Sec. 3 aims to explain why the objective function in Eq. (2) can learn the wanted distribution. But, Algorithm 1 is to explain the training procedure which may be not directly related to theoretical results. 


&gt;&gt;”You should mention in the caption of table 4, what quantity you are computing” 

We replace table 4 (in the original manuscript) with Fig. 7 (in the revised manuscript) for the comprehensive evaluation on both robustness and performance of the models. And the quantity we computed as x-axis (same as the quantity in original table 4) is “epsilon”, which is the l_2 (or l_inf) norm between original image and corresponding adversarial example. The description of epsilon is also added in the caption of Fig. 7.


&gt;&gt; “Section 5.1 is hard to follow and I don't quite get how it connects to the rest.”

We rephrase the descriptions of Sec 5.1 and hope it is more understandable. Briefly saying, Dai et al. (2017) claim that if the generator can satisfy the conditions Eq. (8) and Eq. (9), it can help the semi-supervised learning through the objective function Eq. (5). In our method, if we set the p_{\bar{d}} to the linear combination of labeled and unlabeled data, then the generator can learn the distribution which satisfies both Eq. (8) and Eq. (9). We use this generator to help semi-supervised learning further.


&gt;&gt; “Also, in section 5.1.2 you mention that in comparison to Dai et al. (2017) your method does not need to rely on an additional density estimation network. Even if that is true, I cannot see how it is a useful remark given that the method of Dai et al. seems to always beat your method.”

For comparison with Dai et al. (2017) in Sec. 5.1.2, additional density estimation network may not exist always and be expensive to train (also discussed in Lee et al. (2018)). In the contrast, DSGAN is a simple and effective way for generating complementary data. 
We also claim that the generator might not perfectly learn the distribution we assigned, however, this problem will be attenuated since there are a number of researches on solving this problem.  In Dai et al. (2017), their method relies on feature matching, which aim to match the first-order statistics of the distribution, and it cannot take all the advantages of the progress of GANs. Due to this reason, our method has more benefits in the long term.  The discussion in detail is also in Sec. 5.1.2.


&gt;&gt; “In figure 1, no labels or legends are provided making it hard to figure out what's going on at a glance. It would be very helpful to include labels and a legend.”

We add the legends to those figures and put more illustrations for our idea. Hope those are helpful for understanding our methods.


&gt;&gt;The reformulation of section 3.1 is never justified. What led you to use this reformulation and why do you think it is more stable in practice?

From the view of theory, the reformulation is equivalent to original formula. The original reason is that we can use 2m samples instead of 3m samples for each mini-batch. However, we found that the performance also becomes better. Thus, we conjecture that the equivalence may be based on the linearity of expectation, but mini-batch stochastic gradient descent in practical training may lead to the different outcomes. Due to the limit of space, we move Sec. 3.1 (in the original manuscript) to Appendix C (in the revised manuscript).


&gt;&gt;Right after theorem 1, which assumption are you referring to when you say "the assumption in Theorem 1"?

We rephrase this sentence “the assumption in Theorem 1” as "The assumption, α p_{d}(x) ≤ p_{\bar{d}}(x) for all x’s in Theorem 1".
</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div></div></main></div>
  </div>
</div>


    <!-- Footer -->
    <footer class="sitemap">
      <div class="container">
        <div class="row hidden-xs">
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/venues">All Venues</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="/contact">Contact</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
    
        <div class="row visible-xs-block">
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/contact">Contact</a></li>
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
      </div>
    </footer>
    
    <footer class="sponsor">
      <div class="container">
        <div class="row">
          <div class="col-sm-10 col-sm-offset-1">
            <p class="text-center">
              OpenReview is created by the <a href="http://www.iesl.cs.umass.edu/" target="_blank">Information Extraction and Synthesis Laboratory</a>, College of Information and Computer Science, University of Massachusetts Amherst. We gratefully acknowledge the support of the OpenReview sponsors:  Google,  Facebook, NSF, the University of Massachusetts Amherst Center for Data Science, and Center for Intelligent Information Retrieval, as well as the Google Cloud Platform for donating the computing and networking services on which OpenReview.net runs.
            </p>
          </div>
        </div>
      </div>
    </footer>

  <div id="feedback-modal" class="modal fade" tabindex="-1" role="dialog">
    <div class="modal-dialog">
      <div class="modal-content">
        <div class="modal-header">
          <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button>
          <h3 class="modal-title">Send Feedback</h3>
        </div>
        <div class="modal-body">
          <p>Enter your feedback below and we'll get back to you as soon as possible.</p>
          <form action="/feedback" method="POST">
            <div class="form-group">
              <input type="email" name="from" class="form-control" placeholder="Email" />
            </div>
            <div class="form-group">
              <input type="text" name="subject" class="form-control" placeholder="Subject" />
            </div>
            <div class="form-group">
              <textarea name="message" class="form-control feedback-input" rows="5" placeholder="Message" required=""></textarea>
            </div>
          <ul id="ui-id-2" tabindex="0" class="ui-menu ui-widget ui-widget-content" style="display: none;"></ul></form>
        </div>
        <div class="modal-footer">
          <button type="button" class="btn btn-default" data-dismiss="modal">Cancel</button>
          <button type="button" class="btn btn-primary">Send</button>
        </div>
      </div>
    </div>
  </div>

  <script type="text/javascript" async="" src="https://www.google-analytics.com/analytics.js"></script><script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js"></script>
  <script>window.jQuery || document.write('&lt;script src="/static/js/vendor/jquery-2.2.4.min.js"&gt;&lt;\/script&gt;')</script>

  <script src="/static/dist/vendor.min.js"></script>
  <script src="/static/dist/templates.min.js"></script>
  <script src="/static/dist/openreview.min.js"></script>

    <script>window.legacyScripts = true;</script>


    <script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-108703919-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() { dataLayer.push(arguments); }
      gtag('js', new Date());
      gtag('config', 'UA-108703919-1');
    </script>


<div role="status" aria-live="assertive" aria-relevant="additions" class="ui-helper-hidden-accessible"></div></body></html>
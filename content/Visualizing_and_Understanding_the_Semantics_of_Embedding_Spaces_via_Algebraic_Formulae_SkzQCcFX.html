<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" class="no-js"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>Visualizing and Understanding the Semantics of Embedding Spaces via Algebraic Formulae | OpenReview</title>
  <meta name="description" content="" />

      <meta name="citation_title" content="Visualizing and Understanding the Semantics of Embedding Spaces via Algebraic Formulae" />
        <meta name="citation_author" content="Anonymous" />
      <meta name="citation_publication_date" content="2018/09/27" />
      <meta name="citation_online_date" content="2018/09/27" />
      <meta name="citation_pdf_url" content="https://openreview.net/pdf?id=Skz3Q2CcFX" />
      <meta name="twitter:card" content="summary" />
      <meta name="twitter:site" content="@openreviewnet" />
      <meta name="og:title" content="Visualizing and Understanding the Semantics of Embedding Spaces via..." />
      <meta name="og:description" content="Embeddings are a fundamental component of many modern machine learning and natural language processing models.&#10;  Understanding them and visualizing them is essential for gathering insights about the..." />
      <meta name="og:image" content="https://openreview.net/static/images/openreview_logo_512.png" />

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans:400,400i,700,700i" />

  <link rel="stylesheet" href="/static/css/bootstrap.min.css" />
  <link rel="stylesheet" href="/static/css/jquery-ui.min.css" />
  <link rel="stylesheet" href="/static/css/main.min.css" />
</head>

<body class="forum">
  <nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
  
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand home push-link" href="/"><strong>OpenReview</strong>.net</a>
      </div>
  
      <div id="navbar" class="navbar-collapse collapse">
        <form class="navbar-form navbar-left profile-search" role="search">
          <div class="form-group has-feedback">
            <input id="search_input" type="text" class="form-control ui-autocomplete-input" placeholder="Search ICLR 2019 Conference" autocomplete="off" />
            <span class="glyphicon glyphicon-search form-control-feedback" aria-hidden="true"></span>
          </div>
  
          <input id="search_group" type="hidden" value="ICLR.cc/2019/Conference" />
          <input id="search_content" type="hidden" value="all" />
        <ul id="ui-id-1" tabindex="0" class="ui-menu ui-widget ui-widget-content ui-autocomplete ui-front" style="display: none;"></ul></form>
  
        <ul class="nav navbar-nav navbar-right">
        
            <li id="user-menu"><a href="/login">Login</a></li>
        </ul>
      </div>
  
    </div>
  </nav>

  <div id="or-banner" class="banner" style="">
  <div class="container">
    <div class="row">
      <div class="col-xs-12"><a href="/group?id=ICLR.cc/2019/Conference" title="Venue Homepage"><img class="icon" src="/static/images/arrow_left.svg" /> Go to <strong>ICLR 2019 Conference</strong> homepage</a></div>
    </div>
  </div>
</div>
<div id="flash-message-container" class="alert alert-danger" role="alert" style="display: none;">
  <div class="container">
    <div class="row">
      <div class="col-xs-12">
        <div class="alert-content">
          <button type="button" class="close" aria-label="Close"><span aria-hidden="true">×</span></button>
        </div>
      </div>
    </div>
  </div>
</div>

<div class="container">
  <div class="row">
    <div class="col-xs-12">
      <main id="content" class="clearfix openbanner-visible legacy-styles"><div id="note_Skz3Q2CcFX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Visualizing and Understanding the Semantics of Embedding Spaces via Algebraic Formulae</a> <a class="note_content_pdf" href="/pdf?id=Skz3Q2CcFX" title="Download PDF" target="_blank"><img src="/static/images/pdf_icon_blue.svg" /></a> </h2></div><div class="meta_row"><span class="signatures">Anonymous</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">28 Sep 2018 (modified: 13 Nov 2018)</span><span class="item">ICLR 2019 Conference Blind Submission</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span><span class="item"><a class="action-bibtex-modal" data-bibtex="@inproceedings{    &#10;anonymous2019visualizing,    &#10;title={Visualizing and Understanding the Semantics of Embedding Spaces via Algebraic Formulae},    &#10;author={Anonymous},    &#10;booktitle={Submitted to International Conference on Learning Representations},    &#10;year={2019},    &#10;url={https://openreview.net/forum?id=Skz3Q2CcFX},    &#10;note={under review}    &#10;}">Show Bibtex</a></span><a class="note_content_pdf item" href="/revisions?id=Skz3Q2CcFX" target="_blank">Show Revisions</a></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Abstract: </span><span class="note_content_value">Embeddings are a fundamental component of many modern machine learning and natural language processing models.
Understanding them and visualizing them is essential for gathering insights about the information they capture and the behavior of the models.
State of the art in analyzing embeddings consists in projecting them in two-dimensional planes without any interpretable semantics associated to the axes of the projection, which makes detailed analyses and comparison among multiple sets of embeddings challenging.
In this work, we propose to use explicit axes defined as algebraic formulae over embeddings to project them into a lower dimensional, but semantically meaningful subspace, as a simple yet effective analysis and visualization methodology.
This methodology assigns an interpretable semantics to the measures of variability and the axes of visualizations, allowing for both comparisons among different sets of embeddings and fine-grained inspection of the embedding spaces.
We demonstrate the power of the proposed methodology through a series of case studies that make use of visualizations constructed around the underlying methodology and through a user study. The results show how the methodology is effective at providing more profound insights than classical projection methods and how it is widely applicable to many other use cases.</span></div><div class="note_contents"><span class="note_content_field">Keywords: </span><span class="note_content_value">visualization, embeddings, representations, t-sne, natural, language, processing, machine, learning, algebra</span></div><div class="note_contents"><span class="note_content_field">TL;DR: </span><span class="note_content_value">We propose to use explicit vector algebraic formulae projection as an alternative way to visualize embedding spaces specifically tailored for goal-oriented analysis tasks and it outperforms t-SNE in our user study.</span></div><div class="reply_row clearfix"><div class="item" id="reply_count">7 Replies</div></div></div><hr class="small" /><div id="note_children"><div class="note_with_children"><div id="note_rJgQde81pQ" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>ideas seems a common practice in various prior visualization tasks</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=Skz3Q2CcFX&amp;noteId=rJgQde81pQ"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1395 AnonReviewer3</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">07 Nov 2018</span><span class="item">ICLR 2019 Conference Paper1395 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">Paper presented a new and simple method to visualize the embedding space geometry rather than standard t-SNE or PCA. The key is to carefully select items to be visualized/embed and interpretable dimensions. A few case study and user study were conducted to show the benefit of the proposed approach. 

- on algebraic formulae (AF): it would be good to clarify the def of AF explicitly. Rules/extention/axes are not very clear and mathematically consistent in section 3. Would projection idea be applied to arbitrary AFs?

- while the idea being simple, I am not quite confident about the novelty. For example for the de-bias application, Bolukbasi et al. had already did the same plot along the he-she axis. Similar plots on the polysemous word embedding can be found in Arora et al., 2017, etc. 

- The user study with n=10 are typically less reliable for any p-value evaluation. 

</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">4: Ok but not good enough - rejection</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_Hyl7dLiDaX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>No previous visualization actually used this simple idea</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=Skz3Q2CcFX&amp;noteId=Hyl7dLiDaX"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1395 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">13 Nov 2018</span><span class="item">ICLR 2019 Conference Paper1395 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Thank you for your comments and please see the inlined answers regarding your concerns.

&gt;&gt;&gt; - on algebraic formulae (AF): it would be good to clarify the def of AF explicitly. Rules/extention/axes are not very clear and mathematically consistent in section 3. Would projection idea be applied to arbitrary AFs?

Yes, we allow users to create AFs by compositing vector math operators (e.g., add, sub, mul) to be applied on vectors (referenced by their label in the data, i.e. the vector(apple) is obtained by using the keyword “apple” in the formula). For instance, “(he + him) /2”, resolves he and him with their respective vectors, sums them and then divides the resulting vector by two. We added the following sentence to the manuscrip in the methodology sectiont:
Algebraic formulae are a composition vector math operators (e.g., add, sub, mul) to be applied on vectors (referenced by their label in the data, i.e. the vector of ``apple'' is obtained by using using the keyword ``apple'' in the formula)..

&gt;&gt;&gt; - while the idea being simple, I am not quite confident about the novelty. For example for the de-bias application, Bolukbasi et al. had already did the same plot along the he-she axis. Similar plots on the polysemous word embedding can be found in Arora et al., 2017, etc. 

We acknowledge that those works are relevant, but argue that the information provided in their plots and the nature of their plots is different from our proposal. 

In Bolukbasi et al., the x-axis is the difference between he and she, while the y-axis is a learned direction encoding neutrality (through SVD). As such, only one of the axes is explicitly defined by an algebraic formula. The example in Bolukbasi et al. indeed is a subset the methodology that we are proposing, which is more generic and can be applied widely.

Regarding Arora et al. the task may be similar, but the plots are obtained through isometric mapping rather than explicitly-defined semantically-meaningful subspaces. That is, axes in their plots are not interpretable, which makes their approach more closer to PCA or t-SNE projections and has little in common with our proposal.

&gt;&gt;&gt; - The user study with n=10 are typically less reliable for any p-value evaluation.

While we agree more test subjects usually lead to (perceptually) better statistical confidences, the ANOVA and t-test results in our study already suggested significant difference (p values being magnitudes smaller than 0.01, as described in the result analysis section). 
</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div><div class="note_with_children"><div id="note_S1g6_qV937" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>review</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=Skz3Q2CcFX&amp;noteId=S1g6_qV937"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1395 AnonReviewer2</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">03 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper1395 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">The idea of analyzing embedding spaces in a non-parametric (example-based) way is well-motivated. However, the main technical contribution of this paper is otherwise not clear - the methodology section covers a very broad set of techniques but doesn't provide a clear picture of what is novel; furthermore, it makes a strong assumption about linear structure in the embedding space that may not hold. (It's worth noting that t-SNE does not make this assumption.)

The visualization strategies presented don't appear to be particularly novel. In particular, projection onto a linear subspace defined by particular attributes was done in the original word2vec and GloVe papers for the analogy task. There's also a lot of other literature on interpreting deeper models using locally-linear predictors, see for example LIME (Ribeiro et al. 2016) or TCAV (Kim at el. 2018).

Evaluations are exclusively qualitative, which is disappointing because there are quantitative ways of evaluating a projection - for example, how well do the reduced dimensions predict a particular attribute relative to the entire vector. Five-axis polar plots can pack in more information than a 2-dimensional plot in some ways, but quickly become cluttered. The authors might consider using heatmaps or bar plots, as are commonly used elsewhere in the literature (e.g. for visualizing activation maps or attention vectors).

User study is hard to evaluate. What were the specific formulae used in the comparison? Did subjects just see a list of nearest-neighbors, or did they see the 2D projection? If the latter, I'd imagine it would be easy to tell which was the t-SNE plot, since most researchers are familiar with how these look.</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">3: Clear rejection</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">3: The reviewer is fairly confident that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_B1lGiFoDaQ" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>rebuttal part 1</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=Skz3Q2CcFX&amp;noteId=B1lGiFoDaQ"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1395 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">13 Nov 2018</span><span class="item">ICLR 2019 Conference Paper1395 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Thank you for your comments and please see the inlined answers regarding your concerns.

&gt;&gt;&gt; However, the main technical contribution of this paper is otherwise not clear - the methodology section covers a very broad set of techniques but doesn't provide a clear picture of what is novel;

We axplcitly outlined the contribution in the revised manuscript.
What we described in the methodology is how to map an analysis task in terms of the items to visualize and the dimensions to visualize them on (again, defined as explicit formulae). To the best of our knowledge, there was no precedent work and ours is entirely novel.

&gt;&gt;&gt; furthermore, it makes a strong assumption about linear structure in the embedding space that may not hold. (It's worth noting that t-SNE does not make this assumption.)

The proposed methodology doesn't make any assumption on the structure of the embedding space itself, regardless of whether it is linear or not. What we proposed is to slice the space with a hyperplane that is semantically meaningful with respect to the analysis goal of the user. The slicing can is linear (high-dimensional manifold in case of polar view) but we don’t make assumptions embedding space.

&gt;&gt;&gt; The visualization strategies presented don't appear to be particularly novel. In particular, projection onto a linear subspace defined by particular attributes was done in the original word2vec and GloVe papers for the analogy task.

We find it difficult to relate with this comment and would like to ask the reviewer to kindly provide more details on specific papers and figures.

In the original word2vec paper (Distributed Representations of Words and Phrases and their Compositionality) there is one 2d PCA projection, while in the original GloVe paper (GloVe: Global Vectors for Word Representation) there is no visualization or projection. If the reviewer were referring to the examples on the GloVe website (<a href="https://nlp.stanford.edu/projects/glove/)" target="_blank" rel="nofollow">https://nlp.stanford.edu/projects/glove/)</a> those are again 2d PCA projections with no interpretable semantics along the axes. Or, if Figure 2 in Linguistic Regularities in Continuous Space Word Representations was referenced, that is a cartoon image.

&gt;&gt;&gt; There's also a lot of other literature on interpreting deeper models using locally-linear predictors, see for example LIME (Ribeiro et al. 2016) or TCAV (Kim at el. 2018).

We are aware of this line of work using local descriptors for interpreting deep models, but find it less relevant to the analysis and visualization of embeddings. It would be helpful if the reviewer could help clarify the concerns as local interpretability is an approach applicable to various problem domains, but we don’t see how it is related to to our proposal as we are not learning any predictor.</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_ryeGFtiDT7" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>rebuttal part 2</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=Skz3Q2CcFX&amp;noteId=ryeGFtiDT7"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1395 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">13 Nov 2018</span><span class="item">ICLR 2019 Conference Paper1395 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">&gt;&gt;&gt; Evaluations are exclusively qualitative, which is disappointing because there are quantitative ways of evaluating a projection - for example, how well do the reduced dimensions predict a particular attribute relative to the entire vector.

Yes, there are quantitative measures for comparing different algorithmic ways to perform dimensionality reduction. However, what we proposed is not an algorithm to perform dimensionality reduction, but a methodology to support users to encode intentions (concepts she cares about) explicitly to the axes of the projection. Such intention is different case by case in analytical tasks. The attributes the user cares about are explicitly encoded in the algebraic formulae she decides to use, so using the reduced dimensions to predict the attributes is meaningless.

We made it mode clear in the first paragraph of the evaluation section that we are not trying to find an optimal dimensionality reduction technique, but comapring an approach to keep users in the loop:
“The goal is to find out if and how visualizations using user-defined semantically meaningful algebraic formulae as their axes help users achieve their analysis goals.
What we are not testing for is the quality of projection itself, as in PCA AND t-SNE the projection axes are obtained algorithmically, while in our case they are explicitly defined by the user.”

&gt;&gt;&gt; Five-axis polar plots can pack in more information than a 2-dimensional plot in some ways, but quickly become cluttered. The authors might consider using heatmaps or bar plots, as are commonly used elsewhere in the literature (e.g. for visualizing activation maps or attention vectors).

We explicitly explained in the 3rd paragraph that the polar view is to be preferred in the case where the analysis goal needs more than 2 dimensions of variability, but where the number of items is limited for the reason that several items would make the visualization cluttered. The problem with bar plots and heatmaps is that themselves they don't scale either to a big number of axes of elements and they rely on hue (in the case of heatmaps) and difference in size (in the case of barplots) to provide the information, while the polar view relies on several visual variables at the same time (position, dimension, hue, shape) for the same task, making it a better choice.

&gt;&gt;&gt; User study is hard to evaluate. What were the specific formulae used in the comparison? Did subjects just see a list of nearest-neighbors, or did they see the 2D projection? If the latter, I'd imagine it would be easy to tell which was the t-SNE plot, since most researchers are familiar with how these look.

The tasks and the formulae we used were [banana &amp; strawberry, google &amp; microsoft, nerd &amp; geek, book &amp; magazine, 110392 &amp; 95212, 387862 &amp; 42956, 278209 &amp; 230444, 162363 &amp; 307542], the numbers are the same terms but obfuscated, as described in the manuscript. We added them in the description of the experiment.

As we are evaluating visualizations, the users are shown visualizations of the 2d projections as described in the second paragraph of the user study section.
They are told which visualizations are t-SNE and which use explicit axes as they are required to express a preference at the end (which is reported). Knowing which plot they were looking at was also needed in order to provide an interpretation to the axes (in the t-SNE they are meaningless, without labels, in the explicit case the axes report the formula used to obtain them in order to be interpretable).
Can you elaborate on why do you believe this is a problem?</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div><div class="note_with_children"><div id="note_rJxIh6zc3Q" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>interesting but not clear how useful</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=Skz3Q2CcFX&amp;noteId=rJxIh6zc3Q"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1395 AnonReviewer1</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">03 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper1395 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">To the best of my understanding the paper proposes some methodological ideas for visualizing and analyzing representations. 
The paper is unclear mainly because it is a bit difficult to pinpoint the contribution and its audience. What would help me better understand and potentially raise my rating is an analysis of a classical model on a known dataset as a case study and some interesting findings would help make it more exciting and give the readers more incentives to try this out. Like train an AlexNet and VGG imagenet model and show that the embeddings are better aligned with the wordnet taxonomy in one of the other. This should be possible with their approach if i understand it correctly. 

pros:
- visualization and analysis is a very exciting and important topic in machine learning
- this is clearly useful if it worked
cons:
- not sure what the contribution claim for the paper is since these types of plots existed already in the literature (is it a popularization claim ?)</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">4: Ok but not good enough - rejection</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">3: The reviewer is fairly confident that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_S1eFYDjDaQ" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>rebuttal</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=Skz3Q2CcFX&amp;noteId=S1eFYDjDaQ"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1395 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">13 Nov 2018</span><span class="item">ICLR 2019 Conference Paper1395 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Thank you for your comments and please see the inlined answers regarding your concerns.

&gt;&gt;&gt; To the best of my understanding the paper proposes some methodological ideas for visualizing and analyzing representations. The paper is unclear mainly because it is a bit difficult to pinpoint the contribution and its audience. What would help me better understand and potentially raise my rating is an analysis of a classical model on a known dataset as a case study and some interesting findings would help make it more exciting and give the readers more incentives to try this out. Like train an AlexNet and VGG imagenet model and show that the embeddings are better aligned with the wordnet taxonomy in one of the other. This should be possible with their approach if i understand it correctly.

We did perform an analysis of a classical model (GloVe) on a known dataset (Gigaword) and reported several case studies in the Case Studies section reporting interesting findings:
the presence of gender bias in different datasets and how it changes over the different datasets, 
the characterization of fine-grained differences between extremely close vectors, showing how the embeddings encode polysemy by showing a plane on which multiple senses of words are separable. 
It seems to us we already did what the reviewer was asking us to do, but just on a purely linguistic dataset.

Also, our work is not related with wordnet taxonomies. It would be appreciated if the reviewer could kindly point us to how we should proceed in aligning the embeddings and the wordnet taxonomies, as it is not clear to us and seems unrelated to our work.

&gt;&gt;&gt; pros:
	- visualization and analysis is a very exciting and important topic in machine learning
	- this is clearly useful if it worked

The combination of case studies and user study that we reported in the paper suggest that it actually works.

&gt;&gt;&gt; cons:
        - not sure what the contribution claim for the paper is since these types of plots existed already in the literature (is it a popularization claim ?)

We find it hard to derive actionable items from this comment. We ask the reviewer to kindly provide references where plots using explicit formulae as axes are used. To the best of our knowledge, we are the first to propose such a methodology.
</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div></div></main></div>
  </div>
</div>


    <!-- Footer -->
    <footer class="sitemap">
      <div class="container">
        <div class="row hidden-xs">
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/venues">All Venues</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="/contact">Contact</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
    
        <div class="row visible-xs-block">
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/contact">Contact</a></li>
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
      </div>
    </footer>
    
    <footer class="sponsor">
      <div class="container">
        <div class="row">
          <div class="col-sm-10 col-sm-offset-1">
            <p class="text-center">
              OpenReview is created by the <a href="http://www.iesl.cs.umass.edu/" target="_blank">Information Extraction and Synthesis Laboratory</a>, College of Information and Computer Science, University of Massachusetts Amherst. We gratefully acknowledge the support of the OpenReview sponsors:  Google,  Facebook, NSF, the University of Massachusetts Amherst Center for Data Science, and Center for Intelligent Information Retrieval, as well as the Google Cloud Platform for donating the computing and networking services on which OpenReview.net runs.
            </p>
          </div>
        </div>
      </div>
    </footer>

  <div id="feedback-modal" class="modal fade" tabindex="-1" role="dialog">
    <div class="modal-dialog">
      <div class="modal-content">
        <div class="modal-header">
          <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button>
          <h3 class="modal-title">Send Feedback</h3>
        </div>
        <div class="modal-body">
          <p>Enter your feedback below and we'll get back to you as soon as possible.</p>
          <form action="/feedback" method="POST">
            <div class="form-group">
              <input type="email" name="from" class="form-control" placeholder="Email" />
            </div>
            <div class="form-group">
              <input type="text" name="subject" class="form-control" placeholder="Subject" />
            </div>
            <div class="form-group">
              <textarea name="message" class="form-control feedback-input" rows="5" placeholder="Message" required=""></textarea>
            </div>
          <ul id="ui-id-2" tabindex="0" class="ui-menu ui-widget ui-widget-content" style="display: none;"></ul></form>
        </div>
        <div class="modal-footer">
          <button type="button" class="btn btn-default" data-dismiss="modal">Cancel</button>
          <button type="button" class="btn btn-primary">Send</button>
        </div>
      </div>
    </div>
  </div>

  <script type="text/javascript" async="" src="https://www.google-analytics.com/analytics.js"></script><script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js"></script>
  <script>window.jQuery || document.write('&lt;script src="/static/js/vendor/jquery-2.2.4.min.js"&gt;&lt;\/script&gt;')</script>

  <script src="/static/dist/vendor.min.js"></script>
  <script src="/static/dist/templates.min.js"></script>
  <script src="/static/dist/openreview.min.js"></script>

    <script>window.legacyScripts = true;</script>


    <script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-108703919-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() { dataLayer.push(arguments); }
      gtag('js', new Date());
      gtag('config', 'UA-108703919-1');
    </script>


<div role="status" aria-live="assertive" aria-relevant="additions" class="ui-helper-hidden-accessible"></div></body></html>
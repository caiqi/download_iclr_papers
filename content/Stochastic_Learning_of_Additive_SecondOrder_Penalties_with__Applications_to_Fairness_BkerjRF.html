<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" class="no-js"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>Stochastic Learning of Additive Second-Order Penalties with  Applications to Fairness | OpenReview</title>
  <meta name="description" content="" />

      <meta name="citation_title" content="Stochastic Learning of Additive Second-Order Penalties with  Applications to Fairness" />
        <meta name="citation_author" content="Anonymous" />
      <meta name="citation_publication_date" content="2018/09/27" />
      <meta name="citation_online_date" content="2018/09/27" />
      <meta name="citation_pdf_url" content="https://openreview.net/pdf?id=Bke0rjR5F7" />
      <meta name="twitter:card" content="summary" />
      <meta name="twitter:site" content="@openreviewnet" />
      <meta name="og:title" content="Stochastic Learning of Additive Second-Order Penalties with..." />
      <meta name="og:description" content="Many notions of fairness may be expressed as linear constraints, and the resulting constrained objective is often optimized by transforming the problem into its Lagrangian dual with additive linear..." />
      <meta name="og:image" content="https://openreview.net/static/images/openreview_logo_512.png" />

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans:400,400i,700,700i" />

  <link rel="stylesheet" href="/static/css/bootstrap.min.css" />
  <link rel="stylesheet" href="/static/css/jquery-ui.min.css" />
  <link rel="stylesheet" href="/static/css/main.min.css" />
</head>

<body class="forum">
  <nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
  
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand home push-link" href="/"><strong>OpenReview</strong>.net</a>
      </div>
  
      <div id="navbar" class="navbar-collapse collapse">
        <form class="navbar-form navbar-left profile-search" role="search">
          <div class="form-group has-feedback">
            <input id="search_input" type="text" class="form-control ui-autocomplete-input" placeholder="Search ICLR 2019 Conference" autocomplete="off" />
            <span class="glyphicon glyphicon-search form-control-feedback" aria-hidden="true"></span>
          </div>
  
          <input id="search_group" type="hidden" value="ICLR.cc/2019/Conference" />
          <input id="search_content" type="hidden" value="all" />
        <ul id="ui-id-1" tabindex="0" class="ui-menu ui-widget ui-widget-content ui-autocomplete ui-front" style="display: none;"></ul></form>
  
        <ul class="nav navbar-nav navbar-right">
        
            <li id="user-menu"><a href="/login">Login</a></li>
        </ul>
      </div>
  
    </div>
  </nav>

  <div id="or-banner" class="banner" style="">
  <div class="container">
    <div class="row">
      <div class="col-xs-12"><a href="/group?id=ICLR.cc/2019/Conference" title="Venue Homepage"><img class="icon" src="/static/images/arrow_left.svg" /> Go to <strong>ICLR 2019 Conference</strong> homepage</a></div>
    </div>
  </div>
</div>
<div id="flash-message-container" class="alert alert-danger" role="alert" style="display: none;">
  <div class="container">
    <div class="row">
      <div class="col-xs-12">
        <div class="alert-content">
          <button type="button" class="close" aria-label="Close"><span aria-hidden="true">×</span></button>
        </div>
      </div>
    </div>
  </div>
</div>

<div class="container">
  <div class="row">
    <div class="col-xs-12">
      <main id="content" class="clearfix openbanner-visible legacy-styles"><div id="note_Bke0rjR5F7" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Stochastic Learning of Additive Second-Order Penalties with  Applications to Fairness</a> <a class="note_content_pdf" href="/pdf?id=Bke0rjR5F7" title="Download PDF" target="_blank"><img src="/static/images/pdf_icon_blue.svg" /></a> </h2></div><div class="meta_row"><span class="signatures">Anonymous</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">28 Sep 2018 (modified: 11 Oct 2018)</span><span class="item">ICLR 2019 Conference Blind Submission</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span><span class="item"><a class="action-bibtex-modal" data-bibtex="@inproceedings{    &#10;anonymous2019stochastic,    &#10;title={Stochastic Learning of Additive Second-Order Penalties with  Applications to Fairness},    &#10;author={Anonymous},    &#10;booktitle={Submitted to International Conference on Learning Representations},    &#10;year={2019},    &#10;url={https://openreview.net/forum?id=Bke0rjR5F7},    &#10;note={under review}    &#10;}">Show Bibtex</a></span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Abstract: </span><span class="note_content_value">Many notions of fairness may be expressed as linear constraints, and the resulting constrained objective is often optimized by transforming the problem into its Lagrangian dual with additive linear penalties. In non-convex settings, the resulting problem may be difficult to solve as the Lagrangian is not guaranteed to have a deterministic saddle-point equilibrium.  In this paper, we propose to modify the linear penalties to second-order ones, and we argue that this results in a more practical training procedure in non-convex, large-data settings. For one, the use of second-order penalties allows training the penalized objective with a fixed value of the penalty coefficient, thus avoiding the instability and potential lack of convergence associated with two-player min-max games. Secondly, we derive a method for efficiently computing the gradients associated with the second-order penalties in stochastic mini-batch settings. Our resulting algorithm performs well empirically, learning an appropriately fair classifier on a number of standard benchmarks.</span></div><div class="note_contents"><span class="note_content_field">Keywords: </span><span class="note_content_value">fairness</span></div><div class="note_contents"><span class="note_content_field">TL;DR: </span><span class="note_content_value">We propose a method to stochastically optimize second-order penalties and show how this may apply to training fairness-aware classifiers.</span></div><div class="reply_row clearfix"><div class="item" id="reply_count">3 Replies</div></div></div><hr class="small" /><div id="note_children"><div class="note_with_children"><div id="note_rJg_LYQk6Q" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Motivation and contribution are not very clear</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=Bke0rjR5F7&amp;noteId=rJg_LYQk6Q"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper131 AnonReviewer1</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">06 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper131 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">In this paper, the authors propose a method to generate predictions under fairness constraints by optimizing quadratic penalties over non-convex loss functions. The main idea is to replace the linear fairness constraints by the second-order penalty. Meanwhile, an efficient method is derived to compute the gradients associated with the second-order penalties in stochastic mini-batch settings. Finally, the experimental results show the effectiveness of their proposed method empirically. 

(1) The authors argued that their experimental results in a more practical training procedure in non-convex, large-data settings. However, in Section 6, the sample size of the data-sets they used are small and the loss functions of learning models are convex. I think they need to provide more experimental results to make their proposed method more convincing. 

(2) It is a little difficult to follow the motivation and contributions of this paper. I would recommend the authors to improve the presentation by providing more context for the use of double integral or sampling method and other mostly relevant works in this area. 

(3) From the optimization viewpoint, the second-order penalty in Eq. (3) is convex with respect to d. Why replacing the linear penalties with quadratic penalties to solve the shortcomings of using linear penalties or Lagrange multipliers. Isn't the square of an expectation always an expectation of pairs? In other word, Eq. (4) is always equivalient to Eq. (7) without additional conditions?

</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">5: Marginally below acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">3: The reviewer is fairly confident that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_HJgihpDanm" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Experiments and motivation can be improved</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=Bke0rjR5F7&amp;noteId=HJgihpDanm"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper131 AnonReviewer2</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">05 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper131 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">In this paper, the authors propose a method for optimizing quadratic penalties over non-convex loss functions. The authors motivate their approach by showing the complexity of training non-convex models with linear constraints and proposing a simpler method to introduce these constraints as regularization terms. Finally, they show how their proposed method compares to alternative solutions on a series of benchmarks.

Use of double sampling method for estimating the loss and second order penalty appears to be novel, however, there is no discussion of the implications of using this method to train non-convex models --- one would suspect that use of double sampling may make the gradient descent susceptible to high variance. Simulation results in the paper only demonstrate how the use of the loss changes the solution but there is no discussion or experiments on complexity of training models that use this approach. This is particularly important because authors are claiming their method does not suffer from complexity issues which other methods suffer, but this claim is not supported by any evidence. For example, how many iterations were necessary to train the model? How sensitive is the training to initial conditions and changes in hyper parameters?

Authors motivate their method by pointing out the limitations of using fairness constraints in non-convex models, however, they don’t provide-sufficient evidence for why non-convex models are actually useful in their experiments --- the datasets they used are small and models that are actually convex may perform just as good or nearly as good as highly non-linear, non-convex models which authors are trying to use.

Overall, I would recommend the authors to improve the presentation by providing more context for the use of double sampling method and other relevant works in this area (at least showing the impact of using double sampling on training). Moreover, given the datasets and scope of questions related to fairness they need to provide better experiments that motivate the use of their method (compared to simpler methods) or consider other problems where their approach could be more useful. Given these considerations I believe this paper does not meet the standards for publication.</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">5: Marginally below acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_HJe0uZ753X" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Unclear contribution</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=Bke0rjR5F7&amp;noteId=HJe0uZ753X"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper131 AnonReviewer3</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">03 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper131 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">The authors propose a method to generate predictions under fairness constraints. The main idea is to take linear fairness constraints, and replace them with weak squared penalties plugged into the objectives, which supposed to help in cases where the loss function is not convex. The penalty coefficients are chosen by cross-validation, and the effectiveness of this approach is demonstrated empirically.

In Sec. 3.1, the authors point out several shortcomings of using linear penalties (using Lagrange multipliers) for non-convex losses. These seem valid. Sec. 3.2, however, is not clear on why exactly replacing the linear penalties with quadratic penalties solves these issues. I'm hoping the authors can clarify the following points:

1) The authors note that, for quadratic penalties, \lambda-&gt;0 means no constraints, and \lambda-&gt;\infty means hard constraints. Isn't this also true for linear constraints?

2a) Why do linear penalties have unique \lambda_k for each constraint k, but the quadratic objective has only a single \lambda for all constraints?

2b) Why can CV over \lambda be used for quadratic constraints - what is the justification? And, more importantly, why *can't* it be used with linear constraints? If it can, then this should be one of the baselines compared to in the experiments.

3) What is the criterion optimized for by CV - accuracy or the constraints? Different parts of the paper give different answers to this question. For example, "... may be easily determined via standard hyperparameter optimization methods" vs. "tuning \lambda to directly satisfy the desired fairness metrics". Or even more unclear - "choose \lambda ... so that the final solution gives the desired fairness-accuracy trade-off". How is the desired trade-off defined?

4) If there is a trade-off between fairness and accuracy, and no clear-cut criterion for evaluation is pre-defined, then the evaluation procedure should compare methods across this trade-off (similarly to precision-recall analysis).

5) The authors differentiate between cases where the loss is either convex or non-convex. This is confusing - most losses are convex, and non-linearity appears when they are composed with non-linear predictors. Is this the case here? If so, the fairness constraints are no longer linear, and they're quadratic counterpart is no longer quadratic. It would be helpful if the authors specify where the non-linearity comes from, and what they assume about the loss and predictors.

6) Why is it important to show that the quadratic constraints can be written as an expectation? Isn't the square of an expectation always an expectation of pairs? How does the double summation/integral effect runtime?

7) It would be helpful if the authors differentiate between loss/constraints over the entire distribution vs. over a given sample set.


</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">4: Ok but not good enough - rejection</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">3: The reviewer is fairly confident that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></main></div>
  </div>
</div>


    <!-- Footer -->
    <footer class="sitemap">
      <div class="container">
        <div class="row hidden-xs">
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/venues">All Venues</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="/contact">Contact</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
    
        <div class="row visible-xs-block">
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/contact">Contact</a></li>
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
      </div>
    </footer>
    
    <footer class="sponsor">
      <div class="container">
        <div class="row">
          <div class="col-sm-10 col-sm-offset-1">
            <p class="text-center">
              OpenReview is created by the <a href="http://www.iesl.cs.umass.edu/" target="_blank">Information Extraction and Synthesis Laboratory</a>, College of Information and Computer Science, University of Massachusetts Amherst. We gratefully acknowledge the support of the OpenReview sponsors:  Google,  Facebook, NSF, the University of Massachusetts Amherst Center for Data Science, and Center for Intelligent Information Retrieval, as well as the Google Cloud Platform for donating the computing and networking services on which OpenReview.net runs.
            </p>
          </div>
        </div>
      </div>
    </footer>

  <div id="feedback-modal" class="modal fade" tabindex="-1" role="dialog">
    <div class="modal-dialog">
      <div class="modal-content">
        <div class="modal-header">
          <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button>
          <h3 class="modal-title">Send Feedback</h3>
        </div>
        <div class="modal-body">
          <p>Enter your feedback below and we'll get back to you as soon as possible.</p>
          <form action="/feedback" method="POST">
            <div class="form-group">
              <input type="email" name="from" class="form-control" placeholder="Email" />
            </div>
            <div class="form-group">
              <input type="text" name="subject" class="form-control" placeholder="Subject" />
            </div>
            <div class="form-group">
              <textarea name="message" class="form-control feedback-input" rows="5" placeholder="Message" required=""></textarea>
            </div>
          <ul id="ui-id-2" tabindex="0" class="ui-menu ui-widget ui-widget-content" style="display: none;"></ul></form>
        </div>
        <div class="modal-footer">
          <button type="button" class="btn btn-default" data-dismiss="modal">Cancel</button>
          <button type="button" class="btn btn-primary">Send</button>
        </div>
      </div>
    </div>
  </div>

  <script type="text/javascript" async="" src="https://www.google-analytics.com/analytics.js"></script><script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js"></script>
  <script>window.jQuery || document.write('&lt;script src="/static/js/vendor/jquery-2.2.4.min.js"&gt;&lt;\/script&gt;')</script>

  <script src="/static/dist/vendor.min.js"></script>
  <script src="/static/dist/templates.min.js"></script>
  <script src="/static/dist/openreview.min.js"></script>

    <script>window.legacyScripts = true;</script>


    <script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-108703919-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() { dataLayer.push(arguments); }
      gtag('js', new Date());
      gtag('config', 'UA-108703919-1');
    </script>


<div role="status" aria-live="assertive" aria-relevant="additions" class="ui-helper-hidden-accessible"></div></body></html>
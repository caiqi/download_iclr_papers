<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" class="no-js"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>On Meaning-Preserving Adversarial Perturbations for Sequence-to-Sequence Models | OpenReview</title>
  <meta name="description" content="" />

      <meta name="citation_title" content="On Meaning-Preserving Adversarial Perturbations for Sequence-to-Sequence Models" />
        <meta name="citation_author" content="Anonymous" />
      <meta name="citation_publication_date" content="2018/09/27" />
      <meta name="citation_online_date" content="2018/09/27" />
      <meta name="citation_pdf_url" content="https://openreview.net/pdf?id=BylkG20qYm" />
      <meta name="twitter:card" content="summary" />
      <meta name="twitter:site" content="@openreviewnet" />
      <meta name="og:title" content="On Meaning-Preserving Adversarial Perturbations for..." />
      <meta name="og:description" content="Adversarial examples have been shown to be an effective way of assessing the robustness of neural sequence-to-sequence (seq2seq) models, by applying perturbations to the input of a model leading to..." />
      <meta name="og:image" content="https://openreview.net/static/images/openreview_logo_512.png" />

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans:400,400i,700,700i" />

  <link rel="stylesheet" href="/static/css/bootstrap.min.css" />
  <link rel="stylesheet" href="/static/css/jquery-ui.min.css" />
  <link rel="stylesheet" href="/static/css/main.min.css" />
</head>

<body class="forum">
  <nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
  
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand home push-link" href="/"><strong>OpenReview</strong>.net</a>
      </div>
  
      <div id="navbar" class="navbar-collapse collapse">
        <form class="navbar-form navbar-left profile-search" role="search">
          <div class="form-group has-feedback">
            <input id="search_input" type="text" class="form-control ui-autocomplete-input" placeholder="Search ICLR 2019 Conference" autocomplete="off" />
            <span class="glyphicon glyphicon-search form-control-feedback" aria-hidden="true"></span>
          </div>
  
          <input id="search_group" type="hidden" value="ICLR.cc/2019/Conference" />
          <input id="search_content" type="hidden" value="all" />
        <ul id="ui-id-1" tabindex="0" class="ui-menu ui-widget ui-widget-content ui-autocomplete ui-front" style="display: none;"></ul></form>
  
        <ul class="nav navbar-nav navbar-right">
        
            <li id="user-menu"><a href="/login">Login</a></li>
        </ul>
      </div>
  
    </div>
  </nav>

  <div id="or-banner" class="banner" style="">
  <div class="container">
    <div class="row">
      <div class="col-xs-12"><a href="/group?id=ICLR.cc/2019/Conference" title="Venue Homepage"><img class="icon" src="/static/images/arrow_left.svg" /> Go to <strong>ICLR 2019 Conference</strong> homepage</a></div>
    </div>
  </div>
</div>
<div id="flash-message-container" class="alert alert-danger" role="alert" style="display: none;">
  <div class="container">
    <div class="row">
      <div class="col-xs-12">
        <div class="alert-content">
          <button type="button" class="close" aria-label="Close"><span aria-hidden="true">×</span></button>
        </div>
      </div>
    </div>
  </div>
</div>

<div class="container">
  <div class="row">
    <div class="col-xs-12">
      <main id="content" class="clearfix openbanner-visible legacy-styles"><div id="note_BylkG20qYm" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>On Meaning-Preserving Adversarial Perturbations for Sequence-to-Sequence Models</a> <a class="note_content_pdf" href="/pdf?id=BylkG20qYm" title="Download PDF" target="_blank"><img src="/static/images/pdf_icon_blue.svg" /></a> </h2></div><div class="meta_row"><span class="signatures">Anonymous</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">28 Sep 2018 (modified: 11 Oct 2018)</span><span class="item">ICLR 2019 Conference Blind Submission</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span><span class="item"><a class="action-bibtex-modal" data-bibtex="@inproceedings{    &#10;anonymous2019on,    &#10;title={On Meaning-Preserving Adversarial Perturbations for Sequence-to-Sequence Models},    &#10;author={Anonymous},    &#10;booktitle={Submitted to International Conference on Learning Representations},    &#10;year={2019},    &#10;url={https://openreview.net/forum?id=BylkG20qYm},    &#10;note={under review}    &#10;}">Show Bibtex</a></span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Abstract: </span><span class="note_content_value">Adversarial examples have been shown to be an effective way of assessing the robustness of neural sequence-to-sequence (seq2seq) models, by applying perturbations to the input of a model leading to large degradation in performance. However, these perturbations are only indicative of a weakness in the model if they do not change the semantics of the input in a way that would change the expected output. Using the example of machine translation (MT), we propose a new evaluation framework for adversarial attacks on seq2seq models taking meaning preservation into account and demonstrate that existing methods may not preserve meaning in general. Based on these findings, we propose new constraints for attacks on word-based MT systems and show, via human and automatic evaluation, that they produce more semantically similar adversarial inputs. Furthermore, we show that performing adversarial training with meaning-preserving attacks is beneficial to the model in terms of adversarial robustness without hurting test performance.</span></div><div class="note_contents"><span class="note_content_field">Keywords: </span><span class="note_content_value">Sequence-to-sequence, adversarial attacks, evaluation, meaning preservation, machine translation</span></div><div class="note_contents"><span class="note_content_field">TL;DR: </span><span class="note_content_value">How you should evaluate adversarial attacks on seq2seq</span></div><div class="reply_row clearfix"><div class="item" id="reply_count">10 Replies</div></div></div><hr class="small" /><div id="note_children"><div class="note_with_children"><div id="note_Skexz1j3hm" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Not enough novelty for acceptance</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=BylkG20qYm&amp;noteId=Skexz1j3hm"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1229 AnonReviewer3</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">05 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper1229 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">The paper is about meaning-preserving adversarial perturbations in the context of Seq2Seq models. The paper proposes two ways of achieving that: (a) kNN - substituting word with nearest neighbors from the word embedding space, and (b) character swapping. It's debatable if character swapping is really meaning preserving since a lot of typos can really change the word. Similarly a case can be made about kNNs as well. But even if these are the best approximations we have, I have some major issues about the novelty of the work. Firstly, while the authors are trying to pitch the work in a new mold, there's major overlap with Belinkov and Bisk, 2018. The use of character swapping as an adversarial perturbation/noise and the subsequent benefits of training with adversarial noise have already been shown in Belinkov and Bisk, 2018. Secondly, the models tested are operating at word-level whereas most of the state-of-the-art systems nowadays are all using subword-level vocabularies. The character swap method presented would need to be adapted and some of the takeaways from results are hence less relevant for the current SOTA models. Coming to positives, the two real contributions for me are: (a) the result that chrF correlates better with human judgement, and (b) the measurement of adversarial perturbation's success measured via a sum that includes relative decrease in target score and the similarity of source sentence with the perturbed version. However, these are minor contributions and not enough to cover up the major flaws that I discussed above. 

Some other minor issues:
(a) Table 1: The first example has the CharSwap row missing the word "faire".
(b) Section 3.1.1: "d" is not defined when discussing time complexity. 
(c) No separate section 3.1.2 required as it can be merged with 3.1.1 and would be more easy to understand without confusing the readers that there's some context change.
(d) Table 6 entries are not clearly defined. How is robustness measured?

 </span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">4: Ok but not good enough - rejection</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_rJlfD8QQpX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Author response for Reviewer 3</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=BylkG20qYm&amp;noteId=rJlfD8QQpX"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1229 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">09 Nov 2018</span><span class="item">ICLR 2019 Conference Paper1229 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">We thank the reviewer for their time and their comments.

Before addressing specific comments, we would like to emphasize that the intended contribution of this paper is not so much about proposing new adversarial attacks as to raise the issue of explicitly evaluating meaning preservation in the context of adversarial attacks on sequence to sequence models. We respectfully disagree with the reviewer that this is a minor contribution, as there is a flourishing literature on adversarial attacks on NLP (and seq2seq) models that often sidesteps this important issue [1,2,3].

Now on to specific remarks:

&gt; It is debatable whether kNN or CharSwap are indeed preserving meaning

We agree and the point of this work is precisely to show that this meaning preservation should not just merely be left as an assumption but actually evaluated via human judgement or automatic proxies thereof.

&gt; Major overlap with Belinkov &amp; Bisk (2017)

We disagree with this assessment, While there are similarities in the choice of perturbations (notably CharSwap), B&amp;B only look at random character replacements whereas we use a systematic approach to generate perturbations using gradients. Moreover, their contribution focuses on the brittleness of character level MT systems to noise, while ours is about the necessity to evaluate the level of meaning preservation of any kind of perturbation. As such, we think that these two works present very distinct contributions.

&gt; Word level models whereas SOTA models use subwords (BPE)

This is a fair criticism that has been raised by several reviewers. To clarify, we expect our main contribution (evaluating meaning-preservation is important) to carry over to subwords (or character models). We will be running experiments on BPE models to confirm this hypothesis before the end of the author response period. We would like to emphasize here again that the specific constraints are not the main contribution of the paper.

&gt; minor issues

We acknowledge these and will address those in the revised version. Specifically for (b):  d is the dimension of word embeddings and for (d):  the metric is RDchrF

References:
[1]: Zhao, Zhengli, Dheeru Dua, and Sameer Singh. "Generating natural adversarial examples." arXiv preprint arXiv:1710.11342 (2017).
[2]: Cheng, Minhao, et al. "Seq2Sick: Evaluating the Robustness of Sequence-to-Sequence Models with Adversarial Examples." arXiv preprint arXiv:1803.01128 (2018).
[3]: Ebrahimi, Javid, Daniel Lowd, and Dejing Dou. "On Adversarial Examples for Character-Level Neural Machine Translation." Proceedings of the 27th International Conference on Computational Linguistics. 2018.</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_SJxazWdlCQ" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Still not convinced</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=BylkG20qYm&amp;noteId=SJxazWdlCQ"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1229 AnonReviewer3</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">20 Nov 2018</span><span class="item">ICLR 2019 Conference Paper1229 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Thank you for such a detailed feedback.

I agree with the authors that in the light of their focus on meaning preserving adversarial perturbations for NMT, their work is indeed novel. However, there are certain issues with the approach proposed which have been raised by other reviewers as well:
(a) Measuring semantic similarity is an extremely hard problem in itself. 
(b) The correlation of chrF with human judgement doesn't inspire much confidence, especially given that it might be already inflated because of the varying number of perturbations introduced.

Due to these fundamental issues, the framework proposed is not convincing. Lack of subword-based model experimentation also make the experimental section weak. Hence I'll keep my original rating.</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div></div></div><div class="note_with_children"><div id="note_r1xFfsu9nm" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Interesting, but significant methodological and experimental problems.</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=BylkG20qYm&amp;noteId=r1xFfsu9nm"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1229 AnonReviewer1</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">03 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper1229 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">Summary: Proposes a framework for performing adversarial attacks on an NMT system in which perturbations to a source sentence aim to preserve its meaning, on the theory that an existing reference translation will remain valid if this is done. Given source and target metrics for measuring similarity, an attack is deemed successful if the source difference is smaller than the relative decrease in target similarity to the reference. A first experiment measures correlation with human judgements of similarity between original and perturbed sentences, and concludes that chrF is better than BLEU and METEOR for this purpose. Next, standard gradient-based adversarial attacks are carried out, replacing the three tokens that result in the biggest drop in (approximate) reference probability, either 1) with no constraints, 2) constrained to character swaps of the original token, or 3) constrained be among the 10 closest embeddings to the original token. In comparisons on three language pairs from IWSLT,  the constrained attacks are found to preserve meaning and yield more successful attacks according to the current framework. The Transformer architecture was also found to deal less well with attacks under the 10-closest embedding constraint. Finally, adversarial training with the character-swap constraint confers some robustness to this attack, without degrading performance on normal text.

I think it is a good idea to formalize a method for carrying out and assessing adversarial attacks, but the framework proposed here seems too narrow, as it excludes adversarial inputs that are sensible but not a close perturbation of an existing source/reference pair, or ones that contain varying amounts of noise. It is more difficult to measure output quality for such attacks, but that doesn’t seem like a good reason for excluding them from what is intended to be a general framework. Note also that “more difficult” doesn’t mean impossible, since good attacks can produce severely degraded output that is relatively easy to detect.

I found some of the methodology questionable. Limiting source perturbations to character swaps and neighbors in embedding space, then using automatic metrics to measure semantic distance seems both unnecessary and unlikely to succeed. Unnecessary because knowing the class of perturbation already gives you a lot of information about semantic distance. Unlikely to succeed because automatic metrics are too coarse to reliably distinguish among different perturbations. This is particularly obvious in the case of using character ngram distance (chrF) to determine which character swaps preserve meaning best. The experiments that support the viability of automatic metrics in 4.2 do so by measuring correlation with human judgment when the number of perturbed tokens varies from 1 to 3. I think the good correlation is likely due to the metrics being able to detect that, eg, changing 3 tokens makes things worse than changing only one. To be convincing, the experiments would have to be repeated with number of perturbations fixed at 3, to match the setting in the remaining experiments. 

Apart from the interesting observation about the Transformer’s performance on embedding-neighbor attacks mentioned above, it is difficult to know what conclusions to draw from the experiments. In 4.3 it seems obvious a priori that perturbations intended to be relatively meaning preserving would indeed preserve meaning better than unconstrained ones. Similarly, it is not surprising that character swaps that by design produce an OOV token will cause more damage than choosing a near neighbor in embedding space. In 5.3, training with OOVs (resulting from character swaps) is of course not likely to hurt performance on test sets containing few OOVs, and, as is known from previous work, it will improve robustness to the same kind of noise. A final comment about the experiments is that word-based systems are not state of the art, and it isn’t clear how much we could expect any conclusions to carry over to sub-word models.

To conclude, although this is an interesting initiative, both the framework and the methodology need to be tightened up.

Details:

End of 2.1: this would be easier to interpret if you had previously specified the allowed range for s_src.

3.2 For kNN, being semantically related doesn’t imply that the relationship is synonymy, as would be required for meaning preservation. It also doesn’t imply that the substitution will be grammatical, which could jeopardize meaning preservation even if the words are synonyms.

CharSwap seems odd. If you’re just going to replace a work with an OOV symbol in any case, why go to the trouble of swapping characters? No matter what actual semantic shift is caused by the swap, the model will always see exactly the same representation.

4.1 “Following previous work on adversarial examples for seq2seq models (Belinkov &amp; Bisk, 2018; Ebrahimi et al., 2018a)” - this is misleading: Ebrahimi et al only work with classification, and don’t use IWLST.

4.1 Should mention the size of the training sets in this section.

Table 1, first sentence, CharSwap example omits “faire”.

4.3, “Adding Constraints Helps Preserve…” last sentence: but here you need to reason in the opposite direction.

5.2 It would be good to also give absolute scores for table 6, so we can judge how much the systems actually benefited, and whether these gains were statistically significant.</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">3: Clear rejection</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_HkxhXwXQTQ" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Author response for reviewer 1 (Pt 1)</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=BylkG20qYm&amp;noteId=HkxhXwXQTQ"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1229 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">09 Nov 2018</span><span class="item">ICLR 2019 Conference Paper1229 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">We thank the reviewer for their extensive and in-depth review, and glad that the overall direction was deemed interesting and valuable, even if there were disagreements with the experimental details. We believe that a number of these disagreements have already been resolved in the paper, or can be resolved with additional experimentation, which we will try our hardest to do. Please see the detailed responses below, and we are happy to address any additional comments.

&gt; The framework is too narrow, doesn’t consider adversarial inputs that are not perturbations of existing samples

The reviewer is correct that our contribution focuses on adversarial perturbations only. We do not think that this setting is too narrow as those kinds of attacks constitute a significant chunk of the literature on the topic (in NLP and other areas [1,2,3,4] inter alia).

&gt; The framework excludes perturbations with varying amounts of noise

On the contrary, our framework implicitly quantifies the amount of noise through the value of the semantic similarity metric. For example adversarial perturbations within edit distance 3 will have lower eg. BLEU score than perturbations within edit distance 1. Ultimately this depends on the chosen similarity metric.

&gt; Perturbations are limited to nearest neighbors and character swap

Please keep in mind that for both the human judgment experiments we include unconstrained perturbations as well, as explained in 4.2.

&gt; kNN and charSwap constraints are unnecessary because knowing the class of perturbation already gives you a lot of information about semantic distance

This is certainly somewhat true, but there are exceptions. For example, a nearest neighbor may be syntactically similar but semantically distant, or swapping characters may change the word to another meaning: “care” -&gt; “acre”. However, this is irrespective of our main point here, which is to show that meaning-preservation *should* be evaluated independently of what a-priori knowledge one has of the level of meaning-preservation.

&gt; Automatic metrics are too coarse to reliably distinguish among different perturbations

Results in Table 3 seem to contradict this statement. However, we do understand that our metrics are not perfect, and future metrics may make the results even more significant.

&gt; I think the good correlation is likely due to the metrics being able to detect that, eg, changing 3 tokens makes things worse than changing only one

First, we would like to point out that this does not explain the (statistically significant) difference in correlations between eg. BLEU and RDchrF in the source. However the reviewer raises an interesting point. We computed correlations with each edit-distance bin and the results are as follow:

Edit distance 1:
 - BLEU = 0.351
 - METEOR = 0.351
 - chrF = 0.486
Edit distance 2:
 - BLEU = 0.403
 - METEOR = 0.424
 - chrF = 0.588
Edit distance 3:
 - BLEU: 0.334
 - METEOR: 0.392
 - chrF: 0.559

In summary, our conclusions hold within each edit distance category (chrF is better than BLEU and meteor with p&lt;0.01, with the caveat that the sample size is now smaller for each subset). Therefore the good correlation is not due only to the metrics being able to detect different edit distances.

We will add the results to the revised version of the paper.

&gt; The conclusions are not clear

We will try to clarify this in the paper. The null hypothesis here is that no one type of adversarial attack is better than the other at preserving meaning, and therefore meaning-preservation should not be evaluated. Our experiments show that this is not the case, and the choice of adversarial attack highly affects the amount that meaning is preserved. Thus, when a new variety of adversarial attack is conceived, meaning preservation should definitely be taken into account when comparing it to previous attacks.

&gt; it seems obvious a priori that perturbations intended to be relatively meaning preserving would indeed preserve meaning better than unconstrained ones

We agree with the reviewer that this appears obvious, particularly in hindsight, but the previous literature has not taken this into account in their evaluations whatsoever. The attacks compared in this paper are relatively straightforward and our conclusions are logical, but we expect that for future works that propose more sophisticated attacks we may not be able to predict the conclusions a-priori nearly as easily. Our point is that future work in the literature should take this problem into account when performing evaluation.
</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_rkxBIwX7T7" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Author response for reviewer 1 (Pt 2)</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=BylkG20qYm&amp;noteId=rkxBIwX7T7"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1229 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">09 Nov 2018</span><span class="item">ICLR 2019 Conference Paper1229 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">&gt; training with OOVs (resulting from character swaps) is of course not likely to hurt performance on test sets containing few OOVs

This is a reasonable remark, although a discussion could be had as to whether changing the training distribution while keeping the test distribution and model capacity constant should not decrease test performance in general.

&gt; word-based systems are not state of the art, and it isn’t clear how much we could expect any conclusions to carry over to sub-word models

We acknowledge that this is a valid criticism of our work. Although we expect that our central contribution (clarifying the importance of evaluating meaning-preservation in adversarial perturbations) will carry over to sub-word models, we will be running experiments during the rest of the rebuttal period to validate this claim.

&gt; For kNN, being semantically related doesn’t imply that the relationship is synonymy

We agree with the reviewer, however 
(1): this is a somewhat good approximation in languages where we may not have access to precise synonymy information (like wordnet)
(2): Our point is precisely that even though one may have preconceptions of the capacity of a class of perturbations to preserve meaning, meaning-preservation should still be evaluated explicitly.

&gt; If you’re just going to replace a work with an OOV symbol in any case, why go to the trouble of swapping characters?

For for human and automatic evaluation, we still need to provide “valid” sentences that don’t just replace words with “&lt;unk&gt;”. This is a quirk of word-based model and our experiments with sub-word models should help resolve this.

&gt; Ebrahimi et al only work with classification, and don’t use IWLST

We suspect the reviewer is referring to the Ebrahimi et al 2018b Hotflip paper, however the 2018a reference points to the COLING paper “On adversarial examples for character-level neural machine translation” paper which indeed works with MT on IWSLT. Arguably the lettering is a bit confusing here, we will address this in a revised version.

References:
[1]: Goodfellow, Ian J., Jonathon Shlens, and Christian Szegedy. "Explaining and Harnessing Adversarial Examples." arXiv preprint arXiv:1412.6572 (2014).
[2]: Ebrahimi, Javid, et al. "Hotflip: White-box adversarial examples for text classification." Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers). Vol. 2. 2018.
[3]: Cheng, Minhao, et al. "Seq2Sick: Evaluating the Robustness of Sequence-to-Sequence Models with Adversarial Examples." arXiv preprint arXiv:1803.01128 (2018).
[4]: Ebrahimi, Javid, Daniel Lowd, and Dejing Dou. "On Adversarial Examples for Character-Level Neural Machine Translation." Proceedings of the 27th International Conference on Computational Linguistics. 2018.</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_HJePML_8pX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Still not convinced by the framework and the experiments</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=BylkG20qYm&amp;noteId=HJePML_8pX"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1229 AnonReviewer1</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">12 Nov 2018</span><span class="item">ICLR 2019 Conference Paper1229 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">I appreciate the detailed and careful responses by the authors, but I feel that they don’t directly address the main concerns I had with this paper. I have tried to restate these more clearly below.

Regarding the proposed framework, I don’t think it’s a good idea to try to limit the scope of adversarial attacks to ones that are “meaning preserving”, for several reasons. First the notion is hard to define, especially when perturbations produce ill-formed input. For instance, does introducing a nonsense token at the beginning of a sentence preserve its meaning? This is not just a theoretical question, since such perturbations occur in real data, and can trigger “hallucinatory” behavior in NMT that is very different from what a human translator would do. Second, even if we had a satisfactory definition for “meaning preserving” in this context, it would be very difficult to measure reliably. This is essentially the problem of paraphrase, and it’s not any easier than MT - in fact, harder in practice, due to the lack of parallel data. Finally, even if the above two problems were resolved, I don’t see the point in specifically excluding attacks that change meaning. On the contrary, changing words or grammatical attributes in constrained ways seems like very fertile ground to explore. For instance, “John loves Mary” -&gt; “Bob loves Mary”, “John sees Mary”, “John loved Mary”, “John is loved by Mary”, etc. Of course, these would invalidate any existing reference translation, but permissible changes to the reference could be checked automatically if the experiment were set up carefully. There is work on this from the burgeoning field of challenge sets for MT; see, eg, the “extra test suites” from WMT 2018. Furthermore, cases where the attack triggers hallucinatory behavior are relatively easy to detect, even without a reference. Such behavior is perhaps the most significant problem for MT robustness at the moment, and it is absent from the current paper.

Turning to what the paper actually does, the basic idea to measure the discrepancy between source-side and target-side semantic difference associated with an adversarial attack makes sense in principle. In practice, given the current state of the art, such measurements are always going to amount to just surface distances like chrF as espoused here. If what we’re really doing is perturbing some characters in the source and measuring how many characters change in the target as a result, it seems clearer just to describe it that way. Absent careful constraints like limiting perturbations to word-internal swaps, many such changes won’t preserve meaning, but as I argue above, that’s not necessarily a bad thing.

A final note about the central character-swap experiments. The technique is to find the three tokens that result in the biggest probability drop when replaced with OOVs (resulting from character swapping), then measure the resulting target-side relative delta chrF. That’s fine, although it’s not clear what is to be gleaned from the results. What’s not fine is to also measure the source-side chrF and compare this to the target-side chrF.  From the model’s perspective, all these perturbations are exactly the same (three OOVs, regardless of how they were produced), so the relation between source- and target-side chrF is completely arbitrary. Even from a human perspective, the source chrF scores are unlikely to be meaningful. As the authors correctly observe, the vast majority of word-internal character swaps are meaning preserving in the sense that we automatically correct them when we read them in context. So the role of chrF here is to distinguish between fine degrees of preserving meaning, a task that seems well out of reach for raw character ngrams.</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div></div></div></div></div><div class="note_with_children"><div id="note_Byxb0Ssv3Q" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>An inspiring study on adversarial attacks for natural language</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=BylkG20qYm&amp;noteId=Byxb0Ssv3Q"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1229 AnonReviewer2</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">01 Nov 2018 (modified: 12 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper1229 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span><a class="note_content_pdf item" href="/revisions?id=Byxb0Ssv3Q" target="_blank">Show Revisions</a></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">The authors provide a natural definition of adversarial examples for natural language transduction (meaning-preserving on source side while meaning-destroying on target side) and a human judgment task to measure it. They then investigate three different ways of generating adversarial examples and show that a metric based on character n-gram overlap (chrF) has a stronger correlation with human judgment. Finally, they show that adversarial training with the attack most consistent with the introduced meaning-preservation criteria results in improved robustness to this type of attack without degradation in the non-adversarial setting.

Overall this is a strong paper. It is well structured, the problem studied is highly interesting and the proposed meaning-preserving criteria and human judgement will be useful to anyone interested in adversarial attacks for natural language. While the studied attack methods are fairly primitive, the empirical results are still interesting.

Comments
---------------
I wish the authors would include experiments with CharSwap where OOV is not forced as I'm not sure the assumption that OOV is more meaning-destroying in the target side is necessarily true (one could also argue that since the models are already trained with OOV words, they may be more robust to OOV words than in-vocabulary words in the wrong context).

It would be nice to add correlation for each type of constraint as well to Table 2. The result would be even stronger if the experiment was replicated in the opposite direction or for another language pair as well.

I don't understand why the adversarial output in the second example in table 4 has a RDchrF of zero (the word July is completely dropped).

From Table 6 it looks like random sampling is actually slightly better than adversarial training in terms of robustness to CharSwap attacks in the Transformer model. Moreover, the benefit of adversarial rather than random sampling is quite small in the LSTM model as well. This could be made more clear in the text.

It would be interesting to see how adversarial training with the CharSwap method fares against the unconstrained and kNN attacks in table 6.
</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">6: Marginally above acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">3: The reviewer is fairly confident that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_BylH3PXm6Q" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Author response for reviewer 2</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=BylkG20qYm&amp;noteId=BylH3PXm6Q"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1229 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">09 Nov 2018</span><span class="item">ICLR 2019 Conference Paper1229 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">We thank the reviewer for their encouraging comments. We appreciate the importance that they put on the problematic of evaluating meaning preservation in adversarial attacks.

Regarding some specific comments:

&gt; What about CharSwap where OOV is not forced?

This would indeed be an interesting experiment, which we will try to carry-out should time permit. Note that an attractive property of OOV is that it renders the optimization problem (2) relatively simple which might favor gradient-based attacks. Finally, as the reviewer pointed out, the effectiveness of the various attacks is not the focal point of the paper.

&gt; It would be nice to add correlation for each type of constraint as well to Table 2

For each constraint:

Unconstrained:
 - BLEU: 0.582
 - METEOR: 0.572
 - chrF: 0.599
kNN:
 - BLEU: 0.533
 - METEOR: 0.584
 - chrF: 0.606
CharSwap:
 - BLEU: 0.273
 - METEOR: 0.318
 - chrF: 0.382

As the reviewer can see, we observe the same trend for each kind of constraints (BLEU&lt;meteor&lt;chrF), except for Unconstrained where all metrics correlate highly with human judgment. However, none of those differences are statistically significant (with p&lt;0.01). Note that the sample size is also smaller.

We will include these results in a revised version of the paper.
</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_rJlanx6La7" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Modified rating in light of other reviews</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=BylkG20qYm&amp;noteId=rJlanx6La7"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1229 AnonReviewer2</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">12 Nov 2018</span><span class="item">ICLR 2019 Conference Paper1229 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">I still like the overall mission of this paper and found it highly readable. However, after a more careful reading I do agree with the issues raised by the other reviewers. It seems that there is a fundamental question in the field as to a) how important meaning preservation is for adversarial attacks and b) how this should be assessed. In its current form, I don't think this paper provides satisfactory answers to these questions, but it does point at an important topic to be resolved.</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div></div></div></div></main></div>
  </div>
</div>


    <!-- Footer -->
    <footer class="sitemap">
      <div class="container">
        <div class="row hidden-xs">
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/venues">All Venues</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="/contact">Contact</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
    
        <div class="row visible-xs-block">
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/contact">Contact</a></li>
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
      </div>
    </footer>
    
    <footer class="sponsor">
      <div class="container">
        <div class="row">
          <div class="col-sm-10 col-sm-offset-1">
            <p class="text-center">
              OpenReview is created by the <a href="http://www.iesl.cs.umass.edu/" target="_blank">Information Extraction and Synthesis Laboratory</a>, College of Information and Computer Science, University of Massachusetts Amherst. We gratefully acknowledge the support of the OpenReview sponsors:  Google,  Facebook, NSF, the University of Massachusetts Amherst Center for Data Science, and Center for Intelligent Information Retrieval, as well as the Google Cloud Platform for donating the computing and networking services on which OpenReview.net runs.
            </p>
          </div>
        </div>
      </div>
    </footer>

  <div id="feedback-modal" class="modal fade" tabindex="-1" role="dialog">
    <div class="modal-dialog">
      <div class="modal-content">
        <div class="modal-header">
          <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button>
          <h3 class="modal-title">Send Feedback</h3>
        </div>
        <div class="modal-body">
          <p>Enter your feedback below and we'll get back to you as soon as possible.</p>
          <form action="/feedback" method="POST">
            <div class="form-group">
              <input type="email" name="from" class="form-control" placeholder="Email" />
            </div>
            <div class="form-group">
              <input type="text" name="subject" class="form-control" placeholder="Subject" />
            </div>
            <div class="form-group">
              <textarea name="message" class="form-control feedback-input" rows="5" placeholder="Message" required=""></textarea>
            </div>
          <ul id="ui-id-2" tabindex="0" class="ui-menu ui-widget ui-widget-content" style="display: none;"></ul></form>
        </div>
        <div class="modal-footer">
          <button type="button" class="btn btn-default" data-dismiss="modal">Cancel</button>
          <button type="button" class="btn btn-primary">Send</button>
        </div>
      </div>
    </div>
  </div>

  <script type="text/javascript" async="" src="https://www.google-analytics.com/analytics.js"></script><script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js"></script>
  <script>window.jQuery || document.write('&lt;script src="/static/js/vendor/jquery-2.2.4.min.js"&gt;&lt;\/script&gt;')</script>

  <script src="/static/dist/vendor.min.js"></script>
  <script src="/static/dist/templates.min.js"></script>
  <script src="/static/dist/openreview.min.js"></script>

    <script>window.legacyScripts = true;</script>


    <script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-108703919-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() { dataLayer.push(arguments); }
      gtag('js', new Date());
      gtag('config', 'UA-108703919-1');
    </script>


<div role="status" aria-live="assertive" aria-relevant="additions" class="ui-helper-hidden-accessible"></div></body></html>
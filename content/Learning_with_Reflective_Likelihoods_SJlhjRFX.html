<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" class="no-js"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>Learning with Reflective Likelihoods | OpenReview</title>
  <meta name="description" content="" />

      <meta name="citation_title" content="Learning with Reflective Likelihoods" />
        <meta name="citation_author" content="Anonymous" />
      <meta name="citation_publication_date" content="2018/09/27" />
      <meta name="citation_online_date" content="2018/09/27" />
      <meta name="citation_pdf_url" content="https://openreview.net/pdf?id=SJlh2jR9FX" />
      <meta name="twitter:card" content="summary" />
      <meta name="twitter:site" content="@openreviewnet" />
      <meta name="og:title" content="Learning with Reflective Likelihoods" />
      <meta name="og:description" content="Machine learning systems have achieved state-of-the-art results in many domains. They are usually trained using the maximum likelihood principle. However maximum likelihood learning can lead to..." />
      <meta name="og:image" content="https://openreview.net/static/images/openreview_logo_512.png" />

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans:400,400i,700,700i" />

  <link rel="stylesheet" href="/static/css/bootstrap.min.css" />
  <link rel="stylesheet" href="/static/css/jquery-ui.min.css" />
  <link rel="stylesheet" href="/static/css/main.min.css" />
</head>

<body class="forum">
  <nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
  
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand home push-link" href="/"><strong>OpenReview</strong>.net</a>
      </div>
  
      <div id="navbar" class="navbar-collapse collapse">
        <form class="navbar-form navbar-left profile-search" role="search">
          <div class="form-group has-feedback">
            <input id="search_input" type="text" class="form-control ui-autocomplete-input" placeholder="Search ICLR 2019 Conference" autocomplete="off" />
            <span class="glyphicon glyphicon-search form-control-feedback" aria-hidden="true"></span>
          </div>
  
          <input id="search_group" type="hidden" value="ICLR.cc/2019/Conference" />
          <input id="search_content" type="hidden" value="all" />
        <ul id="ui-id-1" tabindex="0" class="ui-menu ui-widget ui-widget-content ui-autocomplete ui-front" style="display: none;"></ul></form>
  
        <ul class="nav navbar-nav navbar-right">
        
            <li id="user-menu"><a href="/login">Login</a></li>
        </ul>
      </div>
  
    </div>
  </nav>

  <div id="or-banner" class="banner" style="">
  <div class="container">
    <div class="row">
      <div class="col-xs-12"><a href="/group?id=ICLR.cc/2019/Conference" title="Venue Homepage"><img class="icon" src="/static/images/arrow_left.svg" /> Go to <strong>ICLR 2019 Conference</strong> homepage</a></div>
    </div>
  </div>
</div>
<div id="flash-message-container" class="alert alert-danger" role="alert" style="display: none;">
  <div class="container">
    <div class="row">
      <div class="col-xs-12">
        <div class="alert-content">
          <button type="button" class="close" aria-label="Close"><span aria-hidden="true">×</span></button>
        </div>
      </div>
    </div>
  </div>
</div>

<div class="container">
  <div class="row">
    <div class="col-xs-12">
      <main id="content" class="clearfix openbanner-visible legacy-styles"><div id="note_SJlh2jR9FX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Learning with Reflective Likelihoods</a> <a class="note_content_pdf" href="/pdf?id=SJlh2jR9FX" title="Download PDF" target="_blank"><img src="/static/images/pdf_icon_blue.svg" /></a> </h2></div><div class="meta_row"><span class="signatures">Anonymous</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">28 Sep 2018 (modified: 11 Oct 2018)</span><span class="item">ICLR 2019 Conference Blind Submission</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span><span class="item"><a class="action-bibtex-modal" data-bibtex="@inproceedings{    &#10;anonymous2019learning,    &#10;title={Learning with Reflective Likelihoods},    &#10;author={Anonymous},    &#10;booktitle={Submitted to International Conference on Learning Representations},    &#10;year={2019},    &#10;url={https://openreview.net/forum?id=SJlh2jR9FX},    &#10;note={under review}    &#10;}">Show Bibtex</a></span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Abstract: </span><span class="note_content_value">Machine learning systems have achieved state-of-the-art results in many domains. They are usually trained using the maximum likelihood principle. However maximum likelihood learning can lead to poor learned representations of high dimensional data. For example this is manifested in deep generative latent variable models where the latent variables and their associated observations are driven independent from each other. We identify a peculiarity in maximum likelihood learning that causes this problem of poor learned representations. We then propose a new learning criterion for better representation learning. The proposed criterion relies on simultaneously maximizing the likelihood of the data and minimizing what we term the reflective likelihood of the data. We study this new criterion both theoretically and empirically and show improved performance on image classification under imbalance and text modeling with deep generative latent variable models.</span></div><div class="note_contents"><span class="note_content_field">Keywords: </span><span class="note_content_value">new learning criterion, penalized maximum likelihood, posterior inference in deep generative models, input forgetting issue, latent variable collapse issue</span></div><div class="note_contents"><span class="note_content_field">TL;DR: </span><span class="note_content_value">We identify a peculiarity in maximum likelihood learning that causes input collapse and propose a new learning criterion for better representation learning.</span></div><div class="reply_row clearfix"><div class="item" id="reply_count">5 Replies</div></div></div><hr class="small" /><div id="note_children"><div class="note_with_children"><div id="note_rJlp3F0d2Q" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Interesting ideas that need further refinement</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=SJlh2jR9FX&amp;noteId=rJlp3F0d2Q"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper745 AnonReviewer1</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">02 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper745 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">Summary:

This paper proposes maximizing the “reflective likelihood,” which the authors define as: E_x E_y [log q(y|x) - \alpha log q(y)] where the expectations are taken over the data, q is the classifier, and \alpha is a weight on the log q(y) term.  The paper derives the reflective likelihood for classification models and unsupervised latent variable models.  Choices for \alpha are also discussed, and connections are made to ranking losses.  Results show superior F1 and perplexity in MNIST classification and 20NewsGroups modeling.

Pros:

I like how the paper frames the reflective likelihood as a ranking loss.  It does seem like subtracting off the marginal probability of y from the conditional likelihood should indeed ‘focus’ the model on the dependent relationship y|x.  Can this be further formalized?  I would be very interested in seeing a derivation of this kind.    

I like that the authors test under class imbalance and report F1 metrics in the experiments as it does seem the proposed method operates through better calibration.

Cons:

My biggest issue with the paper is that I find much of the discussion lacks rigor.  I followed the argument through to Equation 3, but then I became confused when the discussion turned to ‘dependence paths’: “we want our learning procedure to follow the dependence path—the subspace in Θ for which inputs and outputs are dependent. However this dependence path is unknown to us; there is nothing in Eq. 1 that guides learning to follow this dependence path instead of following Eq. 3—the independence path” (p 3).  What are these dependence paths?  Can they be defined mathematically in a way that is more direct than switching around the KLD directions in Equations 1-3?  Surely any conditional model x--&gt;y has a ‘dependence path’ flowing from y to x, so it seems the paper is trying to make some stronger statement about the conditional structure?

Moving on to the proposed reflective likelihood in Equation 4, I could see some connections to Equations 1-3, but I’m not sure how exactly that final form was settled upon.  There seems to be a connection to maximum entropy methods?  That is,   E_x E_y [log q(y|x) - \alpha log q(y)] = E_x E_y [log q(y|x)] + \alpha E_y [ -log q(y)] \approx E_x E_y [log q(y|x)] + \alpha H[y], if we assume q(y) approximates the empirical distribution of y well.  Thus, the objective can be thought of as maximizing the traditional log model probability plus an estimate of the entropy.  As there is a long history of maximum entropy methods / classifiers, I’m surprised there were no mentions or references to this literature.  Also, I believe there might be some connections to Bayesian loss calibration / risk by viewing \alpha as a utility function (which is easy to do when it is defined to be data dependent).  I’m less sure about this connection though; see Cobb et al. (2018) (<a href="https://arxiv.org/abs/1805.03901)" target="_blank" rel="nofollow">https://arxiv.org/abs/1805.03901)</a> and its citations for references.   

The data sets used in the experiments are also somewhat dissatisfying as MNIST and 20NewsGroups are fairly easy to get high-performing models for.  I would have liked to have seen more direct analysis / simulation of what we expect from the reflective likelihood.  As I mentioned above, I suspect its really providing gains through better calibration---which the authors may recognize as F1 scores are reported and class imbalance tested---but the word ‘calibration’ is never mentioned.  More direction comparison against calibration methods such as Platt scaling would be make the experiments have better focus.  It would be great to show that this method provides good calibration directly during optimization and doesn’t need the post-hoc calibration steps that most methods require. 

Evaluation:  While the paper has some interesting ideas, they are not well defined, making the paper unready for publication.  Discussion of the connections to calibration and maximum entropy seems like a large piece missing from the paper’s argument.  </span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">4: Ok but not good enough - rejection</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_rJl5OkRLnm" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>the paper is technically flawed</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=SJlh2jR9FX&amp;noteId=rJl5OkRLnm"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper745 AnonReviewer2</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">31 Oct 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper745 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">This paper is technically flawed. Here are three key equations from Section 2. The notations are simplified for textual presentation:  d – p_data; d(y|x) – p_d(y|x); m(y|x) – p_theta(y|x)

max E_x~d E_y~d(y|x) [ log m (y|x) ]                 				               (1) 
max E_x~d { E_y~d(y|x) ) [ log d(y|x) ]}  -  E_y~d(y|x) [ log m (y|x) ]}        (2)
max { E_y~d [  log  (y) ]  -  E_y~d  log E_x~d(x|y) [ m (y|x) ]}                        (3)

First error is that the “max” in (2) and (3) should be “min”. I will assume this minor error is corrected in the following.
The equivalence between (1) and (2) is correct and well-known. The reason is that the first entropy term  in (2) does not depend on model.  The MAJOR ERROR is that (1) is NOT equivalent to (3). Instead, it is equivalent to the following:

 min { E_y~d [  log d (y) ]  -  E_y~d  E_x~d(x|y) [ log m (y|x) ]}                     (3’)

Notice the swap of “E_x” and “log”. By Jensen’s nequality, we have 

 log E_x~d(x|y)  m (y|x) ]  &gt; E_x~d(x|y) [ log m (y|x)
 -  E_y~d  log E_x~d(x|y)  [ m (y|x) ]    &lt; -  E_y~d  E_x~d(x|y) [ log m (y|x) ]                    

So, minimizing (3) amounts to minimizing a lower bound of the correct objective (3’). It does not make sense at all.
</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">2: Strong rejection</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_HklxkbeU3X" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>potentially interesting idea, but very confusing in current form</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=SJlh2jR9FX&amp;noteId=HklxkbeU3X"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper745 AnonReviewer3</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">30 Oct 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper745 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">The paper proposes a modification of maximum likelihood estimation that encourages estimated predictive/conditional models p(z|x) to have low entropy and/or to maximize mutual information between z and x under the model p_{data}(x)p_{model}(z|x).

There is pre-existing literature on encouraging low entropy / high mutual information in predictive models, suggesting this can indeed be a good idea. The experiments in the current paper are preliminary but encouraging. However, the setting in which the paper presents this approach (section 2.1) does not make any sense. Also see my previous comments.

- Please reconsider your motivation for the proposed method. Why does it work? Also please try to make the connection with the existing literature on minimum entropy priors and maximizing mutual information.

- Please try to provide some guarantees for the method. Maximum likelihood estimation is consistent: given enough data and a powerful model it will eventually do the right thing. What will your estimator converge to for infinite data and infinitely powerful models?</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">3: Clear rejection</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_r1xoJGzy3X" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>please clarify</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=SJlh2jR9FX&amp;noteId=r1xoJGzy3X"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper745 AnonReviewer3</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">25 Oct 2018</span><span class="item">ICLR 2019 Conference Paper745 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">You write "Maximizing Eq. 1 can be achieved by maximizing either Eq. 2 or Eq. 3 or both", and this seems to be crucial to your motivation for the proposed method. However this statement is false. It's true that the true conditional model p(y|x) is a solution to eq 1,2 and 3, but the converse does not hold: There are many solutions to equation 3 that do not maximize equation 1. You are basically claiming that maximum likelihood is not a consistent estimation method, contradicting all of the statistical literature. Please clarify your motivation for the proposed method, and let me know if I'm misunderstanding.</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_H1e43-v127" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Clarifications</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=SJlh2jR9FX&amp;noteId=H1e43-v127"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper745 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">25 Oct 2018 (modified: 26 Oct 2018)</span><span class="item">ICLR 2019 Conference Paper745 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Thank you AnonReviewer3 for your feedback and for giving us the opportunity to clarify things before you make your decision! There are several points raised in your comment that we would like to provide an answer to.

1. "... this statement is false. It's true that the true conditional model p(y|x) is a solution to eq 1,2 and 3, but the converse does not hold..."

We agree with you that  statement is misleading and wrong as formulated. It was not meant as a statement on the maxima (clearly Eq. 1 and Eq. 3 may not have the same global maxima; there are simple counterexamples to show this), but as a way to distinguish which paths are followed to maximize Eq. 1. Let us clarify what we mean by this as follows: 

Consider a supervised learning setting. We have observations (x, y) and our goal is to fit a conditional model p_{\theta}(y | x). We can fit this model by maximizing either (1) or (2) as they are equivalent; they correspond to maximum likelihood estimation. However, in practice, when we learn a conditional model p_{\theta}(y | x) that is arbitrarily flexible (e.g., parameterized by a deep neural network) by optimizing (1) (or equivalently (2)) using data, the resulting model often has the issue that it ignores the inputs x. In this case, the resulting value of the parameters is analogous as if we had optimized (3) instead. In other words, when optimizing (1) with data, nothing guarantees that (3) is not being optimized. This behavior is undesirable. To prevent that, we want to promote a strong dependency between y and x. That is, we propose to avoid the "marginal path", as induced by (3).

We will edit out the statement in the revision and make that part of the paper more clear.  

2. "You are basically claiming that maximum likelihood is not a consistent estimation method, contradicting all of the statistical literature."

If by "consistent estimation method" you mean consistency in the statistical sense (i.e. convergence in probability of the estimator to the true parameter as sample size goes to infinity) then no we are not studying consistency/inconsistency of maximum likelihood in the paper. 

However we would like to point out that maximum likelihood does not always lead to consistent estimators. Consider the counterexample of Bahadur, 1958 (see [1] for the reference) showing an example where maximum likelihood is inconsistent. 

3. "Please clarify your motivation for the proposed method, and let me know if I'm misunderstanding."

Thank you for giving us the opportunity to make things more clear. Our motivation for the paper is this: there is this common behavior we call “input forgetting” in the paper that happens quite often with models parameterized by deep neural networks. This is manifested in deep latent variable models as the phenomenon known as “posterior collapse” or “latent variable collapse” in the literature. This also happens in RBMs (see [2]). However the problem can happen even without latent variables. Some other examples we have not mentioned in the paper include Seq2Seq models where the decoder does not account for the input. A good manifestation of this is in neural conversation models where the decoder provides very generic responses such as “I don’t know” or “ok” no matter what the query/input is. See for example [3] for more details on generic answers in conversation models. 

One common denominator of all these examples is that the variable being conditioned upon is ignored by the deep network. Our paper proposes a regularization approach to mitigate this problem. We add a regularizer termed the “reflective likelihood” that is basically a marginal distribution over the output variable. We define this marginal in the paper for both supervised and unsupervised learning. The resulting objective is the difference between the usual maximum likelihood objective and this reflective likelihood. Subtracting the reflective likelihood forces the optimization to favor parameter settings that promote usage of the variable being conditioned upon. We validate this hypothesis through our empirical studies where we notice an improvement in terms of latent variable collapse and classification performance for rare classes. 

In summary: for applications where you care about promoting a stronger dependence between inputs and outputs (e.g. in deep latent variable models or in classification under imbalance) then we propose to use the objective proposed in this paper instead of vanilla MLE.

We hope our answer clarifies things. Thank you for bringing these points up. We will add these clarifications in the revision.

[1] R. R. Bahadur. Examples of Inconsistency of Maximum Likelihood Estimates. The Indian Journal of Statistics, 1958.
[2] K. Cho et al. Enhanced Gradient and Adaptive Learning Rate for Training Restricted Boltzmann Machines. In ICML,2011.
[3] J. Li et al. A Diversity-Promoting Objective Function for Neural Conversation Models. In NAACL, 2016.</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div></div></main></div>
  </div>
</div>


    <!-- Footer -->
    <footer class="sitemap">
      <div class="container">
        <div class="row hidden-xs">
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/venues">All Venues</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="/contact">Contact</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
    
        <div class="row visible-xs-block">
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/contact">Contact</a></li>
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
      </div>
    </footer>
    
    <footer class="sponsor">
      <div class="container">
        <div class="row">
          <div class="col-sm-10 col-sm-offset-1">
            <p class="text-center">
              OpenReview is created by the <a href="http://www.iesl.cs.umass.edu/" target="_blank">Information Extraction and Synthesis Laboratory</a>, College of Information and Computer Science, University of Massachusetts Amherst. We gratefully acknowledge the support of the OpenReview sponsors:  Google,  Facebook, NSF, the University of Massachusetts Amherst Center for Data Science, and Center for Intelligent Information Retrieval, as well as the Google Cloud Platform for donating the computing and networking services on which OpenReview.net runs.
            </p>
          </div>
        </div>
      </div>
    </footer>

  <div id="feedback-modal" class="modal fade" tabindex="-1" role="dialog">
    <div class="modal-dialog">
      <div class="modal-content">
        <div class="modal-header">
          <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button>
          <h3 class="modal-title">Send Feedback</h3>
        </div>
        <div class="modal-body">
          <p>Enter your feedback below and we'll get back to you as soon as possible.</p>
          <form action="/feedback" method="POST">
            <div class="form-group">
              <input type="email" name="from" class="form-control" placeholder="Email" />
            </div>
            <div class="form-group">
              <input type="text" name="subject" class="form-control" placeholder="Subject" />
            </div>
            <div class="form-group">
              <textarea name="message" class="form-control feedback-input" rows="5" placeholder="Message" required=""></textarea>
            </div>
          <ul id="ui-id-2" tabindex="0" class="ui-menu ui-widget ui-widget-content" style="display: none;"></ul></form>
        </div>
        <div class="modal-footer">
          <button type="button" class="btn btn-default" data-dismiss="modal">Cancel</button>
          <button type="button" class="btn btn-primary">Send</button>
        </div>
      </div>
    </div>
  </div>

  <script type="text/javascript" async="" src="https://www.google-analytics.com/analytics.js"></script><script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js"></script>
  <script>window.jQuery || document.write('&lt;script src="/static/js/vendor/jquery-2.2.4.min.js"&gt;&lt;\/script&gt;')</script>

  <script src="/static/dist/vendor.min.js"></script>
  <script src="/static/dist/templates.min.js"></script>
  <script src="/static/dist/openreview.min.js"></script>

    <script>window.legacyScripts = true;</script>


    <script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-108703919-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() { dataLayer.push(arguments); }
      gtag('js', new Date());
      gtag('config', 'UA-108703919-1');
    </script>


<div role="status" aria-live="assertive" aria-relevant="additions" class="ui-helper-hidden-accessible"></div></body></html>
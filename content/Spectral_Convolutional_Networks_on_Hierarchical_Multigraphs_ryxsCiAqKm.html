<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" class="no-js"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>Spectral Convolutional Networks on Hierarchical Multigraphs | OpenReview</title>
  <meta name="description" content="" />

      <meta name="citation_title" content="Spectral Convolutional Networks on Hierarchical Multigraphs" />
        <meta name="citation_author" content="Boris Knyazev" />
        <meta name="citation_author" content="Xiao Lin" />
        <meta name="citation_author" content="Mohamed R. Amer" />
        <meta name="citation_author" content="Graham W. Taylor" />
      <meta name="citation_publication_date" content="2018/09/27" />
      <meta name="citation_online_date" content="2018/09/27" />
      <meta name="citation_pdf_url" content="https://openreview.net/pdf?id=ryxsCiAqKm" />
      <meta name="twitter:card" content="summary" />
      <meta name="twitter:site" content="@openreviewnet" />
      <meta name="og:title" content="Spectral Convolutional Networks on Hierarchical Multigraphs" />
      <meta name="og:description" content="Spectral Graph Convolutional Networks (GCNs) are a generalization of convolutional networks to learning on graph-structured data. Applications of spectral GCNs have been successful, but limited to..." />
      <meta name="og:image" content="https://openreview.net/static/images/openreview_logo_512.png" />

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans:400,400i,700,700i" />

  <link rel="stylesheet" href="/static/css/bootstrap.min.css" />
  <link rel="stylesheet" href="/static/css/jquery-ui.min.css" />
  <link rel="stylesheet" href="/static/css/main.min.css" />
</head>

<body class="forum">
  <nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
  
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand home push-link" href="/"><strong>OpenReview</strong>.net</a>
      </div>
  
      <div id="navbar" class="navbar-collapse collapse">
        <form class="navbar-form navbar-left profile-search" role="search">
          <div class="form-group has-feedback">
            <input id="search_input" type="text" class="form-control ui-autocomplete-input" placeholder="Search ICLR 2019 Conference" autocomplete="off" />
            <span class="glyphicon glyphicon-search form-control-feedback" aria-hidden="true"></span>
          </div>
  
          <input id="search_group" type="hidden" value="ICLR.cc/2019/Conference" />
          <input id="search_content" type="hidden" value="all" />
        <ul id="ui-id-1" tabindex="0" class="ui-menu ui-widget ui-widget-content ui-autocomplete ui-front" style="display: none;"></ul></form>
  
        <ul class="nav navbar-nav navbar-right">
        
            <li id="user-menu"><a href="/login">Login</a></li>
        </ul>
      </div>
  
    </div>
  </nav>

  <div id="or-banner" class="banner" style="">
  <div class="container">
    <div class="row">
      <div class="col-xs-12"><a href="/group?id=ICLR.cc/2019/Conference" title="Venue Homepage"><img class="icon" src="/static/images/arrow_left.svg" /> Go to <strong>ICLR 2019 Conference</strong> homepage</a></div>
    </div>
  </div>
</div>
<div id="flash-message-container" class="alert alert-danger" role="alert" style="display: none;">
  <div class="container">
    <div class="row">
      <div class="col-xs-12">
        <div class="alert-content">
          <button type="button" class="close" aria-label="Close"><span aria-hidden="true">Ã—</span></button>
        </div>
      </div>
    </div>
  </div>
</div>

<div class="container">
  <div class="row">
    <div class="col-xs-12">
      <main id="content" class="clearfix openbanner-visible legacy-styles"><div id="note_ryxsCiAqKm" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Spectral Convolutional Networks on Hierarchical Multigraphs</a> <a class="note_content_pdf" href="/pdf?id=ryxsCiAqKm" title="Download PDF" target="_blank"><img src="/static/images/pdf_icon_blue.svg" /></a> </h2></div><div class="meta_row"><span class="signatures"><a href="/profile?email=bknyazev%40uoguelph.ca" class="profile-link" data-toggle="tooltip" data-placement="bottom" title="" data-original-title="bknyazev@uoguelph.ca">Boris Knyazev</a>, <a href="/profile?email=xiao.lin%40sri.com" class="profile-link" data-toggle="tooltip" data-placement="bottom" title="" data-original-title="xiao.lin@sri.com">Xiao Lin</a>, <a href="/profile?email=mohamed.amer%40sri.com" class="profile-link" data-toggle="tooltip" data-placement="bottom" title="" data-original-title="mohamed.amer@sri.com">Mohamed R. Amer</a>, <a href="/profile?email=gwtaylor%40uoguelph.ca" class="profile-link" data-toggle="tooltip" data-placement="bottom" title="" data-original-title="gwtaylor@uoguelph.ca">Graham W. Taylor</a></span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">28 Sep 2018 (modified: 20 Nov 2018)</span><span class="item">ICLR 2019 Conference Withdrawn Submission</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Abstract: </span><span class="note_content_value">Spectral Graph Convolutional Networks (GCNs) are a generalization of convolutional networks to learning on graph-structured data. Applications of spectral GCNs have been successful, but limited to a few problems where the graph is fixed, such as shape correspondence and node classification. In this work, we address this limitation by revisiting a particular family of spectral graph networks, Chebyshev GCNs, showing its efficacy in solving graph classification tasks with a variable graph structure and size. Current GCNs also restrict graphs to have at most one edge between any pair of nodes. To this end, we propose a novel multigraph network that learns from multi-relational graphs. We explicitly model different types of edges: annotated edges, learned edges with abstract meaning, and hierarchical edges. We also experiment with different ways to fuse the representations extracted from different edge types. This restriction is sometimes implied from a dataset, however, we relax this restriction for all kinds of datasets. We achieve state-of-the-art results on a variety of chemical, social, and vision graph classification benchmarks.</span></div><div class="note_contents"><span class="note_content_field">Keywords: </span><span class="note_content_value">graph convolution, hierarchical models, neural networks, multigraph, deep learning</span></div><div class="note_contents"><span class="note_content_field">TL;DR: </span><span class="note_content_value">A novel approach to graph classification based on spectral graph convolutional networks and its extension to multigraphs with learnable relations and hierarchical structure. We show state-of-the art results on chemical, social and image datasets.</span></div><div class="reply_row clearfix"><div class="item" id="reply_count">4 Replies</div></div></div><hr class="small" /><div id="note_children"><div class="note_with_children"><div id="note_Hkx9MSKe07" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Submission Withdrawn by the Authors</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=ryxsCiAqKm&amp;noteId=Hkx9MSKe07"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper927 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">20 Nov 2018</span><span class="item">ICLR 2019 Conference Paper927 Withdraw Submission</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Withdrawal confirmation: </span><span class="note_content_value">I have read and agree with the withdrawal statement on behalf of myself and my co-authors.</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_r1eop2us3m" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>This paper presents several enhancements to spectral GCNs. I don't believe it is novel enough for ICLR, nor are its experimental results strong enough.</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=ryxsCiAqKm&amp;noteId=r1eop2us3m"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper927 AnonReviewer2</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">04 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper927 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">## Summary ##

The authors describe several improvements on existing spectral convolutional networks for graphs:

1. Learning 'abstract' edges that aren't included in the graph.
2. Incorporating multiple edge types by several different methods.
3. Building hierarchical graphs for image tasks.

They apply these modified architectures to classification of chemical compounds, social networks and images.

## Assessment ##

The topic of spectral graph convolutions is interesting, and the enhancements suggested seem promising. However, each of 1-3 above is a straightforward application of an idea that appears elsewhere to spectral graph convolutions, making the work seem incremental. What is more, the experimental results were mixed; it was hard to discern significant improvement from 1-3. I don't think this paper warrants acceptance in ICLR at this time.

## Questions and Concerns ##

* I think section 2.1 (describing approximate spectral graph convolutions) could be made much clearer. The section in the supplementary material was much clearer and didn't take any more space than 2.1. Obviously, the authors can't be expected to cover ChebNet in detail, but it would be nice if they could get the gist of it from section 2.1 without having to read the original paper.
* In many of the experiments, the hierarchical/multigraph ChebNet either underperformed another architecture, or outperformed by a very narrow margin. If there aren'y big improvements on benchmarks, it would be nice to see some other way that these new features are improving the model (e.g. can we show that it implicitly learns some interesting feature of the graphs?).
* I found the comparison of edge fusion methods (summarized in Fig 5) difficult to understand. It was difficult to distinguish which improvements come from a better architecture and which simply come from a larger receptive field.
* In 'Graph formation for images,' the authors say they included features from the last layer of pretrained VGG-16 in the hierarchical ChebNet for PASCAL. Moreover, these features were pretrained on a separate dataset (Imagenet). It wasn't clear whether these features were available to any other architectures, but they seem like they would provide a large advantage.</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">4: Ok but not good enough - rejection</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_H1ew2c9uhQ" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Highly-problematic experimental setup</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=ryxsCiAqKm&amp;noteId=H1ew2c9uhQ"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper927 AnonReviewer1</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">01 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper927 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value"># Summary of the paper

This paper presents a method for graph classification based on spectral convolutional neural networks. At its heart, the paper applies a standard decomposition in terms of the graph Laplacian and uses Chebyshev polynomials to obtain an approximation of node feature convolution. This is now extended to graphs with multiple edge relation types by performing the same calculations for every Laplacian that is induced by a certain relation $r$, and either extended the Chebyshev polynomials to multiple variables, or multiplying/adding the resulting feature vectors.

# Review

The main idea of this paper, i.e. improving graph classification results by exploiting different types of edges, is very interesting. In particular for data sets with additional hierarchical information, this could well increase performance significantly.

However, in its present form, the paper suffers from several issues. The following is a brief listing; each point will be expanded on below:

1. Issues with originality: at times, it is unclear in what ways previous work is extended
2. Issues with clarity: while most of the parts of the method can be 'reconstructed' through literature knowledge, the paper is not self-contained and often uses terms without explaining them.
3. Issues with experiments: the reported results are *not* state-of-the-art for several data sets and I doubt the correctness of the setup.

In particular the experimental issues I consider to be highly problematic at the moment.

## Originality:

The paper needs to be more clear about its contributions. Some parts read like an introduction to GCNs, but it is often not clear what is novel here:

- The main contribution, as far as I understand it, should be an extension of `ChebNet` to multigraphs.  However, different relations in a graph appear to be modelled by calculating multiple graph Laplacians, which in turn can be stacked; this strikes me as a rather straightforward extension. Furthermore, the operation in Eq. 5 also appears a straightforward extension that uses learned node embeddings for each relation type.

- The learning of edges for each relation, described in Section 3.1, is also a straightforward formulation/re-use of previous work (the papers cites Velickovic et al. (2018) as an example), and I do not exactly what is novel here: Velickovic et al. use the same equation to predict coefficients, as claimed in the paper, but how is this different from learning a weight for all edges as in Eq. 7? In Velickovic et al., this coefficient is only calculated for some of the edges. Is the novelty then that this is calculated for _all_ edges here?

## Clarity:

- The explanation of the Chebyshev expansion could be improved: Kipf &amp; Welling (2016), for example, explain this in term of signal convolution (Eq. 3--5 in their paper), while for this paper, the introduction of node features in Eq. 2 is not clear.

- What is $f_0, \dots, f_{R-1}$ in Eq. 5? Is this an input signal at the nodes of a graph or an additional function defined on it, such as in the `ChebNet` paper by Monti et al.?  

- What is $f_{\text{edge}}$ in Eq. 7?

- What is $\bar{X}^{(0)}$ in EQ. 5? The preceding section only introduces a notation for $X$ with multiple indices, but suddenly, $X$ is now indexed over the number of relations.  

- p. 4: The paper seems to be contradicting itself at places: the multi-variable polynomials from Eq. 3 and Eq. 4 are said to have a great computational cost and an exponential number of parameters for many relations. But the edge feature concatenation introduced at the bottom of p. 3 is dismissed by saying that it grows _linearly_ with $R$. What am I missing here?

- The paper claims that most data set, except for the image, only have a single relation type ($R = 1$); later on, 'learned edges' are added for training. While I understand this and the benefits of adding them, I think that this should be clarified more: the advantage of the current approach seems to be that it can leverage more information by treating learned edges as a separate entity. This should be highlighted better.

- In general, the paper would benefit from a section that describes the full method, preferably with a few equations, so that the readers can see at one glance which parts are involved. At present, I am doubtful about the reproducibility of the method.

## Experimental setup

This is the major issue for me: the paper claims to follow a 'standard approach to evaluation' (p. 6) that consists of a 10-fold cross-validation. However, only average classification accuracies are reported, even though the sources I checked (Shervashidze et al., Yanardag &amp; Vishwanathan, Niepert et al.) provide also the *standard deviation* along with the mean accuracy. This is important to know, since often (in particular for smaller data sets), there is a lot of overlap in terms of accuracy +- sdev.

Moreover, the reported accuracies are just not state of the art: the 2016 paper *On Valid Optimal Assignment Kernels and Applications to Graph Classification* by Kriege et al. describes a novel variant of the Weisfeiler-Lehman graph kernel, referred to as WL-OA. The reported accuracies +- sdev are as follows:

- NCI1: 86.1Â±0.2 (better than in the current paper)
- NCI109 86.3Â±0.2 (better than in the current paper)
- MUTAG: 86.0Â±1.7 (worse than in the current paper; WL instead of WL-OA)
- ENYZMES: 59.9Â±1.1 (worse than in the current paper)
- PROTEINS: 76.4Â±0.4 (better/equal to the current paper)
- COLLAB: 80.7Â±0.1 (better than in the current paper)

Even accounting for standard deviations, WL-OA appears to have a good 'safety margin' in terms of accuracy here. The claim that the new method 'wins by a large margin' here is thus flatly false.

Furthermore, I find the way results are reported somewhat misleading: since Table 1 shows the second-best result in bold, the Multigraph Chebnet results appear to be more important. At the very least,  the standard deviations have to reported, and the experimental setup should be described in more detail, because the graph kernel publications also clarify that they learn their parameters on an inner validation such that only training data is used for hyperparameter tuning. It is unclear whether the paper is following the same approach here.

# Minor issues

- p. 2: use a consistent notation for the real space, i.e. $\mathds{R}$ or $\mathbb{R}$
- p. 2: the justification of Eq. 1 could be phrased more succinctly: since $U$ is an orthogonal matrix, the convolution equation simplifies the way it is described; I find the description of '...property of eigendecomposition to eliminate computationally inconvenient eigenvectors' somewhat confusing
- I don't see the significance of Figure 1; it only expresses that matrix powers make eigenvalues smaller if $\lambda &lt; 1$ (this property of the Laplacian is not mentioned, by the way)
- p. 3: the notation for the number of relations is not optimal: $\Theta\in X_{in} K^R X_{out}$ should be rather rephrased as '$\Theta$ is a matrix of the following dimensions'
- The bibliography needs to be updated: there are some inconsistencies with respect to capitalization (such as in journal titles); also, at least the citation of Kipf &amp; Welling should be adjusted as it is *not* a pre-print any more but was published in ICLR 2017
- p. 3: Figure 2 needs a better explanation to be fully useful: its purpose appears to show that a 2D Chebyshev polynomial captures a different sort of information than a 2-hop filter because it does use information about different edge relations. Is this not clear from the onset since multi-hop filters operate only on a _single_ view of the graph?
- p. 3: Eq. 5 seems to be a Hadamard product, so another operator should be used (essentially a circle with a dot); at present, the operator is implying that one _composes_ features by first applying one filter, then another, and so on.

</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">3: Clear rejection</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_BJeBmYYEnm" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>An instance of spectral GCNs on multigraphs</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=ryxsCiAqKm&amp;noteId=BJeBmYYEnm"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper927 AnonReviewer3</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">29 Oct 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper927 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">This paper extends spectral GCN to multigraphs, in which graph size and structure may vary. It builds on Chebnets and extends it to graphs with several relations (more than one edge by pair of nodes).
While the paper is clearly written and is interesting, the contributions are rather incremental and the experimental section does not show a clear improvement wrt the state-of-the-art, neither a clear conclusion on the impact of learning the edges.

Minor comments regarding the experiments:
The experimental section may be improved in order to better demonstrate the value of the proposed method.
Authors use a standard setting for the experiments: 10 reps. of 10 nested CV on several benchmarked datasets. As pointed out by the authors, some of them contain few samples (mutag). Mean accuracies are reported, but standard deviations are also of interested (difficult to see if a method is better than an other one by comparing avg only). In addition, in table 1, some figures are missing (I believe this is because the methods have not been implemented by the authors). 
Regarding social graphs datasets, this is an issue as the results do not build on the same datasets (for multigraph chebnet, some features are added -- this is not the case for some competitors). 
Some experiments on a image classification context are also provided, but some competitive methods are not evaluated (e.g. PSCN). The bold/underlined+bold should be carefully checked as some wrong figures are highlighted.</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">4: Ok but not good enough - rejection</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_BygFudheqQ" class="note panel trashed"><div class="title_pdf_row clearfix"><h2 class="note_content_title">  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=ryxsCiAqKm&amp;noteId=BygFudheqQ"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">[Deleted]</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="item">ICLR 2019 Conference Paper927 Public Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></main></div>
  </div>
</div>


    <!-- Footer -->
    <footer class="sitemap">
      <div class="container">
        <div class="row hidden-xs">
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/venues">All Venues</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="/contact">Contact</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
    
        <div class="row visible-xs-block">
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/contact">Contact</a></li>
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
      </div>
    </footer>
    
    <footer class="sponsor">
      <div class="container">
        <div class="row">
          <div class="col-sm-10 col-sm-offset-1">
            <p class="text-center">
              OpenReview is created by the <a href="http://www.iesl.cs.umass.edu/" target="_blank">Information Extraction and Synthesis Laboratory</a>, College of Information and Computer Science, University of Massachusetts Amherst. We gratefully acknowledge the support of the OpenReview sponsors:  Google,  Facebook, NSF, the University of Massachusetts Amherst Center for Data Science, and Center for Intelligent Information Retrieval, as well as the Google Cloud Platform for donating the computing and networking services on which OpenReview.net runs.
            </p>
          </div>
        </div>
      </div>
    </footer>

  <div id="feedback-modal" class="modal fade" tabindex="-1" role="dialog">
    <div class="modal-dialog">
      <div class="modal-content">
        <div class="modal-header">
          <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">Ã—</span></button>
          <h3 class="modal-title">Send Feedback</h3>
        </div>
        <div class="modal-body">
          <p>Enter your feedback below and we'll get back to you as soon as possible.</p>
          <form action="/feedback" method="POST">
            <div class="form-group">
              <input type="email" name="from" class="form-control" placeholder="Email" />
            </div>
            <div class="form-group">
              <input type="text" name="subject" class="form-control" placeholder="Subject" />
            </div>
            <div class="form-group">
              <textarea name="message" class="form-control feedback-input" rows="5" placeholder="Message" required=""></textarea>
            </div>
          <ul id="ui-id-2" tabindex="0" class="ui-menu ui-widget ui-widget-content" style="display: none;"></ul></form>
        </div>
        <div class="modal-footer">
          <button type="button" class="btn btn-default" data-dismiss="modal">Cancel</button>
          <button type="button" class="btn btn-primary">Send</button>
        </div>
      </div>
    </div>
  </div>

  <script type="text/javascript" async="" src="https://www.google-analytics.com/analytics.js"></script><script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js"></script>
  <script>window.jQuery || document.write('&lt;script src="/static/js/vendor/jquery-2.2.4.min.js"&gt;&lt;\/script&gt;')</script>

  <script src="/static/dist/vendor.min.js"></script>
  <script src="/static/dist/templates.min.js"></script>
  <script src="/static/dist/openreview.min.js"></script>

    <script>window.legacyScripts = true;</script>


    <script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-108703919-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() { dataLayer.push(arguments); }
      gtag('js', new Date());
      gtag('config', 'UA-108703919-1');
    </script>


<div role="status" aria-live="assertive" aria-relevant="additions" class="ui-helper-hidden-accessible"></div></body></html>
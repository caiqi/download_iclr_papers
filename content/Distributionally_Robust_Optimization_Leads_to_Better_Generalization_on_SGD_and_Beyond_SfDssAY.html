<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" class="no-js"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>Distributionally Robust Optimization Leads to Better Generalization: on SGD and Beyond | OpenReview</title>
  <meta name="description" content="" />

      <meta name="citation_title" content="Distributionally Robust Optimization Leads to Better Generalization: on SGD and Beyond" />
        <meta name="citation_author" content="Anonymous" />
      <meta name="citation_publication_date" content="2018/09/27" />
      <meta name="citation_online_date" content="2018/09/27" />
      <meta name="citation_pdf_url" content="https://openreview.net/pdf?id=S1fDssA5Y7" />
      <meta name="twitter:card" content="summary" />
      <meta name="twitter:site" content="@openreviewnet" />
      <meta name="og:title" content="Distributionally Robust Optimization Leads to Better..." />
      <meta name="og:description" content="In this paper, we adopt distributionally robust optimization (DRO) in hope to achieve a better generalization in deep learning tasks. We establish the generalization guarantees and analyze the..." />
      <meta name="og:image" content="https://openreview.net/static/images/openreview_logo_512.png" />

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans:400,400i,700,700i" />

  <link rel="stylesheet" href="/static/css/bootstrap.min.css" />
  <link rel="stylesheet" href="/static/css/jquery-ui.min.css" />
  <link rel="stylesheet" href="/static/css/main.min.css" />
</head>

<body class="forum">
  <nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
  
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand home push-link" href="/"><strong>OpenReview</strong>.net</a>
      </div>
  
      <div id="navbar" class="navbar-collapse collapse">
        <form class="navbar-form navbar-left profile-search" role="search">
          <div class="form-group has-feedback">
            <input id="search_input" type="text" class="form-control ui-autocomplete-input" placeholder="Search ICLR 2019 Conference" autocomplete="off" />
            <span class="glyphicon glyphicon-search form-control-feedback" aria-hidden="true"></span>
          </div>
  
          <input id="search_group" type="hidden" value="ICLR.cc/2019/Conference" />
          <input id="search_content" type="hidden" value="all" />
        <ul id="ui-id-1" tabindex="0" class="ui-menu ui-widget ui-widget-content ui-autocomplete ui-front" style="display: none;"></ul></form>
  
        <ul class="nav navbar-nav navbar-right">
        
            <li id="user-menu"><a href="/login">Login</a></li>
        </ul>
      </div>
  
    </div>
  </nav>

  <div id="or-banner" class="banner" style="">
  <div class="container">
    <div class="row">
      <div class="col-xs-12"><a href="/group?id=ICLR.cc/2019/Conference" title="Venue Homepage"><img class="icon" src="/static/images/arrow_left.svg" /> Go to <strong>ICLR 2019 Conference</strong> homepage</a></div>
    </div>
  </div>
</div>
<div id="flash-message-container" class="alert alert-danger" role="alert" style="display: none;">
  <div class="container">
    <div class="row">
      <div class="col-xs-12">
        <div class="alert-content">
          <button type="button" class="close" aria-label="Close"><span aria-hidden="true">×</span></button>
        </div>
      </div>
    </div>
  </div>
</div>

<div class="container">
  <div class="row">
    <div class="col-xs-12">
      <main id="content" class="clearfix openbanner-visible legacy-styles"><div id="note_S1fDssA5Y7" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Distributionally Robust Optimization Leads to Better Generalization: on SGD and Beyond</a> <a class="note_content_pdf" href="/pdf?id=S1fDssA5Y7" title="Download PDF" target="_blank"><img src="/static/images/pdf_icon_blue.svg" /></a> </h2></div><div class="meta_row"><span class="signatures">Anonymous</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">28 Sep 2018 (modified: 11 Oct 2018)</span><span class="item">ICLR 2019 Conference Blind Submission</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span><span class="item"><a class="action-bibtex-modal" data-bibtex="@inproceedings{    &#10;anonymous2019distributionally,    &#10;title={Distributionally Robust Optimization Leads to Better Generalization: on SGD and Beyond},    &#10;author={Anonymous},    &#10;booktitle={Submitted to International Conference on Learning Representations},    &#10;year={2019},    &#10;url={https://openreview.net/forum?id=S1fDssA5Y7},    &#10;note={under review}    &#10;}">Show Bibtex</a></span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Abstract: </span><span class="note_content_value">In this paper, we adopt distributionally robust optimization (DRO) in hope to achieve a better generalization in deep learning tasks. We establish the generalization guarantees and analyze the localized Rademacher complexity for DRO, and conduct experiments to show that DRO obtains a better performance. We reveal the profound connection between SGD and DRO, i.e., selecting a batch can be viewed as choosing a distribution over the training set. From this perspective, we prove that SGD is prone to escape from bad stationary points and small batch SGD outperforms large batch SGD. We give an upper bound for the robust loss when SGD converges and keeps stable. We propose a novel Weighted SGD (WSGD) algorithm framework, which assigns high-variance weights to the data of the current batch. We devise a practical implement of WSGD that can directly optimize the robust loss. We test our algorithm on CIFAR-10 and CIFAR-100, and WSGD achieves significant improvements over the conventional SGD.</span></div><div class="note_contents"><span class="note_content_field">Keywords: </span><span class="note_content_value">distributionally robust optimization, deep learning, SGD, learning theory</span></div><div class="reply_row clearfix"><div class="item" id="reply_count">11 Replies</div></div></div><hr class="small" /><div id="note_children"><div class="note_with_children"><div id="note_r1gREiBIa7" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Good motivation but shaky theory, disconnected algorithm, and weak experiments.</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=S1fDssA5Y7&amp;noteId=r1gREiBIa7"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper630 AnonReviewer3</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">12 Nov 2018</span><span class="item">ICLR 2019 Conference Paper630 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">This paper motivates performing a “robustified” version of SGD. It attempts to formalize this notion, proves some variants of generalization bounds, and proposes an algorithm that claims to implement such a modified SGD.

The clarity of the paper can be improved. There are several notational and language ambiguities throughout. Most importantly, a couple of paragraphs that are meant to convey key intuitions about the results are very badly written (the one following Theorem 1, the one preceding Theorem 2, the last one in Section 5.1, and the one preceding Theorem 5, more on these later).

Apart from these clarity issues, the significance of the results is weak. This is because although the technical statements seem correct, the leap from them to measurable outcomes (such as actual generalization bounds) are missing. Part of this is due to a lack of a good notion of “true” robust risk. Moreover the algorithmic contribution does not connect well with the suggested theory and the experimental results are modest at best. Here is a more detailed breakdown of my objections.

-	The notion of distributional robust loss is sound, i.e. R(\theta, K). Its empirical variant is also good, \hat{R}(\theta, K). But the notion of robust loss defined in the paper, \hat R_{S,P}(\theta) with the weights on the samples, breaks from this notion. The reason is that in the former case the weights depend on the value of the sample (z) whereas in the latter they depend on the index (i). It is not evident how to map one to the other.

-	This makes the question of what is the “true” robust risk unclear. It is tempting to simply say it is its expectation with respect to a generic sample. This is the view taken in Theorem 3, which offers a kind of generalization bound. But if one looks carefully at this, the location of the expectation and supremum should be swapped. Here is an alternative view: if want to think of the infinite sample limit, then we need to have a sequence of robustness classes P_m, that vary with m (say those that put weight only on a q-fraction of the samples, just like in the suggested WSGD). The “true” robust risk would be the limit of the sup of the empirical risk, this keeps the sup and expectation in the right order. Under the right conditions, this limit would indeed exist. And it is difficult to know, for a given m, how *far* the generic-sample expectation of Theorem 3 is from it. Without this knowledge, it is difficult to interpret Theorem 3 as a generalization bound.

-	Theorem 1 itself is a standard result. The discussion after Theorem 1 is the kind of argument that also explains Fisher information, and can be presented more clearly. I’m not sure whether Theorem 2 exactly proves what the paragraph before it is trying to explain. The fact that SGD converges into the ball seems contrived, since the quantities that we are trying to bound have nothing to do with the optimization method. If the optimum is within the ball (+/- something) then the same result should hold with the step size replaced with the (+/- something). So how does this explain escaping stationary points?

-	If we accept Theorem 3 as a generalization bound, alongside with the Rademacher bounds of Theorem 4, I don’t think the paper treats the balance between the various terms adequately enough. In particular we see that the |P|_\infty term in Theorem 3 has to balance out the (robust) Rademacher bound, and need it to be of the order of (1+RAD_2(P)\sqrt{\log N}/m). For P that puts weight k over 1/k points, |P|_\infty = 1/k. RAD_2(P) is bounded by 1/\sqrt{k}, so it’s negligible next to 1. But the covering number N can grow exponentially with k (when it’s not too large, and for small \epsilon, just by counting arguments). So this seems to say that for a good tradeoff in the bounds will lead to k having to be a growing fraction of m. This intuition, if true, is not presented. Not only that, but it also goes against the suggested approach of choosing some constant fraction of m.

-	Theorem 5 gives a local Rademacher complexity. But again there is a conceptual step missing from this to strong generalization bounds, partly because we are not exactly minimizing the empirical risk within the considered class. Also, the discussion that follows bounding the rad_\infty with |P|_\infty is deficient, because it misses again the fact there are two salient terms that need to balance out.

-	Algorithm 1 (WSGD) needs to specify (q,r) and which G (G_1 or G_2) as inputs too.

-	Most importantly, WSGD does not seem to be minimizing the robust risk at all. First, I’m not really sure what the G_1 variant does. If we were to follow the intuition of Theorem 1, we should be looking at the gradients, not the loss values. As for G_2, by sampling we are in fact replacing the sup over p with an average over P. This can have a significantly different behavior, and we could possibly interpret it as a slightly reduced effective batch size, especially in the case of G_2. In fact, in the experiments, when r is set to 0, this is exactly what is happening! At any rate, it is not clear at all how any of the earlier sections connect with sections 6 or 7.

-	In the experimental section it is not clarified which of the latter two is used (I assume G_2, the randomized one, given the discussion in the end of Section 6.) When the authors write “accuracy improvement”, they should more clearly say “relative decrease in misclassification error”. That’s the only thing that makes sense with the numbers, and if it does in fact  the authors mistakenly say that the 5-15% improvement is for CIFAR 100 and the 5% is for CIFAR 10, it’s the other way around! And the exception (least) improvement seems to be ResNet-34 on CIFAR-100 (not VGG-16, as they claim, unless the table is wrong.) All in all, these are all pretty weak results, albeit consistent. A better benchmark would have been to compare against various batch sizes, and somehow show that the results do *not* follow from batch size effects.
</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">4: Ok but not good enough - rejection</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_SkxDmWLphX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Interesting connection between SGD and DRO, but writing and experiments need more clarity</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=S1fDssA5Y7&amp;noteId=SkxDmWLphX"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper630 AnonReviewer1</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">05 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper630 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">
This paper consider the connections between SGD and distributionally robust optimization. There has long been observed a connection between robust optimization and generalization. Recently, this has been explored through the lens of distributionally robust optimization. e.g., in the papers of Namkoong and Duchi, but also many others, e.g., Farnia and Tse, etc. Primarily, this paper appears to build off the work of Namkoong. 

The key connection this paper tries to make is between SGD and DRO, since SGD in sampling a minibatch, can be considered a small perturbation to the distribution. Therefore the authors use this intuition to propose a weighted version of SGD (WSGD) whereby high variance weights are assigned to mini batch, thus making the training accomplish a higher level of distributional robustness. 

This idea is tested on a few data sets including CIFAR-10 and -100. The results compare WSGD with SGD, and they show that the WSGD-trained models have a lower robust loss, and also have a higher (testing) accuracy. 

This is an interesting paper. There has been much discussion of the role of batch size, and considering it from a different perspective seems to be of interest. But the connection of the empirical results to the theoretical results seems tenuous. It’s not clear how predictions of the theory match up. This would be useful to understand better. More generally, a simpler presentation of the key results would be useful, so as to allow the reader to better appreciate what are the main claims and if they are as substantial as claimed. Overall the writing needs significant polishing, though this is only at a local level, i.e, it doesn’t obscure the flow of the paper. </span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">5: Marginally below acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_rJlmXAkAY7" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>DRO applied to classification</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=S1fDssA5Y7&amp;noteId=rJlmXAkAY7"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures"><a href="/profile?id=~Weihua_Hu1" class="profile-link">Weihua Hu</a></span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">30 Sep 2018 (modified: 01 Oct 2018)</span><span class="item">ICLR 2019 Conference Paper630 Public Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Our ICML 2018 paper "Does Distributionally Robust Supervised Learning Give Robust Classifier?" analyzed DRO applied to classification and showed several negative results about it. The key to show our results is that in classification, the 0-1 loss is used for testing, which is different from a surrogate loss used for training.
Link: <a href="http://proceedings.mlr.press/v80/hu18a/hu18a.pdf" target="_blank" rel="nofollow">http://proceedings.mlr.press/v80/hu18a/hu18a.pdf</a>

It would be great to have discussion on our paper as your empirical evaluation is on classification tasks.</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_S1lr7gmJcX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Thank you for the feedback</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=S1fDssA5Y7&amp;noteId=S1lr7gmJcX"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper630 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">01 Oct 2018</span><span class="item">ICLR 2019 Conference Paper630 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Thank you for the feedback. We have carefully read your work before, but we think there is no conflict between your work and ours. In our understanding, your work compared ERM and DRO with 0-1 loss and with surrogate loss. However, in our paper we don’t deal with ERM loss at all. 

It is true that in classification, the 0-1 loss is used for testing, which is different from a surrogate loss used for training. However, the problem you pointed out is also a problem for ERM. If we write a article “Does Empirical Risk Minimization Give Effective Classifier?”, how will you response us? In classification, we normally think that optimizing an object function with surrogate loss such as cross-entropy will give a solution that performs well when tested with 0-1 loss. Last but not least, our algorithm really performs better than normal SGD on classification tasks in our experiment.</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_B1lZOdyx5Q" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Reply</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=S1fDssA5Y7&amp;noteId=B1lZOdyx5Q"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures"><a href="/profile?id=~Weihua_Hu1" class="profile-link">Weihua Hu</a></span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">02 Oct 2018</span><span class="item">ICLR 2019 Conference Paper630 Public Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">For sure, I agree that ERM with a surrogate loss empirically gives a good classifier when tested with the 0-1 loss, which is also supported by the theory of classification calibration loss.  What our paper shows is that DRO applied to classification gives (almost) the same classifier as the ERM (in terms of the 0-1 loss). Empirically, DRO can even be worse than the ERM because it puts large weights on large losses and thus can be extremely sensitive to outliers. 

I trust your empirical results as well as your theoretical results, but what I want to emphasize here is that there is a huge gap between "small surrogate loss" and "small 0-1 loss (what we really care about)", and we need to be especially careful about this gap when dealing with DRO applied to classification!</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_SkgPhovg57" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Reply</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=S1fDssA5Y7&amp;noteId=SkgPhovg57"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper630 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">02 Oct 2018</span><span class="item">ICLR 2019 Conference Paper630 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">I get your point. Actually we have different views on the data with large losses. The steeper loss function you constructed in your paper can be viewed as a loss function enlarging the gradient (and thus put large weights) of data with large loss. You think that data with large loss may be outliers and can do harm to our model. But I think that large losses reflect a drawback of the model and thus we should pay more attention to those data. In fact,  both of the views can be true in practice, but we can't distinguish without extra domain knowledge. The main idea of our paper is that if the sample is of high quality (few outliers), we should pay more attention to individual instance. By the way, the algorithm in our paper is not based on f-divergence, and the steeper loss may be not applicable to our algorithm.</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_r1eMXmYl57" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Reply</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=S1fDssA5Y7&amp;noteId=r1eMXmYl57"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures"><a href="/profile?id=~Weihua_Hu1" class="profile-link">Weihua Hu</a></span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">02 Oct 2018</span><span class="item">ICLR 2019 Conference Paper630 Public Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">&gt; By the way, the algorithm in our paper is not based on f-divergence, and the steeper loss may be not applicable to our algorithm.
Our steepness result holds as long as the larger weights are assigned to larger losses. However, I am not sure what will happen if the mini-batch losses are reweighted, which is the focus of your paper.

&gt;  The main idea of our paper is that if the sample is of high quality (no outliers), we should pay more attention to individual instance.
I see your point, but I have to say that that is a very strict assumption considering the real-world applications.

&gt;  But I think that large losses reflect a drawback of the model and thus we should pay more attention to those data.
As DNNs often overfit the training data (achieve 0 training error) eventually, why do we need to pay attention to large loss data during training?
Even when DNNs do not have enough capacity to overfit the training data, paying more attention to large surrogate loss will inevitably increase the surrogate loss of other data, which may increase the overall misclassification rate (measured by 0-1 loss). What do you think about this point?</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_Skgpnjql9X" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Reply</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=S1fDssA5Y7&amp;noteId=Skgpnjql9X"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper630 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">02 Oct 2018</span><span class="item">ICLR 2019 Conference Paper630 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">In fact, we just take advantage of of the capacity of DNNs. Due to the strong capacity of DNNs, we can pay more attention to large surrogate loss without increasing the surrogate loss of other data too much. 

We have clarified the necessity to do DRO in our introduction section. I agree that there exists some outliers in the dataset. However, if you want to talk about outliers, you have to introduce extra domain knowledge. Suppose you have trained a model using the dataset, you can't say that the data with large loss (calculated by the model you trained) are outliers. They can be high-quality data which you didn't fit well and the real outliers can have small loss. It is entirely possible that to fit the large loss data is doing regularization on the model and alleviate overfitting.

The last thing I want to say is the number of outliers. Strictly speaking, it depends on your measure. In our experiment, we found that about 0.01%-0.1% of the data in CIFAR are outliers. However, what we actually do by DRO is to pay more attention to the data with top 10% or 50% (roughly speaking) loss, and the effect of outliers is negligible. Actually what we do have achieved a good performance.</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_Skg4rIslqm" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Thanks!</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=S1fDssA5Y7&amp;noteId=Skg4rIslqm"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures"><a href="/profile?id=~Weihua_Hu1" class="profile-link">Weihua Hu</a></span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">02 Oct 2018</span><span class="item">ICLR 2019 Conference Paper630 Public Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">I see your points. Thanks for your discussion!

I think it useful to have training curves in your paper, comparing SGD and WSGD. Intuitively, WSGD may speed up the convergence, but SGD should also achieve 0 training loss eventually. If this is the case, it is mysterious to me why WSGD generalizes better than SGD. Maybe there is inductive bias in WSGD?

Also, CIFAR is just a benchmark dataset; that's why it is clean.</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_HJlGy6ogqQ" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Reply</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=S1fDssA5Y7&amp;noteId=HJlGy6ogqQ"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper630 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">02 Oct 2018</span><span class="item">ICLR 2019 Conference Paper630 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">We sincerely thank you for your discussion. We haven't provided the training curve in our paper because of the paper length. Empirically speaking, WSGD doesn't markedly speed up the convergence, but it achieves a lower robust loss eventually (we use cross-entropy loss). 

The point we want to emphasize in this paper is that an optimization algorithm in deep learning is not only an optimizer but also a minima selector. We propose WSGD because it has better performance in minima selecting.

In the end, we wish to express our thanks for your patient discussion again!</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_BJg0BCNW9Q" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Thanks!</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=S1fDssA5Y7&amp;noteId=BJg0BCNW9Q"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures"><a href="/profile?id=~Weihua_Hu1" class="profile-link">Weihua Hu</a></span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">03 Oct 2018</span><span class="item">ICLR 2019 Conference Paper630 Public Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Thanks for your discussion!
The aspect of minima selector is something our paper did not consider; we basically considered the convex scenario and provided analyses for the global solution of DRO. 

I think it would be extremely helpful to have some discussion on our paper and make the distinction clear. Thanks!</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></main></div>
  </div>
</div>


    <!-- Footer -->
    <footer class="sitemap">
      <div class="container">
        <div class="row hidden-xs">
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/venues">All Venues</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="/contact">Contact</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
    
        <div class="row visible-xs-block">
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/contact">Contact</a></li>
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
      </div>
    </footer>
    
    <footer class="sponsor">
      <div class="container">
        <div class="row">
          <div class="col-sm-10 col-sm-offset-1">
            <p class="text-center">
              OpenReview is created by the <a href="http://www.iesl.cs.umass.edu/" target="_blank">Information Extraction and Synthesis Laboratory</a>, College of Information and Computer Science, University of Massachusetts Amherst. We gratefully acknowledge the support of the OpenReview sponsors:  Google,  Facebook, NSF, the University of Massachusetts Amherst Center for Data Science, and Center for Intelligent Information Retrieval, as well as the Google Cloud Platform for donating the computing and networking services on which OpenReview.net runs.
            </p>
          </div>
        </div>
      </div>
    </footer>

  <div id="feedback-modal" class="modal fade" tabindex="-1" role="dialog">
    <div class="modal-dialog">
      <div class="modal-content">
        <div class="modal-header">
          <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button>
          <h3 class="modal-title">Send Feedback</h3>
        </div>
        <div class="modal-body">
          <p>Enter your feedback below and we'll get back to you as soon as possible.</p>
          <form action="/feedback" method="POST">
            <div class="form-group">
              <input type="email" name="from" class="form-control" placeholder="Email" />
            </div>
            <div class="form-group">
              <input type="text" name="subject" class="form-control" placeholder="Subject" />
            </div>
            <div class="form-group">
              <textarea name="message" class="form-control feedback-input" rows="5" placeholder="Message" required=""></textarea>
            </div>
          <ul id="ui-id-2" tabindex="0" class="ui-menu ui-widget ui-widget-content" style="display: none;"></ul></form>
        </div>
        <div class="modal-footer">
          <button type="button" class="btn btn-default" data-dismiss="modal">Cancel</button>
          <button type="button" class="btn btn-primary">Send</button>
        </div>
      </div>
    </div>
  </div>

  <script type="text/javascript" async="" src="https://www.google-analytics.com/analytics.js"></script><script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js"></script>
  <script>window.jQuery || document.write('&lt;script src="/static/js/vendor/jquery-2.2.4.min.js"&gt;&lt;\/script&gt;')</script>

  <script src="/static/dist/vendor.min.js"></script>
  <script src="/static/dist/templates.min.js"></script>
  <script src="/static/dist/openreview.min.js"></script>

    <script>window.legacyScripts = true;</script>


    <script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-108703919-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() { dataLayer.push(arguments); }
      gtag('js', new Date());
      gtag('config', 'UA-108703919-1');
    </script>


<div role="status" aria-live="assertive" aria-relevant="additions" class="ui-helper-hidden-accessible"></div></body></html>
<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" class="no-js"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>Pearl: Prototype lEArning via Rule Lists | OpenReview</title>
  <meta name="description" content="" />

      <meta name="citation_title" content="Pearl: Prototype lEArning via Rule Lists" />
        <meta name="citation_author" content="Anonymous" />
      <meta name="citation_publication_date" content="2018/09/27" />
      <meta name="citation_online_date" content="2018/09/27" />
      <meta name="citation_pdf_url" content="https://openreview.net/pdf?id=r1gnQ20qYX" />
      <meta name="twitter:card" content="summary" />
      <meta name="twitter:site" content="@openreviewnet" />
      <meta name="og:title" content="Pearl: Prototype lEArning via Rule Lists" />
      <meta name="og:description" content="Deep neural networks have demonstrated promising classification performance on many healthcare applications. However, the interpretability of those models are often lacking. On the other hand..." />
      <meta name="og:image" content="https://openreview.net/static/images/openreview_logo_512.png" />

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans:400,400i,700,700i" />

  <link rel="stylesheet" href="/static/css/bootstrap.min.css" />
  <link rel="stylesheet" href="/static/css/jquery-ui.min.css" />
  <link rel="stylesheet" href="/static/css/main.min.css" />
</head>

<body class="forum">
  <nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
  
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand home push-link" href="/"><strong>OpenReview</strong>.net</a>
      </div>
  
      <div id="navbar" class="navbar-collapse collapse">
        <form class="navbar-form navbar-left profile-search" role="search">
          <div class="form-group has-feedback">
            <input id="search_input" type="text" class="form-control ui-autocomplete-input" placeholder="Search ICLR 2019 Conference" autocomplete="off" />
            <span class="glyphicon glyphicon-search form-control-feedback" aria-hidden="true"></span>
          </div>
  
          <input id="search_group" type="hidden" value="ICLR.cc/2019/Conference" />
          <input id="search_content" type="hidden" value="all" />
        <ul id="ui-id-1" tabindex="0" class="ui-menu ui-widget ui-widget-content ui-autocomplete ui-front" style="display: none;"></ul></form>
  
        <ul class="nav navbar-nav navbar-right">
        
            <li id="user-menu"><a href="/login">Login</a></li>
        </ul>
      </div>
  
    </div>
  </nav>

  <div id="or-banner" class="banner" style="">
  <div class="container">
    <div class="row">
      <div class="col-xs-12"><a href="/group?id=ICLR.cc/2019/Conference" title="Venue Homepage"><img class="icon" src="/static/images/arrow_left.svg" /> Go to <strong>ICLR 2019 Conference</strong> homepage</a></div>
    </div>
  </div>
</div>
<div id="flash-message-container" class="alert alert-danger" role="alert" style="display: none;">
  <div class="container">
    <div class="row">
      <div class="col-xs-12">
        <div class="alert-content">
          <button type="button" class="close" aria-label="Close"><span aria-hidden="true">Ã—</span></button>
        </div>
      </div>
    </div>
  </div>
</div>

<div class="container">
  <div class="row">
    <div class="col-xs-12">
      <main id="content" class="clearfix openbanner-visible legacy-styles"><div id="note_r1gnQ20qYX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Pearl: Prototype lEArning via Rule Lists</a> <a class="note_content_pdf" href="/pdf?id=r1gnQ20qYX" title="Download PDF" target="_blank"><img src="/static/images/pdf_icon_blue.svg" /></a> </h2></div><div class="meta_row"><span class="signatures">Anonymous</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">28 Sep 2018 (modified: 11 Oct 2018)</span><span class="item">ICLR 2019 Conference Blind Submission</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span><span class="item"><a class="action-bibtex-modal" data-bibtex="@inproceedings{    &#10;anonymous2019pearl:,    &#10;title={Pearl: Prototype lEArning via Rule Lists},    &#10;author={Anonymous},    &#10;booktitle={Submitted to International Conference on Learning Representations},    &#10;year={2019},    &#10;url={https://openreview.net/forum?id=r1gnQ20qYX},    &#10;note={under review}    &#10;}">Show Bibtex</a></span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Abstract: </span><span class="note_content_value">Deep neural networks have demonstrated promising classification performance on many healthcare applications. However, the interpretability of those models are often lacking. On the other hand, classical interpretable models such as rule lists or decision trees do not lead to the same level of accuracy as deep neural networks. Despite their interpretable structures, the resulting rules are often too complex to be interpretable (due to the potentially large depth of rule lists). In this work, we present PEARL, short for Prototype lEArning via Rule Lists, which iteratively use rule lists to guide a neural network to learn representative data prototypes. The resulting prototype neural network provides  accurate prediction, and the prediction can be easily explained by  prototype and its guiding rule lists. Thanks to the prediction power of neural networks, the rule lists defining prototypes are more concise and hence provide better interpretability. On two real-world electronic healthcare records (EHR) datasets, PEARL consistently outperforms all baselines,  achieving performance improvement over conventional rule learning by up to 28% and over prototype learning by up to 3%. Experimental results also show the resulting interpretation of PEARL is simpler than the standard rule learning.</span></div><div class="note_contents"><span class="note_content_field">Keywords: </span><span class="note_content_value">rule list learning, prototype learning, interpretability, healthcare</span></div><div class="note_contents"><span class="note_content_field">TL;DR: </span><span class="note_content_value">a method combining rule list learning and prototype learning </span></div><div class="reply_row clearfix"><div class="item" id="reply_count">3 Replies</div></div></div><hr class="small" /><div id="note_children"><div class="note_with_children"><div id="note_Syg5kyhS6X" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Interesting idea but needs significant improvement in terms of presentation and design of method and experiments</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=r1gnQ20qYX&amp;noteId=Syg5kyhS6X"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1394 AnonReviewer2</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">11 Nov 2018</span><span class="item">ICLR 2019 Conference Paper1394 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">Summary: 
This paper presents a new interpretable prediction framework which combines rule based learning, prototype learning, and NNs. The method is particularly applicable to longitudinal data. While the idea of bringing together rules, prototypes, and NNs is definitely novel, the method itself has some unclear design choices. Furthermore, the experiments seem pretty rudimentary and the presentation can be significantly improved. 

Detailed Comments: 
1. In Section 2, the authors seem to define rule list as a set of independent if-then rules. Please note that rule lists have an "else if" clause which creates a dependency between the rules. Please refer to "Interpretable decision sets" by Lakkaraju et. al. for understanding the differences between rule lists and rule sets. 
2. Section 3.1 is quite confusing. It would be good to give an intuition as to how the various pieces are being combined and in why it makes sense to combine them in this way. The data reweighting process seems a bit adhoc to me. What other choices for reweighting were considered?
3. I would strongly encourage the authors to carry out at least a simple user study before claiming that the proposed method is more interpretable than existing rule lists. Adding both prototypes and rules, in fact, adds to the cognitive burden of an end user - it would be interesting to see when and how having both prototypes and rules will help an end user. 

Pros:
1. First approach to combine NNs, rule learning, prototype learning
2. Provides an interpretable method for predictions on longitudinal medical data
3. Experimental results seem to suggest that the proposed approach is resulting in accurate and interpretable models.

Cons:
1. The various pieces in the method (rule learning, prototype, NNs, data reweighting) seem to be somewhat haphazardly connected. Section 3.1 does not give me a good idea about how the different pieces are resulting in an accurate and interpretable model
2. The paper makes claims such as "Experimental results also show the resulting interpretation
of PEARL is simpler than the standard rule learning." without actually doing any significant user studies. Furthermore, any other synthetic data experiments which could demonstrate the various facets of accuracy-interpretability tradeoffs are missing
3. The presentation of the paper is quite unclear. See detailed comments above. 
</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">5: Marginally below acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_SJx0XuLc3Q" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Interpretability insufficiently defined</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=r1gnQ20qYX&amp;noteId=SJx0XuLc3Q"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1394 AnonReviewer1</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">03 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper1394 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">This paper aims at tackling the lack of interpretability of deep learning models, which is especially problematic in a healthcare setting --the focus of this research paper. Specifically, the authors propose Prototype lEArning via Rule Lists (PEARL), which combines rule learning and prototype learning to achieve more accurate classification and better predictive power than either method independently and which the authors claim makes the task of interpretability simpler.  
The authors present an interesting and novel architecture in PEARL. Combining the two approaches of rule lists and prototype learning. However, my main concern with the paper and with the architecture in general is the lack of clarity upfront regarding what the authors perceive as the criteria for interpretability. This seems to be one of the chief aims of the paper, however, the authors donâ€™t reach this point until Section 4 of the paper. Given that this is one of the main strengths of the paper as proposed by the authors, this needs to be given more prominence and also needs to be made more explicit what the authors mean by this. The authors define interpretability as measured by the number of rules and number of protoypes identified by a particular model, without, providing an argument, justification, or a citation of previous work which justifies these criterion. Especially since this is one of the main points of the paper, this needs to be better argued and the authors should either elaborate on this point, or restrain on making claims that these models are more interpretable.
The model architecture of Section 3.1 was quite obscure both from the intuitive and implementation level. Itâ€™s not clear how the different modules (prototype learning, rule lists) link together in practice, nor how these come together to create an interpretable model.
Generally, the paper is quite poorly structured and there were several grammatical errors which made the paper quite hard to follow. Although the problems articulated are important, the paper did not do sufficient justice to addressing these problems. 
</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">3: Clear rejection</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">3: The reviewer is fairly confident that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_HJgb6MBq2m" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Needs more thorough evaluation, more justification of design choices, and improvement in presentation clarity</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=r1gnQ20qYX&amp;noteId=HJgb6MBq2m"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1394 AnonReviewer3</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">03 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper1394 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">

Review Summary
--------------
The paper presents a combination of rule lists, prototypes, and deep representation learning to fit classifiers that are said to be simultaneously "accurate" and "interpretable". While the topic is interesting and the direction seems novel, I don't think the work is quite polished or competitive enough to be accepted without significant revision. The major issues include non-competitive evaluation of what "interpretability" means, ROC AUC numbers that are indistinguishable from standard deep learning (RCNN) pipelines that use many fewer parameters, and many unjustified choices inside the method itself. The paper itself could also benefit from revision to improve flow and introduce technical ideas to be more accessible to readers.


Paper Summary
-------------
The paper presents a new method called "PEARL" (Prototype Learning via Rule Lists), which produces a rule list, a set of prototypes, and a deep feed-forward neural network that can embed any input data into a low-dimensional feature space. The primary intended application is classifying subjects into a finite set of possible disorders given longitudinal electronic health records with categorical features observed at T irregular time intervals. 

The paper suggests learning a representation for each subject's data by feeding the EHR time series into a recurrent convolutional NN. The input data is a 2 x T array, with one row representing observed data and second row giving time delay between successive observations. The vector output of an initial convolutional RNN is then fed into a highway network to produce a final vector denoted "h". 

Given an encoder to produce feature vectors, and a fixed rule list learned from data itself, the paper suggests obtaining a prototype for each rule by computing the average vector of all data that matches the given rule. The quality of these prototypes and related neural networks (for computing features and predicting labels from features) is then assessed via their loss function in Eq. 1: a weighted combination of how well the prototypes match the learned embeddings (distance to closest prototype) and how well the classifier predicts labels.  The core idea is that the embedding is learned to classify well while creating a latent space that looks like the prototypes of the rule list.

After training an embedding and NN classifier on a fixed rule list, it seems the data is reweighted according to some heuristic procedure to obtain better properties, then a new rule list is trained and the process repeats again. (I admit the reweight procedure's purpose was never clear to me).

Experiments are done on a proprietary heart failure EHR dataset and on a subset of MIMIC data. 

Strengths
---------
* Seems original: I'm unaware of any other method connecting rule lists AND prototypes AND NNs
* Neat applications to healthcare

Limitations
-----------
* Interpretability evaluation seems weak: no human subject experiments, no quantiative metrics, unclear if rule-lists shown is an apples-to-apples comparison
* Prototypes themselves never evaluated 
* Many design choices inside method not justified with experiments -- why highway networks + RCNNs?

Major Issues with Method
------------------------

## M1: Not clear that AUC difference between PEARL and baselines is significant

The major issue is that the presented approach does not seem significantly different in predictive performance than the baseline Recurrent CNN. Comparing ROC AUC, we have PEARL's 0.688 to RCNN'S 0.682 with stddev of 0.009 on the proprietary heart failure dataset, and PEARL's 0.769 to RCNN's 0.766 with stddev of 0.009. When AUCs match this closely, I struggle to believe one model is definitively better, especially given that the RCNN has 2x *fewer* parameters (8.4k to 18.4k). 

If the counterargument is that the resulting "deep model" is not "interpretable", one should at least compare to a post-processing step where the decision boundary of the RCNN is the reference to which a rule list or decision tree is trained.

## M2: Interpretability evaluation not clear.

Isn't the maximum number of rules set in advance? 

Additionally, prototypes are a key part of this work, but the learned prototypes are not evaluated at all in any figure (except to track avg. distance from prototype while training). If prototypes are so central to this work, I would like to see a formal evaluation of whether the learned prototypes are indeed better (in terms of distance, or inspection of values by an expert, or something else) than alternatives like Li et al.

## M3: Missing a good synthetic/small dataset experiment

Neither of the presented data tasks is particularly easy to understand for non-experts. I'd suggest creating an additional experiment where the audience of ML readers is likely to easily grasp whether a set of rule lists is "good" for the problem at hand... maybe create your own synthetic task or a UCI dataset or something, or even use the stop-and-frisk crime dataset from the Angelino et al. 2018 paper. Then you can compare against just a few relevant baselines (rule lists only or prototypes only). I think a better illustrative experiment will help readers grasp differences between methods. 

## M4: How crucial is feature selection?

In each iteration, Algo. 1 performs feature selection before learning rules. Are any other baselines (trees, rule lists) allowed feature selection before the classifier is learned? What would happen to PEARL without feature selection? What method is used for selection? (A search of the document only has 'feature selection' occur once, in the Alg. itself, so it seems explanation is missing).

## M5: Why are multiple algorithm iterations needed?

Won't steps 3 and 4 of Alg. 1 result in the same rules every time? It's not clear then why on subsequent iterations the algorithm would improve. Perhaps it's just the reweighting of data that causes these steps to change?

Minor issues
------------

## Loss function notation confusing

Doesn't the rule list classifier s_R take the data itself X? Not the learned embedding h(X)? Please fix or clarify Eq. 1. I think you might clarify notation by just writing yhat(h(X)) if you mean the predicted label of some example as done by your NNs. Using "R" makes folks think the rule list is involved.

## Not clear why per-example reweighting is required

None of the experiments assess why per-example reweighting (lines 6-9 of Algo. 1) is required. Readers would like to see a comparison of performance with and without this step.

## Not clear or justified when "averaged" prototypes are acceptable

Are your "averaged" prototypes guaranteed to satisfy the rule they represent? Is taking the average of vectors that match a rule always guaranteed to also match the rule? I don't think this is necessarily true. Consider a rule that says "if x[0] == 0 or x[1] == 0, then ___".  Suppose the only matching vectors are x_A = [0 1] and x_B = [1 0]. The average vector is [0.5 0.5] which doesn't work.

## Several different measures of distance used without careful justification 

Why use two different distances -- Euclidean distance to assess distance to prototypes for prototype assignment, and then cosine similarity when deciding which examples to upweight or downweight? Why not just use Euclidean distance for both (appropriately transformed to a similarity)?

Comments on Presentation
------------------------
Overall I think every section of the paper needs significant revision to improve a reader's ability to understand main ideas. Notation could be introduced slowly (explain purpose and dimension of every variable), assumptions could be clearly stated (e.g. each individual rule can have ANDs but not ORs), and design choices justified. You might try the test of giving the paper to a colleague and having them explain back the ideas of each section to you... currently I do not believe this version passes this test.

The introduction claims that "clinicians are often unwilling to accept algorithm recommendations without clarity as to the underlying reasoning", but I would be careful in blindly asserting this without evidence. For a nice argument about avoiding blind assumptions about what doctor's will and won't accept, see Lipton's 2017 paper "The Doctor Just Won't Accept That" (<a href="https://arxiv.org/abs/1711.08037)" target="_blank" rel="nofollow">https://arxiv.org/abs/1711.08037)</a>

Additionally, the authors should clarify more precisely what definition of interpretability is needed for their applications. Is it simplicity? Is it conceptual alignment with known medical facts? Is it the ability to transparently list the rules in plain English?

Line-by-line details
--------------------

## Sec. 2

When introducing p_j, should clarify this this is one prototype vector of many.

When defining p_j = f_j(X), can you clarify what dimensionality p_j has? Is it always the same size as each example's data vector x_i?


## Sec. 3

Fig. 2: I don't find this figure very easy-to-understand. It's clear that after embedding raw features to a new space, the learned rules are *different*, but it's not clear they are *better*.  None of the illustrated rules perfectly segments the different colors, for example. I guess the point is all the red dots are within one rule? But they aren't alone (there are blue and orange dots too), so it's still not clear this would be a better classifier.

For EHR datasets, are you assuming that events are always categorical? And that outcomes "y" are always discrete (one-of-L) variables? Or could y be real-valued?

Eq. 1: You should make notation clearly indicate which terms depend on \theta. Currently it seems that nothing is a function of \theta.

Eq. 1: Do you also find the prototype set P that minimizes this objective? Or is there another way to obtain P given parameters \theta? This is confusing just from reading the eqn.

What size is the learned representation h(X)? Is it a vector?

Eq. 6: Do you really need a "network" to compute the distance to each of the K prototypes? Can't you just compute these distances directly?

## Sec 4

"Mac OS 1.4" : Do you mean Mac OS version 10.4? Not clear this is relevant.

4.3 Case Study: How do I read these rules? Is this rule applied only if ALL conditions are true? or if any individual one is true ("or")? This is unclear.</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">4: Ok but not good enough - rejection</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></main></div>
  </div>
</div>


    <!-- Footer -->
    <footer class="sitemap">
      <div class="container">
        <div class="row hidden-xs">
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/venues">All Venues</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="/contact">Contact</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
    
        <div class="row visible-xs-block">
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/contact">Contact</a></li>
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
      </div>
    </footer>
    
    <footer class="sponsor">
      <div class="container">
        <div class="row">
          <div class="col-sm-10 col-sm-offset-1">
            <p class="text-center">
              OpenReview is created by the <a href="http://www.iesl.cs.umass.edu/" target="_blank">Information Extraction and Synthesis Laboratory</a>, College of Information and Computer Science, University of Massachusetts Amherst. We gratefully acknowledge the support of the OpenReview sponsors:  Google,  Facebook, NSF, the University of Massachusetts Amherst Center for Data Science, and Center for Intelligent Information Retrieval, as well as the Google Cloud Platform for donating the computing and networking services on which OpenReview.net runs.
            </p>
          </div>
        </div>
      </div>
    </footer>

  <div id="feedback-modal" class="modal fade" tabindex="-1" role="dialog">
    <div class="modal-dialog">
      <div class="modal-content">
        <div class="modal-header">
          <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">Ã—</span></button>
          <h3 class="modal-title">Send Feedback</h3>
        </div>
        <div class="modal-body">
          <p>Enter your feedback below and we'll get back to you as soon as possible.</p>
          <form action="/feedback" method="POST">
            <div class="form-group">
              <input type="email" name="from" class="form-control" placeholder="Email" />
            </div>
            <div class="form-group">
              <input type="text" name="subject" class="form-control" placeholder="Subject" />
            </div>
            <div class="form-group">
              <textarea name="message" class="form-control feedback-input" rows="5" placeholder="Message" required=""></textarea>
            </div>
          <ul id="ui-id-2" tabindex="0" class="ui-menu ui-widget ui-widget-content" style="display: none;"></ul></form>
        </div>
        <div class="modal-footer">
          <button type="button" class="btn btn-default" data-dismiss="modal">Cancel</button>
          <button type="button" class="btn btn-primary">Send</button>
        </div>
      </div>
    </div>
  </div>

  <script type="text/javascript" async="" src="https://www.google-analytics.com/analytics.js"></script><script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js"></script>
  <script>window.jQuery || document.write('&lt;script src="/static/js/vendor/jquery-2.2.4.min.js"&gt;&lt;\/script&gt;')</script>

  <script src="/static/dist/vendor.min.js"></script>
  <script src="/static/dist/templates.min.js"></script>
  <script src="/static/dist/openreview.min.js"></script>

    <script>window.legacyScripts = true;</script>


    <script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-108703919-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() { dataLayer.push(arguments); }
      gtag('js', new Date());
      gtag('config', 'UA-108703919-1');
    </script>


<div role="status" aria-live="assertive" aria-relevant="additions" class="ui-helper-hidden-accessible"></div></body></html>
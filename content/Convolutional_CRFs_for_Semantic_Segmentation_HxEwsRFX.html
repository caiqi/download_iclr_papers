<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" class="no-js"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>Convolutional CRFs for Semantic Segmentation | OpenReview</title>
  <meta name="description" content="" />

      <meta name="citation_title" content="Convolutional CRFs for Semantic Segmentation" />
        <meta name="citation_author" content="Anonymous" />
      <meta name="citation_publication_date" content="2018/09/27" />
      <meta name="citation_online_date" content="2018/09/27" />
      <meta name="citation_pdf_url" content="https://openreview.net/pdf?id=H1xEwsR9FX" />
      <meta name="twitter:card" content="summary" />
      <meta name="twitter:site" content="@openreviewnet" />
      <meta name="og:title" content="Convolutional CRFs for Semantic Segmentation" />
      <meta name="og:description" content="For the challenging semantic image segmentation task the best performing models&#10;  have traditionally combined the structured modelling capabilities of Conditional&#10;  Random Fields (CRFs) with the..." />
      <meta name="og:image" content="https://openreview.net/static/images/openreview_logo_512.png" />

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans:400,400i,700,700i" />

  <link rel="stylesheet" href="/static/css/bootstrap.min.css" />
  <link rel="stylesheet" href="/static/css/jquery-ui.min.css" />
  <link rel="stylesheet" href="/static/css/main.min.css" />
</head>

<body class="forum">
  <nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
  
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand home push-link" href="/"><strong>OpenReview</strong>.net</a>
      </div>
  
      <div id="navbar" class="navbar-collapse collapse">
        <form class="navbar-form navbar-left profile-search" role="search">
          <div class="form-group has-feedback">
            <input id="search_input" type="text" class="form-control ui-autocomplete-input" placeholder="Search ICLR 2019 Conference" autocomplete="off" />
            <span class="glyphicon glyphicon-search form-control-feedback" aria-hidden="true"></span>
          </div>
  
          <input id="search_group" type="hidden" value="ICLR.cc/2019/Conference" />
          <input id="search_content" type="hidden" value="all" />
        <ul id="ui-id-1" tabindex="0" class="ui-menu ui-widget ui-widget-content ui-autocomplete ui-front" style="display: none;"></ul></form>
  
        <ul class="nav navbar-nav navbar-right">
        
            <li id="user-menu"><a href="/login">Login</a></li>
        </ul>
      </div>
  
    </div>
  </nav>

  <div id="or-banner" class="banner" style="">
  <div class="container">
    <div class="row">
      <div class="col-xs-12"><a href="/group?id=ICLR.cc/2019/Conference" title="Venue Homepage"><img class="icon" src="/static/images/arrow_left.svg" /> Go to <strong>ICLR 2019 Conference</strong> homepage</a></div>
    </div>
  </div>
</div>
<div id="flash-message-container" class="alert alert-danger" role="alert" style="display: none;">
  <div class="container">
    <div class="row">
      <div class="col-xs-12">
        <div class="alert-content">
          <button type="button" class="close" aria-label="Close"><span aria-hidden="true">×</span></button>
        </div>
      </div>
    </div>
  </div>
</div>

<div class="container">
  <div class="row">
    <div class="col-xs-12">
      <main id="content" class="clearfix openbanner-visible legacy-styles"><div id="note_H1xEwsR9FX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Convolutional CRFs for Semantic Segmentation</a> <a class="note_content_pdf" href="/pdf?id=H1xEwsR9FX" title="Download PDF" target="_blank"><img src="/static/images/pdf_icon_blue.svg" /></a> </h2></div><div class="meta_row"><span class="signatures">Anonymous</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">28 Sep 2018 (modified: 11 Oct 2018)</span><span class="item">ICLR 2019 Conference Blind Submission</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span><span class="item"><a class="action-bibtex-modal" data-bibtex="@inproceedings{    &#10;anonymous2019convolutional,    &#10;title={Convolutional CRFs for Semantic Segmentation},    &#10;author={Anonymous},    &#10;booktitle={Submitted to International Conference on Learning Representations},    &#10;year={2019},    &#10;url={https://openreview.net/forum?id=H1xEwsR9FX},    &#10;note={under review}    &#10;}">Show Bibtex</a></span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Abstract: </span><span class="note_content_value">For the challenging semantic image segmentation task the best performing models
have traditionally combined the structured modelling capabilities of Conditional
Random Fields (CRFs) with the feature extraction power of CNNs. In more recent
works however, CRF post-processing has fallen out of favour. We argue that this
is mainly due to the slow training and inference speeds of CRFs, as well as the
difficulty of learning the internal CRF parameters. To overcome both issues we
propose to add the assumption of conditional independence to the framework of
fully-connected CRFs. This allows us to reformulate the inference in terms of
convolutions, which can be implemented highly efficiently on GPUs.Doing so
speeds up inference and training by two orders of magnitude. All parameters of
the convolutional CRFs can easily be optimized using backpropagation. Towards
the goal of facilitating further CRF research we have made our implementations
publicly available.</span></div><div class="note_contents"><span class="note_content_field">Keywords: </span><span class="note_content_value">conditional random fields, semantic segmentation, computer vision, structured learning</span></div><div class="note_contents"><span class="note_content_field">TL;DR: </span><span class="note_content_value">We propose Convolutional CRFs a fast, powerful and trainable alternative to Fully Connected CRFs.</span></div><div class="reply_row clearfix"><div class="item" id="reply_count">3 Replies</div></div></div><hr class="small" /><div id="note_children"><div class="note_with_children"><div id="note_BkxsyqS9n7" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Nice speedup over DenseCRF</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=H1xEwsR9FX&amp;noteId=BkxsyqS9n7"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper254 AnonReviewer2</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">03 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper254 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">+ well written
+ Good idea
- Technical section not fully clear
- Some experimental issues

The paper is well written, and clearly explains the background material and concepts. It might almost be a bit too detailed, as the main technical section (4) feels a bit rushed. (more below). 

From what I can judge the main idea in the paper is sound. The authors replace the large filtering step in the permutohedral lattice with a spatially varying convolutional kernel. They show that inference is more efficient and training is easier.

The technical section is not very clear. For example: Are the filter weights recomputed for each spatial location, is there any acceleration that speeds this up? How large can the authors make the filter kernel, before the perhutohedral lattice is faster again?

Finally, the experimental section has some room for improvement. I liked the comparison of decoupled and coupled CRF training, but I didn't get much out of the synthetic experiments. I found it particularly confusing since Table 1 doesn't mention that the experiments use ground truth (test) labels that were corrupted.
Second, it would be nice to have a side-to-side comparison between ConvCRF and CRFasRNN. I'd recommend the authors to either use the CRFasRNN training setup for both methods, or spend the week or two training CRFasRNN using their training procedure. It is fine to do either of the two experiments and have four entries in that table.</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">7: Good paper, accept</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_r1eHPMg9nm" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Confusing notation, insufficient analysis, main contribution unclear</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=H1xEwsR9FX&amp;noteId=r1eHPMg9nm"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper254 AnonReviewer3</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">02 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper254 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">The authors propose an efficient method to perform message passing on a truncated Gaussian kernel CRF. The main contributions are the definition of a specific form of truncated Gaussian kernel that allows for fast message passing via convolutions, and the implementation of such parallelized message passing on GPU. 

In my opinion, the paper fails to convey the main idea in a clear and precise manner, the notation is mixed and often confusing, furthermore there are a number of sentences that should be rephrased to be less sensationalist, or removed. The experiments seem to show performance in par with the FullCRF on decoupled training, which seem in contrast with the much bigger performance gain of the first experiment on syntetic data. No discussion has been provided as to the possible reasons of this performance gap, although the experimental settings appear to be similar. Finally, in the last experiments with end-to-end training the authors report a performance improvement over CRFasRNN, a 3 years old paper that is far away in terms of performance with the current SOTA on Pascal VOC. The authors base on a different network than that of the CRFasRNN baseline (i.e., the difference is not only in the CRF implementation, but rather the whole network before the CRF in the proposed method), it is therefore difficult to say whether the performance improvement is due to the ResNet101 + FCN unary potentials, which is not a contribution of this manuscript, or to the proposed CRF. In general, I believe that the considerable speed gain of the proposed method might be enough to justify a publication, but the paper should be phrased in that sense if that was the intention of the authors. It is unclear to me whether the main contribution they claim is segmentation performance (IoU) or speed or both. The main contributions of this work should be stated clearly, and the modelling differences w.r.t. the FullCRF model that they aim to improve should be more explicit in the text rather than let to the reader to infer comparing the formulas.

On these grounds, I suggest a major revision of the paper and I don't recommend publication at this stage.



MAJOR

1) I firmly advocate against making strong claims, unless supported by solid proofs. I strongly recommend to rephrase, if not remove, exaggerate claims such as:

a) "[deep networks] lack the capability to utilize context information and cannot model interactions between predictions directly". This is simply not true. Any CNN with enough layers will exploit contextual information. Furthermore, any autoregressive model will model the interaction between predictions directly. See e.g., "RiFCN: Recurrent Network in Fully Convolutional Network for Semantic Segmentation of High Resolution Remote Sensing Images" by Mou et Al., "ReSeg: A Recurrent Neural Network-based Model for Semantic Segmentation" by Visin et Al., or "Predicting Deeper into the Future of Semantic Segmentation" by Luc et Al. for video semantic segmentation.

b) "CRF inference is two orders of magnitude slower than CNN inference": this, of course, depends on the kind of CRF.

c) "The long training times of the current generation of CRFs also make more in-depth research and experiments with such structured models impractical": again, not true. While it's true that CRFs tend to be slow, research with such models is not impractical and indeed there are papers that focus exactly on that (among the others, some of the ones cited in this manuscript).

d) "we propose to add the strong and valid assumption of conditional independence": as with every assumption, this is an approximation. I wouldn't claim it to be valid nor invalid, as it is simply a modeling choice.

e) "Predictions are pixel-wise and conditionally independendent (given the common feature base of nearby pixels). Structured knowledge and background context is ignored in these models.". It's unclear what is meant by "structured knowledge", but to my best understanding this sentence is misleading or wrong. Background context is considered by CNN-based models, as well as the general structure in the image.

f) "In the context of semantic segmentation most CRF based approaches are based on the Fully Connected CRF". CRFs have been used much earlier than 2011, before Fully Connected CRF was published.

g) "This makes the theoretical foundation of ConvCRF very promising, strong and valid assumptions are the powerhouse of machine learning modelling." The authors here propose a logical, but quite obvious, approximation, i.e., to constrain the CRF to model dependencies in a local neighborhood. This is the same implicit assumption of many other Gaussian kernels and algorithms for approximated inference. For how it's surely valid, and possibly strong, I don't see how it can make a "theoretical foundation". The self-congratulatory closure is unnecessary, and inappropriate.



2) While CRFs have been used for a long time on visual data, the citations in this work focus mostly on the last few years. I suggest to add at least one of the following:
* “Discriminative fields for modeling spatial dependencies in natural images" 2003
* "Multiscale conditional random fields for image labelling" 2004
* “Textonboost: Joint appearance, shape and context modeling for mulit-class object recognition and segmentation,” 2006

It could also be beneficial to the reader to add to the references broad overview works, such as "An Introduction to Conditional Random Fields" by Charles Sutton and Andrew McCallum, 2011, and/or "Structured prediction and learning in computer vision" by Nowozin and Lampert, 2011.



3) Line 5 of the algorithm adds the unary potentials at each iteration of message passing. Can you elaborate on the motivation behind this choice? The algorithm is already initialized with such potentials, and to my best knowledge unary potentials are not usually added in the mean field message passing loop. It would be interesting to compare the performance of the algorithm with and without this addition.



4) Sec4.1 reports that the filters are constant over the channel dimension c and that, in other words, this can be seen as applying the convolution over the dimension c. I fail to understand this sentence. My understanding from the formula is that the same kernel is applied to all the channels of the input, i.e., the channels of the input fed to the CRF are all processed in the same way. This should be explained clearly and the reasoning behind this choice should be explained as well. Furthermore, if I am not mistaken the authors learn a different filter in each position *of the input* rather than reusing the same filters at every position. This choice should be clarified and discussed.



5) Regarding the implementation, is there a reason not to apply a convolution with a flipped kernel to compute the cross-correlation? Also, IIRC if the kernel is symmetric (as should be for a Gaussian kernel) convolution and cross-correlation are the same. 



6) The notation is often ambiguous and at times unnecessarely heavy. I strongly recommend to go over the manuscript and use a consistent notation, making sure that every element of the notation is introduced before or right after it's used. In particular,

a) Sec3: in the text, a segmentation instance is referred to as X, while in the formula as \hat x. \tilde I is never introduced. k_{\alpha} is defined but I believe never used (I suggest to drop the name if there is no reference to it). Is there a reason to drop the subscript G in the FullCRF pairwise potential? Or conversely, is there a reason to have it everywhere else? Furthermore, there doesn't seem to be a difference between k_G, k_g and g, I suggest to use only one consistent notation to refer to the Gaussian kernels throughout the paper. It's also unclear if the I superscript is needed for the feature vectors. 

b) Sec4.1, The shape of the Gaussian kernels is the same as that of the input. I believe that the input in this context refers to a patch and not to the whole image. If so, this should be specified, otherwise the dimensions of the kernel should be referred to with a different letter than those of the input. 

c) Sec4.1, I believe dx and dy refer to the in-kernel displacement. Their semantic is not clear from the text and should be defined properly.

d) Sec4.1, the feature vectors are defined in the text as f_1..f_d. The formula of the kernel uses f_i^{(d)} instead. It's unclear what the superscripts stands for and whether it is actually useful or redundant.

e) Sec4.1, x and y are not defined, I suspect they refer to the position of the pixel, which was previously encoded as p_i and p_j. Once again, the notation should be consistent across the manuscript.

f) In the definition of the convCRFs, w is used for the width of the input, w_i for the weights of the kernels. In the FullCRF, w^{(1)} and w^{(2)} for the potentials, w^{(m)} for the sum over the kernels. k is used for the kernel dimension, k_G to refer to the kernel itself, as well as g. The notation could be made less ambiguous and consistent (superscript vs subscript semantics).

g) Sec3, the number of pixel is defined as n but in Formula 2 N is used instead.

g) Vectors and matrices should be bold-face. The use of capital letters for constants might also improve the readability of the manuscript.



7) The experiments with the Conv (ConvCRF?) variants of Table 2 are not discussed in the text.



8) Although Sec5.2 concludes with "The experiments also confirm the observation of Sec5.1, that ConvCRF performs slightly better than FullCRF", Sec5.1 reported that "it can be seen that ConvCRFs outperform FullCRFs significantly". The authors should decide whether the results are slightly better or outperform the baseline. In general a in-depth discussion on the performance of the algorithm is missing.



9) Sec5.3, it's unclear what this sentence means "introduce an auxiliary unary loss to counterbalance the vanishing gradient problem". If such a term has been added, it should be reported in a formula and it's effectiveness should be supported by experimental data.



MINOR

m1) In the related work, the sentence "transposed convolution layers are applied at the end of the prediction pipeline ot produce high-resolution output" seems to suggest these are always applied, while many recent methods rely on bilinear upsampling to recover the original resolution. Please rephrase it accordingly.

m2) In Parameter learning in CRF: "the idea utilizes, that for the message passing the identity .. is valid." This sentence doesn't make any sense to me. Is it possible it is a leftover?

m4) In Sec3, the features vectors [...] may depend on the input image I. I am confused as to when they might be independent of the image. Can you elaborate on that?

m5) In Sec3, it's unclear to me what the vertical bar in the Pot model stands for. I believe the correct formula should be 1_{[xi != xj]}.

m6) In mean field inference, Algorithm 1 does not refer to FullCRFs.

m7) End of page 6, "Note that this gives FullCRFs a natural advantage. The performance of CRFs however is very robust [...]". Why is this an advantage for FullCRFs? How does that relate to the following sentence?

m8) Sec4.1, the authors claim that one of the key contribution of the paper is that exact message passing is efficient. Given the locality assumption, message passing is approximate - which is also why it's efficient. The authors could instead argue that using convolutions is faster and possibly leads to better final performance than using the permutohedral lattice approximation (although it's unclear whether this is the case from the experiments), with proper reference to compelling results in this direction.

Finally, a few typos:
* Abstract, space missing after GPUs
* Introduction, Convolutional Neuronal -&gt; Convolutional Neural
* Introduction, order of magnitude slower then -&gt; than
* Introduction, to slow -&gt; too slow
* Parameter learning in CRF: missing space before proposed to use gradient descent
* Parameter learning in CRF: gradient decent -&gt; descent
* Parameter learning in CRF: extra comma after "another advantage of this method is"
* Sec 3: "weighted sum of Gaussian kernels", the apex of the second should be "M" I believe.
* Sec 3: "can be chosen arbitrary" -&gt; arbitrarily
* Sec 5.2, beginning of page 8: then -&gt; than</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">4: Ok but not good enough - rejection</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_B1x4tVwB2X" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Using convolution in CRFs to increase inference and training time speed</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=H1xEwsR9FX&amp;noteId=B1x4tVwB2X"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper254 AnonReviewer1</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">30 Oct 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper254 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">The paper is well written with many relevant references and easy to read. Some points that need clarification and mentioned below. 
The main points of this paper are the use of the convolution operator to perform the message passing mean field inference. Using this operation allows us to get away from the permutohedral lattice and yet allows speed up of 100x. This also means, that training will be able to done faster. Besides this the training parameters can also be learnt. These are the main contributions. The denoising task experiment shows positive results. The idea could be used in the future by others looking for faster model inference and training.

If a Manhattan distance d is used i.e. dx,dy&lt;k in equation (6), why is this a FullCRF? It seems like the new CRF is no longer a fully connected one. 

Page 5, first paragraph describing how the reorganization in the GPU is avoided is not very clear. It would be helpful to a reader to have more details and explanations about this.

It is not clear from the experimental results how much improvement allowing to train the CRF parameters gets or might get. Comparing to the Deeplab results etc for the non-trained case, the non-trained model still seems to be performing competitively. Table 2 of Table 3 does not really bring out the advantage of training. The +C, +T, +CT don't seem to be hugely different in terms of validation metrics. Note that Table 3 does not mention other models that might not be trained (assuming that those results are in Table 2) but the text also mentions that the training is not completely fair.

In section 5, Unary, it is mentioned that the network is not trained on larger datasets like other work, why?
And under CRF, what does iterations are unrolled mean?

In section 5.1, why does the random flipping help in simulating inaccuracies?


Minor points:
Abstract: Add space after "GPUs.".
Would be good to define what Q, *, ' indicate in paragraph 4, page 2.
"hight" -&gt; "height" in section 4.1

</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">6: Marginally above acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></main></div>
  </div>
</div>


    <!-- Footer -->
    <footer class="sitemap">
      <div class="container">
        <div class="row hidden-xs">
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/venues">All Venues</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="/contact">Contact</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
    
        <div class="row visible-xs-block">
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/contact">Contact</a></li>
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
      </div>
    </footer>
    
    <footer class="sponsor">
      <div class="container">
        <div class="row">
          <div class="col-sm-10 col-sm-offset-1">
            <p class="text-center">
              OpenReview is created by the <a href="http://www.iesl.cs.umass.edu/" target="_blank">Information Extraction and Synthesis Laboratory</a>, College of Information and Computer Science, University of Massachusetts Amherst. We gratefully acknowledge the support of the OpenReview sponsors:  Google,  Facebook, NSF, the University of Massachusetts Amherst Center for Data Science, and Center for Intelligent Information Retrieval, as well as the Google Cloud Platform for donating the computing and networking services on which OpenReview.net runs.
            </p>
          </div>
        </div>
      </div>
    </footer>

  <div id="feedback-modal" class="modal fade" tabindex="-1" role="dialog">
    <div class="modal-dialog">
      <div class="modal-content">
        <div class="modal-header">
          <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button>
          <h3 class="modal-title">Send Feedback</h3>
        </div>
        <div class="modal-body">
          <p>Enter your feedback below and we'll get back to you as soon as possible.</p>
          <form action="/feedback" method="POST">
            <div class="form-group">
              <input type="email" name="from" class="form-control" placeholder="Email" />
            </div>
            <div class="form-group">
              <input type="text" name="subject" class="form-control" placeholder="Subject" />
            </div>
            <div class="form-group">
              <textarea name="message" class="form-control feedback-input" rows="5" placeholder="Message" required=""></textarea>
            </div>
          <ul id="ui-id-2" tabindex="0" class="ui-menu ui-widget ui-widget-content" style="display: none;"></ul></form>
        </div>
        <div class="modal-footer">
          <button type="button" class="btn btn-default" data-dismiss="modal">Cancel</button>
          <button type="button" class="btn btn-primary">Send</button>
        </div>
      </div>
    </div>
  </div>

  <script type="text/javascript" async="" src="https://www.google-analytics.com/analytics.js"></script><script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js"></script>
  <script>window.jQuery || document.write('&lt;script src="/static/js/vendor/jquery-2.2.4.min.js"&gt;&lt;\/script&gt;')</script>

  <script src="/static/dist/vendor.min.js"></script>
  <script src="/static/dist/templates.min.js"></script>
  <script src="/static/dist/openreview.min.js"></script>

    <script>window.legacyScripts = true;</script>


    <script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-108703919-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() { dataLayer.push(arguments); }
      gtag('js', new Date());
      gtag('config', 'UA-108703919-1');
    </script>


<div role="status" aria-live="assertive" aria-relevant="additions" class="ui-helper-hidden-accessible"></div></body></html>
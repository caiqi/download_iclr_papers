<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" class="no-js"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>Neural Variational Inference For Embedding Knowledge Graphs | OpenReview</title>
  <meta name="description" content="" />

      <meta name="citation_title" content="Neural Variational Inference For Embedding Knowledge Graphs" />
        <meta name="citation_author" content="Anonymous" />
      <meta name="citation_publication_date" content="2018/09/27" />
      <meta name="citation_online_date" content="2018/09/27" />
      <meta name="citation_pdf_url" content="https://openreview.net/pdf?id=HJM4rsRqFX" />
      <meta name="twitter:card" content="summary" />
      <meta name="twitter:site" content="@openreviewnet" />
      <meta name="og:title" content="Neural Variational Inference For Embedding Knowledge Graphs" />
      <meta name="og:description" content="Recent advances in Neural Variational Inference allowed for a renaissance in latent variable models in a variety of domains involving high-dimensional data. In this paper, we introduce two generic..." />
      <meta name="og:image" content="https://openreview.net/static/images/openreview_logo_512.png" />

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans:400,400i,700,700i" />

  <link rel="stylesheet" href="/static/css/bootstrap.min.css" />
  <link rel="stylesheet" href="/static/css/jquery-ui.min.css" />
  <link rel="stylesheet" href="/static/css/main.min.css" />
</head>

<body class="forum">
  <nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
  
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand home push-link" href="/"><strong>OpenReview</strong>.net</a>
      </div>
  
      <div id="navbar" class="navbar-collapse collapse">
        <form class="navbar-form navbar-left profile-search" role="search">
          <div class="form-group has-feedback">
            <input id="search_input" type="text" class="form-control ui-autocomplete-input" placeholder="Search ICLR 2019 Conference" autocomplete="off" />
            <span class="glyphicon glyphicon-search form-control-feedback" aria-hidden="true"></span>
          </div>
  
          <input id="search_group" type="hidden" value="ICLR.cc/2019/Conference" />
          <input id="search_content" type="hidden" value="all" />
        <ul id="ui-id-1" tabindex="0" class="ui-menu ui-widget ui-widget-content ui-autocomplete ui-front" style="display: none;"></ul></form>
  
        <ul class="nav navbar-nav navbar-right">
        
            <li id="user-menu"><a href="/login">Login</a></li>
        </ul>
      </div>
  
    </div>
  </nav>

  <div id="or-banner" class="banner" style="">
  <div class="container">
    <div class="row">
      <div class="col-xs-12"><a href="/group?id=ICLR.cc/2019/Conference" title="Venue Homepage"><img class="icon" src="/static/images/arrow_left.svg" /> Go to <strong>ICLR 2019 Conference</strong> homepage</a></div>
    </div>
  </div>
</div>
<div id="flash-message-container" class="alert alert-danger" role="alert" style="display: none;">
  <div class="container">
    <div class="row">
      <div class="col-xs-12">
        <div class="alert-content">
          <button type="button" class="close" aria-label="Close"><span aria-hidden="true">×</span></button>
        </div>
      </div>
    </div>
  </div>
</div>

<div class="container">
  <div class="row">
    <div class="col-xs-12">
      <main id="content" class="clearfix openbanner-visible legacy-styles"><div id="note_HJM4rsRqFX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Neural Variational Inference For Embedding Knowledge Graphs</a> <a class="note_content_pdf" href="/pdf?id=HJM4rsRqFX" title="Download PDF" target="_blank"><img src="/static/images/pdf_icon_blue.svg" /></a> </h2></div><div class="meta_row"><span class="signatures">Anonymous</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">28 Sep 2018 (modified: 19 Nov 2018)</span><span class="item">ICLR 2019 Conference Blind Submission</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span><span class="item"><a class="action-bibtex-modal" data-bibtex="@inproceedings{    &#10;anonymous2019neural,    &#10;title={Neural Variational Inference For Embedding Knowledge Graphs},    &#10;author={Anonymous},    &#10;booktitle={Submitted to International Conference on Learning Representations},    &#10;year={2019},    &#10;url={https://openreview.net/forum?id=HJM4rsRqFX},    &#10;note={under review}    &#10;}">Show Bibtex</a></span><a class="note_content_pdf item" href="/revisions?id=HJM4rsRqFX" target="_blank">Show Revisions</a></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Abstract: </span><span class="note_content_value">Recent advances in Neural Variational Inference allowed for a renaissance in latent variable models in a variety of domains involving high-dimensional data. In this paper, we introduce two generic Variational Inference frameworks for generative models of Knowledge Graphs; Latent Fact Model and Latent Information Model.  While traditional variational methods derive an analytical approximation for the intractable distribution over the latent variables, here we construct an inference network conditioned on the symbolic representation of entities and relation types in the Knowledge Graph, to provide the variational distributions. The new framework can create models able to discover underlying probabilistic semantics for the symbolic representation by utilising parameterisable distributions which permit training by back-propagation in the context of neural variational inference, resulting in a highly-scalable method. Under a Bernoulli sampling framework, we provide an alternative justification for commonly used techniques in large-scale stochastic variational inference, which drastically reduces training time at a cost of an additional approximation to the variational lower bound.  The generative frameworks are flexible enough to allow training under any prior distribution that permits a re-parametrisation trick, as well as under any scoring function that permits maximum likelihood estimation of the parameters. Experiment results display the potential and efficiency of this framework by improving upon multiple benchmarks with Gaussian prior representations. Code publicly available on Github.</span></div><div class="note_contents"><span class="note_content_field">TL;DR: </span><span class="note_content_value">Working toward generative knowledge graph models to better estimate predictive uncertainty in knowledge inference. </span></div><div class="note_contents"><span class="note_content_field">Keywords: </span><span class="note_content_value">Statistical Relational Learning, Knowledge Graphs, Knowledge Extraction, Latent Feature Models, Variational Inference.</span></div><div class="reply_row clearfix"><div class="item" id="reply_count">3 Replies</div></div></div><hr class="small" /><div id="note_children"><div class="note_with_children"><div id="note_H1l7Wh3hnX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>This work proposed variational embedding for knowledge graph inference tasks. However, neither the methods nor the results are really impressive</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HJM4rsRqFX&amp;noteId=H1l7Wh3hnX"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper80 AnonReviewer3</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">05 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper80 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">
This work proposed two variational embedding methods for knowledge graph inference tasks. The experiments show slight improvements compared to other variational embedding methods, e.g., KG2E, TransG, and slight improvement on the WN18 dataset compared with the non-variational method. On the other hand, both the embedding method and the training of variational models used in this work are already well developed. Thus, this work doesn’t show too much novel contribution. However, the reviewer really appreciate the visualization provided in Fig. 4. 
Minor issues:
1)	Notation of the KL divergence is not conventional
2)	There are some mistakes of indices for predicates, e.g., in Eq. 7, 8.
</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">5: Marginally below acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">3: The reviewer is fairly confident that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_SkljN1ID2m" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Interesting variational framework, results not convincing enough</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HJM4rsRqFX&amp;noteId=SkljN1ID2m"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper80 AnonReviewer1</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">31 Oct 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper80 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">* The paper proposed a neural variational inference framework for knowledge graph embedding. The paper proposed two models (Latent Fact Model and Latent Information Model) where the neural variational inference is carried out, with competitive results on standard datasets (WN18 and FB15K).

* I am not fully convinced of the advantage of this variational inference approach compared with the optimization approach used in TransE, TransG, DistMult and ComplEx. As can be seen in Table 1, the best performance on WN18-RR and FB15K-257 are obtained without variational inference. In Table 2, performance of the variational inference approach is not as good as other approaches under the MR or Raw Hits metrics. Moreover, performance on FB15K is not reported in Table 2, which makes the result not as complete as Table 1.

* It seems that the main difference between Latent Fact Model and Latent Information Model is the way prior is imposed on h. The authors may want to explain in plain language the differences and the motivation behind that.

* It is unclear how the (\tau,y) labeled triples are generated, especially for the negative examples with y=0. Is it obtained by randomly corrupting the triples in the knowledge base, as done in other work? It would be better to make this point clear.</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">5: Marginally below acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_Byl2jPWGjX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Interesting work, not mature for publication at ICLR</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HJM4rsRqFX&amp;noteId=Byl2jPWGjX"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper80 AnonReviewer2</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">15 Oct 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper80 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">The paper presents two variational inference frameworks for generative models of knowledge graphs. Such models are based respectively on latent fact model and latent information model.
The authors argue that with the presented framework the underlying probabilistic semantics can be discovered. Experiments show performances comparable with state-of-art approaches.

Unfortunately, the paper seems to me not clear and rather incomplete in its actual form.
Overall, the proposal is novel. I cannot decide about significance because results do not outperform those of other approaches. To this extent, the authors should better discuss the results, explaining in more detail why this approach should be used instead of others (scales better, is faster, etc.).

In the abstract, it is asserted that one can discover underlying probabilistic semantics, but in the corpus of the paper this aspect is not described or mentioned in detail.
Similar problem for the reference to von-Mises distribution. This distribution is just named, it is said that the framework can handle such a distribution, but a reference to a paper and/or a short paragraph to explain the sentence are missing. This statement now results to be just information disconnected by the rest of the paper.

In a similar way, many other points suffer from a poor organization in my opinion.
When describing LIM an error is introduced here that is then copied and pasted throughout the paper: in the productory on p, p is in R not in E. This is a simple typo, but the fact that it is repeated so many times, also in the proof, gives me the feeling that the paper was written at the last moment.
Figures 1 and 2 are never referred.

Formula 6 must be better explained. If I have not lost something, n is the number of labeled triples, s_c is undefined, b_c is the probability of s_c to be equal to 1, the index i is never used. The paper lacks information here.

As regards the experimental part, some results are shown in subsection 4.3 called link prediction, others in section 5 called link prediction analysis. This organization does not seem to me to be really optimal. I would suggest creating an experimental section.
Moreover, the tests should be better explained, the tables are shown without specifying how they are built and how the values are collected. Information is provided in the appendix but could be included in the paper as the maximum limit is of 10 pages (8 suggested but I think an extra half page can be used).
The knowledge bases used should be at least cited, I know that freebase and wordnet are well-known but somewhere, in the description of the test, the name should be included. Also to specify the characteristics of the versions (WN18 vs WN18RR). Moreover, what does the value -257 in column 1, row 4 means?
Then, it is said that Table 1 shows improvements for ComplEx, but such improvements are rather low, is there a way to prove their significance? Otherwise, I would say that the performance is the same for WN18.
Tables 1 and 2 contain cells with '-' value, what does it mean?

Discussion about table 3 is incomplete in my opinion. First of all, the "proportion" column should be described. Also, on one hand, it is true that the _member_meronym is the least accurate and prominent but the most problem may come from _hypernym, which is the most prominent and the accuracy is also low. This fact is highlighted for table 4 but not for table 3.

Minor issues
- sec 3: references to Miao et al. must be enclosed by brackets
- sec 4.3: "We believe this *is* due to ..."
- sec 5.2: what is Model A? Also, the sentence seems incomplete.

Pros:
- Novel approach

Cons
- Test results are not convincing
- The paper is not mathematically sound
- The paper needs to be re-organized</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">4: Ok but not good enough - rejection</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">3: The reviewer is fairly confident that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></main></div>
  </div>
</div>


    <!-- Footer -->
    <footer class="sitemap">
      <div class="container">
        <div class="row hidden-xs">
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/venues">All Venues</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="/contact">Contact</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
    
        <div class="row visible-xs-block">
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/contact">Contact</a></li>
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
      </div>
    </footer>
    
    <footer class="sponsor">
      <div class="container">
        <div class="row">
          <div class="col-sm-10 col-sm-offset-1">
            <p class="text-center">
              OpenReview is created by the <a href="http://www.iesl.cs.umass.edu/" target="_blank">Information Extraction and Synthesis Laboratory</a>, College of Information and Computer Science, University of Massachusetts Amherst. We gratefully acknowledge the support of the OpenReview sponsors:  Google,  Facebook, NSF, the University of Massachusetts Amherst Center for Data Science, and Center for Intelligent Information Retrieval, as well as the Google Cloud Platform for donating the computing and networking services on which OpenReview.net runs.
            </p>
          </div>
        </div>
      </div>
    </footer>

  <div id="feedback-modal" class="modal fade" tabindex="-1" role="dialog">
    <div class="modal-dialog">
      <div class="modal-content">
        <div class="modal-header">
          <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button>
          <h3 class="modal-title">Send Feedback</h3>
        </div>
        <div class="modal-body">
          <p>Enter your feedback below and we'll get back to you as soon as possible.</p>
          <form action="/feedback" method="POST">
            <div class="form-group">
              <input type="email" name="from" class="form-control" placeholder="Email" />
            </div>
            <div class="form-group">
              <input type="text" name="subject" class="form-control" placeholder="Subject" />
            </div>
            <div class="form-group">
              <textarea name="message" class="form-control feedback-input" rows="5" placeholder="Message" required=""></textarea>
            </div>
          <ul id="ui-id-2" tabindex="0" class="ui-menu ui-widget ui-widget-content" style="display: none;"></ul></form>
        </div>
        <div class="modal-footer">
          <button type="button" class="btn btn-default" data-dismiss="modal">Cancel</button>
          <button type="button" class="btn btn-primary">Send</button>
        </div>
      </div>
    </div>
  </div>

  <script type="text/javascript" async="" src="https://www.google-analytics.com/analytics.js"></script><script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js"></script>
  <script>window.jQuery || document.write('&lt;script src="/static/js/vendor/jquery-2.2.4.min.js"&gt;&lt;\/script&gt;')</script>

  <script src="/static/dist/vendor.min.js"></script>
  <script src="/static/dist/templates.min.js"></script>
  <script src="/static/dist/openreview.min.js"></script>

    <script>window.legacyScripts = true;</script>


    <script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-108703919-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() { dataLayer.push(arguments); }
      gtag('js', new Date());
      gtag('config', 'UA-108703919-1');
    </script>


<div role="status" aria-live="assertive" aria-relevant="additions" class="ui-helper-hidden-accessible"></div></body></html>
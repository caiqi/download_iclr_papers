<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" class="no-js"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>Understanding and Improving Interpolation in Autoencoders via an Adversarial Regularizer | OpenReview</title>
  <meta name="description" content="" />

      <meta name="citation_title" content="Understanding and Improving Interpolation in Autoencoders via an Adversarial Regularizer" />
        <meta name="citation_author" content="Anonymous" />
      <meta name="citation_publication_date" content="2018/09/27" />
      <meta name="citation_online_date" content="2018/09/27" />
      <meta name="citation_pdf_url" content="https://openreview.net/pdf?id=S1fQSiCcYm" />
      <meta name="twitter:card" content="summary" />
      <meta name="twitter:site" content="@openreviewnet" />
      <meta name="og:title" content="Understanding and Improving Interpolation in Autoencoders via an..." />
      <meta name="og:description" content="Autoencoders provide a powerful framework for learning compressed representations by encoding all of the information needed to reconstruct a data point in a latent code. In some cases, autoencoders..." />
      <meta name="og:image" content="https://openreview.net/static/images/openreview_logo_512.png" />

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans:400,400i,700,700i" />

  <link rel="stylesheet" href="/static/css/bootstrap.min.css" />
  <link rel="stylesheet" href="/static/css/jquery-ui.min.css" />
  <link rel="stylesheet" href="/static/css/main.min.css" />
</head>

<body class="forum">
  <nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
  
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand home push-link" href="/"><strong>OpenReview</strong>.net</a>
      </div>
  
      <div id="navbar" class="navbar-collapse collapse">
        <form class="navbar-form navbar-left profile-search" role="search">
          <div class="form-group has-feedback">
            <input id="search_input" type="text" class="form-control ui-autocomplete-input" placeholder="Search ICLR 2019 Conference" autocomplete="off" />
            <span class="glyphicon glyphicon-search form-control-feedback" aria-hidden="true"></span>
          </div>
  
          <input id="search_group" type="hidden" value="ICLR.cc/2019/Conference" />
          <input id="search_content" type="hidden" value="all" />
        <ul id="ui-id-1" tabindex="0" class="ui-menu ui-widget ui-widget-content ui-autocomplete ui-front" style="display: none;"></ul></form>
  
        <ul class="nav navbar-nav navbar-right">
        
            <li id="user-menu"><a href="/login">Login</a></li>
        </ul>
      </div>
  
    </div>
  </nav>

  <div id="or-banner" class="banner" style="">
  <div class="container">
    <div class="row">
      <div class="col-xs-12"><a href="/group?id=ICLR.cc/2019/Conference" title="Venue Homepage"><img class="icon" src="/static/images/arrow_left.svg" /> Go to <strong>ICLR 2019 Conference</strong> homepage</a></div>
    </div>
  </div>
</div>
<div id="flash-message-container" class="alert alert-danger" role="alert" style="display: none;">
  <div class="container">
    <div class="row">
      <div class="col-xs-12">
        <div class="alert-content">
          <button type="button" class="close" aria-label="Close"><span aria-hidden="true">×</span></button>
        </div>
      </div>
    </div>
  </div>
</div>

<div class="container">
  <div class="row">
    <div class="col-xs-12">
      <main id="content" class="clearfix openbanner-visible legacy-styles"><div id="note_S1fQSiCcYm" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Understanding and Improving Interpolation in Autoencoders via an Adversarial Regularizer</a> <a class="note_content_pdf" href="/pdf?id=S1fQSiCcYm" title="Download PDF" target="_blank"><img src="/static/images/pdf_icon_blue.svg" /></a> </h2></div><div class="meta_row"><span class="signatures">Anonymous</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">28 Sep 2018 (modified: 14 Nov 2018)</span><span class="item">ICLR 2019 Conference Blind Submission</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span><span class="item"><a class="action-bibtex-modal" data-bibtex="@inproceedings{    &#10;anonymous2019understanding,    &#10;title={Understanding and Improving Interpolation in Autoencoders via an Adversarial Regularizer},    &#10;author={Anonymous},    &#10;booktitle={Submitted to International Conference on Learning Representations},    &#10;year={2019},    &#10;url={https://openreview.net/forum?id=S1fQSiCcYm},    &#10;note={under review}    &#10;}">Show Bibtex</a></span><a class="note_content_pdf item" href="/revisions?id=S1fQSiCcYm" target="_blank">Show Revisions</a></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Abstract: </span><span class="note_content_value">Autoencoders provide a powerful framework for learning compressed representations by encoding all of the information needed to reconstruct a data point in a latent code. In some cases, autoencoders can "interpolate": By decoding the convex combination of the latent codes for two datapoints, the autoencoder can produce an output which semantically mixes characteristics from the datapoints. In this paper, we propose a regularization procedure which encourages interpolated outputs to appear more realistic by fooling a critic network which has been trained to recover the mixing coefficient from interpolated data. We then develop a simple benchmark task where we can quantitatively measure the extent to which various autoencoders can interpolate and show that our regularizer dramatically improves interpolation in this setting. We also demonstrate empirically that our regularizer produces latent codes which are more effective on downstream tasks, suggesting a possible link between interpolation abilities and learning useful representations.</span></div><div class="note_contents"><span class="note_content_field">TL;DR: </span><span class="note_content_value">We propose a regularizer that improves interpolation and autoencoders and show that it also improves the learned representation for downstream tasks.</span></div><div class="note_contents"><span class="note_content_field">Keywords: </span><span class="note_content_value">autoencoders, interpolation, unsupervised learning, representation learning, adversarial learning</span></div><div class="reply_row clearfix"><div class="item" id="reply_count">9 Replies</div></div></div><hr class="small" /><div id="note_children"><div class="note_with_children"><div id="note_SJgQLPtKTm" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Does the technique help in getting better random samples?</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=S1fQSiCcYm&amp;noteId=SJgQLPtKTm"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">(anonymous)</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">14 Nov 2018 (modified: 15 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper73 Public Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">For example, if the proposed regularizer is applied to a VAE, does it help in getting better random samples by decoding z ~ N(0, 1)?

</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_r1g4OITYpX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Re: Does the techinique help in getting better random samples? </a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=S1fQSiCcYm&amp;noteId=r1g4OITYpX"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper73 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">14 Nov 2018</span><span class="item">ICLR 2019 Conference Paper73 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Thanks for your question. In general we do not expect this regularizer to improve the sample quality of a given autoencoder, since the critic's primary objective is to discriminate between interpolants and reconstructions (not interpolants and "real" data). The goal instead is to take an autoencoder which already reconstructs well but interpolates poorly and improve the quality of the interpolations. The VAE typically has the opposite problem - it reconstructs poorly but interpolates smoothly. In other words, the latent space of the VAE is already "continuous" in some sense (due to the enforcement of the prior) but many regions in latent space map to "unrealistic" (i.e. blurry) outputs. So, we aren't sure whether our regularizer would improve VAE reconstructions. It would be pretty straightforward to try using our publicly-available code, though!</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div><div class="note_with_children"><div id="note_HkxOaxgtp7" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Updated draft</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=S1fQSiCcYm&amp;noteId=HkxOaxgtp7"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper73 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">14 Nov 2018</span><span class="item">ICLR 2019 Conference Paper73 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Thanks to all of the reviewers for their feedback on our paper. We have addressed each reviewer's comments individually and have also uploaded an updated draft based on the suggestions. The changes include the following:
- Clarified why smooth and realistic interpolations may potentially lead to better reconstructions in the introduction
- Framed our objective as minimizing an adversarial divergence between reconstructions and interpolants
- Clarified the second term of the critic loss involving \gamma and gave additional justification for this term
- Added comparison of the ACAI and LSGAN critic losses
- Gave additional intuition as to how the critic could potentially regress \alpha when only being shown a single image at a time
- Referred to our lines images as "greyscale" rather than "black and white"
- Noted that the AAE baseline we included has also subsequently been referred to as Wasserstein Autoencoder
- Pointed out some cases where interpolations can be smooth and realistic despite interpolating between dissimilar points

We hope these changes address any concerns the reviewers have.</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_HJeuQMG5n7" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Regularize interpolation or regularize manifold?</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=S1fQSiCcYm&amp;noteId=HJeuQMG5n7"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper73 AnonReviewer3</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">03 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper73 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">Main idea:
This paper investigates the desiderata for a successful interpolation:
1) Interpolation looks realistic;
2) The interpolation path is semantically smooth. 
An adversarial regularizer is proposed to achieve 1), and in practice 2) may also satisfied.  
To evaluate the method, they introduce a synthetic dataset with line images and compare with different autoencoder methods without the interpolation regularization.
For real data, they show that the interpolation regularized autoencoder (i.e. ACAI) leads to a better unsupervised representation.

Questions:
1. Do we really need every interpolated point to be realistic (i.e. similar to a data point in the train-set)? I believe that there exists an interpolation between two totally different objects can never be observed.  
2. Do we need interpolation points to form a semantically smooth morphing? I guess this is a desired property for continuous generators, but it seems not necessary in general.
3. The gamma in the 2nd term in (1) is confusing. If gamma = 1, I understand it forces to predict alpha = 0 since x is real. But if gamma &lt; 1, the average in data space may be very blurry thus not realistic at all. How does gamma affect the optimization?
4. ACAI looks very similar to LSGAN: by giving "0" label to real data and "alpha" label to fake data; in LSGAN, alpha = 1.
Have you tested a LSGAN like regularizer? 
5. The baselines are not representative: since ACAI introduces an adversarial regularizer, you should compare with other GAN techniques induced regularizers, such as WGAN regularized autoencoder. </span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">5: Marginally below acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_ryx6nAJFaQ" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Re: Regularize interpolation or regularize manifold?</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=S1fQSiCcYm&amp;noteId=ryx6nAJFaQ"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper73 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">14 Nov 2018</span><span class="item">ICLR 2019 Conference Paper73 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Thanks for your thorough review and questions. We've answered your questions below and have updated our draft to clarify.

&gt; Do we really need every interpolated point to be realistic (i.e. similar to a data point in the train-set)? I believe that there exists an interpolation between two totally different objects can never be observed.  

We are interested in latent spaces where interpolations produce realistic outputs across the entirety of the interpolation because this suggests some form of continuity in the latent space (as illustrated in FIgure 1). Our paper asks whether this property also results in an improved representation for downstream tasks. If an intermediate point was not realistic, the latent space might not have this property.
Thanks for pointing out that in some cases it's not obvious that there is a smooth and realistic path between two datapoints. We think two good examples of this are in Figure 6, bottom, where we interpolate between different MNIST digits. We find that even though there is no real digit which is at the midpoint of, for example, a 2 and a 9, the midpoint of ACAI's interpolation still appears realistic. We have added a note about this to our paper.

&gt; Do we need interpolation points to form a semantically smooth morphing? I guess this is a desired property for continuous generators, but it seems not necessary in general.

We agree that smoothness is not required for high-quality learned features -- for example, the Denoising Autoencoder fared well on our classification experiments despite producing poor interpolations. However, we are interested in the opposite, namely whether the ability to perform latent-space manipulations like interpolation suggest a better learned representation. We have added some clarification of this point in our paper.

&gt; The gamma in the 2nd term in (1) is confusing. If gamma = 1, I understand it forces to predict alpha = 0 since x is real. But if gamma &lt; 1, the average in data space may be very blurry thus not realistic at all. How does gamma affect the optimization?

Note \hat{x} is a reconstruction of x, so in practice \gamma*x + (1 − \gamma)*\hat{x} will be quite similar to x as long as \hat{x} is a reasonable reconstruction. In other words, we are not interpolating between two totally different points, so typically the blurriness you might expect from pixel-space mixing won't be present. We have added some additional discussion of gamma and this term to our paper.

&gt; ACAI looks very similar to LSGAN: by giving "0" label to real data and "alpha" label to fake data; in LSGAN, alpha = 1. Have you tested a LSGAN like regularizer? 

You're right that the LSGAN loss function and our regularization term are similar in the sense that both measure a squared error between the critic's output and a scalar. The difference is that the LSGAN is designed for use on a GAN-based generative model; our regularizer is designed as a regularizer for an autoencoder. As a result, the scalar in the LSGAN objective is a fixed hyperparameter whereas we regress the interpolation amount \alpha. We added some discussion of the LSGAN objective to our paper.

&gt; The baselines are not representative: since ACAI introduces an adversarial regularizer, you should compare with other GAN techniques induced regularizers, such as WGAN regularized autoencoder. 

Note that the Wasserstein Autoencoder (WAE) is actually equivalent to an adversarial autoencoder when using a GAN loss; in the WAE paper [1] they write "When c is the squared cost and D_Z is the GAN objective, WAE coincides with adversarial auto-encoders". Our paper includes the adversarial autoencoder as a baseline (labeled AAE in tables and described in Section 3.2, paragraph 4). We added a citation to [1] to clarify this.

[1] Ilya Tolstikhin, Olivier Bousquet, Sylvain Gelly and Bernhard Schoelkopf. "Wasserstein Auto-Encoders", ICLR 2017.
</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div><div class="note_with_children"><div id="note_rJlQxJGchX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Review for "Understanding and Improving Interpolation in AE via an Adversarial Regularizer - Interesting Paper with good results.</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=S1fQSiCcYm&amp;noteId=rJlQxJGchX"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper73 AnonReviewer1</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">03 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper73 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">Summary: The authors propose a new approach to encourage valid interpolation in Auto-Encoders (AE). It is based on a regularization procedure involving a critic network judging the realistic nature of reconstructed data point from its mixed latent representations by recovering the mixing coefficient. The authors show that this approach does indeed improve the quality of interpolated samples on few tasks. A synthetic tasks of lines interpolation (proposing new Mean Distance and Smoothness metric for this task), classification task (with a single-layer classifier) from the latent space representation and finally a clustering accuracy on the latent space. On the proposed regularization method seems to help significantly compared to commonly used AE architectures (Basic AE, Denoising AE, Variational AE, Adversarial AE and VQ-VAE).

This paper was a very interesting read, and the work seems to be of significance for the unsupervised learning community.
It was clearly written and conveys the contributions clearly and the experimental results and their interpretations seem valid.

The proposed approach of a critic based regularizer is a simple but seemingly important addition that contributes to improving interpolation in AE significantly and even show impact "downstream tasks" as the authors put it.

Few comments/questions come to mind:

- For the critic Loss L_d in equation (1) , the authors mention that the \gamma based second term (that should ensure that the critic outputs 0 for non-interpolated inputs and expose the critic to realistic data even if the AE reconstruction is poor)  does not seem to be crucial in your approach but stabilized the adversarial training. Could you somehow quantify this. It seems like stability of the adversarial training should be paramount to your method to make sure the AE learns a better latent representation. This comment, even though I assume it well-founded, seems a bit of a contradiction.

- For the Lines synthetic data. It was chosen to use a 32x32 image size with 16 points length lines. This configuration does quantize directly the angles your measures can distinguish. Below a certain angle differences (or delta), 2 angles must have the same pixel representation, i.e. exact overlapping lines. My question is simple: What is the smallest angle you can use/distinguish or, how many exact unique lines can you have? 

Overall this is a good paper that deserves publications.</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">8: Top 50% of accepted papers, clear accept</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">3: The reviewer is fairly confident that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_S1e8zyxY67" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Re: Review for "Understanding and Improving Interpolation in AE via an Adversarial Regularizer - Interesting Paper with good results.</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=S1fQSiCcYm&amp;noteId=S1e8zyxY67"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper73 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">14 Nov 2018</span><span class="item">ICLR 2019 Conference Paper73 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Thanks for your review, we are glad you found the paper interesting and significant. To address your questions and comments:

&gt; For the critic Loss L_d in equation (1) , the authors mention that the \gamma based second term (that should ensure that the critic outputs 0 for non-interpolated inputs and expose the critic to realistic data even if the AE reconstruction is poor)  does not seem to be crucial in your approach but stabilized the adversarial training. Could you somehow quantify this. It seems like stability of the adversarial training should be paramount to your method to make sure the AE learns a better latent representation. This comment, even though I assume it well-founded, seems a bit of a contradiction.

We agree that this comment should be expanded on, and we have done so in our updated draft. To clarify, when we say it "helped stabilize the adversarial learning process", we mean that a) it allowed us to use the same value of \lambda across all of our experiments and still achieve good results and b) it resulted in smooth convergence of the autoencoder's loss. We note that stability of the adversarial learning process was not an issue in general, in the sense that stability across runs was not an issue and our model never "collapsed" to a bad solution.

&gt; For the Lines synthetic data. It was chosen to use a 32x32 image size with 16 points length lines. This configuration does quantize directly the angles your measures can distinguish. Below a certain angle differences (or delta), 2 angles must have the same pixel representation, i.e. exact overlapping lines. My question is simple: What is the smallest angle you can use/distinguish or, how many exact unique lines can you have? 

Our code for synthesizing line images uses anti-aliasing, so for example a line with angle 0.3 and another with angle 0.300001 will be rendered differently. As a result, the number of unique lines is actually up to floating point precision. We think some confusion about this probably stems from the fact that we referred to the line images as "black-and-white"; we have updated the language in the paper to say "grayscale".</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div><div class="note_with_children"><div id="note_B1gmB4Kv2m" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>An interesting regularized AE algorithm that improves interpolation in latent space</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=S1fQSiCcYm&amp;noteId=B1gmB4Kv2m"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper73 AnonReviewer2</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">01 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper73 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">This paper proposed an adversarially regularized AE algorithm that improve interpolation in latent space. Specifically, a critic is used to predict the interpolation weight \alpha and encourage the interpolated images to be more realistic. The paper verified the method on a newly proposed synthetic line benchmark and on downstream classification and clustering tasks.

Pros:
1.	A novel algorithm that promotes the interpolation ability of AE
2.	A new synthesized line benchmark to verify the interpolation ability of different AE variants
3.	Strong results on downstream classification and clustering tasks

Cons: 
1.	The interplay of the adversarial network (between AE and critic) isn’t very clear and can be improved
2.	Eq. 1, should x be x_1 or a new data other than x1 and x2?
3.	The paper states that the 2nd term of Eq. 1 isn’t crucial. If x is a new data (other than x1 or x2), how can the critic infer \alpha without a reference to x1 or x2?
4.	The paper states that “encouraging this behavior also produce semantically smooth interpolation …”. Besides the empirical evidences from data, it would be better to any some theoretical justifications.
</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">9: Top 15% of accepted papers, strong accept</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_BJl0L1xt6m" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Re: An interesting regularized AE algorithm that improves interpolation in latent space </a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=S1fQSiCcYm&amp;noteId=BJl0L1xt6m"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper73 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">14 Nov 2018</span><span class="item">ICLR 2019 Conference Paper73 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Thanks for your review and thoughtful analysis. To address each of your cons in turn:

&gt; The interplay of the adversarial network (between AE and critic) isn’t very clear and can be improved.

The goal of the critic is to predict the interpolation mixing coefficient \alpha; the goal of the autoencoder is to "fool" the critic into outputting \alpha = 0. It can be useful to think of the critic as estimating a divergence between real and interpolated datapoints, and the autoencoder is trying to minimize this divergence. We have added some discussion of this to our paper.

&gt; Eq. 1, should x be x_1 or a new data other than x1 and x2?

It actually can be any real datapoint x - the second term can be computed separately from the first. We have clarified this in our updated draft.

&gt; The paper states that the 2nd term of Eq. 1 isn’t crucial. If x is a new data (other than x1 or x2), how can the critic infer \alpha without a reference to x1 or x2?

The critic must infer \alpha from common artifacts of interpolated datapoints alone. This is best illustrated in Figure 3(a) - note that as the interpolation morphs from one endpoint to the other, the image becomes dimmer and closer to a "dot" in the middle of the image. In this case, it is easy to infer \alpha based on the length and brightness of the line. This is exactly the kind of behavior that ACAI seeks to discourage, and we find it's effective in practice. We have added some additional discussion of this point to our paper.

&gt; The paper states that “encouraging this behavior also produce semantically smooth interpolation …”. Besides the empirical evidences from data, it would be better to any some theoretical justifications.

Our approach can be viewed in the framework of adversarial divergences, where the critic network is being used to estimate a divergence . Of course, the exact form of this divergence is not clear, but it does provide a connection to the GAN theory literature. We have made this connection explicit in our updated draft.</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div></div></main></div>
  </div>
</div>


    <!-- Footer -->
    <footer class="sitemap">
      <div class="container">
        <div class="row hidden-xs">
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/venues">All Venues</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="/contact">Contact</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
    
        <div class="row visible-xs-block">
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/contact">Contact</a></li>
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
      </div>
    </footer>
    
    <footer class="sponsor">
      <div class="container">
        <div class="row">
          <div class="col-sm-10 col-sm-offset-1">
            <p class="text-center">
              OpenReview is created by the <a href="http://www.iesl.cs.umass.edu/" target="_blank">Information Extraction and Synthesis Laboratory</a>, College of Information and Computer Science, University of Massachusetts Amherst. We gratefully acknowledge the support of the OpenReview sponsors:  Google,  Facebook, NSF, the University of Massachusetts Amherst Center for Data Science, and Center for Intelligent Information Retrieval, as well as the Google Cloud Platform for donating the computing and networking services on which OpenReview.net runs.
            </p>
          </div>
        </div>
      </div>
    </footer>

  <div id="feedback-modal" class="modal fade" tabindex="-1" role="dialog">
    <div class="modal-dialog">
      <div class="modal-content">
        <div class="modal-header">
          <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button>
          <h3 class="modal-title">Send Feedback</h3>
        </div>
        <div class="modal-body">
          <p>Enter your feedback below and we'll get back to you as soon as possible.</p>
          <form action="/feedback" method="POST">
            <div class="form-group">
              <input type="email" name="from" class="form-control" placeholder="Email" />
            </div>
            <div class="form-group">
              <input type="text" name="subject" class="form-control" placeholder="Subject" />
            </div>
            <div class="form-group">
              <textarea name="message" class="form-control feedback-input" rows="5" placeholder="Message" required=""></textarea>
            </div>
          <ul id="ui-id-2" tabindex="0" class="ui-menu ui-widget ui-widget-content" style="display: none;"></ul></form>
        </div>
        <div class="modal-footer">
          <button type="button" class="btn btn-default" data-dismiss="modal">Cancel</button>
          <button type="button" class="btn btn-primary">Send</button>
        </div>
      </div>
    </div>
  </div>

  <script type="text/javascript" async="" src="https://www.google-analytics.com/analytics.js"></script><script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js"></script>
  <script>window.jQuery || document.write('&lt;script src="/static/js/vendor/jquery-2.2.4.min.js"&gt;&lt;\/script&gt;')</script>

  <script src="/static/dist/vendor.min.js"></script>
  <script src="/static/dist/templates.min.js"></script>
  <script src="/static/dist/openreview.min.js"></script>

    <script>window.legacyScripts = true;</script>


    <script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-108703919-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() { dataLayer.push(arguments); }
      gtag('js', new Date());
      gtag('config', 'UA-108703919-1');
    </script>


<div role="status" aria-live="assertive" aria-relevant="additions" class="ui-helper-hidden-accessible"></div></body></html>
<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" class="no-js"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>Feature Attribution As Feature Selection | OpenReview</title>
  <meta name="description" content="" />

      <meta name="citation_title" content="Feature Attribution As Feature Selection" />
        <meta name="citation_author" content="Anonymous" />
      <meta name="citation_publication_date" content="2018/09/27" />
      <meta name="citation_online_date" content="2018/09/27" />
      <meta name="citation_pdf_url" content="https://openreview.net/pdf?id=H1lS8oA5YQ" />
      <meta name="twitter:card" content="summary" />
      <meta name="twitter:site" content="@openreviewnet" />
      <meta name="og:title" content="Feature Attribution As Feature Selection" />
      <meta name="og:description" content="Feature attribution methods identify " relevant"="" features="" as="" an="" explanation="" of="" a="" complex="" machine="" learning="" model.="" several="" feature="" attribution="" methods="" have="" been="" proposed;="" however,="" only="" few="" studies..."="" />
      <meta name="og:image" content="https://openreview.net/static/images/openreview_logo_512.png" />

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans:400,400i,700,700i" />

  <link rel="stylesheet" href="/static/css/bootstrap.min.css" />
  <link rel="stylesheet" href="/static/css/jquery-ui.min.css" />
  <link rel="stylesheet" href="/static/css/main.min.css" />
</head>

<body class="forum">
  <nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
  
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand home push-link" href="/"><strong>OpenReview</strong>.net</a>
      </div>
  
      <div id="navbar" class="navbar-collapse collapse">
        <form class="navbar-form navbar-left profile-search" role="search">
          <div class="form-group has-feedback">
            <input id="search_input" type="text" class="form-control ui-autocomplete-input" placeholder="Search ICLR 2019 Conference" autocomplete="off" />
            <span class="glyphicon glyphicon-search form-control-feedback" aria-hidden="true"></span>
          </div>
  
          <input id="search_group" type="hidden" value="ICLR.cc/2019/Conference" />
          <input id="search_content" type="hidden" value="all" />
        <ul id="ui-id-1" tabindex="0" class="ui-menu ui-widget ui-widget-content ui-autocomplete ui-front" style="display: none;"></ul></form>
  
        <ul class="nav navbar-nav navbar-right">
        
            <li id="user-menu"><a href="/login">Login</a></li>
        </ul>
      </div>
  
    </div>
  </nav>

  <div id="or-banner" class="banner" style="">
  <div class="container">
    <div class="row">
      <div class="col-xs-12"><a href="/group?id=ICLR.cc/2019/Conference" title="Venue Homepage"><img class="icon" src="/static/images/arrow_left.svg" /> Go to <strong>ICLR 2019 Conference</strong> homepage</a></div>
    </div>
  </div>
</div>
<div id="flash-message-container" class="alert alert-danger" role="alert" style="display: none;">
  <div class="container">
    <div class="row">
      <div class="col-xs-12">
        <div class="alert-content">
          <button type="button" class="close" aria-label="Close"><span aria-hidden="true">×</span></button>
        </div>
      </div>
    </div>
  </div>
</div>

<div class="container">
  <div class="row">
    <div class="col-xs-12">
      <main id="content" class="clearfix openbanner-visible legacy-styles"><div id="note_H1lS8oA5YQ" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Feature Attribution As Feature Selection</a> <a class="note_content_pdf" href="/pdf?id=H1lS8oA5YQ" title="Download PDF" target="_blank"><img src="/static/images/pdf_icon_blue.svg" /></a> </h2></div><div class="meta_row"><span class="signatures">Anonymous</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">28 Sep 2018 (modified: 11 Oct 2018)</span><span class="item">ICLR 2019 Conference Blind Submission</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span><span class="item"><a class="action-bibtex-modal" data-bibtex="@inproceedings{    &#10;anonymous2019feature,    &#10;title={Feature Attribution As Feature Selection},    &#10;author={Anonymous},    &#10;booktitle={Submitted to International Conference on Learning Representations},    &#10;year={2019},    &#10;url={https://openreview.net/forum?id=H1lS8oA5YQ},    &#10;note={under review}    &#10;}">Show Bibtex</a></span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Abstract: </span><span class="note_content_value">Feature attribution methods identify "relevant" features as an explanation of a complex machine learning model. Several feature attribution methods have been proposed; however, only a few studies have attempted to define the "relevance" of each feature mathematically. In this study, we formalize the feature attribution problem as a feature selection problem. In our proposed formalization, there arise two possible definitions of relevance. We name the feature attribution problems based on these two relevances as Exclusive Feature Selection (EFS) and Inclusive Feature Selection (IFS). We show that several existing feature attribution methods can be interpreted as approximation algorithms for EFS and IFS. Moreover, through exhaustive experiments, we show that IFS is better suited as the formalization for the feature attribution problem than EFS.</span></div><div class="note_contents"><span class="note_content_field">Keywords: </span><span class="note_content_value">feature attribution, feature selection</span></div><div class="reply_row clearfix"><div class="item" id="reply_count">6 Replies</div></div></div><hr class="small" /><div id="note_children"><div class="note_with_children"><div id="note_HJxZkrZ03X" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>FEATURE ATTRIBUTION AS FEATURE SELECTION</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=H1lS8oA5YQ&amp;noteId=HJxZkrZ03X"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper173 AnonReviewer3</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">06 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper173 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">The authors formalize the feature attribution problem as a feature selection problem and they demonstrate that several existing feature attribution methods can be interpreted as approximation algorithms for Exclusive Feature Selection and Inclusive Feature Selection.

- The authors claim that IFS is better suited as the formalization for the feature attribution problem and EFS has several unfavourable properties. Although they did exhaustive experiments to show this, it is not clear to the reviewer. 

- Also, it is more interesting if the authors can show how we use IFS in real applications.
</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">4: Ok but not good enough - rejection</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_Hkgw0NokRQ" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>IFS is better because EFS is quite similar to AE.</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=H1lS8oA5YQ&amp;noteId=Hkgw0NokRQ"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper173 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">19 Nov 2018</span><span class="item">ICLR 2019 Conference Paper173 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">First of all, we would like to thank you for your time and efforts to review our paper.

&gt; - The authors claim that IFS is better suited as the formalization for the feature attribution problem and EFS has several unfavorable properties. Although they did exhaustive experiments to show this, it is not clear to the reviewer. 

The reason why EFS is not favorable is because "In EFS (2.2), instead of the data perturbation, one searches for a small number of corrupted features that reduces the class intensity", which is very similar to adversarial example (AE) where one seeks the minimum data perturbation that changes the model’s output. The experimental results also support this observation. This is the reason why we concluded EFS is not favorable.
We are happy to have more feedbacks where you find it unclear. We will elaborate the discussion in the manuscript based on the feedback.

&gt; it is more interesting if the authors can show how we use IFS in real applications.

All the feature attribution methods mentioned in this paper can be used for the same purposes. For example, as we have done in the experiments, we can used them to highlight where DNN has focused on when making decisions.
We note that our focus is  on formalizing the feature attribution problem. That is, while several feature attribution methods have been proposed, to date, the formal definition of "relevance" underlying those methods remains unclear. We believe that our study is a first step towards understanding the relevance underlying several feature attribution methods. We also believe that formalizing the relevance is also helpful developing better methods, as we have demonstrated in Grad-IFS which attained the best AOIC. </span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div><div class="note_with_children"><div id="note_ryl4-82n2X" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>good review but could be lacking in terms of contribution</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=H1lS8oA5YQ&amp;noteId=ryl4-82n2X"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper173 AnonReviewer1</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">05 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper173 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">In this paper, the authors study the feature attribution problem as feature selection (exclusive and inclusive).  The authors go through previous work, provide definitions and attempt to answer questions that are relevant to this task.  The authors provide several experiments in order to empirically evaluate which of the two feature selection approaches is better suited for feature attibution.  Although this is a good review, and the motivation is sound, I think that much more ellaboration, and experiments on more than 200 images, would be required to reach definitive conclusions.</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">4: Ok but not good enough - rejection</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_ryxJaoskRm" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>We are happy to elaborate the discussion. What should we elaborate?</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=H1lS8oA5YQ&amp;noteId=ryxJaoskRm"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper173 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">19 Nov 2018</span><span class="item">ICLR 2019 Conference Paper173 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">First of all, we would like to thank you for your time and efforts to review our paper.

&gt; much more ellaboration

We are happy to elaborate the discussion so that our manuscript to be more useful to the readers. We are happy if you can point out which part of our manuscript needs elaboration. For example, which of our discussions are less convincing or need to be detailed to improve the readability.

&gt; experiments on more than 200 images

To tell the truth, this was because of our budget and time limitation. Even for 200 images, just evaluating AUEC and AOIC takes around two weeks (see the details below). To increase the number of images to be evaluated, we need expensive environments which we cannot manage. Please takes this fact into consideration.
Here, we would also like to mention that, even with 200 images, Fig4 would be already sufficient to conclude that IFS is advantageous than EFS. We did not select results to bias our conclusion. For 200 images, Grad-EFS produced shot noises (i.e. adversarial examples), while Grad-EFS produced reasonable heatmaps. Moreover, while AUEC was not good at evaluating the performance differences between several methods, AOIC could distinguish good methods and bad methods. These results indicate that IFS is better suited as the formalization of the feature attribution problem.

[Why two weeks?]
To evaluate one g_c(S_q) in Sec4 for a threshold q, we generated 100 noises as r, and computed the empirical average. This requires 100 forward propagation in DNN. To evaluate AUEC and AOIC, we varied the threshold q for around 30 different values. Thus, for one heatmap, 6000 forward propagation is required to compute both AUEC and AOIC. Because we computed AUEC and AOIC for 200 images with 14 different feature attribution methods, the number of forward propagation is then 16800000 for one DNN. Because we evaluated for three DNNs and for two types of noises r, the total number of forward propagation is 1000800000. Even if one forward pass takes 0.01sec, the total runtime required is 10008000sec ~ 280hours, which is almost two weeks.
We also note that, this 280 hours is just for evaluating AUEC and AOIC. Our experiments also require certain amount of times for computing heatmaps (thus, the entire experiments can take more than two weeks).</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div><div class="note_with_children"><div id="note_HylGTEbi2m" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Limited novelty and technical contribution</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=H1lS8oA5YQ&amp;noteId=HylGTEbi2m"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper173 AnonReviewer2</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">03 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper173 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">This paper formulates feature attribution from a feature selection perspective, and compares EFS (Exclusive Feature Selection) and IFS (Exclusive Feature Selection), which shows IFS is a better fit for feature attribution.

[+] The paper is well-structured and the proposed approach is clearly presented.
[-] It would helpful if the author could discuss the time complexity of proposed methods and compare the running time with baseline methods in evaluation.
[-] My major concern on this paper is the significance, as the contribution of the paper seems to be very limited.
    1) Formalizing the feature attribution problem as a feature selection problem is straightforward. IFS and EFS are just Forward and Backward stepwise feature selection, which are classic feature selection schemes. Applying them to feature attribution/saliency map does not seem to have much technical contribution.
    2) One claimed contribution of this paper is that existing feature attribution methods can be viewed as approximation of IFS and EFS. However, this contribution also seems to be minor. As many feature selection methods are known to be approximation of backward or forward stepwise feature selection, it is straightforward to show the connection between other feature attribution methods and IFS/EFS.

In conclusion, I would recommend to reject this paper due to the limited novelty and technical contribution.
</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">3: Clear rejection</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">3: The reviewer is fairly confident that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_HJgCuX21A7" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Clarifying the connection between feature attribution and feature selection will open up future research directions.</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=H1lS8oA5YQ&amp;noteId=HJgCuX21A7"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper173 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">19 Nov 2018</span><span class="item">ICLR 2019 Conference Paper173 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">First of all, we would like to thank you for your time and efforts to review our paper.

&gt; the time complexity

Grad-IFS (which attained the best AOIC) requires solving an optimization problem, and it is therefore not very fast. Practically it takes around a few minutes with one GPU. We are working on improving the computation time, but we leave it beyond the scope of this manuscript because our focus is on *formalizing the feature attribution problem* rather than claiming that our method is SOTA.
We would also like to mention that *fast computation* is not always the first priority. Feature attribution is used, e.g. for checking whether the model made decisions based on right reasons. For that purpose, less accurate methods are not preferable even though they are computationally fast. Grad-IFS (or PertMap) would be more appropriate for such purpose where they can highlight "the reason" more accurately (as we have demonstrated in the experiments).

&gt; 1) Formalizing the feature attribution problem as a feature selection problem is straightforward. IFS and EFS are just Forward and Backward stepwise feature selection, which are classic feature selection schemes. Applying them to feature attribution/saliency map does not seem to have much technical contribution.

Please remind the fact that while tens of feature attribution methods have been proposed in the last few years, the connection between feature attribution and feature selection was overlooked. Instead, most studies have focused on improving the gradient-based methods (as we can see in Fig1) although, to date, the connection between the gradient and the "relevance" remains unclear. We believe that clarifying the connection between feature attribution and feature selection can enrich the research direction beyond the gradient. This is the reason why we raised the research question "(Q1) how can we define relevance?" Our observation is that there is no reason to stick to the gradient. We believe that (even though it may sound straightforward), our observation is important to push the entire research field forward beyond the gradient.

&gt; 2) One claimed contribution of this paper is that existing feature attribution methods can be viewed as approximation of IFS and EFS. However, this contribution also seems to be minor. As many feature selection methods are known to be approximation of backward or forward stepwise feature selection, it is straightforward to show the connection between other feature attribution methods and IFS/EFS.

We believe that understanding existing feature attribution methods from the feature selection perspective is very useful. For example, in Appendix B, we found that SmoothGrad can be interpreted as one-step GD approximation starting from a non-zero parameter, while other gradient-based methods are one-step GD approximation starting from zeros. This can explain the practical advantage of SmoothGrad, which is known to perform well in practice (and also in AOIC as we have demonstrated). The connection can also open up future research directions for improving feature attribution methods. For example, we can naturally extend the existing gradient-based methods from one-step GD approximation to few-steps GD approximation.</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div></div></main></div>
  </div>
</div>


    <!-- Footer -->
    <footer class="sitemap">
      <div class="container">
        <div class="row hidden-xs">
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/venues">All Venues</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="/contact">Contact</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
    
        <div class="row visible-xs-block">
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/contact">Contact</a></li>
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
      </div>
    </footer>
    
    <footer class="sponsor">
      <div class="container">
        <div class="row">
          <div class="col-sm-10 col-sm-offset-1">
            <p class="text-center">
              OpenReview is created by the <a href="http://www.iesl.cs.umass.edu/" target="_blank">Information Extraction and Synthesis Laboratory</a>, College of Information and Computer Science, University of Massachusetts Amherst. We gratefully acknowledge the support of the OpenReview sponsors:  Google,  Facebook, NSF, the University of Massachusetts Amherst Center for Data Science, and Center for Intelligent Information Retrieval, as well as the Google Cloud Platform for donating the computing and networking services on which OpenReview.net runs.
            </p>
          </div>
        </div>
      </div>
    </footer>

  <div id="feedback-modal" class="modal fade" tabindex="-1" role="dialog">
    <div class="modal-dialog">
      <div class="modal-content">
        <div class="modal-header">
          <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button>
          <h3 class="modal-title">Send Feedback</h3>
        </div>
        <div class="modal-body">
          <p>Enter your feedback below and we'll get back to you as soon as possible.</p>
          <form action="/feedback" method="POST">
            <div class="form-group">
              <input type="email" name="from" class="form-control" placeholder="Email" />
            </div>
            <div class="form-group">
              <input type="text" name="subject" class="form-control" placeholder="Subject" />
            </div>
            <div class="form-group">
              <textarea name="message" class="form-control feedback-input" rows="5" placeholder="Message" required=""></textarea>
            </div>
          <ul id="ui-id-2" tabindex="0" class="ui-menu ui-widget ui-widget-content" style="display: none;"></ul></form>
        </div>
        <div class="modal-footer">
          <button type="button" class="btn btn-default" data-dismiss="modal">Cancel</button>
          <button type="button" class="btn btn-primary">Send</button>
        </div>
      </div>
    </div>
  </div>

  <script type="text/javascript" async="" src="https://www.google-analytics.com/analytics.js"></script><script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js"></script>
  <script>window.jQuery || document.write('&lt;script src="/static/js/vendor/jquery-2.2.4.min.js"&gt;&lt;\/script&gt;')</script>

  <script src="/static/dist/vendor.min.js"></script>
  <script src="/static/dist/templates.min.js"></script>
  <script src="/static/dist/openreview.min.js"></script>

    <script>window.legacyScripts = true;</script>


    <script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-108703919-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() { dataLayer.push(arguments); }
      gtag('js', new Date());
      gtag('config', 'UA-108703919-1');
    </script>


<div role="status" aria-live="assertive" aria-relevant="additions" class="ui-helper-hidden-accessible"></div></body></html>
<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" class="no-js"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>Learning Robust, Transferable Sentence Representations for Text Classification | OpenReview</title>
  <meta name="description" content="" />

      <meta name="citation_title" content="Learning Robust, Transferable Sentence Representations for Text Classification" />
        <meta name="citation_author" content="Wasi Uddin Ahmad" />
        <meta name="citation_author" content="Xueying Bai" />
        <meta name="citation_author" content="Nanyun Peng" />
        <meta name="citation_author" content="Kai-Wei Chang" />
      <meta name="citation_publication_date" content="2018/09/27" />
      <meta name="citation_online_date" content="2018/09/27" />
      <meta name="citation_pdf_url" content="https://openreview.net/pdf?id=Sye8S209KX" />
      <meta name="twitter:card" content="summary" />
      <meta name="twitter:site" content="@openreviewnet" />
      <meta name="og:title" content="Learning Robust, Transferable Sentence Representations for Text..." />
      <meta name="og:description" content="Despite deep recurrent neural networks (RNNs) demonstrate strong performance in text classification, training RNN models are often expensive and requires an extensive collection of annotated data..." />
      <meta name="og:image" content="https://openreview.net/static/images/openreview_logo_512.png" />

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans:400,400i,700,700i" />

  <link rel="stylesheet" href="/static/css/bootstrap.min.css" />
  <link rel="stylesheet" href="/static/css/jquery-ui.min.css" />
  <link rel="stylesheet" href="/static/css/main.min.css" />
</head>

<body class="forum">
  <nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
  
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand home push-link" href="/"><strong>OpenReview</strong>.net</a>
      </div>
  
      <div id="navbar" class="navbar-collapse collapse">
        <form class="navbar-form navbar-left profile-search" role="search">
          <div class="form-group has-feedback">
            <input id="search_input" type="text" class="form-control ui-autocomplete-input" placeholder="Search ICLR 2019 Conference" autocomplete="off" />
            <span class="glyphicon glyphicon-search form-control-feedback" aria-hidden="true"></span>
          </div>
  
          <input id="search_group" type="hidden" value="ICLR.cc/2019/Conference" />
          <input id="search_content" type="hidden" value="all" />
        <ul id="ui-id-1" tabindex="0" class="ui-menu ui-widget ui-widget-content ui-autocomplete ui-front" style="display: none;"></ul></form>
  
        <ul class="nav navbar-nav navbar-right">
        
            <li id="user-menu"><a href="/login">Login</a></li>
        </ul>
      </div>
  
    </div>
  </nav>

  <div id="or-banner" class="banner" style="">
  <div class="container">
    <div class="row">
      <div class="col-xs-12"><a href="/group?id=ICLR.cc/2019/Conference" title="Venue Homepage"><img class="icon" src="/static/images/arrow_left.svg" /> Go to <strong>ICLR 2019 Conference</strong> homepage</a></div>
    </div>
  </div>
</div>
<div id="flash-message-container" class="alert alert-danger" role="alert" style="display: none;">
  <div class="container">
    <div class="row">
      <div class="col-xs-12">
        <div class="alert-content">
          <button type="button" class="close" aria-label="Close"><span aria-hidden="true">Ã—</span></button>
        </div>
      </div>
    </div>
  </div>
</div>

<div class="container">
  <div class="row">
    <div class="col-xs-12">
      <main id="content" class="clearfix openbanner-visible legacy-styles"><div id="note_Sye8S209KX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Learning Robust, Transferable Sentence Representations for Text Classification</a> <a class="note_content_pdf" href="/pdf?id=Sye8S209KX" title="Download PDF" target="_blank"><img src="/static/images/pdf_icon_blue.svg" /></a> </h2></div><div class="meta_row"><span class="signatures"><a href="/profile?email=wasiahmad%40cs.ucla.edu" class="profile-link" data-toggle="tooltip" data-placement="bottom" title="" data-original-title="wasiahmad@cs.ucla.edu">Wasi Uddin Ahmad</a>, <a href="/profile?email=xubai%40cs.stonybrook.edu" class="profile-link" data-toggle="tooltip" data-placement="bottom" title="" data-original-title="xubai@cs.stonybrook.edu">Xueying Bai</a>, <a href="/profile?email=npeng%40isi.edu" class="profile-link" data-toggle="tooltip" data-placement="bottom" title="" data-original-title="npeng@isi.edu">Nanyun Peng</a>, <a href="/profile?email=kwchang%40cs.ucla.edu" class="profile-link" data-toggle="tooltip" data-placement="bottom" title="" data-original-title="kwchang@cs.ucla.edu">Kai-Wei Chang</a></span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">28 Sep 2018 (modified: 17 Nov 2018)</span><span class="item">ICLR 2019 Conference Withdrawn Submission</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Abstract: </span><span class="note_content_value">Despite deep recurrent neural networks (RNNs) demonstrate strong performance in text classification, training RNN models are often expensive and requires an extensive collection of annotated data which may not be available. To overcome the data limitation issue, existing approaches leverage either pre-trained word embedding or sentence representation to lift the burden of training RNNs from scratch. In this paper, we show that jointly learning sentence representations from multiple text classification tasks and combining them with pre-trained word-level and sentence level encoders result in robust sentence representations that are useful for transfer learning. Extensive experiments and analyses using a wide range of transfer and linguistic tasks endorse the effectiveness of our approach.</span></div><div class="note_contents"><span class="note_content_field">Keywords: </span><span class="note_content_value">sentence representations learning, multi-task learning, transfer learning</span></div><div class="reply_row clearfix"><div class="item" id="reply_count">6 Replies</div></div></div><hr class="small" /><div id="note_children"><div class="note_with_children"><div id="note_r1x3NaPMpm" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Submission Withdrawn by the Authors</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=Sye8S209KX&amp;noteId=r1x3NaPMpm"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1542 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">09 Nov 2018</span><span class="item">ICLR 2019 Conference Paper1542 Withdraw Submission</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Withdrawal confirmation: </span><span class="note_content_value">I have read and agree with the withdrawal statement on behalf of myself and my co-authors.</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_HJeBif8jnX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Slight gains from concatenating token-based and sentence-based representations</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=Sye8S209KX&amp;noteId=HJeBif8jnX"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1542 AnonReviewer2</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">04 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper1542 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">This paper proposes a sentence encoder that is the concatenation of three separately trained component representations:
1.  An encoder adversarially trained in a multi-task setting (Section 3.1., trained with AllNLI and Quora)
2.  GenSen from Subramanian et al, ICLR 2018 (encoder trained with multi-task learning with 5 tasks/datasets, one of which is AllNLI)
3.  ELMo (average pooling of the word representations to get a sentence representation)

This combined representation is the best in the transfer learning setting for 5 out of the 15 tasks investigated (Tables 1 and 2).  

The portion of the representation learned in this paper (Sent2vec) appears to be mostly dominated by the existing GenSen.  In Table 1, GenSen is more accurate than Sent2vec for 7 out of the 8 investigated tasks.  Adding Sent2vec to the combination of GenSen+ELMo (comparing lines 4.2 and 4.3) changes the results by less than 1% absolute in 7 out of the 8 tasks.

Page 7 mentions that "we observe a significant improvement on 4 out of 8 tasks..." -- how was significance determined here?

In Table 2, the line for GenSen+ELMo (the equivalent of line 4.2 in Table 1) is missing.  This would be good to include for completeness.  

The idea of multitask learning for sentence representations is not new to this paper (see for example GenSen, which also uses multitask learning, with more tasks and includes two out of the three source datasets used here already).  </span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">4: Ok but not good enough - rejection</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_BkeIsjBqnX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Unclear Contribution and Novelty, Lack Ablation Study</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=Sye8S209KX&amp;noteId=BkeIsjBqnX"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1542 AnonReviewer3</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">03 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper1542 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">The paper studies several variants of BiLSTM-max for feature transfer learned from text classification tasks, shared or not shared. It also includes experiments with an adversary that attempts to improve the transferrability of the features.

The main issue of the paper is that the contribution and novelty cannot be clearly identified. All of the proposed models have appeared before, and these respective papers offer enough experiments to showcase their effectiveness. Furthermore, there is not a clear winner for any of the models studied in this paper. This makes it impossible to assess the novelty of the particular combination of methods.

Secondly, since the methods are different combinations of previously proposed approaches, better ablation study should be included that compare each component individually. The study offered in the paper only assesses the weights between transfer tasks, but not on the individual component.

Based on these comments, I recommend rejection of the paper</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">3: Clear rejection</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_BkeVFurd3Q" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Limited Novelty with questionable "improvements" over simpler setups from prior work</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=Sye8S209KX&amp;noteId=BkeVFurd3Q"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1542 AnonReviewer1</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">01 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper1542 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">The paper introduces an approach to train sentence representations from multiple text classification tasks. Two variants of shared private multi-task learning are employed to train BiLSTM based sentence encoders. Experiments were conducted with care and nicely compared to existing results from the literature. However, these show only incremental improvements over recent baselines. 

The idea of using shared and private encoders in the multitask setup is interesting, however, results do not indicate much improvements over simple MTL settings like the one from Conneau et al. Overall, the paper seems to be a straight-forward combination of 2 existing ideas: the model and datasets (except for QQP) from Conneau et al. and the SP setup from Liu et al. The additional QQP dataset actually doesn't seem to offer all that much looking at the appendix. Furthermore, the authors simply concatenate all embeddings that exist to build their universal representations which is fairly obvious that this helps. They also concatenate all private embeddings with the shared one, which is not all that fair in comparison to other results, because the larger dimensionality typically helps in these tasks, even with random projections [1]. Nevertheless there is no real gain over previous approaches.


So overall I believe that the incremental contributions in this paper as well as the lack of favorable results that would support the additions made over Conneau et al. make this paper rather an interesting workshop addition than a conference full-paper.


Comment:
On a sidenote, as a line of research I would also like to raise awareness on how little trained sentence representations actually offer over simple BoW representations. See for instance the following parallel submission [1] that uses BoW representations with random projections. This paper also points out a problem in InferSent that prevents proper evaluation when using max-pooling. In case the InferSent library was used to obtain results for this paper, this would make it hard to trust the results.

[1] <a href="https://openreview.net/forum?id=BkgPajAcY7" target="_blank" rel="nofollow">https://openreview.net/forum?id=BkgPajAcY7</a></span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">4: Ok but not good enough - rejection</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_HJxHufrD6m" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Sidenote</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=Sye8S209KX&amp;noteId=HJxHufrD6m"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">(anonymous)</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">13 Nov 2018</span><span class="item">ICLR 2019 Conference Paper1542 Public Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">About the sidenote: as one of the authors of the paper you mention, I'd like to urge you to be careful with premature conclusions about InferSent - it has fixed the max pooling issue a long time ago, and has been very open about it. The main effect of the issue is improved performance on small datasets like MR and CR, which we should probably stop using anyway :-) Also note that other well-known models, such as GenSen, suffer from the same issue. Hence, I think that your conclusion that using InferSent "makes it hard to trust the results" is not accurate.</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_BJefdYrD67" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>RE</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=Sye8S209KX&amp;noteId=BJefdYrD67"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1542 AnonReviewer1</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">13 Nov 2018</span><span class="item">ICLR 2019 Conference Paper1542 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Thanks a lot for the clarification. By no means I intended to put the InferSent library on the spot (although unfortunately I did) knowing that it offers a very comfortable way to evaluate sentence representations, but I just wanted to raise awawreness of my findings from browsing related papers at this conference. My review was of course not influenced by these findings, I just found it worth sharing. 

The fact that also GenSen has this problem, however, just supports my feeling that results on popular sentence representation benchmarks have to be taken with a grain of salt. However, again my final evaluation of this work was by no means influenced on this very personal opinion of mine.
</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div></div></div></div></main></div>
  </div>
</div>


    <!-- Footer -->
    <footer class="sitemap">
      <div class="container">
        <div class="row hidden-xs">
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/venues">All Venues</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="/contact">Contact</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
    
        <div class="row visible-xs-block">
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/contact">Contact</a></li>
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
      </div>
    </footer>
    
    <footer class="sponsor">
      <div class="container">
        <div class="row">
          <div class="col-sm-10 col-sm-offset-1">
            <p class="text-center">
              OpenReview is created by the <a href="http://www.iesl.cs.umass.edu/" target="_blank">Information Extraction and Synthesis Laboratory</a>, College of Information and Computer Science, University of Massachusetts Amherst. We gratefully acknowledge the support of the OpenReview sponsors:  Google,  Facebook, NSF, the University of Massachusetts Amherst Center for Data Science, and Center for Intelligent Information Retrieval, as well as the Google Cloud Platform for donating the computing and networking services on which OpenReview.net runs.
            </p>
          </div>
        </div>
      </div>
    </footer>

  <div id="feedback-modal" class="modal fade" tabindex="-1" role="dialog">
    <div class="modal-dialog">
      <div class="modal-content">
        <div class="modal-header">
          <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">Ã—</span></button>
          <h3 class="modal-title">Send Feedback</h3>
        </div>
        <div class="modal-body">
          <p>Enter your feedback below and we'll get back to you as soon as possible.</p>
          <form action="/feedback" method="POST">
            <div class="form-group">
              <input type="email" name="from" class="form-control" placeholder="Email" />
            </div>
            <div class="form-group">
              <input type="text" name="subject" class="form-control" placeholder="Subject" />
            </div>
            <div class="form-group">
              <textarea name="message" class="form-control feedback-input" rows="5" placeholder="Message" required=""></textarea>
            </div>
          <ul id="ui-id-2" tabindex="0" class="ui-menu ui-widget ui-widget-content" style="display: none;"></ul></form>
        </div>
        <div class="modal-footer">
          <button type="button" class="btn btn-default" data-dismiss="modal">Cancel</button>
          <button type="button" class="btn btn-primary">Send</button>
        </div>
      </div>
    </div>
  </div>

  <script type="text/javascript" async="" src="https://www.google-analytics.com/analytics.js"></script><script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js"></script>
  <script>window.jQuery || document.write('&lt;script src="/static/js/vendor/jquery-2.2.4.min.js"&gt;&lt;\/script&gt;')</script>

  <script src="/static/dist/vendor.min.js"></script>
  <script src="/static/dist/templates.min.js"></script>
  <script src="/static/dist/openreview.min.js"></script>

    <script>window.legacyScripts = true;</script>


    <script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-108703919-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() { dataLayer.push(arguments); }
      gtag('js', new Date());
      gtag('config', 'UA-108703919-1');
    </script>


<div role="status" aria-live="assertive" aria-relevant="additions" class="ui-helper-hidden-accessible"></div></body></html>
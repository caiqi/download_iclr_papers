<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" class="no-js"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>Capacity of Deep Neural Networks under Parameter Quantization | OpenReview</title>
  <meta name="description" content="" />

      <meta name="citation_title" content="Capacity of Deep Neural Networks under Parameter Quantization" />
        <meta name="citation_author" content="Anonymous" />
      <meta name="citation_publication_date" content="2018/09/27" />
      <meta name="citation_online_date" content="2018/09/27" />
      <meta name="citation_pdf_url" content="https://openreview.net/pdf?id=HylIcj0qFQ" />
      <meta name="twitter:card" content="summary" />
      <meta name="twitter:site" content="@openreviewnet" />
      <meta name="og:title" content="Capacity of Deep Neural Networks under Parameter Quantization" />
      <meta name="og:description" content="Most deep neural networks (DNNs) require complex models to achieve high performance. Parameter quantization is widely used for reducing the implementation complexities. Previous studies on..." />
      <meta name="og:image" content="https://openreview.net/static/images/openreview_logo_512.png" />

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans:400,400i,700,700i" />

  <link rel="stylesheet" href="/static/css/bootstrap.min.css" />
  <link rel="stylesheet" href="/static/css/jquery-ui.min.css" />
  <link rel="stylesheet" href="/static/css/main.min.css" />
</head>

<body class="forum">
  <nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
  
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand home push-link" href="/"><strong>OpenReview</strong>.net</a>
      </div>
  
      <div id="navbar" class="navbar-collapse collapse">
        <form class="navbar-form navbar-left profile-search" role="search">
          <div class="form-group has-feedback">
            <input id="search_input" type="text" class="form-control ui-autocomplete-input" placeholder="Search ICLR 2019 Conference" autocomplete="off" />
            <span class="glyphicon glyphicon-search form-control-feedback" aria-hidden="true"></span>
          </div>
  
          <input id="search_group" type="hidden" value="ICLR.cc/2019/Conference" />
          <input id="search_content" type="hidden" value="all" />
        <ul id="ui-id-1" tabindex="0" class="ui-menu ui-widget ui-widget-content ui-autocomplete ui-front" style="display: none;"></ul></form>
  
        <ul class="nav navbar-nav navbar-right">
        
            <li id="user-menu"><a href="/login">Login</a></li>
        </ul>
      </div>
  
    </div>
  </nav>

  <div id="or-banner" class="banner" style="">
  <div class="container">
    <div class="row">
      <div class="col-xs-12"><a href="/group?id=ICLR.cc/2019/Conference" title="Venue Homepage"><img class="icon" src="/static/images/arrow_left.svg" /> Go to <strong>ICLR 2019 Conference</strong> homepage</a></div>
    </div>
  </div>
</div>
<div id="flash-message-container" class="alert alert-danger" role="alert" style="display: none;">
  <div class="container">
    <div class="row">
      <div class="col-xs-12">
        <div class="alert-content">
          <button type="button" class="close" aria-label="Close"><span aria-hidden="true">×</span></button>
        </div>
      </div>
    </div>
  </div>
</div>

<div class="container">
  <div class="row">
    <div class="col-xs-12">
      <main id="content" class="clearfix openbanner-visible legacy-styles"><div id="note_HylIcj0qFQ" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Capacity of Deep Neural Networks under Parameter Quantization</a> <a class="note_content_pdf" href="/pdf?id=HylIcj0qFQ" title="Download PDF" target="_blank"><img src="/static/images/pdf_icon_blue.svg" /></a> </h2></div><div class="meta_row"><span class="signatures">Anonymous</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">28 Sep 2018 (modified: 11 Oct 2018)</span><span class="item">ICLR 2019 Conference Blind Submission</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span><span class="item"><a class="action-bibtex-modal" data-bibtex="@inproceedings{    &#10;anonymous2019capacity,    &#10;title={Capacity of Deep Neural Networks under Parameter Quantization},    &#10;author={Anonymous},    &#10;booktitle={Submitted to International Conference on Learning Representations},    &#10;year={2019},    &#10;url={https://openreview.net/forum?id=HylIcj0qFQ},    &#10;note={under review}    &#10;}">Show Bibtex</a></span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Abstract: </span><span class="note_content_value">Most deep neural networks (DNNs) require complex models to achieve high performance. Parameter quantization is widely used for reducing the implementation complexities. Previous studies on quantization were mostly based on extensive simulation using training data. We choose a different approach and attempt to measure the per-parameter capacity of DNN models and interpret the results to obtain insights on optimum quantization of parameters. This research uses artificially generated data and generic forms of fully connected DNNs, convolutional neural networks, and recurrent neural networks. We conduct memorization and classification tests to study the effects of the number and precision of the parameters on the performance. The model and the per-parameter capacities are assessed by measuring the mutual information between the input and the classified output. We also extend the memorization capacity measurement results to image classification and language modeling tasks. To get insight for parameter quantization when performing real tasks, the training and test performances are compared.</span></div><div class="note_contents"><span class="note_content_field">Keywords: </span><span class="note_content_value">quantization, network capacity, hardware implementation, network compression</span></div><div class="note_contents"><span class="note_content_field">TL;DR: </span><span class="note_content_value">We suggest the sufficient number of bits for representing weights of DNNs and the optimum bits are conservative when solving real problems.</span></div><div class="reply_row clearfix"><div class="item" id="reply_count">3 Replies</div></div></div><hr class="small" /><div id="note_children"><div class="note_with_children"><div id="note_BkeamNU0hX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a> Interesting results that are well presented, but reads like a lab report with minimal background research, and lacks novelty or significant experimental insight</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HylIcj0qFQ&amp;noteId=BkeamNU0hX"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper534 AnonReviewer3</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">06 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper534 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">Missing references about VC dimension /shattering, Rademacher complexity, etc.

I would like to see more discussion and motivation of using MI to measure capacity (of NNs, or in other contexts). I am not an expert in this area, so I do not know what the appropriate references would be, but only one reference about MI is cited. The paragraph under eqn (1) is helpful, but the relationship between classification accuracy and MI still seems unclear to me.

I also find it is not clear exactly what the MI is measured between - this should be made clearer in the main text, and also in appendix B. Xi and f(theta, Xi) are defined, but nothing else is. It is fairly easy for someone familiar with the notation to guess what the variables refer to, but this should be explicitly stated to avoid confusion and ambiguity. What exactly is Y? The output of the softmax?

Aside from the lack of clarity about notation/what symbols represent, I have two main issues with appendix B.
First is the claim "Note that X and Y are independent as well as Yi and Yj when i neq j"; I think it should be made clearer that X and Y are independent only in this setting because the experiments are with random data, and it does not seem obvious to me that Yi and Yj are independent. 
Second, using average accuracy as the probability that the class is the true class seems strange to me for random data. Maybe it's fine and I just haven't wrapped my head around it, or I misunderstood something, but I would like to understand why it makes sense to do this.

Is it standard not to quantize bias values? why does having a large dynamic range mean they shouldn't be quantized?

I find section 3 not very clear. I understand why the loss under perturbation is interesting, but this should be discussed along with what are the results of your experiments. The procedure for doing this should also be cited, unless you came up with it on your own in which case the justification for it should be further discussed.
I assume you don't do this, but the way the section is worded makes it sound like you train networks with a noisy loss.

It would be interesting to investigate the claims about parameter-sharing in CNNs (and RNNs) increasing their capacity as measured by MI; e.g. plot MI vs. #times filter is used for different convnet configurations, and #timesteps for RNNs.

Quality: 6/10 The writing is mostly clear to follow, although paragraphs don't always flow well into each other and some sections assume a lot of knowledge. 
Clarity: 7/10 Results are clearly presented, although more intuition and context would be helpful, and some sections are not well explained or contextualized
Originality: 2/10 The methods are not novel, to my knowledge, and there is little exploration or insight given for the extensive experimental results
Significance: 7/10 measuring and reporting results is valuable, and the reported results are interesting

Pros:
 - interesting results, good plots
 - overall well structured and explained

Cons:
 - plots could use more explanation and interpretation in the captions, and more investigation and insight from the experiments
 - some sections are not clearly worded and I think the objective/interpretation of the experiments would not be clear to someone even a little unfamiliar with the approaches cited


Specific comments/nits (in order reading through paper):
1. First paragraph of intro is kind of fluff/unnecessary. I would suggest beginning with the 3rd paragraph and work in the second.
2. It is usually advised in scientific writing not to use phrases like "it is known". "It has been shown by [refs]" would be better.
3. "in the over-parameter region" -&gt; overparameterized
4. "real-models" -&gt; real models (although this seems like a bit of an odd thing to say to me. What are fake models?? maybe "empirical study" would be better)
5. "Related work and backgrounds" remove s
6. "capacity ... is related to the learnability of networks" I don't think this makes it more clear; it just brings up the question about what you mean by learnabilty. Maybe "how much a network can learn to capture about a dataset" or something like that. 
7. "is shown as" odd phrasing, maybe "is defined as?
8. "classification task (Collins et al)" -&gt; "classiification task, as in Collins et al"
9. mention what scikit learn uses for hyperparameter tuning / why you use this
10. Figure 1 would benefit from a bit more explanation in the caption (e.g. memorization performance on/of what; explain what the acronyms mean and what the results tell us)
11. Some of the hyperparameter specifications here could be put in an appendix if you need space. Some of this information is also not specific to FCDNNs and should go in the preamble before the subsections for each architecture
12. Figure 2: Why does accuracy go to 1.4? Like Figure 1, caption would benefit from more information and some interpretation. Why do you think the MI levels off/goes up on the right hand side of A?
13. References about capacity here at the end of 4.1 should go in the background and related work section
14. "Result is consistent with theoretical study" In what ways? How consistent is it? What does the theory say?
15. Mention if you use truncated bptt in the RNN experiments
16. Mention what it means for "all models use full capacity"
17. VLSI mentioned without definition
18. "RNNs have the tendency of demanding more bits when compared to FCDNNs" I find this sentence unclear
19. "conducting memorization tasks, rather than inferencing with unseen data" -&gt; saying "generalization tasks" would be more accurate; maybe this is being too picky but they can inference with unseen data just fine wihtout requiring more parameter precision; it's only if we care about the generalization performance that they require more parameter precision.</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">5: Marginally below acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">3: The reviewer is fairly confident that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_ryeAuPHj27" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Interesting analysis, but a bit confusing in some parts</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HylIcj0qFQ&amp;noteId=ryeAuPHj27"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper534 AnonReviewer2</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">04 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper534 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">This paper presents an analysis of the capacity of different models of deep neural networks with and without parameter quantization. The capacity of a network is calculated as the maximum of the mutual information between the real output and the neural network output, considering both of them as random variables. For the estimation of the network capacity the network is trained to maximize the mutual information given random inputs and random labels. As shown in Fig. 2 (a), the capacity of the network corresponds to the maximum number of random samples that a network can memorize. The capacity can be divided by the number of parameters, so that we can estimate how many bits of information every parameter can memorize, and therefore having an estimation of the maximum parameter quantization that we can use without losing memorization capabilities. Interestingly, the measured capacity seems to not depend on the number of parameters, but on the architecture of the network. Experiments on real data seem to show that the estimation made is conservative and when the aim of the network is generalization, the number of bits per parameter can be reduced further.

Pros:
- The idea of evaluating the network capability of memorization for estimating the quantization of the parameters make sense to me and is novel in my knowledge.
- With the proposed experiments, one can have an idea about a possible quantization of the network parameters that is independent of the data that we want to train on.

Cons:
- The presentation of the paper is sometimes confusing. The conclusion gives a better explanation of the work than the introduction. Sec. 3.3 talks about weight perturbation, but no figure or experiments are shown until section 5.2 Figures are often very far from the corresponding text. In general, I found difficult to keep track of where we are in the paper.
- Some parts of the text should be improved for a better comprehension. For instance in equ.1 \hat{Y} is not defined. Also in the same section, the authors talk about mutual information of a trained network, but in my understanding the mutual information should be between two random variables. See also additional comments.
- The connection between memorization and generalization is not clear. The authors say that the estimation obtained with memorization is conservative, but it would be good to have a better understanding of that. Finally we want to speed-up the network with quantization and if the estimation is too conservative, we will be force to empirically test the quantization again, and therefore the proposed estimation would not really help.
- The proposed experiments can help us to estimate the amount of quantization of a given network independently of the data, which is quite nice. However, this estimation is still based on relatively long experiments.

Overall evaluation:
The proposed idea and experiments seem interesting, however the presentation of the paper needs some extra work to make it easier to read and understand. It took me several passes before understanding the paper.
I am willing to increase my score if the authors will be able to improve the quality of the presentation of the text and the experiments.

Additional comments:
- From the experiments the estimated bits per parameter for memorization are: 2.3 bit/param for the fully connected networks, 3 bits/param for CNN and 3.7 for RNN. The idea is that more the parameters are "shared" and more bits they require. Now, based on your observations, the actual capacity when using quantized parameters is of 6, 8 and 10 respectively. So, why there is a discrepancy between estimation and real experiments?
- In the last paragraph of sec. 3.1 the authors explain the training protocol for the experiments. I do not fully understand the need of those three phases, and the meaning of the boundary values for the hyper-parameters.
- In Fig. 4 N_{in} is confusing because before you used N for the number of samples and n_{in} for the number of input dimensions.
- From Fig. 3(a), it seems that for fully connected it is needed at least a 5 bits quantization to keep full accuracy. Why in the text you always mention 6 bits instead? </span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">5: Marginally below acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_ryxSIMVjn7" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>A good setup but very thin on relevant conceptual details</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HylIcj0qFQ&amp;noteId=ryxSIMVjn7"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper534 AnonReviewer1</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">03 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper534 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">
This paper indeed asks a very pertinent question about quantifying the effect of  parameter quantization on a neural net's performance. The authors take a very principled approach towards exploring this by splitting up their experiments for (fully connected) DNN, CNN and RNN.  And they define the notion of "network capacity per parameter" which they show is varying in a small interval around 2 for all architectures and data set sizes. 

But the overall analysis of the paper is pretty thin and its hard to extract any specific insight out of this paper except to say that RNN's performance is hit the most by parameter quantization possibly because it had the largest capacity per parameter. 

But this conclusion comes from a context which has multiple unconvincing issues surrounding it which I list below, 

1. 
Isnt plot 2(b) essentially saying that there is something wrong with this notion of "capacity per parameter" because it doesnt seem to be very sensitive to data size or architecture? Across a wide range of changes it seems to be hardly varying and that seems to suggest that it is possibly sensing some approximate invariant rather than a discriminator between the different situations! And I cant see any plot showing how this capacity vs parameters changes when quantization is done. Shouldnt that have been the most crucial thing to demonstrate? 

2.
The basic notion of "capacity" comes from the equation (1) which seems tied to using 0/1 labels and binary data vectors. But most experiments (figure 6 and 7 say) in this paper do not seem to be in this setup. Given this why should any of the insights in section 3.1 transfer to the rest of the paper? 

3.
To the best of my understanding it seems to me that a lot is going on in how the quantization is done and how the training plays with this. This is only lightly mentioned in the beginning of section 3.2 and this is hardly any information to understand exactly as to how quantization has been implemented in training. I strongly feel that a lot more needs to be said about it and there should have been a clear pseudocode explaining this process. For all I know at this point, literally all conclusions depend on this implementation detail and that is missing. 

4.
Equation 3 looks somewhat confusing to me. The RHS is a random variable/function. Then what does it mean to say that the this random function is being plotted in Appendix C? 
</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">5: Marginally below acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">3: The reviewer is fairly confident that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></main></div>
  </div>
</div>


    <!-- Footer -->
    <footer class="sitemap">
      <div class="container">
        <div class="row hidden-xs">
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/venues">All Venues</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="/contact">Contact</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
    
        <div class="row visible-xs-block">
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/contact">Contact</a></li>
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
      </div>
    </footer>
    
    <footer class="sponsor">
      <div class="container">
        <div class="row">
          <div class="col-sm-10 col-sm-offset-1">
            <p class="text-center">
              OpenReview is created by the <a href="http://www.iesl.cs.umass.edu/" target="_blank">Information Extraction and Synthesis Laboratory</a>, College of Information and Computer Science, University of Massachusetts Amherst. We gratefully acknowledge the support of the OpenReview sponsors:  Google,  Facebook, NSF, the University of Massachusetts Amherst Center for Data Science, and Center for Intelligent Information Retrieval, as well as the Google Cloud Platform for donating the computing and networking services on which OpenReview.net runs.
            </p>
          </div>
        </div>
      </div>
    </footer>

  <div id="feedback-modal" class="modal fade" tabindex="-1" role="dialog">
    <div class="modal-dialog">
      <div class="modal-content">
        <div class="modal-header">
          <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button>
          <h3 class="modal-title">Send Feedback</h3>
        </div>
        <div class="modal-body">
          <p>Enter your feedback below and we'll get back to you as soon as possible.</p>
          <form action="/feedback" method="POST">
            <div class="form-group">
              <input type="email" name="from" class="form-control" placeholder="Email" />
            </div>
            <div class="form-group">
              <input type="text" name="subject" class="form-control" placeholder="Subject" />
            </div>
            <div class="form-group">
              <textarea name="message" class="form-control feedback-input" rows="5" placeholder="Message" required=""></textarea>
            </div>
          <ul id="ui-id-2" tabindex="0" class="ui-menu ui-widget ui-widget-content" style="display: none;"></ul></form>
        </div>
        <div class="modal-footer">
          <button type="button" class="btn btn-default" data-dismiss="modal">Cancel</button>
          <button type="button" class="btn btn-primary">Send</button>
        </div>
      </div>
    </div>
  </div>

  <script type="text/javascript" async="" src="https://www.google-analytics.com/analytics.js"></script><script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js"></script>
  <script>window.jQuery || document.write('&lt;script src="/static/js/vendor/jquery-2.2.4.min.js"&gt;&lt;\/script&gt;')</script>

  <script src="/static/dist/vendor.min.js"></script>
  <script src="/static/dist/templates.min.js"></script>
  <script src="/static/dist/openreview.min.js"></script>

    <script>window.legacyScripts = true;</script>


    <script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-108703919-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() { dataLayer.push(arguments); }
      gtag('js', new Date());
      gtag('config', 'UA-108703919-1');
    </script>


<div role="status" aria-live="assertive" aria-relevant="additions" class="ui-helper-hidden-accessible"></div></body></html>
<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" class="no-js"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>Multi-Domain Adversarial Learning | OpenReview</title>
  <meta name="description" content="" />

      <meta name="citation_title" content="Multi-Domain Adversarial Learning" />
        <meta name="citation_author" content="Anonymous" />
      <meta name="citation_publication_date" content="2018/09/27" />
      <meta name="citation_online_date" content="2018/09/27" />
      <meta name="citation_pdf_url" content="https://openreview.net/pdf?id=Sklv5iRqYX" />
      <meta name="twitter:card" content="summary" />
      <meta name="twitter:site" content="@openreviewnet" />
      <meta name="og:title" content="Multi-Domain Adversarial Learning" />
      <meta name="og:description" content="Multi-domain learning (MDL) aims at obtaining a model with minimal average risk across multiple domains. Our empirical motivation is automated microscopy data, where cultured cells are imaged after..." />
      <meta name="og:image" content="https://openreview.net/static/images/openreview_logo_512.png" />

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans:400,400i,700,700i" />

  <link rel="stylesheet" href="/static/css/bootstrap.min.css" />
  <link rel="stylesheet" href="/static/css/jquery-ui.min.css" />
  <link rel="stylesheet" href="/static/css/main.min.css" />
</head>

<body class="forum">
  <nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
  
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand home push-link" href="/"><strong>OpenReview</strong>.net</a>
      </div>
  
      <div id="navbar" class="navbar-collapse collapse">
        <form class="navbar-form navbar-left profile-search" role="search">
          <div class="form-group has-feedback">
            <input id="search_input" type="text" class="form-control ui-autocomplete-input" placeholder="Search ICLR 2019 Conference" autocomplete="off" />
            <span class="glyphicon glyphicon-search form-control-feedback" aria-hidden="true"></span>
          </div>
  
          <input id="search_group" type="hidden" value="ICLR.cc/2019/Conference" />
          <input id="search_content" type="hidden" value="all" />
        <ul id="ui-id-1" tabindex="0" class="ui-menu ui-widget ui-widget-content ui-autocomplete ui-front" style="display: none;"></ul></form>
  
        <ul class="nav navbar-nav navbar-right">
        
            <li id="user-menu"><a href="/login">Login</a></li>
        </ul>
      </div>
  
    </div>
  </nav>

  <div id="or-banner" class="banner" style="">
  <div class="container">
    <div class="row">
      <div class="col-xs-12"><a href="/group?id=ICLR.cc/2019/Conference" title="Venue Homepage"><img class="icon" src="/static/images/arrow_left.svg" /> Go to <strong>ICLR 2019 Conference</strong> homepage</a></div>
    </div>
  </div>
</div>
<div id="flash-message-container" class="alert alert-danger" role="alert" style="display: none;">
  <div class="container">
    <div class="row">
      <div class="col-xs-12">
        <div class="alert-content">
          <button type="button" class="close" aria-label="Close"><span aria-hidden="true">Ã—</span></button>
        </div>
      </div>
    </div>
  </div>
</div>

<div class="container">
  <div class="row">
    <div class="col-xs-12">
      <main id="content" class="clearfix openbanner-visible legacy-styles"><div id="note_Sklv5iRqYX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Multi-Domain Adversarial Learning</a> <a class="note_content_pdf" href="/pdf?id=Sklv5iRqYX" title="Download PDF" target="_blank"><img src="/static/images/pdf_icon_blue.svg" /></a> </h2></div><div class="meta_row"><span class="signatures">Anonymous</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">28 Sep 2018 (modified: 17 Nov 2018)</span><span class="item">ICLR 2019 Conference Blind Submission</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span><span class="item"><a class="action-bibtex-modal" data-bibtex="@inproceedings{    &#10;anonymous2019multi-domain,    &#10;title={Multi-Domain Adversarial Learning},    &#10;author={Anonymous},    &#10;booktitle={Submitted to International Conference on Learning Representations},    &#10;year={2019},    &#10;url={https://openreview.net/forum?id=Sklv5iRqYX},    &#10;note={under review}    &#10;}">Show Bibtex</a></span><a class="note_content_pdf item" href="/revisions?id=Sklv5iRqYX" target="_blank">Show Revisions</a></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Abstract: </span><span class="note_content_value">Multi-domain learning (MDL) aims at obtaining a model with minimal average risk across multiple domains. Our empirical motivation is automated microscopy data, where cultured cells are imaged after being exposed to known and unknown chemical perturbations, and each dataset displays significant experimental bias. This paper presents a multi-domain adversarial learning approach, MuLANN, to leverage multiple datasets with overlapping but distinct class sets, in a semi-supervised setting. Our contributions include: i) a bound on the average- and worst-domain risk in MDL, obtained using the H-divergence; ii) a new loss to accommodate semi-supervised multi-domain learning and domain adaptation; iii) the experimental validation of the approach, improving on the state-of-the-art on two standard image benchmarks, and a novel bioimage dataset, Cell.</span></div><div class="note_contents"><span class="note_content_field">Keywords: </span><span class="note_content_value">multi-domain learning, domain adaptation, adversarial learning, H-divergence, deep representation learning, high-content microscopy</span></div><div class="note_contents"><span class="note_content_field">TL;DR: </span><span class="note_content_value">Adversarial Domain adaptation and Multi-domain learning: a new loss to handle multi- and single-domain classes in the semi-supervised setting.</span></div><div class="reply_row clearfix"><div class="item" id="reply_count">6 Replies</div></div></div><hr class="small" /><div id="note_children"><div class="note_with_children"><div id="note_HylcynXA2X" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Good idea, but the results are not particularly convincing</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=Sklv5iRqYX&amp;noteId=HylcynXA2X"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper541 AnonReviewer2</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">06 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper541 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">PROS:
* Original idea of using separate "discriminator" paths for unknown classes
* Thorough theoretical explanation
* A variety of experiments
* Very well-written, and clear paper

CONS:
* The biggest problem for me was the unconvincing results. MNIST-to-MNIST-M has better baselines  (PixelDA performed better on this task for example), Office is not suitable for domain adaptation experiments anymore unless one wants to be in a few-datasample regime or work with data with noisy labels(the dataset is plagued with label pollution, and there are too few examples per class per domain for NN-based domain adaptation); the results on CELL were not convincing, I don't know the dataset but it seems that baseline NN does better than DA most of the times.
* Comparison with other methods did not take into account a variety of hyperparameters. Although I do understand the problem of evaluation in unsupervised DA, this should have at least been done in the semi-supervised case, and some analysis/discussion should be included for the unsupervised one. What if the proposed method performs that much better than baselines but they hyperparameters are not set correctly?</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">5: Marginally below acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_S1giTvK6am" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Updated results with hyper-parameter optimization, overall better than existing methods</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=Sklv5iRqYX&amp;noteId=S1giTvK6am"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper541 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">17 Nov 2018</span><span class="item">ICLR 2019 Conference Paper541 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">We thank the reviewer for their encouraging words.
 
"There are better baselines for MNIST to MNIST-M": yes, the presented method might not outperform all other methods on all other datasets. Still, we hope to convince the reviewer that the results on the other datasets are worth being considered. 

"Office is not suitable unless one wants to be in a few-datasample regime or work with data with noisy labels": we would like to point that this regime is quite realistic in Bioimage informatics (noisy, with few samples per class).

"The results on Cell are not convincing": as our goal is multi-domain learning on this dataset, the relevant performance indicator is the average risk over all domains. Table 2 details what happens in various categories of cases (on classes with/without labelled samples). Despite the (well-known) degradation of the results on labeled classes when one also considers unlabelled classes, the bottom line is that -- regarding the average risk -- our method outperforms the baseline. Importantly, MuLANN results on Cell are significantly better than the baseline on all rows which involve unlabeled classes (rows  3, 6, 9, 13), while remaining not significantly different to the baseline on 6/9 of the other rows.

"Comparison with other methods did not take into account a variety of hyperparameters". The reviewer is right. Complementary experiments have thus been performed, and tables 1, 2 updated. We investigated the impact of varying the learning rate, the weight lambda on the discriminator loss, the weight dzeta of the known-unknown discrimination loss, the learning rate schedule, lambda schedule as well as using different learning rates for pre-trained layers versus from scratch layers (see Table 5 for more detailed information). These results show a moderate sensitivity of MuLANN, MADA and DANN wrt hyper-parameters and confirm that MuLANN outperforms both MADA and DANN (detailed results available here <a href="https://drive.google.com/file/d/1NjtMKF53qmnx4_Jyvh-ofxb0WjzcDvow/view?usp=sharing)." target="_blank" rel="nofollow">https://drive.google.com/file/d/1NjtMKF53qmnx4_Jyvh-ofxb0WjzcDvow/view?usp=sharing).</a> </span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div><div class="note_with_children"><div id="note_SkeOpvO227" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>This paper has good presentation and sufficient contribution to the field</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=Sklv5iRqYX&amp;noteId=SkeOpvO227"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper541 AnonReviewer1</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">04 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper541 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">In this paper, the authors proposed a multi-domain adversarial learning approach, MULANN, to improve the classification accuracy on three datasets-DIGITS, OFFICE and CELL-in the semi-supervised DA setting. Itâ€™s contributions include: i) using the H-divergence to bound both the risk across all domains and the worst-domain risk (imbalance on a specific domain); ii) a new loss to accommodate semi-supervised multi-domain learning and domain adaptation; iii) the experimental validation of the approach, improving on the state-of-the-art on two standard image benchmarks, and a novel bioimage dataset, CELL. 
In addition, this paper has a clear logic to explain and prove the problem to be solved, and has ample experimental evidence. Above on, this paper did a meaningful work. But there are some errors of expression, so it should be checked.
</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">8: Top 50% of accepted papers, clear accept</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_ryxYrEt66X" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Thank you</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=Sklv5iRqYX&amp;noteId=ryxYrEt66X"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper541 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">17 Nov 2018</span><span class="item">ICLR 2019 Conference Paper541 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">We thank the reviewer for their encouraging words and will correct the errors of expression.</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div><div class="note_with_children"><div id="note_SkgS2HI5hQ" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Interesting known/unknown label multidomain learning setting, but weak evaluation</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=Sklv5iRqYX&amp;noteId=SkgS2HI5hQ"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper541 AnonReviewer3</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">03 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper541 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">Summary:

The manuscript proposes a multi-domain adversarial learning (MDL) method called MULANN, to leverage multiple datasets with overlapping but distinct class sets, in a semi-supervised setting. The authors define a new discrimination task to discriminate, within each domain, labeled samples from unlabeled ones that most likely belong to extra classes (classes with no labeled or unlabeled samples in the domain). They also introduce a bound on the average- and worst-domain risk in MDL, obtained using the H-divergence.

Strengths:

-Â The idea of using discriminators for separating the labeled samples from unlabeled ones that most likely belongÂ to extra classes is interesting.

-Â A new generalization bound for MDL is introduced.

-Â The paper was clear, well written, well-motivated and nicely structured.

-Â The authors perform numerous empirical experiments on several types of problems on various datasets (Digit, OFFICE,CELL) successfully showing how the MULANN can reduce the nasty effects of the adversarial domainÂ discriminator and repulse (a fraction of) unlabeled examples from labeled ones in each domain.

Weaknesses:

-Â all the experiments except the last row of Table 2 concern adaptation between two domains. Given the paper title, the reviewer would have expected more experiments in a multiple domain context. More precisely, for the digit datasets, the reviewer was interested to see how the proposed MDL performs on jointly adapting SVHN, MNIST, MNIST-M, and USPS or jointly adapting DSLR, Amazon, and Webcam for OFFICE dataset.Â Moreover, comparison with some of the DA baselines (ADDA[1], DSN[2]) is missing.

-Â The authors propose to rank the unlabeled samples of each domain according to the entropy of their classification of the current classifier. Obviously there must be some false ranking (specially at the initial stages of updating the classifier) for the unlabeled samples (e.g. the classifier may output high entropy for the unlabeled samples of the classes with labeled samples) and they may harm the performance of adaptation.Â  It is not clear how MULANN can work in this situation and how its performance vary with the noisy signals conveyed in those false pseudolabeled samples.

-Â Although the paper introduces the generalization bound for MDL, it does not give new formulation or algorithm to handle MDL (MULANN handles only the class asymmetry when domains involve distinct sets of classes and it has nothing to do with MDL). hence, there is no connection between the theoretical results on MDL generalization bound and the proposed method MULANN.

-Â Since each domain may have different number of classes, it is not clear how the number of classes (L) is set in the classification module (maximum number of classes in all domain?).

The reviewer is also interested to see how the the generalization bound introduced in this paper is related to the recent theoretical works [3],[4] on MDL.

[1]Â Tzeng, Eric, et al. "Adversarial discriminative domain adaptation."Â Computer Vision and Pattern Recognition (CVPR). Vol. 1. No. 2. 2017.

[2]Â Bousmalis, Konstantinos, et al. "Domain separation networks."Â Advances in Neural Information Processing Systems. 2016.

[3]Â Zhao, Han, et al. "Multiple Source Domain Adaptation with Adversarial Learning." Advances in Neural Information Processing Systems. 2018.

[4]Â Hoffman, Judy, Mehryar Mohri, and Ningshan Zhang. "Algorithms and Theory for Multiple-Source Adaptation."Â Â Advances in Neural Information Processing Systems. 2018.</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">6: Marginally above acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_SygyoFtapX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Connection between the theoretical results and proposed approach, addition of 3-domain experiments on Office and commenting on recent multiple source DA papers</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=Sklv5iRqYX&amp;noteId=SygyoFtapX"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper541 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">17 Nov 2018</span><span class="item">ICLR 2019 Conference Paper541 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">We thank the reviewer for their insightful comments.

Q1 "all the experiments except the last row of Table 2 concern adaptation between two domains. Given the paper title, the reviewer would have expected more experiments in a multiple domain context." 

A1 A main difference between domain adaptation and MDL is the fact that the former aims to minimize the target error, while the latter aims to minimize the average error. In this sense, our goal (and the validation experiments on Cell) are focused on MDL.

Q2 "Although the paper introduces the generalization bound for MDL, it does not give new formulation or algorithm to handle MDL" [...] "There is no connection between the theoretical results on MDL generalization bound and the proposed method MULANN."

A2 This issue is related to the above: the new generalization bound extends that of Ben David et al. in the sense that it considers all pairs of domains involved, thus bounding the *average* risk; and this bound is the one underlying the proposed algorithm and its MDL experiments. We have clarified this in the manuscript.

Q3 "the reviewer was interested to see how the proposed MDL performs on jointly adapting SVHN, MNIST, MNIST-M, and USPS or jointly adapting DSLR, Amazon, and Webcam for OFFICE dataset. "

A3: We added 3 domain experiments for Office, which are now displayed in Appendix E.1 table 6. As discussed in [3], we also find that the addition of a second source is not necessarily beneficial to target accuracy.

Q4: Comparison with some of the DA baselines (ADDA[1], DSN[2]) is missing."
A4: ADDA, an unsupervised DA method, proceeds by training sequentially a classifier on Source, then learning the Target feature space by making it indistinguishable from the Source one. However this is not applicable to the semi-supervised setting: either target labels would not be used in the first training step, or they would be used but without any domain loss to account for the fact that two domains are being used at the same time. Thus, the classifier would actually learn two sub-classifiers: one for each domain, which would turn counter-productive in the second step where this strong distinction between source and target would have to be un-learned. 
We are re-programming DSN and experimental results will be added. We thank the reviewer for the suggestion.

Q5: "The reviewer is also interested to see how the the generalization bound introduced in this paper is related to the recent theoretical works [3],[4] on MDL."

A5 Zhao et al. [3] consider the multiple source context; they define a weighted scheme where the weight of a source depends on its H-divergence with the target, plus its own classification error. The feature extractor is trained either from the best source only (in the sense of this weight), or from a weighted sum of the sources. When interested in multi-domain learning (thus aiming to minimize the average risk), it seems that there are two possibilities: a single feature extractor; or a feature extractor per domain. In the former case, the feature extractor might be overly conservative; in both cases, scalability w.r.t. the number of domains might be an issue. 

Hoffman et al. [4] also consider the multiple source context, assuming that the target is a unknown mixture of the sources (or not too far thereof in terms of Renyi divergence). Their experiments follow this assumption (using as target a mixture of sources Amazon, Webcam and DSLR). In our case this assumption does not hold, e.g. the joint distribution of England(x,y) is *not* a mixture of Texas(x,y) and California(x,y) (as can be seen by eye, and confirmed by experiments). The adversarial change of representation only enforces the merge of the marginals. 

Q6 "The authors propose to rank the unlabeled samples of each domain according to the entropy of their classification of the current classifier. Obviously there must be some false ranking (specially at the initial stages of updating the classifier) for the unlabeled samples"
    
A6 As the reviewer suggests, there are indeed misclassifications of samples using their entropy ranking in early training stages. We mention this section 4.3. This misclassification is the reason why it is better that hyper-parameter p slightly underestimates p* than is equal to it, as can be seen in Fig. 1, right (except when p*=1 as one could expect).

Q7 "Since each domain may have different number of classes, it is not clear how the number of classes (L) is set in the classification module (maximum number of classes in all domain?)."

A7 L is the cardinal of the union of classes with labeled examples in at least one domain.</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div></div></main></div>
  </div>
</div>


    <!-- Footer -->
    <footer class="sitemap">
      <div class="container">
        <div class="row hidden-xs">
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/venues">All Venues</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="/contact">Contact</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
    
        <div class="row visible-xs-block">
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/contact">Contact</a></li>
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
      </div>
    </footer>
    
    <footer class="sponsor">
      <div class="container">
        <div class="row">
          <div class="col-sm-10 col-sm-offset-1">
            <p class="text-center">
              OpenReview is created by the <a href="http://www.iesl.cs.umass.edu/" target="_blank">Information Extraction and Synthesis Laboratory</a>, College of Information and Computer Science, University of Massachusetts Amherst. We gratefully acknowledge the support of the OpenReview sponsors:  Google,  Facebook, NSF, the University of Massachusetts Amherst Center for Data Science, and Center for Intelligent Information Retrieval, as well as the Google Cloud Platform for donating the computing and networking services on which OpenReview.net runs.
            </p>
          </div>
        </div>
      </div>
    </footer>

  <div id="feedback-modal" class="modal fade" tabindex="-1" role="dialog">
    <div class="modal-dialog">
      <div class="modal-content">
        <div class="modal-header">
          <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">Ã—</span></button>
          <h3 class="modal-title">Send Feedback</h3>
        </div>
        <div class="modal-body">
          <p>Enter your feedback below and we'll get back to you as soon as possible.</p>
          <form action="/feedback" method="POST">
            <div class="form-group">
              <input type="email" name="from" class="form-control" placeholder="Email" />
            </div>
            <div class="form-group">
              <input type="text" name="subject" class="form-control" placeholder="Subject" />
            </div>
            <div class="form-group">
              <textarea name="message" class="form-control feedback-input" rows="5" placeholder="Message" required=""></textarea>
            </div>
          <ul id="ui-id-2" tabindex="0" class="ui-menu ui-widget ui-widget-content" style="display: none;"></ul></form>
        </div>
        <div class="modal-footer">
          <button type="button" class="btn btn-default" data-dismiss="modal">Cancel</button>
          <button type="button" class="btn btn-primary">Send</button>
        </div>
      </div>
    </div>
  </div>

  <script type="text/javascript" async="" src="https://www.google-analytics.com/analytics.js"></script><script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js"></script>
  <script>window.jQuery || document.write('&lt;script src="/static/js/vendor/jquery-2.2.4.min.js"&gt;&lt;\/script&gt;')</script>

  <script src="/static/dist/vendor.min.js"></script>
  <script src="/static/dist/templates.min.js"></script>
  <script src="/static/dist/openreview.min.js"></script>

    <script>window.legacyScripts = true;</script>


    <script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-108703919-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() { dataLayer.push(arguments); }
      gtag('js', new Date());
      gtag('config', 'UA-108703919-1');
    </script>


<div role="status" aria-live="assertive" aria-relevant="additions" class="ui-helper-hidden-accessible"></div></body></html>
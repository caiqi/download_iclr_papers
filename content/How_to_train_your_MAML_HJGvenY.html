<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" class="no-js"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>How to train your MAML | OpenReview</title>
  <meta name="description" content="" />

      <meta name="citation_title" content="How to train your MAML" />
        <meta name="citation_author" content="Anonymous" />
      <meta name="citation_publication_date" content="2018/09/27" />
      <meta name="citation_online_date" content="2018/09/27" />
      <meta name="citation_pdf_url" content="https://openreview.net/pdf?id=HJGven05Y7" />
      <meta name="twitter:card" content="summary" />
      <meta name="twitter:site" content="@openreviewnet" />
      <meta name="og:title" content="How to train your MAML" />
      <meta name="og:description" content="The field of few-shot learning has recently seen substantial advancements. Most of these advancements came from casting few-shot learning as a meta-learning problem.Model Agnostic Meta Learning or..." />
      <meta name="og:image" content="https://openreview.net/static/images/openreview_logo_512.png" />

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans:400,400i,700,700i" />

  <link rel="stylesheet" href="/static/css/bootstrap.min.css" />
  <link rel="stylesheet" href="/static/css/jquery-ui.min.css" />
  <link rel="stylesheet" href="/static/css/main.min.css" />
</head>

<body class="forum">
  <nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
  
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand home push-link" href="/"><strong>OpenReview</strong>.net</a>
      </div>
  
      <div id="navbar" class="navbar-collapse collapse">
        <form class="navbar-form navbar-left profile-search" role="search">
          <div class="form-group has-feedback">
            <input id="search_input" type="text" class="form-control ui-autocomplete-input" placeholder="Search ICLR 2019 Conference" autocomplete="off" />
            <span class="glyphicon glyphicon-search form-control-feedback" aria-hidden="true"></span>
          </div>
  
          <input id="search_group" type="hidden" value="ICLR.cc/2019/Conference" />
          <input id="search_content" type="hidden" value="all" />
        <ul id="ui-id-1" tabindex="0" class="ui-menu ui-widget ui-widget-content ui-autocomplete ui-front" style="display: none;"></ul></form>
  
        <ul class="nav navbar-nav navbar-right">
        
            <li id="user-menu"><a href="/login">Login</a></li>
        </ul>
      </div>
  
    </div>
  </nav>

  <div id="or-banner" class="banner" style="">
  <div class="container">
    <div class="row">
      <div class="col-xs-12"><a href="/group?id=ICLR.cc/2019/Conference" title="Venue Homepage"><img class="icon" src="/static/images/arrow_left.svg" /> Go to <strong>ICLR 2019 Conference</strong> homepage</a></div>
    </div>
  </div>
</div>
<div id="flash-message-container" class="alert alert-danger" role="alert" style="display: none;">
  <div class="container">
    <div class="row">
      <div class="col-xs-12">
        <div class="alert-content">
          <button type="button" class="close" aria-label="Close"><span aria-hidden="true">×</span></button>
        </div>
      </div>
    </div>
  </div>
</div>

<div class="container">
  <div class="row">
    <div class="col-xs-12">
      <main id="content" class="clearfix openbanner-visible legacy-styles"><div id="note_HJGven05Y7" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>How to train your MAML</a> <a class="note_content_pdf" href="/pdf?id=HJGven05Y7" title="Download PDF" target="_blank"><img src="/static/images/pdf_icon_blue.svg" /></a> </h2></div><div class="meta_row"><span class="signatures">Anonymous</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">28 Sep 2018 (modified: 11 Oct 2018)</span><span class="item">ICLR 2019 Conference Blind Submission</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span><span class="item"><a class="action-bibtex-modal" data-bibtex="@inproceedings{    &#10;anonymous2019how,    &#10;title={How to train your MAML},    &#10;author={Anonymous},    &#10;booktitle={Submitted to International Conference on Learning Representations},    &#10;year={2019},    &#10;url={https://openreview.net/forum?id=HJGven05Y7},    &#10;note={under review}    &#10;}">Show Bibtex</a></span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Abstract: </span><span class="note_content_value">The field of few-shot learning has recently seen substantial advancements. Most of these advancements came from casting few-shot learning as a meta-learning problem.Model Agnostic Meta Learning or MAML is currently one of the best approaches for few-shot learning via meta-learning. MAML is simple, elegant and very powerful, however, it has a variety of issues, such as being very sensitive to neural network architectures, often leading to instability during training, requiring arduous hyperparameter searches to stabilize training and achieve high generalization and being very computationally expensive at both training and inference times. In this paper, we propose various modifications to MAML that not only stabilize the system, but also substantially improve the generalization performance, convergence speed and computational overhead of MAML, which we call MAML++.</span></div><div class="note_contents"><span class="note_content_field">Keywords: </span><span class="note_content_value">meta-learning, deep-learning, few-shot learning, supervised learning, neural-networks, stochastic optimization</span></div><div class="note_contents"><span class="note_content_field">TL;DR: </span><span class="note_content_value">MAML is great, but it has many problems, we solve many of those problems and as a result we learn most hyper parameters end to end, speed-up training and inference and set a new SOTA in few-shot learning</span></div><div class="reply_row clearfix"><div class="item" id="reply_count">10 Replies</div></div></div><hr class="small" /><div id="note_children"><div class="note_with_children"><div id="note_Skg14bX92X" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>A paper with marginal novelty over an established framework.</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HJGven05Y7&amp;noteId=Skg14bX92X"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1086 AnonReviewer2</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">03 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper1086 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">[Summary]
This work presents several enhancements to the established Model-Agnostic Meta-Learning (MAML) framework. Specifically, the paper starts by analyzing the issues in the original implementations of MAML, including instability during training, costly second order derivatives evaluation, missing/shared batch normalization statistics accumulation/bias, and learning rate setting, which causes unstable or slow convergence, and weak generalization. The paper then proposes solutions corresponding to each of these issues, and reports improved performance on benchmark datasets.          

Pros
Good technical enhancements that fix some issues of a popular meta-learning framework
Cons
Little conceptual and technical novelty 

[Originality]
The major problem I found in this work is the lack of conceptual and technical novelty. The paper basically picks up some issues of the well-established MAML framework, and applies some common practices or off-the-shelf technical treatments to fix these drawbacks and improve the training stability, convergence, or generalization, etc. E.g., it seems to me that the most effective enhancement comes from the use of adoption of learning rate setting (LSLR), or variant version of batch normalization (BNWB+BNRS) in Table 1, which have been the standard tricks to improve performance in the deep learning literature. Overall, the conceptual originality is little.         

[Quality]
The paper does get most things well executed from the technical point of view. There does not seem any major errors to me. The results reported are also reasonable within the meta-learning context, despite lack of originality.  

[Clarity]
The paper is generally well written and I did not have much difficulty to follow. 

[Significance]
The significance of this work is marginal, given the lack of originality. The technical enhancements presented in the paper, however, may be of interest to people working in this area. 
</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">5: Marginally below acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">3: The reviewer is fairly confident that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_BklkMRGpam" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Response to Reviewer 2</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HJGven05Y7&amp;noteId=BklkMRGpam"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1086 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">17 Nov 2018</span><span class="item">ICLR 2019 Conference Paper1086 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Thank you for your review. 

Regarding the conceptual and technical novelty concerns.

To clarify, our main contribution comes in the form of carrying an investigation on how MAML can be stabilized and how the model can be modified such that it can consistently achieve faster convergence and strong generalization results without any hyperparameter tuning required. Then, once the investigation is completed and key problem-areas isolated, we use our investigation insights to improve the system. In fact, the whole reason for doing this was because we attempted to built new research ideas on top of MAML only to find out just how sensitive and unstable the system was. Therefore, we decided that finding the issues and fixing them would enable researchers working on gradient-based end-to-end meta-learning, such as MAML or Meta Learner LSTM [1] to concentrate on the new approach they want to build rather than trying to overcome instability issues of the base methodology. Furthermore, the industry would also benefit from this, as they would have an easier time training MAML based models. 

Most of the proposed approaches are novel and non-obvious (i.e. LSLR, BNWB+BNRS, and multi-step loss optimization). Overcoming gradient degradation issues by utilizing multi-step target-loss optimization which is annealed over time, is in our knowledge, done for the first time in this work. Furthermore, we provide novel contributions in the form of learning things “step-by-step”.

For example, we propose that learning per-layer, per-step learning rates would benefit the system, more so than just learning per-layer learning rates and sharing them. The reason is that the model would be free to choose to decrease its learning rate or otherwise change it from step to step to reduce overfitting. This technique is both novel and non-obvious. Furthermore, LSLR is not something that is possible in standard deep learning, as learning the learning rates would require an additional level of abstraction (thus entering the meta-learning arena). 

Another contribution with significant novelty comes in the form of proposing a step-by-step batch norm variant, designed for meta-learning systems that require inner loop optimization. Learning batch norm parameters for every step, as well as collecting per-step running statistics speeds up the system and allows batch normalization to truly work in this setting, whereas the previous variant of batch norm used, constrained things further, instead of achieving the improved convergence and generalization that batch norm can achieve in standard deep learning training setups. 

The rest of the contributions, such as annealing the derivative order and using cosine scheduling for Adam are less novel, but nonetheless important to investigate. We show from our experiments that those approaches can improve the system, something which was previously unconfirmed. 

The comparative performance (between MAML and MAML++) both in convergence speed and final generalization is significant and produces state of the art results. Furthermore, that performance is achieved far more consistently and with more stability across architectures. We hold the belief that the community would really benefit from this work, hence why we submitted it.

1. Ravi, S. and Larochelle, H. (2016). Optimization as a model for few-shot learning.
</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div><div class="note_with_children"><div id="note_rJg-0D-927" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>In-depth discussions and improvements on MAML</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HJGven05Y7&amp;noteId=rJg-0D-927"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1086 AnonReviewer3</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">03 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper1086 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">In the work, the authors improve a simple yet effective meta-learning algorithm called Model Agnostic meta-learning (MAML) from various aspects including training instability, batch normalization etc. The authors firstly point out the issues in MAML training and tackle each of the issue with a practical alternative approach respectfully. The few-shot classification results show convincing evidence.

Some major concerns:
1. The paper is too specific about improving one algorithm, the scope of the research is quite narrow and I'm afraid that some of the observations and proposed solutions might not generalize into other algorithms;
2. Section 4, "Gradient Instability → Multi-Step Loss Optimization." I don't see clearly why the multi-step loss would lead to stable gradients. It causes much more gradient paths than the original version. I do see the point of weighting the losses from different step;
3. The authors should have conducted careful ablation study of each of the issues and solutions. The six ways of proposed improvements may make the the performance boost hard to understand. It would help to see which way of the proposed improvement contribute more than others;
4. Many of the proposed improvements are essentially utilizing annealing mechanisms to stabilize the training, including 1) anneals the weighting of the losses from different step; 2) anneal the second derivative  to the first derivative;
5. For the last two improvements about the learning rate, there are dozens of literature on meta-learning learning rate and the proposed approach does not seem to be novel;  
 
Minors
1. The reference style is inconsistent across the paper, sometimes it feels quite messy. For example, "Batch Stochastic Gradient Descent Krizhevsky et al. (2012)" "Another notable advancement was the gradient-conditional meta-learner LSTM Ravi &amp; Larochelle (2016)";
2. Equation (2) (3) the index b should start from 1, size of B should be 1 to B;
</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">6: Marginally above acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_H1eHVoEaaX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Response to Reviewer 3</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HJGven05Y7&amp;noteId=H1eHVoEaaX"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1086 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">17 Nov 2018</span><span class="item">ICLR 2019 Conference Paper1086 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Thank you for taking the time to review our paper. Before I start delving into the technical aspects of this response. To address your concerns, I will use an enumeration that matches the indexes of your concerns.
The paper is indeed targeted towards a particular class of algorithms. That class being end-to-end differentiable gradient-based meta-learning. MAML and Meta-learner LSTM [1] are two instances of that particular class of algorithms. Our proposed techniques can be applied to any algorithm of that class, given that they utilize inner-loop optimization processes as part of their learning. So, even though this work is indeed targeted towards a particular class of models, that class is general enough and applicable to enough domains that we felt that an investigation of the type presented in this paper was necessary. In fact, the work in this paper was the result of the first author’s attempts to build systems that learn various other components (i.e. instead of just learning a highly adaptable parameter initialization, he was attempting to learn loss functions/update functions and dynamic generation of parameter initializations given a task among others). What he realized, however, was that MAML was really hard to actually work with, being very inflexible to architecture configuration, causing gradient degradation problems, instability in training and requiring lots of manual inner loop learning rate tuning.  In attempting to fix those problems, so he could build on top more complicated systems, this paper came to be. 
In MAML, the resulting inference model is effectively an unrolled 5 layer network over N steps. If that N=5, then the resulting model has a depth of effectively 25 layers. In standard deep networks, gradient degradation can be greatly reduced or altogether removed via the usage of skip-connections. Since in MAML we can’t really apply skip-connections from a subsequent model to a previous one (because that would further complicate the gradients), we decided that the best way to inject clean/stable gradients to all iterations of the network would be to use 2 losses for each step-wise network. One loss, providing an implicit gradient, coming from subsequent iterations of the network (i.e. the original MAML loss), and another per-step loss, providing an explicit gradient, coming directly from evaluating the model on the target set. This way, every network iteration receives stable gradients which keep the network stable during the early epoch training. Eventually, the importance of earlier steps becomes 0, which means that the original MAML loss is used instead. However, since the network has already learned a stable parameterization, the stability remains throughout training (we empirically confirmed this).
We conducted an ablation study on 20-way 1-shot Omniglot, as shown in table 2. We did want to conduct even more exhaustive ablation studies across all Omniglot and Mini-Imagenet tasks, however, due to computing constraints we had to restrict ourselves. Using the “hardest” Omniglot 20-way 1-shot task as the ablation study’s subject seemed like a sensible thing to do since it was cheaper computationally, but “hard” enough for the results to generalize well in other tasks.
Indeed, annealing various components is not as novel as some of the other proposals in the paper. However, since this paper was essentially an engineer’s handbook on how to train MAML-like models, we felt that people should be aware of the effect those techniques have on the system’s performance.
Indeed, there is other literature on meta-learning learning rates. Our approach’s novelty lies in learning “per-step” and “per-layer” learning rates. By being able to learn per step learning rates, we allow the network to choose to decrease or increase it’s learning rates at each step, to minimize overfitting. Another interesting phenomenon, that we will address in a future blog post, is the fact that across all networks, we noticed that particular layers choose to “un-learn” (flipping the direction of the learning rate) at particular steps. We theorize that the network might be attempting to remove some existing knowledge to replace it with new knowledge, or using forgetting as a way to steer gradients for more efficient learning.

Regarding the minor concerns, yes, we will fix the referencing inconsistencies and the batch size indexing problem.

Once again, I want to thank you for taking the time to review our work.

1. Ravi, S. and Larochelle, H. (2016). Optimization as a model for few-shot learning.
</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div><div class="note_with_children"><div id="note_rJxOlkMPh7" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Improving MAML</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HJGven05Y7&amp;noteId=rJxOlkMPh7"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1086 AnonReviewer1</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">31 Oct 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper1086 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">Paper summary - This paper provides a bag of sensible tricks for making MAML more stable, faster to learn, and better in final performance.
Quality - The quality of the work is strong: the results demonstrate that tweaks to MAML produce significant improvements in performance. However, I have some concern that certain portions of the text overclaim (see concerns section below).
Clarity - The paper is reasonably clear, with some exceptions (see concerns section).
Originality - The techniques described in the paper range from only mildly novel (e.g. MSL, DA), to very obvious (e.g. CA). Additionally, the paper's contributions amount to tweaks to a previously existing algorithm. 
Significance - The quality of the results make this a significant contribution in my view.
Pros - Good results on a problem/algorithm of great current interest.
Cons - Only presents (in some cases obvious) tweaks to a previous algorithm; clarity and overclaiming issues in the writeup.

Concerns (please address in author response)
- The paper says  "we … propose multiple ways to automate most of the hyperparameter searching required". I'm not sure that this is true. The only technique that arguably removes a hyperparameter is LSLR. Even in this case, you still have to initialize the inner loop learning rates, so I'm not convinced that even this reduces hyperparameters. Perhaps I've missed something, please clarify.
- Section 4's paragraph on LSLR seems to say that you have a single alpha for each layer of the network. If this is right, then saying your method has a "per layer gradient direction" is very confusing. Each layer's alpha modulates the magnitude of that layer's update vector, but not its direction. The per-layer alphas together modify the direction of the global update vector. Perhaps I've misunderstood; equations describing exactly what LSLR does would be helpful. In any case, this should be clarified in the text.

Suggestions (less essential than the concerns above)
- The write-up is redundant and carries unnecessary content. The paper would be better shorter (8 pages is not a minimum :)
Section 1 covers a lot of background on the basics of meta-learning background that could be skipped. Other papers you cite (e.g. the MAML paper cover this). 
    - Section 2 goes into more detail about e.g. matching nets than is necessary. 
    - Section 2 explains MAML, which is then covered in much more detail in Section 3; better to leave out the Section 2 MAML paragraph. 
    - Sections 3 and 4 are very redundant. Combine them for a shorter (i.e., better!) paper.
- The paper says, "Furthermore, for each learning rate learned, there will be N instances of that learning rate, one for each step to be taken. By doing this, the parameters are free to learn to decrease the learning rates at each step which may help alleviate overfitting." Does this happen empirically? Space could be freed up (see above) to have a figure showing whether or not this happens.
- The paper says, "we propose MAML++, an improved meta-learning framework" -- it's a little too far to call this a new framework. it's still MAML, with improvements.

Typos
- "4) increase the system’s computational overheads" -&gt; overhead
- "composed by" -&gt; composed of
- "Santurkar et al. (2018).", "Krizhevsky et al. (2012),",  "Finn et al. (2017) " -&gt; misplaced citation parens
- "a method that reduce" -&gt; reduces
- "An evaluation ran consisted" -&gt; evaluation consisted
- The Loshchlikov and Hutter citation in the bibliography isn't right. It should be "Sgdr: Stochastic gradient descent with restarts." (2016) instead of "Fixing weight decay regularization in adam" (2017).
</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">7: Good paper, accept</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_H1ewhME6TQ" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Response to Reviewer 1</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HJGven05Y7&amp;noteId=H1ewhME6TQ"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1086 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">17 Nov 2018</span><span class="item">ICLR 2019 Conference Paper1086 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Thanks for taking the time to review our paper. Further thanks for your very detailed, useful and constructive comments. We will now address your concerns below in the same order they were made:

We claim that we reduce the hyperparameter choices needed because once our methodologies are applied exactly as proposed, the resulting system will achieve very high generalization and fast convergence without any additional tuning. We have attempted to initialize the learning rates from a random uniform distribution (ranging from 0.1 to 0.01) in addition to initializing manually. Both methods, interestingly, converge to very similar learning rates. Thus, random initialization suffices for that aspect, which does reduce the need for explicitly choosing a learning rate.
Regarding the gradient directions. The alpha also includes a sign. So, in other words, the alpha also learns the direction of the learning rate, hence our claim. In fact, an interesting finding is that, in specific steps and layers, the network chooses to “unlearn” or flip the sign of the learning rate. Further investigation is required to understand this behavior, but a current working hypothesis is that the network is trying to “forget” particular parts of its weights, which somehow produces more efficient learning, in subsequent steps. We will further expand on this in a future blog post. 

All of your suggestions and typo-locations are spot-on and we will take care to address all of those in the final version of the paper. Again, we really thank you for providing such a detailed and constructive review.

</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div><div class="note_with_children"><div id="note_rJlF4Lf-97" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Method of Learning Gradient Directions Not Clear</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HJGven05Y7&amp;noteId=rJlF4Lf-97"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">(anonymous)</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">03 Oct 2018</span><span class="item">ICLR 2019 Conference Paper1086 Public Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">When describing LSLR you likened your method to Meta-SGD, but in Meta-SGD the gradient direction is represented by the optimizer parameters \alpha which has the same dimensionality as the learner parameters \theta. In your method you claim that you reduce computational costs by learning "per layer per step" learning rates and directions. Can you please clarify how are your directions represented if not with the same number of parameters as used in Meta-SGD?
</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_HJgieSXZ5X" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Method of Learning Gradient Directions Clarification</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HJGven05Y7&amp;noteId=HJgieSXZ5X"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1086 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">03 Oct 2018</span><span class="item">ICLR 2019 Conference Paper1086 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Meta-SGD learns alphas of dimensionality equal to the network parameters. Instead with LSLR we propose learning one alpha for each layer of the network. A component qualifies as a layer if it has learnable weights or biases in it. In addition, instead of just learning a learning rate and direction (alpha) for each layer to be used across all inner loop steps, we instead propose to learn different alphas for each inner loop step. This allows the network to choose to decay its alphas or otherwise change them, to maximize generalization performance (in some cases we noticed the network choosing to unlearn for some inner loop steps by using a negative learning rate and learn in others). So, to summarise, we learn one learning rate and direction for each layer for any given inner loop step. The network we used had 4 CNN layers along with a final softmax. That's a total of 5 layers, but since we learn learning rates for weights and biases separately, this means that the model learns a total of 10 learning rates and directions for any given step. For example, in the case where the model takes 5 inner loop steps, we have a total of 5 x 10 = 50 learning rates and directions, which is represented by 50 learnable parameters in the system. </span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div><div class="note_with_children"><div id="note_rke46mAatQ" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Related works that have better results are missing?</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HJGven05Y7&amp;noteId=rke46mAatQ"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">(anonymous)</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">30 Sep 2018</span><span class="item">ICLR 2019 Conference Paper1086 Public Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value"><a href="https://arxiv.org/pdf/1805.08311.pdf" target="_blank" rel="nofollow">https://arxiv.org/pdf/1805.08311.pdf</a> has better Omniglot 5-way results and better Mini-Imagenet 5-way results
https://arxiv.org/pdf/1707.03141.pdf has better Mini-Imagenet 5-way results
https://arxiv.org/pdf/1807.02872.pdf has better Mini-Imagenet 5-way 5-shot results
</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_HkgRQ8EAtQ" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Re: Related Works with better results</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HJGven05Y7&amp;noteId=HkgRQ8EAtQ"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1086 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">30 Sep 2018 (modified: 01 Oct 2018)</span><span class="item">ICLR 2019 Conference Paper1086 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Thanks for your comment. Firstly, I'll reiterate that the main point of the paper is to improve MAML as a model itself. Furthermore, we did a very thorough literature review but missed out on the papers you have stated. The work in our paper had already taken full shape in May thus meaning that works 1 and 3 (that came later) escaped our radar. The second paper you mentioned, "Neural Attentive Meta Learner" was not included in many of the latest few-shot learning papers that came out in June 2018, thus making it harder for us to be aware of it. We did try to cover everything in the literature prior to starting our work, however as is often the case, one or two papers might escape ones review. Especially in this field, where papers keep coming out on a daily basis on arxiv. We shall add the approaches you mentioned in our result tables when editing is allowed again. Thank you for informing us of some literature we were previously unaware of.</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div></div></main></div>
  </div>
</div>


    <!-- Footer -->
    <footer class="sitemap">
      <div class="container">
        <div class="row hidden-xs">
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/venues">All Venues</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="/contact">Contact</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
    
        <div class="row visible-xs-block">
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/contact">Contact</a></li>
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
      </div>
    </footer>
    
    <footer class="sponsor">
      <div class="container">
        <div class="row">
          <div class="col-sm-10 col-sm-offset-1">
            <p class="text-center">
              OpenReview is created by the <a href="http://www.iesl.cs.umass.edu/" target="_blank">Information Extraction and Synthesis Laboratory</a>, College of Information and Computer Science, University of Massachusetts Amherst. We gratefully acknowledge the support of the OpenReview sponsors:  Google,  Facebook, NSF, the University of Massachusetts Amherst Center for Data Science, and Center for Intelligent Information Retrieval, as well as the Google Cloud Platform for donating the computing and networking services on which OpenReview.net runs.
            </p>
          </div>
        </div>
      </div>
    </footer>

  <div id="feedback-modal" class="modal fade" tabindex="-1" role="dialog">
    <div class="modal-dialog">
      <div class="modal-content">
        <div class="modal-header">
          <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button>
          <h3 class="modal-title">Send Feedback</h3>
        </div>
        <div class="modal-body">
          <p>Enter your feedback below and we'll get back to you as soon as possible.</p>
          <form action="/feedback" method="POST">
            <div class="form-group">
              <input type="email" name="from" class="form-control" placeholder="Email" />
            </div>
            <div class="form-group">
              <input type="text" name="subject" class="form-control" placeholder="Subject" />
            </div>
            <div class="form-group">
              <textarea name="message" class="form-control feedback-input" rows="5" placeholder="Message" required=""></textarea>
            </div>
          <ul id="ui-id-2" tabindex="0" class="ui-menu ui-widget ui-widget-content" style="display: none;"></ul></form>
        </div>
        <div class="modal-footer">
          <button type="button" class="btn btn-default" data-dismiss="modal">Cancel</button>
          <button type="button" class="btn btn-primary">Send</button>
        </div>
      </div>
    </div>
  </div>

  <script type="text/javascript" async="" src="https://www.google-analytics.com/analytics.js"></script><script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js"></script>
  <script>window.jQuery || document.write('&lt;script src="/static/js/vendor/jquery-2.2.4.min.js"&gt;&lt;\/script&gt;')</script>

  <script src="/static/dist/vendor.min.js"></script>
  <script src="/static/dist/templates.min.js"></script>
  <script src="/static/dist/openreview.min.js"></script>

    <script>window.legacyScripts = true;</script>


    <script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-108703919-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() { dataLayer.push(arguments); }
      gtag('js', new Date());
      gtag('config', 'UA-108703919-1');
    </script>


<div role="status" aria-live="assertive" aria-relevant="additions" class="ui-helper-hidden-accessible"></div></body></html>
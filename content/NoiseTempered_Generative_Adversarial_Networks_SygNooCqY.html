<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" class="no-js"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>Noise-Tempered Generative Adversarial Networks | OpenReview</title>
  <meta name="description" content="" />

      <meta name="citation_title" content="Noise-Tempered Generative Adversarial Networks" />
        <meta name="citation_author" content="Simon Jenni" />
        <meta name="citation_author" content="Paolo Favaro" />
      <meta name="citation_publication_date" content="2018/09/27" />
      <meta name="citation_online_date" content="2018/09/27" />
      <meta name="citation_pdf_url" content="https://openreview.net/pdf?id=SygNooCqY7" />
      <meta name="twitter:card" content="summary" />
      <meta name="twitter:site" content="@openreviewnet" />
      <meta name="og:title" content="Noise-Tempered Generative Adversarial Networks" />
      <meta name="og:description" content="We present a novel method to stabilize the training of generative adversarial networks. The training stability is often undermined by the limited and low-dimensional support of the probability..." />
      <meta name="og:image" content="https://openreview.net/static/images/openreview_logo_512.png" />

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans:400,400i,700,700i" />

  <link rel="stylesheet" href="/static/css/bootstrap.min.css" />
  <link rel="stylesheet" href="/static/css/jquery-ui.min.css" />
  <link rel="stylesheet" href="/static/css/main.min.css" />
</head>

<body class="forum">
  <nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
  
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand home push-link" href="/"><strong>OpenReview</strong>.net</a>
      </div>
  
      <div id="navbar" class="navbar-collapse collapse">
        <form class="navbar-form navbar-left profile-search" role="search">
          <div class="form-group has-feedback">
            <input id="search_input" type="text" class="form-control ui-autocomplete-input" placeholder="Search ICLR 2019 Conference" autocomplete="off" />
            <span class="glyphicon glyphicon-search form-control-feedback" aria-hidden="true"></span>
          </div>
  
          <input id="search_group" type="hidden" value="ICLR.cc/2019/Conference" />
          <input id="search_content" type="hidden" value="all" />
        <ul id="ui-id-1" tabindex="0" class="ui-menu ui-widget ui-widget-content ui-autocomplete ui-front" style="display: none;"></ul></form>
  
        <ul class="nav navbar-nav navbar-right">
        
            <li id="user-menu"><a href="/login">Login</a></li>
        </ul>
      </div>
  
    </div>
  </nav>

  <div id="or-banner" class="banner" style="">
  <div class="container">
    <div class="row">
      <div class="col-xs-12"><a href="/group?id=ICLR.cc/2019/Conference" title="Venue Homepage"><img class="icon" src="/static/images/arrow_left.svg" /> Go to <strong>ICLR 2019 Conference</strong> homepage</a></div>
    </div>
  </div>
</div>
<div id="flash-message-container" class="alert alert-danger" role="alert" style="display: none;">
  <div class="container">
    <div class="row">
      <div class="col-xs-12">
        <div class="alert-content">
          <button type="button" class="close" aria-label="Close"><span aria-hidden="true">Ã—</span></button>
        </div>
      </div>
    </div>
  </div>
</div>

<div class="container">
  <div class="row">
    <div class="col-xs-12">
      <main id="content" class="clearfix openbanner-visible legacy-styles"><div id="note_SygNooCqY7" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Noise-Tempered Generative Adversarial Networks</a> <a class="note_content_pdf" href="/pdf?id=SygNooCqY7" title="Download PDF" target="_blank"><img src="/static/images/pdf_icon_blue.svg" /></a> </h2></div><div class="meta_row"><span class="signatures"><a href="/profile?email=jenni%40inf.unibe.ch" class="profile-link" data-toggle="tooltip" data-placement="bottom" title="" data-original-title="jenni@inf.unibe.ch">Simon Jenni</a>, <a href="/profile?email=paolo.favaro%40inf.unibe.ch" class="profile-link" data-toggle="tooltip" data-placement="bottom" title="" data-original-title="paolo.favaro@inf.unibe.ch">Paolo Favaro</a></span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">28 Sep 2018 (modified: 17 Nov 2018)</span><span class="item">ICLR 2019 Conference Withdrawn Submission</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Abstract: </span><span class="note_content_value">We present a novel method to stabilize the training of generative adversarial networks. The training stability is often undermined by the limited and low-dimensional support of the probability density function of the data samples. To address this problem we propose to simultaneously train the generative adversarial networks against different additive noise models, including the noise-free case. The benefits of this approach are that: 1) The case with noise added to both real and generated samples extends the support of the probability density function of the data, while not compromising the exact matching of the original data distribution, and 2) The noise-free case allows the exact matching of the original data distribution. We demonstrate our approach with both fixed additive noise and with learned noise models. We show that our approach results in a stable and well-behaved training of even the original minimax GAN formulation. Moreover, our technique can be incorporated in most modern GAN formulations and leads to a consistent improvement on several common datasets.</span></div><div class="reply_row clearfix"><div class="item" id="reply_count">4 Replies</div></div></div><hr class="small" /><div id="note_children"><div class="note_with_children"><div id="note_HygMrEbopX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Submission Withdrawn by the Authors</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=SygNooCqY7&amp;noteId=HygMrEbopX"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper615 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">15 Nov 2018</span><span class="item">ICLR 2019 Conference Paper615 Withdraw Submission</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Withdrawal confirmation: </span><span class="note_content_value">I have read and agree with the withdrawal statement on behalf of myself and my co-authors.</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_B1lJS3GA2Q" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Fundamental questions regarding the premises of this paper seem to be unanswered.</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=SygNooCqY7&amp;noteId=B1lJS3GA2Q"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper615 AnonReviewer3</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">06 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper615 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">In this work, a new method for (adaptively) choosing the noise distribution in a noise-tempered generative adversarial network is proposed. Noise tempering in training GANs has been around for a while. The main argument in those existing work (and also in this paper) is that GAN training gets stuck when gradient vanishes due to non-intersecting support of the real and generated distributions. Hypothetically, if such phenomenon is happening, then adding noise to the samples ensures that the support overlap and hence gradient vanishing is expected to be prevented. Typical scenarios of adding noise has been studied, for example adding a noise with variance vanishing with training iterations. This ensures that later in the training, if the generator is close to the real data, the error from having noisy samples do not propagate to the generator training. 

This paper starts off from this assumption, asking the question of why we need to reduce the noise. This suggests training with non-vanishing noise. Two heuristic reasonings in support of such approach are (i) in existing approach of vanishing noise, it is not clear how to schedule the reduction of noise variance, leading to inefficiency or non-convergence, and (ii) minimizing noisy divergence can also achieve convergence to the true distribution, as long as the noise is not degenerate. In the latter the non-degeneracy can be achieved by using multiple noise distributions. 

The main contribution of this paper is that a neural network based adaptive noise generator is proposed. During the training, the noise (from a family of noise distributions) that makes the real and generated distributions as similar as possible is chosen, while constrained to having a bounded variance. The only evidence that this improves the training is via numerical experiments run by the authors (with no (anonymized) reproducible implementation references, e.g.~github). The FID and IS scores on several datasets are presented, which suggest that NTGAN achieves better scores. 

In table 3, specific architectural and hyper-parameter choices have been made for competing baselines. For example, for SNGAN, the authors of SNGAN report IS score of 8.22 on CIFAR-10 with ResNET and 7.58 with standard CNN. If the settings are fair, then these improves upon the reported IS of NTGAN. Given that no code is available, how does one interpret the resulting table of scores? How do you ensure fairness in different choices made for different architectures?

The proposed approach of minimizing the loss over the noise with regularizer for the variance is surprising, as the theory in Lemma 1 seems to suggest an alternative (but more natural) approach. That is maximize the loss over the noise with perhaps regularizer that restricts the choice of no-noise or small variance. Can the authors elaborate on that choice?  

The metric of IS and FID score is too coarse to measure the subtle improvements that are made by the proposed approach. Given that the paper is motivated by the paths the gradients are taking during the training, it seems that analysis of the gradients (with and without the noise) is in order. Such thorough analyses will settle several myths regarding gradient vanishing, such as does gradient vanishing happen in the training of typical GANs, and does noise adding mitigate it. This is particularly interesting, as if WGAN is used with Wasserstein distance, there should be no gradient vanishing due to non-overlapping support. Checking these conjectures numerically is an important task, and is particularly critical for this paper. 
</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">4: Ok but not good enough - rejection</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_SkxI7_Ep2X" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Interesting results, but missing comparison to earlier work and questionable theory</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=SygNooCqY7&amp;noteId=SkxI7_Ep2X"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper615 AnonReviewer1</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">05 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper615 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">This paper presents a new GAN training objective to stabilize training and prevent mode collapse. The new objective trains the generator and discriminator with multiple scales of fixed additive noise, neural network generated noise, and no noise. They experimentally demonstrate the robustness of their approach to hyperparameters, perform extensive ablation studies, and show improvements in FID and IS over prior approaches on CIFAR-10 and CelebA.

Overall, this was a clear paper that presented an interesting idea of combining multiple scales and types of noise to stabilize GAN training. The experiments and ablations were far more thorough than most GAN papers and helped to show which components of the model were most important. However, I have two major concerns: (1) there is a very related and uncited paper from ICML 18 with a similar name and method: Tempered Adversarial Networks from Sajjadi et al., and (2) there is a gap between the theory and practice, in particular the discriminator should depend on the noise being added and vary for different noise types. Given these two concerns, I cannot recommend acceptance at this time. If the authors can clear up the relationship between their approach and Sajjadi et al., and addresss my theoretical complaint then I could be persuaded to increase my rating.

Strengths:
+ Interesting idea of combining multiple noise types along with learned noise
+ Clearly written, includes details of architectures and experiments.
+ Thorough experiments and ablation studies, including sensitivity to optimizer, types of noise, hyerparaemters, and generator architecture. Compares to recent SN-GAN and GAN-GP modelss.

Weaknesses:
- Missing prior work: no discussion of Tempered Adversarial Networks from Sajjadi et al. They add a neural network that transforms samples and adjust how large the transformations are over the course of training. Please discuss how your work is related to theirs and what the tradeoffs are between these approaches.
- Theory: The optimal discriminator depends on the distribution of the real and generated images being fed to it. This means that the optimal discriminator for eps1 ~ N(0, 1) will be different than the optimal discriminator for eps2 ~ N(0, 1). However, you train the same shared discriminator across all scales and types of noise. How does this impact the theory presented and the interpretation of your approach? As an alternative, you could imagine conditioning the generator on an an additional input specifying the type of noise, i.e. D(x, noise_type) and then you could learn a D that is optimal for all noise types.
- No evaluation of how having the multiple losses for different noise types impacts the training time. Even if iteration time is the same as standard GANs, adding more noise could result in slower training. Please add a plot of FID or IS vs. wall clock time to get a better sense of the tradeoffs in different approaches. 
- It looks like clean + noise with fixed or learned sigma (variants d/e) performs quite well, and has much less overhead vs. NTGAN. Can you discuss this result more? Would you advocate using this approach over NTGAN?

Minor comments:
- Why does NTGAN + SGD (variant b) perform much better than other approaches? Can you provide more details with how you chose the variants in Table 4?
- Might want to cite Generative Adversarial Trainer, another approach for learning additive noise distributions in the context of adversarial examples</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">5: Marginally below acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_BJxxiecu37" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Review for "Noise-Tempered Generative Adversarial Networks"</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=SygNooCqY7&amp;noteId=BJxxiecu37"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper615 AnonReviewer2</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">01 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper615 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">The authors make two observations. 1) Matching real and fake with postprocessing by an additive noise model is attained when the real and fake distributions are the same (thus there is a priori no need to anneal the noise like in previous work), however while a necessary condition for Pr = Pg, it is not sufficient. 2) The condition becomes sufficient if P_{r+epsilon} = P_{g + epsilon} for all noise distributions in a certain *class*. Thus, they propose to match multiple noisy versions of probability distributions. This has the known advantageous property that doesn't suffer from the disjoint / negligible intersection of supports problem, but it benefits as well from the fact that if the class of noise models is large enough, the solution to the proposed loss is the real distribution, and that by not anealling the noise term, it doesn't degenerate back to the original ill-conditioned problem.

Then, however, the authors propose two particular kinds of family of noise distributions. In particular, the additive noise is a (random) mixture between a delta at 0 and gaussians with varying sigmas (let's call this family A) or a (random mixture) between a delta at 0 and N(w) with w ~ Gaussian(0, I) with N a learned neural net. Furthermore, for some reason pick the minimum cost over noise distributions (with some regularizer), which is unexplained.

Here are my concerns about this:
- For these particular kinds of distributions, and this optimization process (minimizing the cost as a function of sigma / N, with this regularizers), why would the minimum be only at Pr=Pg? Namely, the authors point out that P_{r+e} = P_{g+e} for all e dists implies that P_r = P_g, why is that the case when considering only the distribution that minimizes the inner loop and in this limited family of distributions? This seems to be a crucial point. 
- By doing a mixture with the unmodified (probably colapsed to a low dimensional structure) data and fake distributions, the resulting distributions are likely not absolutely continuous. Thus, a priori I don't see why the JSD(P_{r+epsilon}, P_{g+epsilon}) is a continuous quantity as a function of the generator's parameters, or why it provides a usable gradient.

The authors only provide results in reasonably mid-dimensional benchmarks, (CIFAR, celeb-A, LSUN), and results are not particularly impressive. I would urge the authors to do more controlled experiments: check that for the proposed distributions, the gradients of the cost with respect to the generator don't vanish / explode when the discriminator gets more confident (as in Arjovsky &amp; Bottou). Check that the discriminator doesn't get 'perfect' too quickly. In a 1D or 2D experiment, actually plot the gradients of the cost with respect to the discriminator with respect to the input (i.e. what's the gradient field), or plot the discriminator itself (e.g. figure 1 of wgan) to see if it provides a usable gradient. Make sure to plot these for a very well trained discriminator, since this is what would ensure that no careful balance between gen and disc needs to be maintained. The only controlled experiments (figure 5) are not particularly encouraging, since it seems that the generator has still a quite significant amount of samples away from the modes.

The paper is in general well written, and the ideas and observations are simple, to the best of my knowledge novel, and have clear consequences. The actual instantiation of these ideas seem to have several caveats, or aspects that need elaboration, as mentioned before. Furthermore, the experiments aren't too convincing. Some parts also require better writing. For example, in points 1 and 2 (noise descriptions) in page 4, delta(epsilon) is not a notation commonly employed to refer to no noise (which is what the authors mention in text). If the noise is additive then this is just delta_0. As well, int delta(eps - N(w)) p(w) dw is hard to understand / nonstandard, the authors should just say N(w) with w ~ N(0, I) or N^# N(0, I) [and clarify that # means push-forward of a distribution].

Pet peeve: In the third line of the abstract 'probability density function' -&gt; 'probability distribution'. A low dimensional distribution doesn't have a density :).</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">5: Marginally below acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></main></div>
  </div>
</div>


    <!-- Footer -->
    <footer class="sitemap">
      <div class="container">
        <div class="row hidden-xs">
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/venues">All Venues</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="/contact">Contact</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
    
        <div class="row visible-xs-block">
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/contact">Contact</a></li>
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
      </div>
    </footer>
    
    <footer class="sponsor">
      <div class="container">
        <div class="row">
          <div class="col-sm-10 col-sm-offset-1">
            <p class="text-center">
              OpenReview is created by the <a href="http://www.iesl.cs.umass.edu/" target="_blank">Information Extraction and Synthesis Laboratory</a>, College of Information and Computer Science, University of Massachusetts Amherst. We gratefully acknowledge the support of the OpenReview sponsors:  Google,  Facebook, NSF, the University of Massachusetts Amherst Center for Data Science, and Center for Intelligent Information Retrieval, as well as the Google Cloud Platform for donating the computing and networking services on which OpenReview.net runs.
            </p>
          </div>
        </div>
      </div>
    </footer>

  <div id="feedback-modal" class="modal fade" tabindex="-1" role="dialog">
    <div class="modal-dialog">
      <div class="modal-content">
        <div class="modal-header">
          <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">Ã—</span></button>
          <h3 class="modal-title">Send Feedback</h3>
        </div>
        <div class="modal-body">
          <p>Enter your feedback below and we'll get back to you as soon as possible.</p>
          <form action="/feedback" method="POST">
            <div class="form-group">
              <input type="email" name="from" class="form-control" placeholder="Email" />
            </div>
            <div class="form-group">
              <input type="text" name="subject" class="form-control" placeholder="Subject" />
            </div>
            <div class="form-group">
              <textarea name="message" class="form-control feedback-input" rows="5" placeholder="Message" required=""></textarea>
            </div>
          <ul id="ui-id-2" tabindex="0" class="ui-menu ui-widget ui-widget-content" style="display: none;"></ul></form>
        </div>
        <div class="modal-footer">
          <button type="button" class="btn btn-default" data-dismiss="modal">Cancel</button>
          <button type="button" class="btn btn-primary">Send</button>
        </div>
      </div>
    </div>
  </div>

  <script type="text/javascript" async="" src="https://www.google-analytics.com/analytics.js"></script><script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js"></script>
  <script>window.jQuery || document.write('&lt;script src="/static/js/vendor/jquery-2.2.4.min.js"&gt;&lt;\/script&gt;')</script>

  <script src="/static/dist/vendor.min.js"></script>
  <script src="/static/dist/templates.min.js"></script>
  <script src="/static/dist/openreview.min.js"></script>

    <script>window.legacyScripts = true;</script>


    <script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-108703919-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() { dataLayer.push(arguments); }
      gtag('js', new Date());
      gtag('config', 'UA-108703919-1');
    </script>


<div role="status" aria-live="assertive" aria-relevant="additions" class="ui-helper-hidden-accessible"></div></body></html>
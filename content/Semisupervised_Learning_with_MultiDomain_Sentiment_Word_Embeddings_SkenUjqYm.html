<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" class="no-js"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>Semi-supervised Learning with Multi-Domain Sentiment Word Embeddings | OpenReview</title>
  <meta name="description" content="" />

      <meta name="citation_title" content="Semi-supervised Learning with Multi-Domain Sentiment Word Embeddings" />
        <meta name="citation_author" content="Anonymous" />
      <meta name="citation_publication_date" content="2018/09/27" />
      <meta name="citation_online_date" content="2018/09/27" />
      <meta name="citation_pdf_url" content="https://openreview.net/pdf?id=SkenUj0qYm" />
      <meta name="twitter:card" content="summary" />
      <meta name="twitter:site" content="@openreviewnet" />
      <meta name="og:title" content="Semi-supervised Learning with Multi-Domain Sentiment Word Embeddings" />
      <meta name="og:description" content="Word embeddings are known to boost performance of many NLP tasks such as text classification, meanwhile they can be enhanced by labels at the document level to capture nuanced meaning such as..." />
      <meta name="og:image" content="https://openreview.net/static/images/openreview_logo_512.png" />

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans:400,400i,700,700i" />

  <link rel="stylesheet" href="/static/css/bootstrap.min.css" />
  <link rel="stylesheet" href="/static/css/jquery-ui.min.css" />
  <link rel="stylesheet" href="/static/css/main.min.css" />
</head>

<body class="forum">
  <nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
  
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand home push-link" href="/"><strong>OpenReview</strong>.net</a>
      </div>
  
      <div id="navbar" class="navbar-collapse collapse">
        <form class="navbar-form navbar-left profile-search" role="search">
          <div class="form-group has-feedback">
            <input id="search_input" type="text" class="form-control ui-autocomplete-input" placeholder="Search ICLR 2019 Conference" autocomplete="off" />
            <span class="glyphicon glyphicon-search form-control-feedback" aria-hidden="true"></span>
          </div>
  
          <input id="search_group" type="hidden" value="ICLR.cc/2019/Conference" />
          <input id="search_content" type="hidden" value="all" />
        <ul id="ui-id-1" tabindex="0" class="ui-menu ui-widget ui-widget-content ui-autocomplete ui-front" style="display: none;"></ul></form>
  
        <ul class="nav navbar-nav navbar-right">
        
            <li id="user-menu"><a href="/login">Login</a></li>
        </ul>
      </div>
  
    </div>
  </nav>

  <div id="or-banner" class="banner" style="">
  <div class="container">
    <div class="row">
      <div class="col-xs-12"><a href="/group?id=ICLR.cc/2019/Conference" title="Venue Homepage"><img class="icon" src="/static/images/arrow_left.svg" /> Go to <strong>ICLR 2019 Conference</strong> homepage</a></div>
    </div>
  </div>
</div>
<div id="flash-message-container" class="alert alert-danger" role="alert" style="display: none;">
  <div class="container">
    <div class="row">
      <div class="col-xs-12">
        <div class="alert-content">
          <button type="button" class="close" aria-label="Close"><span aria-hidden="true">×</span></button>
        </div>
      </div>
    </div>
  </div>
</div>

<div class="container">
  <div class="row">
    <div class="col-xs-12">
      <main id="content" class="clearfix openbanner-visible legacy-styles"><div id="note_SkenUj0qYm" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Semi-supervised Learning with Multi-Domain Sentiment Word Embeddings</a> <a class="note_content_pdf" href="/pdf?id=SkenUj0qYm" title="Download PDF" target="_blank"><img src="/static/images/pdf_icon_blue.svg" /></a> </h2></div><div class="meta_row"><span class="signatures">Anonymous</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">28 Sep 2018 (modified: 11 Oct 2018)</span><span class="item">ICLR 2019 Conference Blind Submission</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span><span class="item"><a class="action-bibtex-modal" data-bibtex="@inproceedings{    &#10;anonymous2019semi-supervised,    &#10;title={Semi-supervised Learning with Multi-Domain Sentiment Word Embeddings},    &#10;author={Anonymous},    &#10;booktitle={Submitted to International Conference on Learning Representations},    &#10;year={2019},    &#10;url={https://openreview.net/forum?id=SkenUj0qYm},    &#10;note={under review}    &#10;}">Show Bibtex</a></span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Abstract: </span><span class="note_content_value">Word embeddings are known to boost performance of many NLP tasks such as text classification, meanwhile they can be enhanced by labels at the document level to capture nuanced meaning such as sentiment and topic. Can one combine these two research directions to benefit from both? In this paper, we propose to jointly train a text classifier with a label-enhanced and domain-aware word embedding model, using an unlabeled corpus and only a few labeled data from non-target domains. The embeddings are trained on the unlabed corpus and enhanced by pseudo labels coming from the classifier, and at the same time are used by the classifier as input and training signals. We formalize this symbiotic cycle in a variational Bayes framework, and show that our method improves both the embeddings and the text classifier, outperforming state-of-the-art domain adaptation and semi-supervised learning techniques. We conduct detailed ablative tests to reveal gains from important components of our approach. The source code and experiment data will be publicly released.</span></div><div class="reply_row clearfix"><div class="item" id="reply_count">6 Replies</div></div></div><hr class="small" /><div id="note_children"><div class="note_with_children"><div id="note_SkeDSxzF37" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Nice Application of Variational Bayes semi-supervised learning</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=SkenUj0qYm&amp;noteId=SkeDSxzF37"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper208 AnonReviewer2</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">02 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper208 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">This paper jointly trains a sentiment classifier with a sentiment and domain-aware embedding
model, using both labeled and unlabeled data. When sentiment label is observed, this model is trained
with the usual cross entropy and maximum likelihood objectives; for unlabeled data, it uses pseudo
labels produced by the sentiment classifier with variational Bayes objective. This idea is not novel but the authors report that there is no previous work that jointly trains sentiment aware embeddings with a sentiment classifier specifically, and makes use of an unlabeled corpus to improve both. However, there are general and broader methods such as 'Toward Controlled Generation of Text' by Hu et al that apply semi-supervised techniques for generation (not classification) with specific constraints (sentiment, domain, etc). There are other recent methods such as 'Improving Language Understanding by Generative Pre-Training' by Redford et al that use the idea of generative pre-training with discriminative fine-tuning that are task-agnostic and achieve very good performance - how does the paper compare to this approach? 
The experiments and analysis is very well written in the paper. Table 4 also shows very interesting, somewhat surprising results in the paper. The authors say that they will release the code and data for this technique which will be useful for the sentiment analysis research community.  
</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">6: Marginally above acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">3: The reviewer is fairly confident that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_SJx79i1WRm" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>We see plenty of potential in combining generative and discriminative models in NLP</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=SkenUj0qYm&amp;noteId=SJx79i1WRm"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper208 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">20 Nov 2018</span><span class="item">ICLR 2019 Conference Paper208 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Thanks for the informative comment. Hu et al.’s ICML2017 paper is especially a very interesting read. It is not directly comparable to this paper because, as the reviewer already pointed out, Hu et al.’s is about (sentence) generation but this paper is about (document) classification. Nevertheless, let’s have a deep discussion about these two papers.

First, Hu et al.’s is insightful in that it models different semantic attributes as independent factors which control generation; our paper shares a very similar spirit by learning a disentangled sentiment part and a domain specific part for word embeddings. When the data is unlabeled, both papers use discriminators to produce pseudo-labels for training the generative model.

But then, Hu et al.’s model propagates gradients of the discriminator directly back to the generator, using softmax annealing to circumvent the discreteness of text data; this technique is unnecessary in our setting, because the classifier in our model uses word embeddings (rather than words themselves) as input, and the embeddings are shared between classifier and the generative model. In other words, Hu et al.’s approach uses the discriminator to train the generator, whereas in our model the two are jointly trained.

On the other hand, Hu et al. achieve semi-supervised learning of the discriminator by synthesizing data samples from the generator, whereas we use a variational Bayes objective on unlabeled data. Synthesized data only work if one has a good generator; we know that LSTM is a good generator for short sentences, but things are less clear for other types of objects, such as lengthy documents. Therefore, I would not say which one is more general and broader method; both Hu et al.’s and our work are meaningful extensions/applications of Kingma’s variational Bayes framework.

From a broader perspective, there is no doubt that combining generative and discriminative models is a promising methodology toward semi-supervised learning, and we are interested in this direction because there are plenty of potential applications in Natural Language Processing. For example, one could combine parser and sentence generator, by parsing the generated sentences back to semantic structures to check if intended meanings are conveyed. This idea dates back to old days such as in Duan and White (ACL2014), and is still very active such as in Konstas et al. (ACL2017). Domain adaptation of sentiment classifiers is just another, simple but important application task, and there is novelty in applying variational Bayes methods here. We believe the knowledge obtained here will be helpful to other tasks as well. We will modify Related Works to discuss this broader point, including Hu et al. and Redford et al., as is also suggested by AnnoReviewer1.

As for Redford et al.’s in-progress work, we believe it belongs to the realm of pretraining unsupervised language models in order to enhance a wide range of classification tasks. We have already compared with one of its state-of-the-art, ELMo, and shown that we can outperform ELMo in this task, with much smaller unlabeled data. The big difference here, is that the representation learned by our generative model is aware of task-specific latent labels (i.e. sentiment), thus it is more task-oriented; in contrast, representations learned by pretraining unsupervised language models are task-agnostic. Our ablation tests clearly show that more task-oriented representations can improve performance on that task.</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div><div class="note_with_children"><div id="note_r1xl1tcu37" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Interesting approach and well conducted evaluation; some details missing and limited applicability</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=SkenUj0qYm&amp;noteId=r1xl1tcu37"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper208 AnonReviewer1</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">01 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper208 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">The authors propose a semi-supervised learning techhnique involving jointly tuning word embeddings and a classifier. The idea is to rapidly adapt models to new domains with minimal (actually, zero) supervision by exploiting such embeddings.

In effect, this is an approach to "disentangling" sentiment from domain, via a variational objective and semi-supervision via the embedding parameters. This is a nice idea as disentanglement enables transfer (or should). The experiments are well-executed (albeit on a limited set of classification tasks). Still the comparisons are relatively exhaustive, and the authors have done a nice job of providing ablations. I found Table 4 and Figure 2 particularly nice. 

- The authors should speak to the generalizability of this approach beyond sentiment tasks, as presently it seems largely constrained to this domain. This would of course hinder the potential utility/impact of the work.

- Due to the very concise description of baselines, it was not obvious to me if these were also taking a semi-supervised approach? I *think* the pivot-based model is. But then how was CNN+ELMo trained exactly? With zero target sentiment labels, I presume? If so, an obvious baseline would be to "pseudo-label" instances in the target domain first, and then use these predictions as a target to fine-tune the CNN (or whatever), back-propping through to the embeddings. Was this done? In general more details on the baselines and training setups should be included, even if only in the Appendix.

- The strategy, I think, is to learn a prediction model p_\phi(y|z, D) where \phi are model parameters. Then this is applied to instances in the target dataset to infer latent z, and then use these inferred labels to fine-tune word embeddings. Specifically, sentiment label information is pushed into embeddings via a modified CBOW objective that effectively shifts the meaning (as codified in the distributed representation) via task specific sentiment. One thing here that confused me is that this would seem to perform this affine transformation to all words, but only certain of these will exhibit domain specific variation with respect to sentiment. Can the authors speak to this? 

- I found Eq 7 counterintuitive, since it treats sentiment and domain independently, but the authors explicitly noted above that this is not the case, i.e., words will depend jointly on sentiment + domain. I actually think p(w_i|y) also depends on the domain via M (implicitly), but perhaps this should be made explicit (or perhaps I am misunderstanding something!)

- In 2.1, the authors assume a prior p(z|c) and then say that `'naively' marginalizing over this performs poorly. But I not think the particular prior distribution used was not discussed here. Could they elaborate? 

- I think i indices are needed on the w's in Eq 6?</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">6: Marginally above acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">3: The reviewer is fairly confident that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_rkeChhJ-0X" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>We will add broader discussion; about some details and an additional experiment</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=SkenUj0qYm&amp;noteId=rkeChhJ-0X"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper208 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">20 Nov 2018</span><span class="item">ICLR 2019 Conference Paper208 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Thanks for the insightful review and suggestion of the word “disentangling”. It really puts this work in a broader context of representation learning.

&gt; The authors should speak to the generalizability of this approach beyond sentiment tasks

Indeed. Thanks for the suggestion. We have conducted this work partially because it is a neat yet important application of semi-supervised learning by combining generative and discriminative models. This approach to semi-supervised learning is general enough to be applied to various tasks, and we see plenty of its potential in Natural Language Processing to overcome data sparsity and increase accuracy. For example, combining parsing and sentence generation might well be a fruitful direction. The generative model in this work has its own characteristics in that it disentangles sentiment from a domain specific part in order to enhance domain adaptation. We believe similar techniques can be useful in other tasks, given the ubiquity of word embeddings and the constant need for domain adaptation. However, we believe specific model designs should be considered task-by-task; frankly we do not believe a general model can always perform superbly in every task (recall the No Free Lunch Theorem). We will add more discussion about generalizability of this approach in our Conclusion, as well as Related Works being discussed with AnnoReviewer2.

&gt; very concise description of baselines; CNN+ELMo with pseudo-labels

We will add more details about the baselines. And yes, CNN+ELMo is trained with zero target sentiment labels. Actually, in our pre-experiments we have tried self-training with the DAN classifier; namely, using labeled data to train DAN in the first round, predict latent distributions for unlabeled data, then sample pseudo-labels for unlabeled data and mix them with labeled data, in order to train DAN in the second round. This approach brought almost no change to the performance (and in hindsight, drastic changes seem unlikely to us); so we abandoned this self-training idea. However, since the reviewer brought it up, we tried CNN+ELMo with pseudo-labels as indicated (the experiments just completed very recently). This time we did not sample pseudo-labels using predicted distributions, but simply use the predicted labels to annotate unlabeled data and train CNN+ELMo again. The results are as follows:

Books: 77.58    Dvd: 78.56    Electronics: 82.09    Kitchen: 83.06
Airline: 80.16    Airport: 64.69    Lounge: 66.46    Seat: 79.52

As it shows, the results are better than Random+CNN but worse than ELMo+CNN trained on labeled data. We consider ELMo+CNN as a semi-supervised approach in a broad sense: namely, the large unlabeled corpus used for training the ELMo model certainly has effects.

&gt; affine transformation to all words

Yes that’s correct. As a result, it is no surprise that the learned affine transformations for positive and negative sentiments are similar, because only a limited set of words exhibit variation w.r.t. sentiment. Take the model tested on books domain as an example (models for other domains are mostly the same): for each sentiment, if we decompose the learned matrix M into A+B, where A is a scalar multiplication of the identity matrix and B is orthogonal to A; then the Frobenius norms of A and B are about the same, and the cosine similarity between B_positive and B_negative is about 0.95. As for the learned vector b, the cosine similarity between b_positive and b_negative is about 0.93.

&gt; Eq 7 counterintuitive

This might be a misunderstanding. Modeling the sentiment and domain parts as independent factors of word generation helps learn disentangled representations (and in this way word generation still depends on both sentiment and domain). On the other hand, it is indeed conventional wisdom that sentiment and domain interact with each other in word generation; but we believe this is more about the surrounding context than the domain per sentiment. For example, it is said that “easy” is usually used as positive in electronics but negative in books domain, but it should be more suited to say that “easy” is used positively in the context “easy to use”, but negatively in “easy to guess ending”. Thus, we model sentiment interacting with surrounding context words instead of the domain vector. In this sense, yes, p(w_i|y) also depends on the surrounding context words, which implicitly carry domain information to some extent, but surrounding context itself is domain independent and we believe it is better to use than the domain vector. We will try to make this point clearer in the paper.

&gt; prior p(z|c)

For the purely Bayesian approach, we have tried both setting prior p(z|c) to the uniform distribution, or learning it as specified in Section 2.4. In both cases the model learns to infer all-positive or all-negative labels. We will improve the narration and make this clearer.

&gt; i indices are needed on the w's in Eq 6

That’s correct. We’ll fix it. Thanks!
</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div><div class="note_with_children"><div id="note_r1gMSyoHh7" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Review #3</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=SkenUj0qYm&amp;noteId=r1gMSyoHh7"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper208 AnonReviewer3</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">30 Oct 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper208 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">This paper proposes to jointly train a classifier with a domain and label-aware word embedding model and a variational Bayes model for sentiment domain adaptation. The model is evaluated on a standard multi-domain sentiment analysis dataset where it achieves convincing results against strong baselines. Extensive ablations are conducted.

Pros:
- The paper is clearly written. I particularly appreciated Figure 1 as it might otherwise be difficult to see the relation of the different components of the model.
- The model achieves convincing results and ablations and analyses are extensive.

Cons:
- None of the presented ideas are entirely novel. The model rather combines many existing ideas successfully.
- The framework consisting of many components (particularly the joint training with CBOW as indicated in the appendix) seems rather brittle and very task-specific. I am concerned if this framework will be able to work on other tasks. I would love to see an evaluation on another dataset. 
- The joint variational Bayes approach seems to be the most interesting aspect of the paper. Despite the ablations, it's not entirely clear to me, though, how useful this component is and if it can be applied beyond this particular model. I would like to see one of the baselines models or another model augmented with this component. 

Questions:
- Do you alternate updates between each of the components or use a more sophisticated multi-task learning strategy when training the word embedding model and the other components jointly? Did you try fine-tuning the trained word embeddings with the classifier?
- Why do you use this particular affine transformation for learning sentiment-specific word embeddings? Did you try, for instance, an MLP as used in [1]?
- You say that you use a classifier q_φ(z |D, c) in order to benefit from more freedom of design for Bayesian inference. Could you elaborate why you use this classifier in addition to the label classifier q_φ(y |D, c)? In Table 6, it seems that it doesn't help much. The use of the term "classifier" is confusing at times, as it seems to be both used to refer to the latent variable and the label classifier.

[1] Tang, D., Wei, F., Yang, N., Zhou, M., Liu, T., &amp; Qin, B. (2014). Learning Sentiment-Specific Word Embedding. Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, 1, 1555–1565.</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">6: Marginally above acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">3: The reviewer is fairly confident that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_Hklu8akbC7" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Thanks! and clarifying some details</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=SkenUj0qYm&amp;noteId=Hklu8akbC7"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper208 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">20 Nov 2018</span><span class="item">ICLR 2019 Conference Paper208 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Thanks for the helpful comment. Our answers are as below:

&gt; framework seems rather brittle and very task-specific

It is true that the hyper-parameters have to be set correctly in order to train the model appropriately. But this, we believe, is an issue for all neural networks. In our case, models trained with suboptimal hyper-parameters are qualitatively different and quite easy to spot, for example by assessing top 15 similar words. Once the correct set of hyper-parameters is found, it seems working for all datasets: Note that we fix the same set of hyper-parameters for all experiments in this work, and qualitative inspection suggests that all trainings went well. Furthermore, at least some of the hyper-parameters are likely portable to other models/tasks, because it should be much the same as in this model we have inherited the same hyper-parameters we previously found effective for CBOW.

&gt; if variational Bayes can be applied beyond this particular model

Actually, before we switched to the current CNN classifier, we have applied variational Bayes to a simple DAN classifier and confirmed that it can improve performance (eg., it improves books domain from 74% to 78%). Afterwards, we found that CNN better than DAN in this task, so we did not present the DAN results in the paper. But thanks for the suggestion!

&gt; Do you alternate updates between each of the components

No, all components are jointly trained, meaning that they are updated at each step. We use an enhanced SGD optimization, in which learning rates are adjusted so that the norms of updates for each component are controlled during training (similar idea is found in Takahashi et al. ACL2018, and also controlling the norms of updates is the main ingredient of Adam). 

&gt; Did you try fine-tuning the trained word embeddings with the classifier?

Yes, we do fine-tune the word embeddings with the classifier. It is conducted jointly with the training of word embeddings. Details of this joint training are found in Appendix. A qualitative comparison showing the effect of joint training is found in Table 3.

&gt; Why do you use this particular affine transformation

We believe an affine transformation is just an MLP reduced to one layer and without non-linear activation. We chose it because it is simple yet expressive enough to model interactions between sentiment and surrounding context. We did not try Tang et al. (ACL2014)’s model specifically because it cannot be trained on unlabeled data. But we will include and discuss it in Related Works.

&gt; q_φ(z |D, c) and q_φ(y |D, c)

This might be a misunderstanding. q_φ(z |D, c) and q_φ(y |D, c) denote the same classifier; only the classifier is used differently. When the sentiment label is not observed (i.e. unlabeled data), the classifier is used to PREDICT a probabilistic distribution of the sentiment label (i.e. q_φ(z |D, c)), and this “pseudo-label” is used for training embeddings. In this way our sentiment-aware embeddings can be trained on unlabeled data. On the other hand, when the sentiment label is observed, the classifier is TRAINED by maximizing log-likelihood of q_φ(y |D, c). We’ll try to make this clearer.</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div></div></main></div>
  </div>
</div>


    <!-- Footer -->
    <footer class="sitemap">
      <div class="container">
        <div class="row hidden-xs">
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/venues">All Venues</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="/contact">Contact</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
    
        <div class="row visible-xs-block">
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/contact">Contact</a></li>
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
      </div>
    </footer>
    
    <footer class="sponsor">
      <div class="container">
        <div class="row">
          <div class="col-sm-10 col-sm-offset-1">
            <p class="text-center">
              OpenReview is created by the <a href="http://www.iesl.cs.umass.edu/" target="_blank">Information Extraction and Synthesis Laboratory</a>, College of Information and Computer Science, University of Massachusetts Amherst. We gratefully acknowledge the support of the OpenReview sponsors:  Google,  Facebook, NSF, the University of Massachusetts Amherst Center for Data Science, and Center for Intelligent Information Retrieval, as well as the Google Cloud Platform for donating the computing and networking services on which OpenReview.net runs.
            </p>
          </div>
        </div>
      </div>
    </footer>

  <div id="feedback-modal" class="modal fade" tabindex="-1" role="dialog">
    <div class="modal-dialog">
      <div class="modal-content">
        <div class="modal-header">
          <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button>
          <h3 class="modal-title">Send Feedback</h3>
        </div>
        <div class="modal-body">
          <p>Enter your feedback below and we'll get back to you as soon as possible.</p>
          <form action="/feedback" method="POST">
            <div class="form-group">
              <input type="email" name="from" class="form-control" placeholder="Email" />
            </div>
            <div class="form-group">
              <input type="text" name="subject" class="form-control" placeholder="Subject" />
            </div>
            <div class="form-group">
              <textarea name="message" class="form-control feedback-input" rows="5" placeholder="Message" required=""></textarea>
            </div>
          <ul id="ui-id-2" tabindex="0" class="ui-menu ui-widget ui-widget-content" style="display: none;"></ul></form>
        </div>
        <div class="modal-footer">
          <button type="button" class="btn btn-default" data-dismiss="modal">Cancel</button>
          <button type="button" class="btn btn-primary">Send</button>
        </div>
      </div>
    </div>
  </div>

  <script type="text/javascript" async="" src="https://www.google-analytics.com/analytics.js"></script><script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js"></script>
  <script>window.jQuery || document.write('&lt;script src="/static/js/vendor/jquery-2.2.4.min.js"&gt;&lt;\/script&gt;')</script>

  <script src="/static/dist/vendor.min.js"></script>
  <script src="/static/dist/templates.min.js"></script>
  <script src="/static/dist/openreview.min.js"></script>

    <script>window.legacyScripts = true;</script>


    <script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-108703919-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() { dataLayer.push(arguments); }
      gtag('js', new Date());
      gtag('config', 'UA-108703919-1');
    </script>


<div role="status" aria-live="assertive" aria-relevant="additions" class="ui-helper-hidden-accessible"></div></body></html>
<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" class="no-js"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>Ergodic Measure Preserving Flows | OpenReview</title>
  <meta name="description" content="" />

      <meta name="citation_title" content="Ergodic Measure Preserving Flows" />
        <meta name="citation_author" content="Anonymous" />
      <meta name="citation_publication_date" content="2018/09/27" />
      <meta name="citation_online_date" content="2018/09/27" />
      <meta name="citation_pdf_url" content="https://openreview.net/pdf?id=HJx4KjRqYQ" />
      <meta name="twitter:card" content="summary" />
      <meta name="twitter:site" content="@openreviewnet" />
      <meta name="og:title" content="Ergodic Measure Preserving Flows" />
      <meta name="og:description" content="Training probabilistic models with neural network components is intractable in most cases and requires to use approximations such as Markov chain Monte Carlo (MCMC), which is not scalable and..." />
      <meta name="og:image" content="https://openreview.net/static/images/openreview_logo_512.png" />

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans:400,400i,700,700i" />

  <link rel="stylesheet" href="/static/css/bootstrap.min.css" />
  <link rel="stylesheet" href="/static/css/jquery-ui.min.css" />
  <link rel="stylesheet" href="/static/css/main.min.css" />
</head>

<body class="forum">
  <nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
  
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand home push-link" href="/"><strong>OpenReview</strong>.net</a>
      </div>
  
      <div id="navbar" class="navbar-collapse collapse">
        <form class="navbar-form navbar-left profile-search" role="search">
          <div class="form-group has-feedback">
            <input id="search_input" type="text" class="form-control ui-autocomplete-input" placeholder="Search ICLR 2019 Conference" autocomplete="off" />
            <span class="glyphicon glyphicon-search form-control-feedback" aria-hidden="true"></span>
          </div>
  
          <input id="search_group" type="hidden" value="ICLR.cc/2019/Conference" />
          <input id="search_content" type="hidden" value="all" />
        <ul id="ui-id-1" tabindex="0" class="ui-menu ui-widget ui-widget-content ui-autocomplete ui-front" style="display: none;"></ul></form>
  
        <ul class="nav navbar-nav navbar-right">
        
            <li id="user-menu"><a href="/login">Login</a></li>
        </ul>
      </div>
  
    </div>
  </nav>

  <div id="or-banner" class="banner" style="">
  <div class="container">
    <div class="row">
      <div class="col-xs-12"><a href="/group?id=ICLR.cc/2019/Conference" title="Venue Homepage"><img class="icon" src="/static/images/arrow_left.svg" /> Go to <strong>ICLR 2019 Conference</strong> homepage</a></div>
    </div>
  </div>
</div>
<div id="flash-message-container" class="alert alert-danger" role="alert" style="display: none;">
  <div class="container">
    <div class="row">
      <div class="col-xs-12">
        <div class="alert-content">
          <button type="button" class="close" aria-label="Close"><span aria-hidden="true">×</span></button>
        </div>
      </div>
    </div>
  </div>
</div>

<div class="container">
  <div class="row">
    <div class="col-xs-12">
      <main id="content" class="clearfix openbanner-visible legacy-styles"><div id="note_HJx4KjRqYQ" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Ergodic Measure Preserving Flows</a> <a class="note_content_pdf" href="/pdf?id=HJx4KjRqYQ" title="Download PDF" target="_blank"><img src="/static/images/pdf_icon_blue.svg" /></a> </h2></div><div class="meta_row"><span class="signatures">Anonymous</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">28 Sep 2018 (modified: 11 Oct 2018)</span><span class="item">ICLR 2019 Conference Blind Submission</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span><span class="item"><a class="action-bibtex-modal" data-bibtex="@inproceedings{    &#10;anonymous2019ergodic,    &#10;title={Ergodic Measure Preserving Flows},    &#10;author={Anonymous},    &#10;booktitle={Submitted to International Conference on Learning Representations},    &#10;year={2019},    &#10;url={https://openreview.net/forum?id=HJx4KjRqYQ},    &#10;note={under review}    &#10;}">Show Bibtex</a></span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Abstract: </span><span class="note_content_value">Training probabilistic models with neural network components is intractable in most cases and requires to use approximations such as Markov chain Monte Carlo (MCMC), which is not scalable and requires significant hyper-parameter tuning, or mean-field variational inference (VI), which is biased. While there has been attempts at combining both approaches, the resulting methods have some important limitations in theory and in practice. As an alternative, we propose a novel method which is scalable, like mean-field VI, and, due to its theoretical foundation in ergodic theory, is also asymptotically accurate, like MCMC. We test our method on popular benchmark problems with deep generative models and Bayesian neural networks. Our results show that we can outperform existing approximate inference methods.</span></div><div class="note_contents"><span class="note_content_field">Keywords: </span><span class="note_content_value">Markov chain Monte Carlo, variational inference, deep generative models</span></div><div class="note_contents"><span class="note_content_field">TL;DR: </span><span class="note_content_value">A novel computational scalable inference framework for training deep generative models and general statistical inference.</span></div><div class="reply_row clearfix"><div class="item" id="reply_count">19 Replies</div></div></div><hr class="small" /><div id="note_children"><div class="note_with_children"><div id="note_HJeijVAJ67" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>An interesting heuristic and some interesting derivations, but there's a gap between the two.</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HJx4KjRqYQ&amp;noteId=HJeijVAJ67"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper439 AnonReviewer2</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">07 Nov 2018</span><span class="item">ICLR 2019 Conference Paper439 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">This paper proposes a simple heuristic for tuning HMC's parameters: just optimize the expected log-density of the Lth sample. It seems to work reasonably well on the problems the authors evaluate on.

This heuristic is arrived at by a somewhat roundabout derivation, which I found interesting (although many of the same ideas are implicit in Salimans et al. (2014; "MCMC &amp; VI: Bridging the Gap")). But ultimately this derivation comes to a head at this very heuristic argument:

“…since qL(zL; φ) converges to pθ(z|x) as L increases, we expect the effect of H[qL(zL; φ)] on φ to be small and that most of the similarity of qL(zL; φ) to pθ(z|x) will be captured by the first term in the RHS of (15). Therefore, we propose to tune φ by optimizing the tractable objective given by the first term…”: 

I don’t see why this argument applies to the entropy term and not to the log-joint term. In particular, If q_L has really converged to p(z|x), then there’s no point optimizing φ either, right?

Here’s a concrete example of how I could imagine this procedure going wrong: make q(z0) a delta at the latent vector z* that maximizes the log-joint, and set the step size of the Hamiltonian simulation to 0. This will make the entropy term (which is ignored) -∞, maximize the log-joint term, and I think it even makes D^L_{KL}=0.

It seems like this isn’t what actually happens experimentally, though—perhaps I’m missing something?

Regarding the experiments, a natural baseline would be something akin to the approach of Hoffman (2017; "Learning Deep Latent Gaussian Models with Markov Chain Monte Carlo”), simply initializing the HMC sampler with a mean-field Gaussian. I would expect this to produce worse results for small numbers of steps, since the variational Gaussian would choose a single mode, but I’m curious how the quantitative metrics would compare.

Some more minor points:

* “Variational auto-encoders (VAEs) (Kingma &amp; Welling, 2014) are DGMs trained by using mean-field
VI with a Gaussian parametric distribuion and amortization.” I disagree with this terminology—DGMs trained with, say, IAF are routinely called VAEs.

* Section 3.1: It might be good to clarify that you’re describing exact Hamiltonian integration, whereas in practice one always uses a discretized numerical integrator. (The leapfrog integrator is reversible and preserves volume, but doesn’t conserve energy, so this does make the results a bit more complicated.)
</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">5: Marginally below acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_BJl8M8MApQ" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Thanks for the review and the hint of gap is in the paper</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HJx4KjRqYQ&amp;noteId=BJl8M8MApQ"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper439 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">18 Nov 2018</span><span class="item">ICLR 2019 Conference Paper439 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">First, we would like to thank the reviewer's effort.

Here is the clarification on the missing entropy term.

First of all, let's start with the basic MCMC knowledge: the condition for ergodic Markov chains. A Markov chain is ergodic must satisfy following conditions (see wikipedia for more detailed explanation):
-irreducible (precondition of recurrence): The probability of any state change to any other state must be positive. 
-recurrent: revisit any state with positive probability under stationary infinite many times
-aperiodic: the period of the chain must be 1
-existing stationary distribution: there must exists a stationary distribution

Second, some relevant HMC basics: if the simulation time/discretized step size is zero, then the state of Hamiltonian dynamics simply do not change. Therefore, the input and output of Hamiltonian simulation is the same with probability 1. This breaks the most basic condition of ergodicity: irreducibility.

Finally, we made it very clear that there is a precondition for ignoring the entropy term: "If with the initial flow parameter φ0, the objective F˜ &lt; Epθ(x,z)[log pθ(x, z)]..." (*right under* the definition of the loss without entropy (equation 16))
We are happy to make this more obvious somehow. But, we assume that it is not too hard to understand why this makes sense. If you want to optimise this loss to converge to the target, then the initial loss value should be lower than the loss value of the target. 

Back to your question: 
"Here’s a concrete example of how I could imagine this procedure going wrong: make q(z0) a delta at the latent vector z* that maximizes the log-joint, and set the step size of the Hamiltonian simulation to 0. This will make the entropy term (which is ignored) -∞, maximize the log-joint term, and I think it even makes D^L_{KL}=0.

It seems like this isn’t what actually happens experimentally, though—perhaps I’m missing something?"

Yes, here is what missing here:
1) The irreducibility of ergodic Markov kernel (not in the paper)
2) HMC step size can never be 0 otherwise the kernel is not irreducible therefore not ergodic (not in the paper)
3) Our precondition for dropping the entropy term (in the paper)
We didn't include the first two points, because we assume that the basic MCMC knowledge the researchers in this field should be familiar with.

On the comment:
"Regarding the experiments, a natural baseline would be something akin to the approach of Hoffman (2017; "Learning Deep Latent Gaussian Models with Markov Chain Monte Carlo”),..."
This is a fair point. We do have experiment results with this paper, but we didn't include it because Hoffman's method is much worse than VAE with the same amount of computation time. We are happy to add this results in, if the paper is accepted.</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div><div class="note_with_children"><div id="note_Skxf6fdt2Q" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Interesting idea, missing some baselines and theoretical justifications</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HJx4KjRqYQ&amp;noteId=Skxf6fdt2Q"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper439 AnonReviewer1</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">02 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper439 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">This paper presents an approximate bayesian inference method based on chaining measure preserving transformation with trainable parameters and optimizing for those using an ad-hoc objective based on a lower-bound on the likelihood.

The paper is clearly written and easy to follow. The proofs seem correct.

In terms of methods, I still have major questions:
- The whole premise of the paper is based on chaining transformations that preserve the target density. However, in practice, you use a leapfrog operator without the Metropolis-Hastings step --what happens to the theoretical guarantees in that case? I'm guessing Eq (8), (9) don't hold anymore and neither does Theorem 1.
- When swapping L for F, could you provide more justifications? You use the argument that p(z|x) ~= q_L so the effect of the entropy term will be negligible. It seems that if they are so similar for large L, why even train the \phi? It also comes back to my first point that in your experiment, the transformations *do not* preserve the target density. 
- Regarding the use of measure preserving flow, I think it can be quite hurtful in certain settings -- a very simple example would be a mixture of two gaussians with vastly different variance. 

I think this paper also lacks recent references on training parameters for MCMC algorithms, most notably Song et al. (2017) and Levy et al. (2018). Both of these work seem quite related and should be mentioned and compared to. I would have also liked to see the authors contrast their work with Salimans (2015), especially the HVI part; is the main difference the reverse model?

In terms of evaluation, the toy distributions show that the method seems to converge to the right target but does not compare to either vanilla HMC, A-NICE-MC or L2HMC --which all guarantee asymptotic convergence. There should probably also be a mention of one of ESS/Auto-correlation/ESS per sec to get a sense of how helpful the method could be.

For the generative model experiments, I agree with the comments of AnonReviewer3 in that evaluating HMPF-VAE with AIS while evaluating HVI with IWAE is somewhat unfair as the latter can happen to be much looser. I also think a natural baseline to compare to would be Hoffman (2017) or Levy et al. (2018) where after obtaining an approximate posterior sample, these works run an MCMC algorithm before updating the decoder. The algorithms seem to be related (albeit the objectives are slightly different) and should be talked about I think.

References:

Hoffman, Matt. Learning Deep Latent Gaussian Models with Markov Chain Monte Carlo, ICML 2017.

Song, Jiaming et al. A-NICE-MC: Adversarial Training for MCMC, NIPS 2017.

Levy, Daniel et al. Generalizing Hamiltonian Monte Carlo with Neural Networks, ICLR 2018.</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">5: Marginally below acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">3: The reviewer is fairly confident that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_r1lFKbVCaX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Thanks for the review and here is the clarifications</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HJx4KjRqYQ&amp;noteId=r1lFKbVCaX"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper439 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">18 Nov 2018</span><span class="item">ICLR 2019 Conference Paper439 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">*"- The whole premise of the paper is based on chaining transformations that preserve the target density. However, in practice, you use a leapfrog operator without the Metropolis-Hastings step --what happens to the theoretical guarantees in that case? I'm guessing Eq (8), (9) don't hold anymore and neither does Theorem 1."
For Eq(8) and Theorem 1, they still hold for a stationary distribution with difference from the target around \epsilon^2 in log density, where \epsilon is the leapfrog step size. Good reference on this is Radford Neal's tutorial on HMC and "Simulating Hamiltonian Dynamics, Chapter 4, Leimkuhler, Benedict and Reich, Sebastian". Eq (9) holds even without the convergence to target distribution. The reason of that is also very clear in the paper. Radford Neal explains this more clear in his tutorial on HMC.

*"- When swapping L for F, could you provide more justifications? You use the argument that p(z|x) ~= q_L so the effect of the entropy term will be negligible. It seems that if they are so similar for large L, why even train the \phi? It also comes back to my first point that in your experiment, the transformations *do not* preserve the target density. "

We made it clear that the precondition for ignoring the entropy term in the paper: "If with the initial flow parameter φ0, the objective F˜ &lt; Epθ(x,z)[log pθ(x, z)]..." (*right under* the definition of the loss without entropy (equation 16))
We are happy to make this more obvious somehow. Intuitively, it is not hard to see why this precondition make sense. In particular, we want to maximize this loss to converge to the target, then the initial loss value should be lower than the loss value of the target. This precondition is what it means formally for "p(z|x) ~= q_L so the effect of the entropy term will be negligible". If "p(z|x) ~= q_L" is taken out of the context, in particular, the formal condition we give in the paper, your question makes sense. But, the critical theoretical justification is in the paper. We can work on to make this formal precondition better explained and connected with "p(z|x) ~= q_L".

*"- Regarding the use of measure preserving flow, I think it can be quite hurtful in certain settings -- a very simple example would be a mixture of two gaussians with vastly different variance. "

We guess by this example, the reviewer want to say MCMC can miss some mode in this example. I think what the review want to propose by this example is the classic problem of MCMC of being trapped in high density area, even the probability mass is small. Please confirm this is what you mean.

If so, here is the answer. As long as the ergodicity holds, the convergence to arbitrary distribution holds for any measure preserving flow. Measure preserving is the precondition of ergodicity, so *measure preserving never hurts convergence to the correct target*. However, the target measure is preserved is not sufficient for ergodicity. In particular, many MCMC kernels are weak in irreducibility. On continuous target with the big density gap, many MCMC mehods, including HMC, have difficulties in exploring high probability area with low density. This is not an issue if the precondition "with the initial flow parameter φ0, the objective F˜ &lt; Epθ(x,z)[log pθ(x, z)]..." holds. Because this implies that with initial parameter, the flow distribution should explore the low density area even more than the target distribution.</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_SkeaTWNR6X" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Follow up</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HJx4KjRqYQ&amp;noteId=SkeaTWNR6X"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper439 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">18 Nov 2018</span><span class="item">ICLR 2019 Conference Paper439 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">*"I think this paper also lacks recent references on training parameters for MCMC algorithms, most notably Song et al. (2017) and Levy et al. (2018). Both of these work seem quite related and should be mentioned and compared to. I would have also liked to see the authors contrast their work with Salimans (2015), especially the HVI part; is the main difference the reverse model?

In terms of evaluation, the toy distributions show that the method seems to converge to the right target but does not compare to either vanilla HMC, A-NICE-MC or L2HMC --which all guarantee asymptotic convergence. There should probably also be a mention of one of ESS/Auto-correlation/ESS per sec to get a sense of how helpful the method could be."

Yes, many MCMC methods are relevant, but the reviewer seems confused with the nature of the proposed method. The proposed method is to simulate finite-step ergodic Markov chain that transforms i.i.d. samples from q_0 to q_N, therefore the samples from q_N are i.i.d.. We think it is not fair to compare the proposed method with MCMC on ESS/Auto-correlation/ESS per sec. ESS of any i.i.d. samples is equal to the number of samples. Because the simulation can be parallelized, ESS per sec becomes 0 as the number of samples goes infinity. This is the motivation of this work. The review may have different opinion on this. Could you clarify why ESS and auto-correlation related metrics are relevant?

*"For the generative model experiments, I agree with the comments of AnonReviewer3 in that evaluating HMPF-VAE with AIS while evaluating HVI with IWAE is somewhat unfair as the latter can happen to be much looser. I also think a natural baseline to compare to would be Hoffman (2017) or Levy et al. (2018) where after obtaining an approximate posterior sample, these works run an MCMC algorithm before updating the decoder. The algorithms seem to be related (albeit the objectives are slightly different) and should be talked about I think."

Ok, we also agree with the reviewer on this. How about a simple fix the issue on "unfair comparison of different biased estimators". It is trivial to recover the unbiased estimation of likelihood by taking exponential of the reported log likelihood and our number. Then, the comparison of two unbiased estimator should be fair now. Otherwise, please clarify why it is still unfair to compare two unbiased estimators. (Unless you want to consider the variance of the estimator, but as far as I know there is no literature report the variance of test likelihood.) Moreover, we replicated the experiment in the literature and evaluate the baseline in HAIS. Could you clarify why this is unfair to baseline?</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div></div></div><div class="note_with_children"><div id="note_ByggukyLhQ" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>simple idea that might be useful, but unnecessarily complicated exposition</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HJx4KjRqYQ&amp;noteId=ByggukyLhQ"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper439 AnonReviewer3</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">30 Oct 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper439 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">This paper proposes training latent variable models (as in VAE decoders) by running HMC to approximate the posterior of the latents, and then estimating model parameters by maximizing the complete data log-likelihood. This is not a new idea by itself and is used e.g. as a baseline in Kingma and Welling's original VAE paper. The novelty in this paper is that it proposes tuning the parameters of the HMC inference algo by maximizing the likelihood achieved by the final sample in the MCMC chain. This seems to work well in practice and might be a useful method, but it is not clear under what conditions it should work.

The paper is written in an unnecessarily complicated and formal way. On first read it seems like the proposed method has much more formal justification than it really has. The discussion up to section 3.5 makes it seem as if there is some new kind of tractable variational bound (the ERLBO) that is optimized, but in practice the actual objective in equation 16 is simply the likelihood at the final sample of the MCMC chain, that is Monte Carlo EM as e.g. used by Kingma &amp; Welling, 2013 as a baseline.  The propositions and theorems seem to apply to an idealized setting, but not to the actual algorithm that is used. They could have been put in an appendix, or even a reference to the exisiting literature on HMC would have sufficed.

The experiments do not clearly demonstrate that the method is much better than previous methods from the literature, although it is much more expensive. (The reported settings require 150 likelihood evaluations per example per minibatch update, versus 1 likelihood evaluation for a VAE). Also see my previous comments about evaluation in this paper's thread.

- Please explain why tuning the HMC algo by maximizing eq 16 should work. I don't think it is a method that generally would work, e.g. if the initial sample z0 ~ q(z|x) is drawn from a data dependent encoder as in HVI (Salimans et al) then I would expect the step size of the HMC to simply go to zero as the encoder gets good. However in your case this does not happen as the initial sample is unconditional from x. Are there general guidelines or guarantees we can conclude from this?

- The authors write "Because MPFs are equivalent to ergodic Markov chains, the density obtained at the output of an MPF, that is, qL, will converge to the stationary distribution π as L increases."

This is true for the idealized flow in continuous time, but HMC with finite step size does generally NOT converge to the correct distribution. This is why practical use of HMC includes a Metropolis-Hastings correction step. You omit this step in your algorithm, with the justification that we don't care about asymptotic convergence in this case. Fair enough, but then you should also omit all statements in the paper that claim that your method converges to the correct posterior in the limit. E.g. the writing makes it seem like Proposition 2 and Theorem 1 apply to your algorithm, but it in fact they do not apply for finite step size. Maybe the statements are still correct if we take the limit with L-&gt;inf and the stepsize delta-&gt;0 at a certain rate? This is not obvious to me.

In practice, you learn the stepsize delta. Do we have any guarantees this will make delta go to zero at the right rate as we increase the number of steps L? I.e. is this statement from your abstract true? -&gt; "we propose a novel method which is scalable, like mean-field VI, and, due to its theoretical foundation in ergodic theory, is also asymptotically accurate". (convergence of uncorrected HMC only holds in the idealized case with step size -&gt; 0)</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">4: Ok but not good enough - rejection</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_ryxu5rERam" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Thanks for the review and here is the justifications</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HJx4KjRqYQ&amp;noteId=ryxu5rERam"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper439 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">18 Nov 2018</span><span class="item">ICLR 2019 Conference Paper439 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">*"The paper is written in an unnecessarily complicated and formal way. On first read it seems like the proposed method has much more formal justification than it really has. The discussion up to section 3.5 makes it seem as if there is some new kind of tractable variational bound (the ERLBO) that is optimized, but in practice the actual objective in equation 16 is simply the likelihood at the final sample of the MCMC chain, that is Monte Carlo EM as e.g. used by Kingma &amp; Welling, 2013 as a baseline.  The propositions and theorems seem to apply to an idealized setting, but not to the actual algorithm that is used. They could have been put in an appendix, or even a reference to the exisiting literature on HMC would have sufficed."

For Eq(8) and Theorem 1, they still hold for a stationary distribution with difference in log density from the target around \epsilon^2, where \epsilon is the leapfrog step size. See reference on this in Radford Neal's tutorial on HMC and "Simulating Hamiltonian Dynamics, Chapter 4, Leimkuhler, Benedict and Reich, Sebastian". Eq (9) holds even without the convergence to target distribution. The reason of that is also very clear in the paper. Radford Neal explains this more clear in his tutorial on HMC.

"Monte Carlo EM" is for training latent variable model rather than optimising kernel parameters in MCMC. In Monte Carlo EM, the expectation is computed by Monte Carlo estimation using perfect or MCMC approximate samples. The Simulation of samples is not optimised or tuned w.r.t. any loss. This is *fundamentally* different from what we propose in this work. 
First, what we propose is an inference method not a training method for latent variable model.  To avoid this confusion, we have the other experiment for Bayesian NNs.
Second, the same loss function here is the same as likelihood, but we fit the approximation distribution rather than maximum likelihood for latent variable. I hope the reviewer would agree on this: even the same loss function, optimising completely different variable is not a trivial difference. 
Finally, we have the formal condition of ignoring the entropy term: "If with the initial flow parameter φ0, the objective F˜ &lt; Epθ(x,z)[log pθ(x, z)]..." (*right under* the definition of the loss without entropy (equation 16)) For the explanation to this precondition, please check the reply to other reviewers.</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_SklSPtNATQ" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Follow up</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HJx4KjRqYQ&amp;noteId=SklSPtNATQ"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper439 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">18 Nov 2018</span><span class="item">ICLR 2019 Conference Paper439 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">*In practice, you learn the stepsize delta. Do we have any guarantees this will make delta go to zero at the right rate as we increase the number of steps L? I.e. is this statement from your abstract true? -&gt; "we propose a novel method which is scalable, like mean-field VI, and, due to its theoretical foundation in ergodic theory, is also asymptotically accurate". (convergence of uncorrected HMC only holds in the idealized case with step size -&gt; 0)*

Here seems to be a confusion of the definition of discretization step size. Discretization step size can approach 0 under one condition that is the total sum of the step size cannot go to zero with the step size. This is the basic knowledge of numeric methods. I think this explains why the step size cannot be zero in our experiment. We assume the reviewer did not understand the precondition of the loss eq(16), otherwise it is intuitive that the optimal step size cannot be zero.</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_HJg6p8EApX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Follow up</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HJx4KjRqYQ&amp;noteId=HJg6p8EApX"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper439 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">18 Nov 2018</span><span class="item">ICLR 2019 Conference Paper439 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">*"- Please explain why tuning the HMC algo by maximizing eq 16 should work. I don't think it is a method that generally would work, e.g. if the initial sample z0 ~ q(z|x) is drawn from a data dependent encoder as in HVI (Salimans et al) then I would expect the step size of the HMC to simply go to zero as the encoder gets good. However in your case this does not happen as the initial sample is unconditional from x. Are there general guidelines or guarantees we can conclude from this?"

First of all, let's start with the basic MCMC knowledge: the condition for ergodic Markov chains. A Markov chain is ergodic must satisfy following conditions (see wikipedia for more detailed explanation):
-irreducible (precondition of recurrence): The probability of any state change to any other state must be positive. 
-recurrent: revisit any state with positive probability under stationary infinite many times
-aperiodic: the period of the chain must be 1
-existing stationary distribution: there must exists a stationary distribution

Here is the answer to the question:
1) The irreducibility of ergodic Markov kernel (not in the paper)
2) HMC step size can never be 0 otherwise the kernel is irreducible therefore not ergodic (not in the paper)
3) Our precondition for dropping the entropy term (in the paper, *right below* the definition of the loss without entropy (equation 16))
We didn't include the first two points, because we assume that the basic MCMC knowledge the researchers in this field should be familiar with.

By the equation (16) in the paper, the initial flow with initial parameter must have lower loss than the target p(z |x) this rule out the variational distribution as initial, because variational approximation will underestimate the variance therefor overestimate the the expectation of log p(x, z) under p(z | x).
</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div></div></div><div class="note_with_children"><div id="note_H1lYr-3H3X" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>clarification on IS lower bound</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HJx4KjRqYQ&amp;noteId=H1lYr-3H3X"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper439 AnonReviewer3</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">30 Oct 2018</span><span class="item">ICLR 2019 Conference Paper439 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">As a clarification to my earlier comment: The importance sampling estimator of the likelihood reported in the literature that is compared against is a lower bound (see the Importance Weighted Autoencoder paper by Burda et al), which the AIS method used in this paper is not. Not to be confused with the 1-sample variational lower bound that is also reported.</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_H1e3Pug8h7" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Clarification on IS and The relationship between IS and Annealed IS</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HJx4KjRqYQ&amp;noteId=H1e3Pug8h7"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper439 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">30 Oct 2018</span><span class="item">ICLR 2019 Conference Paper439 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">*First, it is in standard textbook of Monte Carlo methods that *importance sampling gives unbiased estimation*.
Given unnormalised density function p*(x), the normalisation constant is
Z = \int p*(x)dx,
which can be rewritten as
Z = \int p*(x)/q(x) q(x) dx,
where q(x) is some distribution.
Using Monte Carlo method, we replace the integral with sampled average by samples from q(x)
Z = \int p*(x)/q(x) q(x) dx 
\approx Z_{is} 
= 1/N \sum_i=1^N p*(x_i) / q(x_i),
where x_i is sampled from q(x). 
The ratio w_i = p*(x_i) / q(x_i) is often known as the weight of samples.
As a Monte Carlo estimator, Z_{is} is an unbiased estimator to Z independent of the number of samples  is 1 or 1000.
However, the MC estimator can have a lower variance as the sample size N increases. 
Let Z_{is, k} = \sum_i=1^k w_i an k-sample unbiased estimator of Z. Z_{is, k} is essentially a random variable. Because it is unbiased estimator the mean of Z_{is, k} is equal to the true value Z, that is
\log \Exp[Z_{is, k}] = \log \Exp[\sum_i=1^k w_i] = \log Z. (1)
By Jensen's inequality, we have the lower bound
\Exp[\log Z_{is, k}] \ge \log \Exp[Z_{is, k}].   (2)
This is exactly the equation (9) in Importance Weighted Autoencoder paper by Burda et al.

If we take k = 1, then the LHS of (2) above become 1-sample lower bound. Naturally, there are k-sample lower bound, that is different from k-sample IS estimator by (1).
In (Salimans et al., 2015), the test log likelihood reported refers to the k-sample IS estimator (1) rather than k-sample lower bound (2). 

* Annealed IS ("Annealed Importance Sampling", Radford M. Neal, 1998) is simply a special IS method, where the q distribution is constructed as a sequence of annealing distributions q_1, q_2,... that systematically converges to p(x). The purpose of annealing distributions in AIS is to reduce the variance of weights *rather than* to be unbiased estimator.

So, can you clarity the point of your comment? In particular, you said "The importance sampling estimator of the likelihood reported in the literature that is compared against is a lower bound (see the Importance Weighted Autoencoder paper by Burda et al), which the AIS method used in this paper is not."

This difference should not be critical, because the quality of different IS estimators can be estimated by effective sample size.  For this reason, we report ESS for comparison of other work with different IS evaluation. But ESS is not reported in (Salimans et al., 2015).

</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_HklKJS-UhX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>no</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HJx4KjRqYQ&amp;noteId=HklKJS-UhX"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper439 AnonReviewer3</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">31 Oct 2018</span><span class="item">ICLR 2019 Conference Paper439 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">"In (Salimans et al., 2015), the test log likelihood reported refers to the k-sample IS estimator (1) rather than k-sample lower bound (2)."

\log Z_{is, k} is what is reported in Salimans et al (for very large k). This is exactly the left hand side of your equation 2, which is indeed equation 9 in Burda et al. Your equation 1 includes intractable expectations (\Exp): How would Salimans et al. report those? Surely they just approximate by using Z_{is, k} and making k large? You're right that the reported number is meant to estimate Z, but the estimate is a lower bound (in expectation) and thus conservative. Pointing that out was one of the main contributions of Burda et al.

"*First, it is in standard textbook of Monte Carlo methods that *importance sampling gives unbiased estimation*."

Yes, Z_{is, k} is an unbiased estimator of Z, but \log Z_{is, k} is not unbiased, it's expectation is a lower bound.

My point in making that comment was that if you claim that the IS based estimate is no good (inferior to AIS), it also means that all previous results in the literature are too conservative and that the comparison is biased in your favor.

(* your equation 2 should have \leq where you have \ge)</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_SyeA3Y-L27" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Please read more basics on Importance sampling!</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HJx4KjRqYQ&amp;noteId=SyeA3Y-L27"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper439 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">31 Oct 2018</span><span class="item">ICLR 2019 Conference Paper439 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Please read "Importance Weighted Autoencoder" paper by Burda et al. carefully. In particularly, look at the equation (9).

You said "Yes, Z_{is, k} is an unbiased estimator of Z, but \log Z_{is, k} is not unbiased, it is a lower bound.", but why?

If in (Salimans et al., 2015), they made it clear that the they report test log likelihood by IS, that precisely means  
\log \Exp[Z_{is, k}] = \log \Exp[\sum_i=1^k w_i] = \log Z. (1)
No one can argue this is wrong or not log likelihood. It is simple, the log of any unbiased estimator is also unbiased estimator.

Not all log likelihood estimators are lower bound. Again all IS, AIS, HAIS are unbiased estimator. See more detailed explanation in "On the Quantitative Alysis of Decoder-based Generative Models", Grosse et al., ICLR, 2017.

Can you explain why AIS is unbiased but IS is biased?</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_B1e6_h-Un7" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>no</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HJx4KjRqYQ&amp;noteId=B1e6_h-Un7"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper439 AnonReviewer3</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">31 Oct 2018</span><span class="item">ICLR 2019 Conference Paper439 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">"It is simple, the log of any unbiased estimator is also unbiased estimator."

This is not true, and basic statistics.
I'm going to stop arguing now.</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_BJxb-WkPhm" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Appreciate your comments and Please let us know your concern</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HJx4KjRqYQ&amp;noteId=BJxb-WkPhm"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper439 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">31 Oct 2018</span><span class="item">ICLR 2019 Conference Paper439 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">We appreciate the time and effort that you have invested in providing feedback about the paper and would like to apologize for any confusion regarding the previous responses.

To clarify things, we would like to make the following points:

1) We agree with your comment that "Z_{is, k} is an unbiased estimator of Z, but \log Z_{is, k} is not unbiased, it's expectation is a lower bound.”.

2) We believe that you are concerned about the IS estimator having higher variance than the AIS estimator. If this were the case, when we take the log of the resulting estimate, the IS estimator could produce lower values on expectation than the AIS estimator.

Our answer to 2) above is as follows:

- The effective sample size (ESS) is a metric related to the variance of an IS estimator. To make a fair comparison with the literature, we reproduced the experiments in (Salimans et al., 2015) using HAIS and reported the ESS of the generated HAIS samples. In fact, the ESS metrics for our methods (Table 1, row 6-10) and HVI (Table 1, row 5) are similar (from 38 to 50). To this extent, we believe that comparing these different estimates of average test log marginal likelihood is fair because we obtain similar ESS metrics. We also agree that a direct comparison of our test log marginal likelihood metrics with other values reported in the literature that do not include ESS metrics can be unreliable (for example, if those other values could just be lower on average due to the higher variance of the used IS estimators).

Please let us know if this has correctly addressed your concern or if your concern was actually different.</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_BJe2k9yPhX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>thanks</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HJx4KjRqYQ&amp;noteId=BJe2k9yPhX"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper439 AnonReviewer3</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">31 Oct 2018</span><span class="item">ICLR 2019 Conference Paper439 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Thanks, that's useful clarification, I agree.

In addition to the bias of the IS estimator (= variance + log transform) my concern was also with the bias of AIS: Some results in some papers suggest that it may have an optimistic bias, see e.g. Figure 2 in Sohl-Dickstein &amp; Culpepper, 2012, and that this bias may depend on the model, making comparison across models difficult. It's unclear to me in exactly what cases this is a problem and to what extent.

My comment about the different likelihood estimators was only intended as a minor point: I believe your replication of the Salimans et al. result is a good effort towards a fair comparison.</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div></div></div></div></div></div></div></div></div><div class="note_with_children"><div id="note_r1g4I4TrhQ" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a> The difference of IS and AIS has been addressed in the submitted paper.</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HJx4KjRqYQ&amp;noteId=r1g4I4TrhQ"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper439 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">30 Oct 2018</span><span class="item">ICLR 2019 Conference Paper439 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">First, in your previous comment you mentioned explicitly lower bound rather than log likelihood as "However, the method in the cited work is a lower bound and is thus conservative, whereas AIS is sometimes biased to the optimistic side." This is why we emphasised that we reported the log likelihood rather than lower bound from the literature.

Second, we are aware of the difference of IS and AIS log likelihood estimation as you commented here. We clarified this important detail In the submitted paper in the caption of Table 1: "... In (Salimans et al., 2015), the test likelihood is estimated using importence-weighted samples from the encoder network. In our experiment, we use a more reliable estimation method based on Hamiltonian annealled importance sampling ...". 

Moreover, we also report the ESS of our HAIS samplers. Effective sample size (ESS) is a well-known quality metric for the *all* kind of importance weighted sampling methods, like importence-weighted sampleing and Hamiltonian annealled importance sampling. ESS has been used in many literature for both IS and HAIS on evaluation of deep generative models, like "Approximate Inference with Amortised MCMC" from Li et al., icml, 2017 and "On the Quantitative Alysis of Decoder-based Generative Models", Grosse et al., ICLR, 2017.

Finally, for more fair comparison with HVI, we have also reproduced the experiment of (Salimans et al., 2015) with HAIS evaluation which is reported in the middle rows of Table 1 (This has been mentioned in our previous comment.)</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div><div class="note_with_children"><div id="note_SylPxcEy3m" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>comparison to previous results</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HJx4KjRqYQ&amp;noteId=SylPxcEy3m"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper439 AnonReviewer3</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">25 Oct 2018</span><span class="item">ICLR 2019 Conference Paper439 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">The comparison to results from the literature might be slightly misleading. Please clarify.

* The toughest baseline that is compared to in section 4.2 is from 2015. Please include some more recent results for reference. There exist several better results.

* You write
"In (Salimans et al., 2015), the test likelihood is estimated using importence-weighted
samples from the encoder network. In our experiment, we use a more reliable estimation method
based on Hamiltonian annealled importance sampling and report the effective sample size (ESS)."
However, the method in the cited work is a lower bound and is thus conservative, whereas AIS is sometimes biased to the optimistic side. Can you clarify whether the reported numbers are indeed guaranteed to be comparable to the literature?</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_BJglCADJ2m" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Some Clarifications on the Experiment of DeepConvNet on MNIST and Results (Section 4.2)</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HJx4KjRqYQ&amp;noteId=BJglCADJ2m"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper439 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">26 Oct 2018 (modified: 27 Oct 2018)</span><span class="item">ICLR 2019 Conference Paper439 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">We are aware of that the baseline we chose is not the most recent work and there are better results in recent literature.
We address the two comments as following.

*First of all, this work is about a new inference method that can accelerate the training of deep generative models rather than new state-of-the-art models.

For this purpose, the experiment in Section 4.2 is to demonstrate the training of deep generative models using our inference method over can converge faster than traditional variational inference in both wall-clock time and epochs.
HVI (Salimans et al., 2015) is the most relevant baseline, because HVI is a variational method that uses HMC sampler as variational approximate distribution, that shares the same spirit of our method. 

Because the code of HVI is not publicly available, we reimplement their generator network and reproduced their results (that is in the middle rows of Table 1). For a fair comparison, we tested our method on the our implementation of the same generator network in  (Salimans et al., 2015). In our paper, we cited the results from Salimans et al. (that is in the top rows of Table 1) to support that our reimplementation (along with the estimation of log likelihood) is comparable to the original one in (Salimans et al., 2015).

More recent works on variational inference for deep generative models are based on more advanced generator networks than the network used in (Salimans et al., 2015). There is no universal benchmark generator network that is used in most works. So, direct comparison with those results cross different works can be *misleading*, because it can be biased towards more advanced generator networks. To avoid this, we need to reimplement the generator networks used in other works, like what we did with HVI. Due to limited time, we could not do this. But, it is still good to add more recent works as a reference. We will do that in the next version of the paper.

* In (Salimans et al., 2015), both lower bound and the test log likelihood are reported. The test log likelihood in (Salimans et al., 2015) is estimated by IS rather than AIS. In particular, Hamiltonian AIS we used is based on the recent work on "ON THE QUANTITATIVE ANALYSIS OF DECODER-BASED GENERATIVE MODELS" (Roger et al.,  ICLR 2017). We compare our method with the test log likelihood rather than the lower bound reported in (Salimans et al., 2015). The result of our HAIS evaluation on HVI is consistent with (Salimans et al., 2015). (Our reproduced result of HVI as shown in the middle rows of Table 1 is actually slightly worse than that in their paper) So, there is no direct evidence of the HAIS evaluation we used is biased. We are fairly confident that our results are comparable to (Salimans et al., 2015).</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div></div></main></div>
  </div>
</div>


    <!-- Footer -->
    <footer class="sitemap">
      <div class="container">
        <div class="row hidden-xs">
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/venues">All Venues</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="/contact">Contact</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
    
        <div class="row visible-xs-block">
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/contact">Contact</a></li>
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
      </div>
    </footer>
    
    <footer class="sponsor">
      <div class="container">
        <div class="row">
          <div class="col-sm-10 col-sm-offset-1">
            <p class="text-center">
              OpenReview is created by the <a href="http://www.iesl.cs.umass.edu/" target="_blank">Information Extraction and Synthesis Laboratory</a>, College of Information and Computer Science, University of Massachusetts Amherst. We gratefully acknowledge the support of the OpenReview sponsors:  Google,  Facebook, NSF, the University of Massachusetts Amherst Center for Data Science, and Center for Intelligent Information Retrieval, as well as the Google Cloud Platform for donating the computing and networking services on which OpenReview.net runs.
            </p>
          </div>
        </div>
      </div>
    </footer>

  <div id="feedback-modal" class="modal fade" tabindex="-1" role="dialog">
    <div class="modal-dialog">
      <div class="modal-content">
        <div class="modal-header">
          <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button>
          <h3 class="modal-title">Send Feedback</h3>
        </div>
        <div class="modal-body">
          <p>Enter your feedback below and we'll get back to you as soon as possible.</p>
          <form action="/feedback" method="POST">
            <div class="form-group">
              <input type="email" name="from" class="form-control" placeholder="Email" />
            </div>
            <div class="form-group">
              <input type="text" name="subject" class="form-control" placeholder="Subject" />
            </div>
            <div class="form-group">
              <textarea name="message" class="form-control feedback-input" rows="5" placeholder="Message" required=""></textarea>
            </div>
          <ul id="ui-id-2" tabindex="0" class="ui-menu ui-widget ui-widget-content" style="display: none;"></ul></form>
        </div>
        <div class="modal-footer">
          <button type="button" class="btn btn-default" data-dismiss="modal">Cancel</button>
          <button type="button" class="btn btn-primary">Send</button>
        </div>
      </div>
    </div>
  </div>

  <script type="text/javascript" async="" src="https://www.google-analytics.com/analytics.js"></script><script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js"></script>
  <script>window.jQuery || document.write('&lt;script src="/static/js/vendor/jquery-2.2.4.min.js"&gt;&lt;\/script&gt;')</script>

  <script src="/static/dist/vendor.min.js"></script>
  <script src="/static/dist/templates.min.js"></script>
  <script src="/static/dist/openreview.min.js"></script>

    <script>window.legacyScripts = true;</script>


    <script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-108703919-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() { dataLayer.push(arguments); }
      gtag('js', new Date());
      gtag('config', 'UA-108703919-1');
    </script>


<div role="status" aria-live="assertive" aria-relevant="additions" class="ui-helper-hidden-accessible"></div></body></html>
<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" class="no-js"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>Adversarial Sampling for Active Learning | OpenReview</title>
  <meta name="description" content="" />

      <meta name="citation_title" content="Adversarial Sampling for Active Learning" />
        <meta name="citation_author" content="Anonymous" />
      <meta name="citation_publication_date" content="2018/09/27" />
      <meta name="citation_online_date" content="2018/09/27" />
      <meta name="citation_pdf_url" content="https://openreview.net/pdf?id=r1GB5jA5tm" />
      <meta name="twitter:card" content="summary" />
      <meta name="twitter:site" content="@openreviewnet" />
      <meta name="og:title" content="Adversarial Sampling for Active Learning" />
      <meta name="og:description" content="This paper proposes ASAL, a new pool based active learning method that generates high entropy samples. Instead of directly annotating the synthetic samples, ASAL searches similar samples from the..." />
      <meta name="og:image" content="https://openreview.net/static/images/openreview_logo_512.png" />

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans:400,400i,700,700i" />

  <link rel="stylesheet" href="/static/css/bootstrap.min.css" />
  <link rel="stylesheet" href="/static/css/jquery-ui.min.css" />
  <link rel="stylesheet" href="/static/css/main.min.css" />
</head>

<body class="forum">
  <nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
  
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand home push-link" href="/"><strong>OpenReview</strong>.net</a>
      </div>
  
      <div id="navbar" class="navbar-collapse collapse">
        <form class="navbar-form navbar-left profile-search" role="search">
          <div class="form-group has-feedback">
            <input id="search_input" type="text" class="form-control ui-autocomplete-input" placeholder="Search ICLR 2019 Conference" autocomplete="off" />
            <span class="glyphicon glyphicon-search form-control-feedback" aria-hidden="true"></span>
          </div>
  
          <input id="search_group" type="hidden" value="ICLR.cc/2019/Conference" />
          <input id="search_content" type="hidden" value="all" />
        <ul id="ui-id-1" tabindex="0" class="ui-menu ui-widget ui-widget-content ui-autocomplete ui-front" style="display: none;"></ul></form>
  
        <ul class="nav navbar-nav navbar-right">
        
            <li id="user-menu"><a href="/login">Login</a></li>
        </ul>
      </div>
  
    </div>
  </nav>

  <div id="or-banner" class="banner" style="">
  <div class="container">
    <div class="row">
      <div class="col-xs-12"><a href="/group?id=ICLR.cc/2019/Conference" title="Venue Homepage"><img class="icon" src="/static/images/arrow_left.svg" /> Go to <strong>ICLR 2019 Conference</strong> homepage</a></div>
    </div>
  </div>
</div>
<div id="flash-message-container" class="alert alert-danger" role="alert" style="display: none;">
  <div class="container">
    <div class="row">
      <div class="col-xs-12">
        <div class="alert-content">
          <button type="button" class="close" aria-label="Close"><span aria-hidden="true">×</span></button>
        </div>
      </div>
    </div>
  </div>
</div>

<div class="container">
  <div class="row">
    <div class="col-xs-12">
      <main id="content" class="clearfix openbanner-visible legacy-styles"><div id="note_r1GB5jA5tm" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Adversarial Sampling for Active Learning</a> <a class="note_content_pdf" href="/pdf?id=r1GB5jA5tm" title="Download PDF" target="_blank"><img src="/static/images/pdf_icon_blue.svg" /></a> </h2></div><div class="meta_row"><span class="signatures">Anonymous</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">28 Sep 2018 (modified: 11 Oct 2018)</span><span class="item">ICLR 2019 Conference Blind Submission</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span><span class="item"><a class="action-bibtex-modal" data-bibtex="@inproceedings{    &#10;anonymous2019adversarial,    &#10;title={Adversarial Sampling for Active Learning},    &#10;author={Anonymous},    &#10;booktitle={Submitted to International Conference on Learning Representations},    &#10;year={2019},    &#10;url={https://openreview.net/forum?id=r1GB5jA5tm},    &#10;note={under review}    &#10;}">Show Bibtex</a></span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Abstract: </span><span class="note_content_value">This paper proposes ASAL, a new pool based active learning method that generates high entropy samples. Instead of directly annotating the synthetic samples, ASAL searches similar samples from the pool and includes them for training. Hence, the quality of new samples is high and annotations are reliable.  ASAL is particularly suitable for large data sets because it achieves a better run-time complexity (sub-linear) for sample selection than traditional uncertainty sampling (linear). We present a comprehensive set of experiments on two data sets and show that ASAL outperforms similar methods and clearly exceeds the established baseline (random sampling).  In the discussion section we analyze in which situations ASAL performs best and why it is sometimes hard to outperform random sample selection. To the best of our knowledge this is the first adversarial active learning technique that is applied for multiple class problems using deep convolutional classifiers and demonstrates superior performance than random sample selection.</span></div><div class="note_contents"><span class="note_content_field">Keywords: </span><span class="note_content_value">active learning, adversarial training, GAN</span></div><div class="note_contents"><span class="note_content_field">TL;DR: </span><span class="note_content_value">ASAL is a pool based active learning method that generates high entropy samples and retrieves matching samples from the pool in sub-linear time.</span></div><div class="reply_row clearfix"><div class="item" id="reply_count">3 Replies</div></div></div><hr class="small" /><div id="note_children"><div class="note_with_children"><div id="note_r1gbAqUSpm" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Nice idea for important problem, but requires validation on algorithm speed.</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=r1GB5jA5tm&amp;noteId=r1gbAqUSpm"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper532 AnonReviewer2</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">11 Nov 2018</span><span class="item">ICLR 2019 Conference Paper532 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">This paper proposes adversarial sampling for pool-based active learning, which is a sublinear-time algorithm based on 1) generating “uncertain” synthetic examples and 2) using the generated example to find “uncertain” real examples from the pool. I liked the whole idea of developing a faster algorithm for active learning based on the nearest neighborhood method. However, my only &amp; major concern is that one has to train GANs before the active learning process, which might cost more than the whole active learning process.  

Pros: 
- This paper tackles the important problem of reducing the time complexity needed for active learning with respect to the pool size. I think this is a very important problem that is necessary to be addressed for the application of active learning.
-The paper is well written and easy to understand.
-I think the overall idea is novel and useful even though it is very simple. I think this work has a very promising potential to be a building block for future works of fast active learning.

Cons:
-There is no theoretical guarantee on the "uncertainty" of obtained real examples. 
-The main contribution of this algorithm is computational complexity, but I am not very persuaded by the idea of using the GAN in order to produce a sublinear (faster) time algorithm for active learning, since training the GAN may sometimes take more time that the whole active learning process. Explicitly describing situations where the proposed method is useful seems necessary. I would expect the proposed algorithm to be beneficial when there is a lot of queries asked and answered, but this seems unlikely to happen in real situations.  
-Empirical evaluation is weak, since the algorithm only outperforms the random sampling of queries. Especially, given that sublinear nature of the algorithm is the main strength of the paper, it would have been meaningful to evaluate the actual time spent for the whole learning process including the training of GANs. Especially, one could also speed-up max entropy criterion by first sampling subset of data-points from the pool and evaluating upon them. 
</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">6: Marginally above acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_rkedwDJo3Q" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Nice Idea but Weak Experiments</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=r1GB5jA5tm&amp;noteId=rkedwDJo3Q"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper532 AnonReviewer1</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">03 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper532 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">The paper presents a pool-based active learning method that achieves sub-linear 
runtime complexity while generating high-entropy samples, as opposed to linear 
complexity of more traditional uncertainty sampling (i.e., max-entropy) methods. 
This is achieved by using a generative adversarial network (GAN) to generate 
high-entropy samples that are then used by a nearest neighbor method to pick 
samples from a pool, that are closest to the generated samples. The sub-linear 
complexity is achieved through the use of a k-d tree, combined with the fact 
that similarity is computed on the feature space and samples can thus be indexed 
once (as the feature space does not change while training).

The proposed idea builds on top of previously published work on Generative 
Adversarial Active Learning (GAAL). The main difference is the added nearest 
neighbor component, as GAAL is directly using the generated examples, thus 
achieving constant runtime complexity, rather than sub-linear.

I like the overall direction and the idea of being able to perform uncertainty 
sampling in sub-linear time. The approach is interesting. However, the results 
presented in the paper are not strong and I do not see whether or not I should 
be using this method over uncertainty sampling. Most importantly, the results 
are strongest only for the MNIST experiments, which are over a small dataset. 
Given that the method is motivated by the scalability argument, I would like to 
see at least one large scale experiment where it performs well, and more 
specifically, outperform random sampling. Also, I would really like to see a 
more principled and thorough experimental investigation with justifications for 
the configurations used and with more comparisons to alternative approaches, 
such as GAAL, which has constant complexity.

I believe that it would be better for your paper if you work a bit more on the 
experimental evaluation and submit a revised version at a later deadline.

== Background and Method ==

The background and method sections are clear and easy to follow. One improvement 
I can see is making figure 1 more clear, by maybe explicitly stating in the 
figure what "G" and "F" are. One more point of interest is that the way you 
perform sample matching makes some smoothness assumption about the feature 
space as related to the classifier uncertainty. I perceive this as a smoothness 
assumption on the decision boundary of the classifier and I do not know how true 
is may be for deep neural networks, but I can see how it may be true for 
logistic regression models and support vector machines (SVMs), depending on the 
kernel used. I believe that this point and main assumption may be worth further 
discussion, given that it is also about the main difference your method has with 
respect to GAAL.

I do not have any other major comments for these sections as my main concerns 
are about the experiments section.

== Experiments ==

In the experiments, it would be very useful to have plots against execution 
time, given that the main motivation for this method is scalability. For 
example, the method outperforms random sampling for small datasets, based on 
number of samples, but what happens when you look at execution time? Given that 
random sampling is very cheap, I imagine that it probably does better. Also, as 
mentioned earlier, I would like to see at least one experiment using a big 
dataset, where the method outperforms random sampling, as I am not currently 
convinced of its usefulness.

Also, you present a lot of results and list observations but I felt there was 
not much discussion as to why you observe/obtain some of the results. Given that 
your method is not working very well for CIFAR, I would like to see a more 
thorough investigation as to why that may be the case. This investigation could 
conclude with some "tips" on when it may be a good idea to use your method over 
GAAL, or uncertainty sampling, for example.

Regarding the experimental setup, I find lots of configuration choices very 
arbitrary and have difficulty understanding how they were chosen. For example:

  - For the two-class MNIST you use classes "5" and "7" and for the two-class 
    CIFAR you use classes "automobile" and "horse". Why is that? How did you 
    pick the two classes to use in each case? Do the results match for other 
    class pairs?
  - "learning rate of 0.01 that we decay by a factor of 10 at the 130th and 
    140th epochs" -- end of page 6
  - "In contrast to the previous experiments we use a residual Wasserstein GAN 
    with gradient penalty and soft consistency term" -- page 7 -- why do you 
    make that change?

Questions:
  - Why do you think using Wasserstein GANs perform better than using DCGANs? -- section 5.3.1
  - Why not compare to GAAL in all of figures 3 and 4?
  - How/why were the number of samples you start with and sample in each round, 
    chosen? Do you observe any difference if you increase/decrease the number of 
    samples sampled in each round or if you start with fewer samples?
  - How/why were these model architectures chosen?</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">5: Marginally below acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_rJeOCbdwnX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>GAN-based active learning for query synthesis </a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=r1GB5jA5tm&amp;noteId=rJeOCbdwnX"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper532 AnonReviewer3</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">01 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper532 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">This paper proposed a query-synthesis-based active learning algorithm that uses GAN to generate high entropy sample; instead of annotating the synthesized sample, the paper proposed to find the most similar unlabeled data from the pool via nearest neighbor search, with the latter is the main contribution of the paper.

Pros: 
(1)	the paper is well written and easy to follow;
(2)	evaluations look reasonable and fair

Cons:
(1)	The idea of using GAN for active query synthesis isn’t new. As the authors pointed out, this idea is mainly from GAAL (Zhu &amp; Bento 2017). The main difference is sample matching that searches the nearest neighbor from pool and add the real unlabeled data for AL. So the novelty of the paper isn’t significant.
(2)	In terms of accuracy comparison, on Cifar-10-ten classes experiments, all ASAL variants have similar accuracies as random sampling, while traditional pool-based max-entropy clearly works much better. Although the former is much faster (O(1) vs. O(N)), this benefit is mainly due to GAAL (Zhu &amp; Bento 2017).

The paper provides additional evidence showing that GAN-based active learning might be an interesting research direction for active query synthesis. However, given the reasons above, particularly novelty, I think the authors might need to additional work to improve the method.
</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">5: Marginally below acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></main></div>
  </div>
</div>


    <!-- Footer -->
    <footer class="sitemap">
      <div class="container">
        <div class="row hidden-xs">
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/venues">All Venues</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="/contact">Contact</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
    
        <div class="row visible-xs-block">
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/contact">Contact</a></li>
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
      </div>
    </footer>
    
    <footer class="sponsor">
      <div class="container">
        <div class="row">
          <div class="col-sm-10 col-sm-offset-1">
            <p class="text-center">
              OpenReview is created by the <a href="http://www.iesl.cs.umass.edu/" target="_blank">Information Extraction and Synthesis Laboratory</a>, College of Information and Computer Science, University of Massachusetts Amherst. We gratefully acknowledge the support of the OpenReview sponsors:  Google,  Facebook, NSF, the University of Massachusetts Amherst Center for Data Science, and Center for Intelligent Information Retrieval, as well as the Google Cloud Platform for donating the computing and networking services on which OpenReview.net runs.
            </p>
          </div>
        </div>
      </div>
    </footer>

  <div id="feedback-modal" class="modal fade" tabindex="-1" role="dialog">
    <div class="modal-dialog">
      <div class="modal-content">
        <div class="modal-header">
          <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button>
          <h3 class="modal-title">Send Feedback</h3>
        </div>
        <div class="modal-body">
          <p>Enter your feedback below and we'll get back to you as soon as possible.</p>
          <form action="/feedback" method="POST">
            <div class="form-group">
              <input type="email" name="from" class="form-control" placeholder="Email" />
            </div>
            <div class="form-group">
              <input type="text" name="subject" class="form-control" placeholder="Subject" />
            </div>
            <div class="form-group">
              <textarea name="message" class="form-control feedback-input" rows="5" placeholder="Message" required=""></textarea>
            </div>
          <ul id="ui-id-2" tabindex="0" class="ui-menu ui-widget ui-widget-content" style="display: none;"></ul></form>
        </div>
        <div class="modal-footer">
          <button type="button" class="btn btn-default" data-dismiss="modal">Cancel</button>
          <button type="button" class="btn btn-primary">Send</button>
        </div>
      </div>
    </div>
  </div>

  <script type="text/javascript" async="" src="https://www.google-analytics.com/analytics.js"></script><script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js"></script>
  <script>window.jQuery || document.write('&lt;script src="/static/js/vendor/jquery-2.2.4.min.js"&gt;&lt;\/script&gt;')</script>

  <script src="/static/dist/vendor.min.js"></script>
  <script src="/static/dist/templates.min.js"></script>
  <script src="/static/dist/openreview.min.js"></script>

    <script>window.legacyScripts = true;</script>


    <script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-108703919-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() { dataLayer.push(arguments); }
      gtag('js', new Date());
      gtag('config', 'UA-108703919-1');
    </script>


<div role="status" aria-live="assertive" aria-relevant="additions" class="ui-helper-hidden-accessible"></div></body></html>
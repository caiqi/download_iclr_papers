<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" class="no-js"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>Evolving intrinsic motivations for altruistic behavior | OpenReview</title>
  <meta name="description" content="" />

      <meta name="citation_title" content="Evolving intrinsic motivations for altruistic behavior" />
        <meta name="citation_author" content="Jane X. Wang" />
        <meta name="citation_author" content="Edward Hughes" />
        <meta name="citation_author" content="Chrisantha Fernando" />
        <meta name="citation_author" content="Wojciech M. Czarnecki" />
        <meta name="citation_author" content="Edgar A. Duenez-Guzman" />
        <meta name="citation_author" content="Joel Z. Leibo" />
      <meta name="citation_publication_date" content="2018/09/27" />
      <meta name="citation_online_date" content="2018/09/27" />
      <meta name="citation_pdf_url" content="https://openreview.net/pdf?id=r1e-nj05FQ" />
      <meta name="twitter:card" content="summary" />
      <meta name="twitter:site" content="@openreviewnet" />
      <meta name="og:title" content="Evolving intrinsic motivations for altruistic behavior" />
      <meta name="og:description" content="Multi-agent cooperation is an important feature of the natural world. Many tasks involve individual incentives that are misaligned with the common good, yet a wide range of organisms from bacteria..." />
      <meta name="og:image" content="https://openreview.net/static/images/openreview_logo_512.png" />

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans:400,400i,700,700i" />

  <link rel="stylesheet" href="/static/css/bootstrap.min.css" />
  <link rel="stylesheet" href="/static/css/jquery-ui.min.css" />
  <link rel="stylesheet" href="/static/css/main.min.css" />
</head>

<body class="forum">
  <nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
  
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand home push-link" href="/"><strong>OpenReview</strong>.net</a>
      </div>
  
      <div id="navbar" class="navbar-collapse collapse">
        <form class="navbar-form navbar-left profile-search" role="search">
          <div class="form-group has-feedback">
            <input id="search_input" type="text" class="form-control ui-autocomplete-input" placeholder="Search ICLR 2019 Conference" autocomplete="off" />
            <span class="glyphicon glyphicon-search form-control-feedback" aria-hidden="true"></span>
          </div>
  
          <input id="search_group" type="hidden" value="ICLR.cc/2019/Conference" />
          <input id="search_content" type="hidden" value="all" />
        <ul id="ui-id-1" tabindex="0" class="ui-menu ui-widget ui-widget-content ui-autocomplete ui-front" style="display: none;"></ul></form>
  
        <ul class="nav navbar-nav navbar-right">
        
            <li id="user-menu"><a href="/login">Login</a></li>
        </ul>
      </div>
  
    </div>
  </nav>

  <div id="or-banner" class="banner" style="">
  <div class="container">
    <div class="row">
      <div class="col-xs-12"><a href="/group?id=ICLR.cc/2019/Conference" title="Venue Homepage"><img class="icon" src="/static/images/arrow_left.svg" /> Go to <strong>ICLR 2019 Conference</strong> homepage</a></div>
    </div>
  </div>
</div>
<div id="flash-message-container" class="alert alert-danger" role="alert" style="display: none;">
  <div class="container">
    <div class="row">
      <div class="col-xs-12">
        <div class="alert-content">
          <button type="button" class="close" aria-label="Close"><span aria-hidden="true">Ã—</span></button>
        </div>
      </div>
    </div>
  </div>
</div>

<div class="container">
  <div class="row">
    <div class="col-xs-12">
      <main id="content" class="clearfix openbanner-visible legacy-styles"><div id="note_r1e-nj05FQ" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Evolving intrinsic motivations for altruistic behavior</a> <a class="note_content_pdf" href="/pdf?id=r1e-nj05FQ" title="Download PDF" target="_blank"><img src="/static/images/pdf_icon_blue.svg" /></a> </h2></div><div class="meta_row"><span class="signatures"><a href="/profile?email=wangjane%40google.com" class="profile-link" data-toggle="tooltip" data-placement="bottom" title="" data-original-title="wangjane@google.com">Jane X. Wang</a>, <a href="/profile?email=edwardhughes%40google.com" class="profile-link" data-toggle="tooltip" data-placement="bottom" title="" data-original-title="edwardhughes@google.com">Edward Hughes</a>, <a href="/profile?email=chrisantha%40google.com" class="profile-link" data-toggle="tooltip" data-placement="bottom" title="" data-original-title="chrisantha@google.com">Chrisantha Fernando</a>, <a href="/profile?email=lejlot%40google.com" class="profile-link" data-toggle="tooltip" data-placement="bottom" title="" data-original-title="lejlot@google.com">Wojciech M. Czarnecki</a>, <a href="/profile?email=duenez%40google.com" class="profile-link" data-toggle="tooltip" data-placement="bottom" title="" data-original-title="duenez@google.com">Edgar A. Duenez-Guzman</a>, <a href="/profile?email=jzl%40google.com" class="profile-link" data-toggle="tooltip" data-placement="bottom" title="" data-original-title="jzl@google.com">Joel Z. Leibo</a></span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">28 Sep 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Withdrawn Submission</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Abstract: </span><span class="note_content_value">Multi-agent cooperation is an important feature of the natural world. Many tasks involve individual incentives that are misaligned with the common good, yet a wide range of organisms from bacteria to insects and humans are able to overcome their differences and collaborate. Therefore, the emergence of cooperative behavior amongst self-interested individuals is an important question for the fields of multi-agent reinforcement learning (MARL) and evolutionary theory. Here, we study a particular class of multi-agent problems called intertemporal social dilemmas (ISDs), where the conflict between the individual and the group is particularly sharp. By combining MARL with appropriately structured natural selection, we demonstrate that individual inductive biases for cooperation can be learned in a model-free way. To achieve this, we introduce an innovative modular architecture for deep reinforcement learning agents which supports multi-level selection. We present results in two challenging environments, and interpret these in the context of cultural and ecological evolution.</span></div><div class="note_contents"><span class="note_content_field">Keywords: </span><span class="note_content_value">evolution, reinforcement learning, intrinsic reward, multi-agent, social dilemmas, cooperation</span></div><div class="note_contents"><span class="note_content_field">TL;DR: </span><span class="note_content_value">We introduce a biologically-inspired modular evolutionary algorithm in which deep RL agents learn to cooperate in a difficult multi-agent social game, which could help to explain the evolution of altruism.</span></div><div class="reply_row clearfix"><div class="item" id="reply_count">4 Replies</div></div></div><hr class="small" /><div id="note_children"><div class="note_with_children"><div id="note_Syx87aQ16Q" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Submission Withdrawn by the Authors</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=r1e-nj05FQ&amp;noteId=Syx87aQ16Q"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper683 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">06 Nov 2018</span><span class="item">ICLR 2019 Conference Paper683 Withdraw Submission</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Withdrawal confirmation: </span><span class="note_content_value">I have read and agree with the withdrawal statement on behalf of myself and my co-authors.</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_H1gQ4rKR2Q" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>A decent contribution but requires more focus.</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=r1e-nj05FQ&amp;noteId=H1gQ4rKR2Q"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper683 AnonReviewer2</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">06 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper683 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">The paper considers cooperative multiagent learning tasks with identical individual agents. To solve the dilemma between individual and social optimality, an additive internal reward function is evolved on a slower timescale than policy learning.  This slower task was carried out within the so-called PBT multiagent training environment using genetic algorithms. 

The paper relies heaviiy on evolutionary-related motivation and analogy, and hints at lessons that can be learned regarding the evolution of cooperation in wider contexts. As an RL  person, I must admit that I found this perspective too central and somewhat distractive of the essential algorithmic idea. As mentioned, the latter is to add an internal reward function, learned using the social reward as a fitness signal. 

The proposed scheme makes a number of specific choices of architecture and algorithms along the way, which make it hard to give full credibility to conclusions found regarding the effectiveness of different components. 

Some details of the implementation are not clear, such as the reference to stop-gradient after equation (3). Later on that page an LSTM network is mentioned, for which I did not find details. The appendix could give a more detailed description of the implementation.

Overall I found the presentation somewhat confusing, and not focused enough from the algorithmic learning perspective.
    


</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">5: Marginally below acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">3: The reviewer is fairly confident that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_r1l-TFPc27" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Review of Paper "Evolving intrinsic motivations for altruistic behavior"</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=r1e-nj05FQ&amp;noteId=r1l-TFPc27"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper683 AnonReviewer1</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">03 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper683 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">The paper describes an approach to develop a learning mechanism that shows the emergence of altruistic behaviour in public goods games across longer time scales. The essential idea is to combine principles of evolution that favour long-term behaviour with learning that focuses on the short term. 

To achieve this, individual social preferences are modelled as intrinsic motivations and combined with deep reinforcement learning to develop individualised reward structures. This approach is then combined in a training setup that evolves varying policies, from which agents are sampled based on scenario performance and subjected to further selection. Finally, individuals are then matched based on assortative matching, with the baseline configuration being randomised matching. 

The paper is well developed and systematically introduces the approach, along with an experimental evaluation and discussion. Moreover, the paper contributes to a challenging problem - the explanation of cooperative behaviour (more below). 

The quality of the writing is good, apart from some odd expressions on Page 7. The figures are of good quality and sufficiently legible. However, the time series would benefit from better contrast in order to unambiguously identify those when reading the printed paper (black &amp; white).

Some questions/comments:

One specific question relates to the calculation of cooperativeness in the Harvest scenario. In the current operationalisation the difference between the agent's return and the mean return value is the cooperativeness ranking, confusing poor performance and cooperative behaviour. Could you think of a better metric to disambiguate this interpretation?

Given the comprehensive evaluation of retrospective and prospective metrics, can you provide generalisable insights as to when you deem the use of prospective reward networks as useful, since they (mostly) perform worse than retrospective ones?

Overall, the paper tackles one of the most challenging problems of all - the explanation of cooperative behaviour. The combination of short-term learning and long-term evolutionary factors is a valuable exploration, which is we illustrated in this work. One more general question remains: can you really explain the basis of cooperative behaviour? The closest you get is the final discussion of the emerging weights, and extracting one of the insights that suggests reward if others are rewarded. While it is intuitively as well as scientifically accessible (e.g., as affective empathy), how do you substantiate that claim simply based on the weights?
</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">6: Marginally above acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_SJexVzN_3Q" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>The purpose and conclusion are unclear.  The validity of intrinsic reward is questionable.</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=r1e-nj05FQ&amp;noteId=SJexVzN_3Q"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper683 AnonReviewer3</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">01 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper683 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">The purpose and the conclusion of the paper are unclear.  Introduction emphasizes how cooperation emerges in nature.  The last sentence of the second paragraph states "the goal", but is this the goal of this paper or some others?  Does the paper tries to develop a model of multi-agent reinforcement learning (MARL) to provide theoretical or empirical underpinnings to how cooperation emerges in nature?  Is the paper simply motivated by nature and trying to develop a method of MARL that performs well?

The authors state that they apply evolution rater than hand-crafting intrinsic motivation, but it appears that intrinsic motivation is hand-crafted in the paper.  Specifically, in Section 2.2, intrinsic reward is defined through hand-crafted features of the other agents.

Furthermore, those hand-crafted features are based on recently received reward or expected future reward of those agents.  The intrinsic reward for an agent is essentially the reward of the other agents.  Then it is no surprising that the cooperation emerges, because each agent seeks to maximize the total reward of all agents.

If the agents have access to the reward of each other, and the purpose of the paper is to maximize the overall performance, why not just let each agent simply maximize the total reward?  If the purpose of the paper is to provide some underpinnings to the emergence of cooperation in nature, how this definition of intrinsic reward provide any underpinnings?

In addition, technical contributions of the paper are rather limited.  What are proposed include (a) two time scales for learning and evolution, (b) assortative matchmaking that let players of a similar kind play each other, and (c) shared reward network.  The novelty of each is limited.
</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">3: Clear rejection</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></main></div>
  </div>
</div>


    <!-- Footer -->
    <footer class="sitemap">
      <div class="container">
        <div class="row hidden-xs">
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/venues">All Venues</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="/contact">Contact</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
    
        <div class="row visible-xs-block">
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/contact">Contact</a></li>
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
      </div>
    </footer>
    
    <footer class="sponsor">
      <div class="container">
        <div class="row">
          <div class="col-sm-10 col-sm-offset-1">
            <p class="text-center">
              OpenReview is created by the <a href="http://www.iesl.cs.umass.edu/" target="_blank">Information Extraction and Synthesis Laboratory</a>, College of Information and Computer Science, University of Massachusetts Amherst. We gratefully acknowledge the support of the OpenReview sponsors:  Google,  Facebook, NSF, the University of Massachusetts Amherst Center for Data Science, and Center for Intelligent Information Retrieval, as well as the Google Cloud Platform for donating the computing and networking services on which OpenReview.net runs.
            </p>
          </div>
        </div>
      </div>
    </footer>

  <div id="feedback-modal" class="modal fade" tabindex="-1" role="dialog">
    <div class="modal-dialog">
      <div class="modal-content">
        <div class="modal-header">
          <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">Ã—</span></button>
          <h3 class="modal-title">Send Feedback</h3>
        </div>
        <div class="modal-body">
          <p>Enter your feedback below and we'll get back to you as soon as possible.</p>
          <form action="/feedback" method="POST">
            <div class="form-group">
              <input type="email" name="from" class="form-control" placeholder="Email" />
            </div>
            <div class="form-group">
              <input type="text" name="subject" class="form-control" placeholder="Subject" />
            </div>
            <div class="form-group">
              <textarea name="message" class="form-control feedback-input" rows="5" placeholder="Message" required=""></textarea>
            </div>
          <ul id="ui-id-2" tabindex="0" class="ui-menu ui-widget ui-widget-content" style="display: none;"></ul></form>
        </div>
        <div class="modal-footer">
          <button type="button" class="btn btn-default" data-dismiss="modal">Cancel</button>
          <button type="button" class="btn btn-primary">Send</button>
        </div>
      </div>
    </div>
  </div>

  <script type="text/javascript" async="" src="https://www.google-analytics.com/analytics.js"></script><script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js"></script>
  <script>window.jQuery || document.write('&lt;script src="/static/js/vendor/jquery-2.2.4.min.js"&gt;&lt;\/script&gt;')</script>

  <script src="/static/dist/vendor.min.js"></script>
  <script src="/static/dist/templates.min.js"></script>
  <script src="/static/dist/openreview.min.js"></script>

    <script>window.legacyScripts = true;</script>


    <script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-108703919-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() { dataLayer.push(arguments); }
      gtag('js', new Date());
      gtag('config', 'UA-108703919-1');
    </script>


<div role="status" aria-live="assertive" aria-relevant="additions" class="ui-helper-hidden-accessible"></div></body></html>
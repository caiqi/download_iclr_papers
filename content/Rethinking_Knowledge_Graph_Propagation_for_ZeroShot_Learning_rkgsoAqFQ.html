<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" class="no-js"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>Rethinking Knowledge Graph Propagation for Zero-Shot Learning | OpenReview</title>
  <meta name="description" content="" />

      <meta name="citation_title" content="Rethinking Knowledge Graph Propagation for Zero-Shot Learning" />
        <meta name="citation_author" content="Michael Kampffmeyer" />
        <meta name="citation_author" content="Yinbo Chen" />
        <meta name="citation_author" content="Xiaodan Liang" />
        <meta name="citation_author" content="Hao Wang" />
        <meta name="citation_author" content="Yujia Zhang" />
        <meta name="citation_author" content="Eric P. Xing" />
      <meta name="citation_publication_date" content="2018/09/27" />
      <meta name="citation_online_date" content="2018/09/27" />
      <meta name="citation_pdf_url" content="https://openreview.net/pdf?id=rkgs0oAqFQ" />
      <meta name="twitter:card" content="summary" />
      <meta name="twitter:site" content="@openreviewnet" />
      <meta name="og:title" content="Rethinking Knowledge Graph Propagation for Zero-Shot Learning" />
      <meta name="og:description" content="Graph convolutional neural networks have recently shown great potential for the task of zero-shot learning. These models are highly sample efficient as related concepts in the graph structure share..." />
      <meta name="og:image" content="https://openreview.net/static/images/openreview_logo_512.png" />

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans:400,400i,700,700i" />

  <link rel="stylesheet" href="/static/css/bootstrap.min.css" />
  <link rel="stylesheet" href="/static/css/jquery-ui.min.css" />
  <link rel="stylesheet" href="/static/css/main.min.css" />
</head>

<body class="forum">
  <nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
  
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand home push-link" href="/"><strong>OpenReview</strong>.net</a>
      </div>
  
      <div id="navbar" class="navbar-collapse collapse">
        <form class="navbar-form navbar-left profile-search" role="search">
          <div class="form-group has-feedback">
            <input id="search_input" type="text" class="form-control ui-autocomplete-input" placeholder="Search ICLR 2019 Conference" autocomplete="off" />
            <span class="glyphicon glyphicon-search form-control-feedback" aria-hidden="true"></span>
          </div>
  
          <input id="search_group" type="hidden" value="ICLR.cc/2019/Conference" />
          <input id="search_content" type="hidden" value="all" />
        <ul id="ui-id-1" tabindex="0" class="ui-menu ui-widget ui-widget-content ui-autocomplete ui-front" style="display: none;"></ul></form>
  
        <ul class="nav navbar-nav navbar-right">
        
            <li id="user-menu"><a href="/login">Login</a></li>
        </ul>
      </div>
  
    </div>
  </nav>

  <div id="or-banner" class="banner" style="">
  <div class="container">
    <div class="row">
      <div class="col-xs-12"><a href="/group?id=ICLR.cc/2019/Conference" title="Venue Homepage"><img class="icon" src="/static/images/arrow_left.svg" /> Go to <strong>ICLR 2019 Conference</strong> homepage</a></div>
    </div>
  </div>
</div>
<div id="flash-message-container" class="alert alert-danger" role="alert" style="display: none;">
  <div class="container">
    <div class="row">
      <div class="col-xs-12">
        <div class="alert-content">
          <button type="button" class="close" aria-label="Close"><span aria-hidden="true">Ã—</span></button>
        </div>
      </div>
    </div>
  </div>
</div>

<div class="container">
  <div class="row">
    <div class="col-xs-12">
      <main id="content" class="clearfix openbanner-visible legacy-styles"><div id="note_rkgs0oAqFQ" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Rethinking Knowledge Graph Propagation for Zero-Shot Learning</a> <a class="note_content_pdf" href="/pdf?id=rkgs0oAqFQ" title="Download PDF" target="_blank"><img src="/static/images/pdf_icon_blue.svg" /></a> </h2></div><div class="meta_row"><span class="signatures"><a href="/profile?email=michael.c.kampffmeyer%40uit.no" class="profile-link" data-toggle="tooltip" data-placement="bottom" title="" data-original-title="michael.c.kampffmeyer@uit.no">Michael Kampffmeyer</a>, <a href="/profile?email=cyvius96%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="bottom" title="" data-original-title="cyvius96@gmail.com">Yinbo Chen</a>, <a href="/profile?email=xdliang328%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="bottom" title="" data-original-title="xdliang328@gmail.com">Xiaodan Liang</a>, <a href="/profile?email=hwang87%40mit.edu" class="profile-link" data-toggle="tooltip" data-placement="bottom" title="" data-original-title="hwang87@mit.edu">Hao Wang</a>, <a href="/profile?email=zhangyujia2014%40ia.ac.cn" class="profile-link" data-toggle="tooltip" data-placement="bottom" title="" data-original-title="zhangyujia2014@ia.ac.cn">Yujia Zhang</a>, <a href="/profile?email=epxing%40cs.cmu.edu" class="profile-link" data-toggle="tooltip" data-placement="bottom" title="" data-original-title="epxing@cs.cmu.edu">Eric P. Xing</a></span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">28 Sep 2018 (modified: 20 Nov 2018)</span><span class="item">ICLR 2019 Conference Withdrawn Submission</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Abstract: </span><span class="note_content_value">Graph convolutional neural networks have recently shown great potential for the task of zero-shot learning. These models are highly sample efficient as related concepts in the graph structure share statistical strength allowing generalization to new classes when faced with a lack of data. However, we find that the extensive use of Laplacian smoothing at each layer in current approaches can easily dilute the knowledge from distant nodes and consequently decrease the performance in zero-shot learning. In order to still enjoy the benefit brought by the graph structure while preventing the dilution of knowledge from distant nodes, we propose a Dense Graph Propagation (DGP) module with carefully designed direct links among distant nodes. DGP allows us to exploit the hierarchical graph structure of the knowledge graph through additional connections. These connections are added based on a node's relationship to its ancestors and descendants. A weighting scheme is further used to weigh their contribution depending on the distance to the node. Combined with finetuning of the representations in a two-stage training approach our method outperforms state-of-the-art zero-shot learning approaches.</span></div><div class="note_contents"><span class="note_content_field">Keywords: </span><span class="note_content_value">Dense graph propagation, zero-shot learning</span></div><div class="note_contents"><span class="note_content_field">TL;DR: </span><span class="note_content_value">We rethink the way information can be exploited more efficiently in the knowledge graph in order to improve performance on the Zero-Shot Learning task and propose a dense graph propagation (DGP) module for this purpose.</span></div><div class="reply_row clearfix"><div class="item" id="reply_count">7 Replies</div></div></div><hr class="small" /><div id="note_children"><div class="note_with_children"><div id="note_r1etzXgRa7" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Submission Withdrawn by the Authors</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=rkgs0oAqFQ&amp;noteId=r1etzXgRa7"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper928 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">18 Nov 2018</span><span class="item">ICLR 2019 Conference Paper928 Withdraw Submission</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Withdrawal confirmation: </span><span class="note_content_value">I have read and agree with the withdrawal statement on behalf of myself and my co-authors.</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_BklDE8I5n7" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Simple solution, large improvements.</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=rkgs0oAqFQ&amp;noteId=BklDE8I5n7"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper928 AnonReviewer2</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">03 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper928 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">This authors propose a solution to the problem of over-smoothing in Graph conv networks that prevents knowledge propagation between distant yet related nodes. Specifically, they allow dense propagation between all related nodes, weighted by the mutual distance. Dense connections ensure influence of related nodes and distance weighting moderates this influence based on proximity of nodes. The scheme is used for knowledge graph based zero-shot learning. Like Wang et. al. 2018, their model learns to predict pre-trained weights of known classifiers and infer, using the knowledge graph, weights for unseen classes.  The simple fix to graph propagation seems to produce large gains over zero-shot baselines (Table 1 &amp; 2). I think the solution is intuitive and results are really good. Therefor, I am in favor of accepting. </span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">7: Good paper, accept</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_SygfA0yC6Q" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Response to Reviewer 2</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=rkgs0oAqFQ&amp;noteId=SygfA0yC6Q"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper928 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">18 Nov 2018</span><span class="item">ICLR 2019 Conference Paper928 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Dear Reviewer 2. Thank you for your positive feedback.</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div><div class="note_with_children"><div id="note_ryxS_ZXEnX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Not self-contained paper.</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=rkgs0oAqFQ&amp;noteId=ryxS_ZXEnX"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper928 AnonReviewer1</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">29 Oct 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper928 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">This paper proposes a novel graph convolutional neural network to tackle the problem of zero-shot classification. To learn the classifier of unseen classes, the relational structure between classes are used as the input of graph convolutional network (GCN). And then the model imposes the output of GCN to be weights of a classifier learned from a supervised classification model such as ResNet, in the hope of having a good classifier for unseen classes while fitting the known classes.

Overall, the paper is not self-contained. It is almost impossible to understand the overall architecture without prerequisites (GCNZ paper in this context). The description of each module is relatively clear, however, it fails to give an overall connection between different modules used in the proposed paper. For example, it has never been described what would be the input feature of the GCN or DGP modules (such as the number of nodes should be the same as the number of all classes). There is no explanation why the output of GCN should resemble the final weight of the ResNet, and what this means to solve the zero-shot learning problem, and eventually how the knowledge graph would help to solve the problem of zero-shot learning. I personally found the answers to these important questions from the description in GCNZ paper. Therefore, although the model improves the performance of the previous work, I don't think it is publishable in its current condition.

- Missed some of recent work. Recent papers [1,2] incorporates attention mechanism to deal with the potential dilution in GCN. Although DGP uses different weighting based on the distance from a node, the attention mechanism is clearly more expressive than the distant-wise weighting used in this paper.
- Section 3.5 should be in the experiments section since it describes the details of experiments.

[1] W.L. Hamilton, R. Ying, and J. Leskovec. Inductive representation learning on large graphs. arXiv preprint,
arXiv:1603.04467, 2017.
[2] Velickovic, P., Cucurull, G., Casanova, A., Romero, A., Lio, P., &amp; Bengio, Y. (2017). Graph attention networks. arXiv preprint arXiv:1710.10903, 1(2).
</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">5: Marginally below acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">3: The reviewer is fairly confident that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_SJl4kWxCaX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Response to Reviewer 1</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=rkgs0oAqFQ&amp;noteId=SJl4kWxCaX"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper928 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">18 Nov 2018</span><span class="item">ICLR 2019 Conference Paper928 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Dear Reviewer 1. Thank you for your comments. 

1) We will update the description of our model in order to clarify the overall architecture, input feature, and why the output of the GCN should resemble the final weight of the ResNet. We will further clarify how this solves the zero-shot learning problem, and how the knowledge graph would help to solve the problem of zero-shot learning.
Section 3.2 will start with the following improved description of the overall architecture presented in Figure 2:
Our zero-shot learning framework to address this task is illustrated in Figure 2. The last layer CNN weights are interpreted as a class-specific classifier for a given output class on top of the extracted CNN features. The zero-shot task can then be expressed as learning a new set of weights for each of the unseen classes in order to extend the output layer of the CNN. Our DGP takes as an input the combined knowledge graph for all seen and unseen classes where each class is represented by a word embedding vector that encodes the class name. It is then trained to predict the last layer CNN weights for all (seen and unseen) classes in a semi-supervised manner. Utilizing the knowledge graph for the prediction allows us to capture semantic relationships between classes, while the word embedding provides a semantic description of each specific class. During the inference phase, the predicted weights can then be used to extend the set of output classes in the original CNN by using the predicted weights in order to enable it to classify datapoints to unseen classes.

2) Thank you for pointing out that our paper would benefit from explicitly mentioning the link to attention. We will add at the end of Section 3.3:
Our proposed weighting scheme is related to recent advances of introducing attention mechanisms to graph convolutional neural networks (Velickovic et al. 2018). However, unlike attention approaches, our weighting scheme adds only a negligible amount of additional parameters and does not add the potentially considerable memory overhead of attention approaches. Further, in our zero-shot learning setting, we observed a drop in performance when including attention approaches and we hypothesize that this is due to fact that a more complex model will be more prone to overfit given the limited amount of labeled data (sparsely labeled graph).

3) We will move the training details to the experiment section (Section 4.1).</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div><div class="note_with_children"><div id="note_rJgkxwPJ27" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>The motivation is not well justified</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=rkgs0oAqFQ&amp;noteId=rJgkxwPJ27"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper928 AnonReviewer3</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">25 Oct 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper928 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">This paper uses a collection of methods (with minor improvements) to obtain good prediction performance on ImageNet-subset data. I sincerely recommend authors improving the paper's quality by offering more analysis and insights of their method.

1. Could authors add more experiments on explaining their motivations?
- The big motivation to their work is "feature representations will become more similar as depth increases leading to easier classification" (in the introduction). However, this is only supported with results in a small table in Appendix. C.
- It is better to show results directly based on GCNZ, and then results on SGCN. 
- It seems that the performance in Table 6 and 1 (hop 2) are not consistent. Are there any reasons for this?
- Except for accuracy, could author design some other measurement to evaluate the smoothness of the embedding in deeper layers? (perhaps t-SNE as Wang etal 2018).
- All the above will make the paper sound more principle and better motivated. Currently, the motivation is not well justified.

2. "Rethinking" indicates in-depth analysis of existing works, based on Q1, I suggest the author changes their title as well.

3. The connections to ancestors and descendants look tricky. Are there any insight reasons for connecting and training in this way?
- Specifically, the connectivity patterns in the graph is very complex. The authors have also said there can be DAG in the graph, so, why should we connect in this way?

4. Can the proposed method be used on other kinds of data sets except those from the image domain?

5. The motivation in this paper is inconsistent with experiments in Wang et al 2018. Wang has shown in Section:"how important is the depth of GCN" &amp; Table 4 that the model performance increasing with the depth of layers. So, could the authors repeat the same experiments on NELL &amp; NEIL? This will make the motivation more convincing.</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">5: Marginally below acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_rylqfzeCT7" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Response to Reviewer 3</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=rkgs0oAqFQ&amp;noteId=rylqfzeCT7"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper928 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">18 Nov 2018</span><span class="item">ICLR 2019 Conference Paper928 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Dear Reviewer 3. Thank you for your constructive comments.

1. 
- Thank you for pointing out that the motivation might not have been clear enough in the original submission. In Appendix C we only include a small study because our conclusion is derived from theoretical analysis. We will update Section 3.2 to include:
The Laplacian smoothing operation in matrix form can be written as $(I-\gamma D^{-1}L)H$, as also noted in Li et al. (2018). Substituting the graph Laplacian with its definition $L=D-A$ the operation simplifies for $\gamma=1$ (looking only at the immediate neighbors) to $D^{-1}AH$. This corresponds to the first part of the update rule in Equation~(1) meaning that the complete update rule is thus a smoothing operating followed by a matrix multiplication with the weights $\Theta^{(l)}$, which can be interpreted as a fully connected layer. Thus, repeatedly applying the update rule in Equation~(1) will lead to repeatedly applying Laplacian smoothing, thus diluting the information. 

- It is better to show results directly based on GCNZ, and then results on SGCN.
Appendix D shows the transition from GCNZ to SGCN illustrating all the modifications that have been made.

- It seems that the performance in Table 6 and 1 (hop 2) are not consistent. Are there any reasons for this?
Thank you for indicating that this can cause confusion. The results in Table 6 are for the non-finetuned version of SGCN while the results in Table 1 are for the finetuned version of SGCN. We will state this explicitly in the updated version.

3. We designed it so that that it allows all nodes to communicate with each other within two propagation steps. Another advantage of this connection scheme is that it is not very complex as ancestors and descendants are well defined in a DAG due to the direction of the edges.

4. Indeed, the proposed method can be used for other kinds of data sets. The only requirement is that we have a DAG that describes meaningful relations between classes and some form of semantic representation of each class (for example the word embedding). Non-image data could be considered by replacing the pre-trained CNN with a pre-trained fully connected network.

5. Our motivation of focusing on the ImageNet dataset is that it is a commonly used large-scale benchmark dataset for zero-shot learning that, most importantly, is openly available to allow reproducibility. We want to stress that there is a fundamental difference in our experimental setting and the study in Wang et al 2018 as their ablation study does not only modify the number of layers in the network but at the same time the number of neurons per layer. Their 2-layer (one hidden layer) model has 512 neurons, the 4-layer (three hidden layer) one uses a 2048-1024-512 setup and the 6-layer (five hidden layer) setup is 2048-2048-1024-1024-512. In our study in Appendix C we instead keep the number of neurons in the hidden layer constant to avoid the effects that varying the number of nodes introduces.</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div></div></main></div>
  </div>
</div>


    <!-- Footer -->
    <footer class="sitemap">
      <div class="container">
        <div class="row hidden-xs">
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/venues">All Venues</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="/contact">Contact</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
    
        <div class="row visible-xs-block">
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/contact">Contact</a></li>
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
      </div>
    </footer>
    
    <footer class="sponsor">
      <div class="container">
        <div class="row">
          <div class="col-sm-10 col-sm-offset-1">
            <p class="text-center">
              OpenReview is created by the <a href="http://www.iesl.cs.umass.edu/" target="_blank">Information Extraction and Synthesis Laboratory</a>, College of Information and Computer Science, University of Massachusetts Amherst. We gratefully acknowledge the support of the OpenReview sponsors:  Google,  Facebook, NSF, the University of Massachusetts Amherst Center for Data Science, and Center for Intelligent Information Retrieval, as well as the Google Cloud Platform for donating the computing and networking services on which OpenReview.net runs.
            </p>
          </div>
        </div>
      </div>
    </footer>

  <div id="feedback-modal" class="modal fade" tabindex="-1" role="dialog">
    <div class="modal-dialog">
      <div class="modal-content">
        <div class="modal-header">
          <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">Ã—</span></button>
          <h3 class="modal-title">Send Feedback</h3>
        </div>
        <div class="modal-body">
          <p>Enter your feedback below and we'll get back to you as soon as possible.</p>
          <form action="/feedback" method="POST">
            <div class="form-group">
              <input type="email" name="from" class="form-control" placeholder="Email" />
            </div>
            <div class="form-group">
              <input type="text" name="subject" class="form-control" placeholder="Subject" />
            </div>
            <div class="form-group">
              <textarea name="message" class="form-control feedback-input" rows="5" placeholder="Message" required=""></textarea>
            </div>
          <ul id="ui-id-2" tabindex="0" class="ui-menu ui-widget ui-widget-content" style="display: none;"></ul></form>
        </div>
        <div class="modal-footer">
          <button type="button" class="btn btn-default" data-dismiss="modal">Cancel</button>
          <button type="button" class="btn btn-primary">Send</button>
        </div>
      </div>
    </div>
  </div>

  <script type="text/javascript" async="" src="https://www.google-analytics.com/analytics.js"></script><script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js"></script>
  <script>window.jQuery || document.write('&lt;script src="/static/js/vendor/jquery-2.2.4.min.js"&gt;&lt;\/script&gt;')</script>

  <script src="/static/dist/vendor.min.js"></script>
  <script src="/static/dist/templates.min.js"></script>
  <script src="/static/dist/openreview.min.js"></script>

    <script>window.legacyScripts = true;</script>


    <script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-108703919-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() { dataLayer.push(arguments); }
      gtag('js', new Date());
      gtag('config', 'UA-108703919-1');
    </script>


<div role="status" aria-live="assertive" aria-relevant="additions" class="ui-helper-hidden-accessible"></div></body></html>
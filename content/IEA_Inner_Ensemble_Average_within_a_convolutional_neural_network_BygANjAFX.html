<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" class="no-js"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>IEA: Inner Ensemble Average within a convolutional neural network | OpenReview</title>
  <meta name="description" content="" />

      <meta name="citation_title" content="IEA: Inner Ensemble Average within a convolutional neural network" />
        <meta name="citation_author" content="Anonymous" />
      <meta name="citation_publication_date" content="2018/09/27" />
      <meta name="citation_online_date" content="2018/09/27" />
      <meta name="citation_pdf_url" content="https://openreview.net/pdf?id=BygANjA5FX" />
      <meta name="twitter:card" content="summary" />
      <meta name="twitter:site" content="@openreviewnet" />
      <meta name="og:title" content="IEA: Inner Ensemble Average within a convolutional neural network" />
      <meta name="og:description" content="Ensemble learning is a method of combining multiple trained models to improve the model accuracy. We introduce the usage of such methods, specifically ensemble average inside Convolutional Neural..." />
      <meta name="og:image" content="https://openreview.net/static/images/openreview_logo_512.png" />

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans:400,400i,700,700i" />

  <link rel="stylesheet" href="/static/css/bootstrap.min.css" />
  <link rel="stylesheet" href="/static/css/jquery-ui.min.css" />
  <link rel="stylesheet" href="/static/css/main.min.css" />
</head>

<body class="forum">
  <nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
  
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand home push-link" href="/"><strong>OpenReview</strong>.net</a>
      </div>
  
      <div id="navbar" class="navbar-collapse collapse">
        <form class="navbar-form navbar-left profile-search" role="search">
          <div class="form-group has-feedback">
            <input id="search_input" type="text" class="form-control ui-autocomplete-input" placeholder="Search ICLR 2019 Conference" autocomplete="off" />
            <span class="glyphicon glyphicon-search form-control-feedback" aria-hidden="true"></span>
          </div>
  
          <input id="search_group" type="hidden" value="ICLR.cc/2019/Conference" />
          <input id="search_content" type="hidden" value="all" />
        <ul id="ui-id-1" tabindex="0" class="ui-menu ui-widget ui-widget-content ui-autocomplete ui-front" style="display: none;"></ul></form>
  
        <ul class="nav navbar-nav navbar-right">
        
            <li id="user-menu"><a href="/login">Login</a></li>
        </ul>
      </div>
  
    </div>
  </nav>

  <div id="or-banner" class="banner" style="">
  <div class="container">
    <div class="row">
      <div class="col-xs-12"><a href="/group?id=ICLR.cc/2019/Conference" title="Venue Homepage"><img class="icon" src="/static/images/arrow_left.svg" /> Go to <strong>ICLR 2019 Conference</strong> homepage</a></div>
    </div>
  </div>
</div>
<div id="flash-message-container" class="alert alert-danger" role="alert" style="display: none;">
  <div class="container">
    <div class="row">
      <div class="col-xs-12">
        <div class="alert-content">
          <button type="button" class="close" aria-label="Close"><span aria-hidden="true">×</span></button>
        </div>
      </div>
    </div>
  </div>
</div>

<div class="container">
  <div class="row">
    <div class="col-xs-12">
      <main id="content" class="clearfix openbanner-visible legacy-styles"><div id="note_BygANjA5FX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>IEA: Inner Ensemble Average within a convolutional neural network</a> <a class="note_content_pdf" href="/pdf?id=BygANjA5FX" title="Download PDF" target="_blank"><img src="/static/images/pdf_icon_blue.svg" /></a> </h2></div><div class="meta_row"><span class="signatures">Anonymous</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">28 Sep 2018 (modified: 11 Oct 2018)</span><span class="item">ICLR 2019 Conference Blind Submission</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span><span class="item"><a class="action-bibtex-modal" data-bibtex="@inproceedings{    &#10;anonymous2019iea:,    &#10;title={IEA: Inner Ensemble Average within a convolutional neural network},    &#10;author={Anonymous},    &#10;booktitle={Submitted to International Conference on Learning Representations},    &#10;year={2019},    &#10;url={https://openreview.net/forum?id=BygANjA5FX},    &#10;note={under review}    &#10;}">Show Bibtex</a></span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Abstract: </span><span class="note_content_value">Ensemble learning is a method of combining multiple trained models to improve the model accuracy. We introduce the usage of such methods, specifically ensemble average inside Convolutional Neural Networks (CNNs) architectures. By Inner Average Ensemble (IEA) of multiple convolutional neural layers (CNLs) replacing the single CNL inside the CNN architecture, the accuracy of the CNN increased. A visual and a similarity score analysis of the features generated from IEA explains why it boosts the model performance. Empirical results using different benchmarking datasets and well-known deep model architectures shows that IEA outperforms the ordinary CNL used in CNNs.</span></div><div class="note_contents"><span class="note_content_field">Keywords: </span><span class="note_content_value">Ensemble Convolutional Neural Networks</span></div><div class="note_contents"><span class="note_content_field">TL;DR: </span><span class="note_content_value">We inner ensemble the features of a convolutional neural layer, it increases the network accuracy and generates distinct features.</span></div><div class="reply_row clearfix"><div class="item" id="reply_count">3 Replies</div></div></div><hr class="small" /><div id="note_children"><div class="note_with_children"><div id="note_BkgksQPZ6m" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>A number of missing comparisons, needs stronger empirical results</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=BygANjA5FX&amp;noteId=BkgksQPZ6m"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper48 AnonReviewer4</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">08 Nov 2018</span><span class="item">ICLR 2019 Conference Paper48 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">IEA proposes to use multiple "parallel" convolution groups, which are then averaged to improve performance.

This fundamental idea of ensembles combined with simple functions has been explored in detail in Maxout (Goodfellow et.  al., <a href="https://arxiv.org/abs/1302.4389)" target="_blank" rel="nofollow">https://arxiv.org/abs/1302.4389)</a> in the context of learning activation functions, and greater integration with dropout regularization.

Under the lens of comparison to Maxout (which should be cited, and is a key comparison point for this work), a number of questions emerge. Does IEA also work for feedforward layers? Does IEA give any performance improvement or have some fundamental synergy with the regularizers used here? Is the performance boost greater than simply using an ensemble of m networks directly (resulting in the equivalent number of parameters overall)? The choice of the mean here seems insufficient for creating the types of complexity in activation which are normally desirable for neural networks, so some description of why a simple mean is a good choice would be beneficial since many, many other functions are possible.

Crucially Maxout seems much too close to this work, and I would like to see an indepth comparison (since it appears to be use of mean() instead of max() is the primary difference). I would also significantly reduce the claims of novelty, such as "We introduce the usage of such methods, specifically ensemble average inside Convolutional Neural Networks (CNNs) architectures." in the abstract, given that this is the exact idea explored in other work including followups to Maxout.

For example, MNIST performance here matches Maxout (.45% for both, but Maxout uses techniques known in 2013). CIFAR-10 results are better, but again Maxout first appeared 5 years ago. There are more recent followups that continued on the line of work first shown in Maxout, and there should be some greater comparison and literature review on these papers. The CIFAR-10 baseline numbers are not ideal, and since IEA is basically "plug and play" in existing architectures, starting from one of these settings instead (such as Wide ResNet https://arxiv.org/abs/1605.07146) and showing a boost would be a stronger indication that this method actually improves results. In addition, there are a number of non-image settings where CNNs are used (text or audio), and showing this idea works on multiple domains would also be good.

There seems to be a similarity between ResNet and this method - specifically assuming the residual pathway is convolution with an identity activation, the summation that combines the two pathways bears a similarity to IEA. With multiple combined paths (as in Dense ResNet) this equivalence seems stronger still. A discussion of this comparison in greater detail, or even derivation of IEA as a special setting or extension of ResNet (coupled with stronger performance on the datasets) would help ground the work in prior publication.

The section on visualization and inspection of IEA features seems interesting, but too brief. A greater exploration of this, and possible reduction or removal of the ensemble selection section (which didn't have a clear contribution to the message of the paper, in my opinion) would strengthen the work - and again, comparisons to activations learned by Maxout and followups would make this inspection much stronger.

My key concerns here are on relation to past work, greater comparison to closely related methods, and improvement of baselines results. Given the close similarity of this work to Maxout and others, a much stronger indication of the benefits and improvements of IEA seems necessary to prove out the concepts here.</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">4: Ok but not good enough - rejection</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">3: The reviewer is fairly confident that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_BygZMqts3Q" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Issues of clarity and comparison</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=BygANjA5FX&amp;noteId=BygZMqts3Q"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper48 AnonReviewer3</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">04 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper48 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">This work proposes an ensemble method for convolutional neural networks wherein each convolutional layer is replicated m times and the resulting activations are averaged layerwise.

There are a few issues that undermine the conclusion that this simple method is an improvement over full-model ensembles:
	1. Equation (1) is unclear on the definition of C_layer, a critical detail. In the context, C_layer could be weights, activations before the nonlinearity/pooling/batch-norm, or activations after the nonlinearity/pooling/batch-norm. Averaging only makes sense after some form of non-linearity, otherwise the “ensemble” is merely a linear operation, so hopefully it’s the latter.
	2. The headings in the results tables could be clarified. To be sure that I am understanding them correctly, I’ll propose a new notation here. Please note in the comments if I’ve misunderstood! Since “m” is used to represent the number of convolutional layer replications, let’s use “k” to represent the number of full model replications. So, instead of “CNL” and “IEA (ours)” in Table 1 and “Ensemble of models using CNL” and “Ensemble of models using IEA (ours)” in Table 2, I would recommend a single table with these headings: “(m=1, k=1)”,  “(m=3, k=1)”,  “(m=1, k=3)”,  and “(m=3, k=3)”, corresponding to the columns in Tables 1 and 2 in order. Likewise for Tables 3-6.
	3. Under this interpretation of the tables---again, correct me if I’m wrong---the proper comparison would be “IEA (ours)” versus “Ensemble of models using CNL”, or  “(m=3, k=1)” versus “(m=1, k=3)” in my notation. This pair share a similar amount of computation and a similar number of parameters. (The k=3 model would be slightly larger on account of any fully-connected layers.) In this case, the “outer ensemble” wins handily in 4 of 5 cases for CIFAR-10.
	4. The CNL results, or “(k=1,m=1)”, seem to not be state-of-the-art, adding more uncertainty to the evaluation. See, for instance, <a href="https://www.github.com/kuangliu/pytorch-cifar." target="_blank" rel="nofollow">https://www.github.com/kuangliu/pytorch-cifar.</a> Apologies that this isn’t a published table. A quick scan of the DenseNets paper and another didn’t yield a matching set of models. In any case, the lack of data augmentation may account for this disparity, but can easily be remedied.

Given the above issues of clarity and that this simple method seems to not make a favorable comparison to the comparable ensemble baseline (significance), I can’t recommend acceptance at this time. 

Other notes:
	* The wrong LaTeX citation function is used, yielding the “author (year)” form (produced by \citet), instead of “(author, year)” (produced by \citep), which seems to be intended. It’s possible that \cite defaults to \citet.
	* The acronyms CNL and FCL hurt the readability a bit. Since there is ample space available, spelling out “convolutional layer” and “fully-connected layer” would be preferred.
	* Other additions to the evaluation could or should include: a plot of test error vs. number of parameters/FLOPS/inference time; additional challenging datasets including CIFAR-100, SVHN, and ImageNet; and consideration of other ways to use additional parameters or computation, such as increased depth or width (perhaps the various depths of ResNet would be useful here).
</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">2: Strong rejection</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_ryx_iuvFnX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Review</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=BygANjA5FX&amp;noteId=ryx_iuvFnX"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper48 AnonReviewer1</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">02 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper48 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">This paper describes a new op: Inner Average Ensemble (IAE). This op is constructed by $m$ convolution ops followed by an averaging op. The author claims using this IAE op is able to improve CNN classification performance. The experiments include MNIST and CIFAR-10 with a few network structures. 

First of all, this new proposed op is not efficient. Replace a traditional conv layer with one IAE layer it will introduce $m$ times more parameters, while, the performance gain from the authors’ experiment is relatively small, which indicates, most learning capacity is wasted.

Secondly, only MNIST and CIFAR-10 is not convincing that this structure change will be widely useful.

Thirdly, this work is not practical to apply on real tasks, because it introduced $m - 1$ times more computation. 

Overall, I am not convinced this structure change meets innovation standard. 

</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">4: Ok but not good enough - rejection</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></main></div>
  </div>
</div>


    <!-- Footer -->
    <footer class="sitemap">
      <div class="container">
        <div class="row hidden-xs">
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/venues">All Venues</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="/contact">Contact</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
    
        <div class="row visible-xs-block">
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/contact">Contact</a></li>
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
      </div>
    </footer>
    
    <footer class="sponsor">
      <div class="container">
        <div class="row">
          <div class="col-sm-10 col-sm-offset-1">
            <p class="text-center">
              OpenReview is created by the <a href="http://www.iesl.cs.umass.edu/" target="_blank">Information Extraction and Synthesis Laboratory</a>, College of Information and Computer Science, University of Massachusetts Amherst. We gratefully acknowledge the support of the OpenReview sponsors:  Google,  Facebook, NSF, the University of Massachusetts Amherst Center for Data Science, and Center for Intelligent Information Retrieval, as well as the Google Cloud Platform for donating the computing and networking services on which OpenReview.net runs.
            </p>
          </div>
        </div>
      </div>
    </footer>

  <div id="feedback-modal" class="modal fade" tabindex="-1" role="dialog">
    <div class="modal-dialog">
      <div class="modal-content">
        <div class="modal-header">
          <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button>
          <h3 class="modal-title">Send Feedback</h3>
        </div>
        <div class="modal-body">
          <p>Enter your feedback below and we'll get back to you as soon as possible.</p>
          <form action="/feedback" method="POST">
            <div class="form-group">
              <input type="email" name="from" class="form-control" placeholder="Email" />
            </div>
            <div class="form-group">
              <input type="text" name="subject" class="form-control" placeholder="Subject" />
            </div>
            <div class="form-group">
              <textarea name="message" class="form-control feedback-input" rows="5" placeholder="Message" required=""></textarea>
            </div>
          <ul id="ui-id-2" tabindex="0" class="ui-menu ui-widget ui-widget-content" style="display: none;"></ul></form>
        </div>
        <div class="modal-footer">
          <button type="button" class="btn btn-default" data-dismiss="modal">Cancel</button>
          <button type="button" class="btn btn-primary">Send</button>
        </div>
      </div>
    </div>
  </div>

  <script type="text/javascript" async="" src="https://www.google-analytics.com/analytics.js"></script><script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js"></script>
  <script>window.jQuery || document.write('&lt;script src="/static/js/vendor/jquery-2.2.4.min.js"&gt;&lt;\/script&gt;')</script>

  <script src="/static/dist/vendor.min.js"></script>
  <script src="/static/dist/templates.min.js"></script>
  <script src="/static/dist/openreview.min.js"></script>

    <script>window.legacyScripts = true;</script>


    <script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-108703919-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() { dataLayer.push(arguments); }
      gtag('js', new Date());
      gtag('config', 'UA-108703919-1');
    </script>


<div role="status" aria-live="assertive" aria-relevant="additions" class="ui-helper-hidden-accessible"></div></body></html>
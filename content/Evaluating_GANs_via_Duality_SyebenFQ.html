<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" class="no-js"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>Evaluating GANs via Duality | OpenReview</title>
  <meta name="description" content="" />

      <meta name="citation_title" content="Evaluating GANs via Duality" />
        <meta name="citation_author" content="Anonymous" />
      <meta name="citation_publication_date" content="2018/09/27" />
      <meta name="citation_online_date" content="2018/09/27" />
      <meta name="citation_pdf_url" content="https://openreview.net/pdf?id=Syeben09FQ" />
      <meta name="twitter:card" content="summary" />
      <meta name="twitter:site" content="@openreviewnet" />
      <meta name="og:title" content="Evaluating GANs via Duality" />
      <meta name="og:description" content="Generative Adversarial Networks (GANs) have shown great results in accurately modeling complex distributions, but their training is known to be difficult due to instabilities caused by a..." />
      <meta name="og:image" content="https://openreview.net/static/images/openreview_logo_512.png" />

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans:400,400i,700,700i" />

  <link rel="stylesheet" href="/static/css/bootstrap.min.css" />
  <link rel="stylesheet" href="/static/css/jquery-ui.min.css" />
  <link rel="stylesheet" href="/static/css/main.min.css" />
</head>

<body class="forum">
  <nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
  
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand home push-link" href="/"><strong>OpenReview</strong>.net</a>
      </div>
  
      <div id="navbar" class="navbar-collapse collapse">
        <form class="navbar-form navbar-left profile-search" role="search">
          <div class="form-group has-feedback">
            <input id="search_input" type="text" class="form-control ui-autocomplete-input" placeholder="Search ICLR 2019 Conference" autocomplete="off" />
            <span class="glyphicon glyphicon-search form-control-feedback" aria-hidden="true"></span>
          </div>
  
          <input id="search_group" type="hidden" value="ICLR.cc/2019/Conference" />
          <input id="search_content" type="hidden" value="all" />
        <ul id="ui-id-1" tabindex="0" class="ui-menu ui-widget ui-widget-content ui-autocomplete ui-front" style="display: none;"></ul></form>
  
        <ul class="nav navbar-nav navbar-right">
        
            <li id="user-menu"><a href="/login">Login</a></li>
        </ul>
      </div>
  
    </div>
  </nav>

  <div id="or-banner" class="banner" style="">
  <div class="container">
    <div class="row">
      <div class="col-xs-12"><a href="/group?id=ICLR.cc/2019/Conference" title="Venue Homepage"><img class="icon" src="/static/images/arrow_left.svg" /> Go to <strong>ICLR 2019 Conference</strong> homepage</a></div>
    </div>
  </div>
</div>
<div id="flash-message-container" class="alert alert-danger" role="alert" style="display: none;">
  <div class="container">
    <div class="row">
      <div class="col-xs-12">
        <div class="alert-content">
          <button type="button" class="close" aria-label="Close"><span aria-hidden="true">×</span></button>
        </div>
      </div>
    </div>
  </div>
</div>

<div class="container">
  <div class="row">
    <div class="col-xs-12">
      <main id="content" class="clearfix openbanner-visible legacy-styles"><div id="note_Syeben09FQ" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Evaluating GANs via Duality</a> <a class="note_content_pdf" href="/pdf?id=Syeben09FQ" title="Download PDF" target="_blank"><img src="/static/images/pdf_icon_blue.svg" /></a> </h2></div><div class="meta_row"><span class="signatures">Anonymous</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">28 Sep 2018 (modified: 17 Nov 2018)</span><span class="item">ICLR 2019 Conference Blind Submission</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span><span class="item"><a class="action-bibtex-modal" data-bibtex="@inproceedings{    &#10;anonymous2019evaluating,    &#10;title={Evaluating GANs via Duality},    &#10;author={Anonymous},    &#10;booktitle={Submitted to International Conference on Learning Representations},    &#10;year={2019},    &#10;url={https://openreview.net/forum?id=Syeben09FQ},    &#10;note={under review}    &#10;}">Show Bibtex</a></span><a class="note_content_pdf item" href="/revisions?id=Syeben09FQ" target="_blank">Show Revisions</a></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Abstract: </span><span class="note_content_value">Generative Adversarial Networks (GANs) have shown great results in accurately modeling complex distributions, but their training is known to be difficult due to instabilities caused by a challenging minimax optimization problem. This is especially troublesome given the lack of an evaluation metric that can reliably detect non-convergent behaviors. We leverage the notion of duality gap from game theory in order to propose a novel convergence metric for GANs that has low computational cost. We verify the validity of the proposed metric for various test scenarios commonly used in the literature. </span></div><div class="note_contents"><span class="note_content_field">Keywords: </span><span class="note_content_value">Generative Adversarial Networks, GANs, game theory</span></div><div class="reply_row clearfix"><div class="item" id="reply_count">8 Replies</div></div></div><hr class="small" /><div id="note_children"><div class="note_with_children"><div id="note_H1gYbPGh3X" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Please justify the novelty and validation, and explain the computation details</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=Syeben09FQ&amp;noteId=H1gYbPGh3X"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1049 AnonReviewer1</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">04 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper1049 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">In this paper, the authors proposed the duality gap as the criterion for evaluating the training of GAN. To justify the proposed criterion, the authors designed empirical experiments on both synthetic and real-world datasets to demonstrate the ability of the duality gap for detecting divergence, mode collapse, sample equality, as well as the generalization to other application domains besides image generation. Comparing with the existing criteria, e.g., FID and INC, the duality gap shows better ability and computational efficiency. 


However, the paper ignores rich literatures in optimization that uses the duality gap as the criterion for characterizing the convergence of algorithms for min-max saddle point problem, e.g., [1]. In fact, in optimization community, using duality gap to screening the convergence on saddle point problem is a common knowledge. [1] even provides the finite-step convergence rate when the saddle point problem is convex-concave. This paper is only introducing that into machine learning community. Therefore, the novelty of the paper seems not enough. 

Secondly, the duality gap is only able to screen the optimization convergence and the solution quality w.r.t. **the same objective**. It is not valid to compare different GANs with different losses function using the duality gap. Theoretically, for any loss function derived from some divergences, e.g. [2], the global optimal solution  can always achieve zero duality gap. In other words, for different GANs, with different objectives, the duality gap cannot distinguish which one is better. In such sense, the title is very misleading. 

Thirdly, how the evaluate such criterion in practice in GAN scenario is not clearly explained. Considering the neural network parametrization of both the generator and discriminator, the argmax_v M(u, v) and argmin_u M(u, v) is not tractable. Without the optimal solution, what is the meaning of the ``duality gap'' should be explained. What will happen if we only obtain the suboptimal solutions which themselves are model collapsed? Without such discussion in both theoretical and/or empirical aspects, I am not very convincing about the conclusion. 

Finally, if one follows the Fenchel dual view of GAN in [2, 3], the min-max is the variational form of some divergences, which the GANs are directly optimizing. It is straightforwardly to see the better min-max value is, the smaller divergence between generated samples and ground-truth is, and thus, the better quality of the generator is. The fact that min-max objective is indeed able to characterize the quality of generator is obvious and well-known. Otherwise, there is not need to use such objective in the optimization to train the model. 


[1] Nemirovski, A., Juditsky, A., Lan, G., and Shapiro, A. (2009). Robust stochastic approximation approach to stochastic programming. SIAM J. on Optimization, 19(4):1574–1609.

[2]  I. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley, S. Ozair, A. Courville, and Y. Bengio. Generative adversarial nets. In Advances in Neural Information Processing Systems (NIPS), pages 2672–2680, 2014.

[3] S. Nowozin, B. Cseke, and R. Tomioka. f-gan: Training generative neural samplers using variational divergence minimization. arXiv:1606.00709, 2016</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">4: Ok but not good enough - rejection</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">3: The reviewer is fairly confident that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_HJearNF36X" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>[Part 1/2] An important open issue in GANs is the lack of a convergence metric: We introduce the duality gap to GANs and show how to compute and use it efficiently in practice </a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=Syeben09FQ&amp;noteId=HJearNF36X"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1049 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">17 Nov 2018</span><span class="item">ICLR 2019 Conference Paper1049 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">We thank the reviewer for the thoughtful comments. In the following we address their concerns and questions:

1. “Please justify the novelty and validity”
First, we would like to emphasize that the lack of a convergence metric for GANs is an open issue in the community. As discussed in the introduction, the need for such a metric is crucial and affects several important aspects such as:

- *Convergence analysis*. Over the past years, GANs have been the subject of intense research in the community, giving rise to a plethora of GAN models as well as training methods. In practice, it has been observed that GANs might not converge under certain settings. While this non-convergence behavior can in practice be visually recognized for some low-dimensional examples (such as a 2D mixture of Gaussian), this is in general more difficult in high-dimensional spaces due to the lack of a convergence metric. This problem is actually often discussed in the litterature, see e.g. Mescheder et al. [ICML 2018]: “Measuring convergence for GANs is hard for high dimensional problems, because we lack a metric that can reliably detect non-convergent behavior. We therefore first examine the behavior [...] on simple 2D examples where we can assess convergence using an estimate of the Wasserstein-1-distance.” [1]
- *Stopping criteria and meaningful curve*. GANs are known to be hard to train in practice [2]. One of the common challenges practitioners are facing is when to stop training. See for example [3]: “GAN foundations: cons: Unclear stopping criteria”. In particular, it is well known that the curves of the discriminator and generator losses oscillate and are non-informative as to whether the model is improving or not (See Fig. 12 and 13). This is especially troublesome when a GAN is trained on non-image data in which case one might not be able to use visual inspection or FID/Inception score as a proxy.
- *Domain-independent evaluation metric*. Commonly used evaluation metrics such as FID and Inception Score are mainly suitable for natural images as they rely on a pretrained Imagenet classifier. This is also a problem that is commonly discussed in the literature, see e.g. [4]: “Generative adversarial networks are a promising [...] that has so far been held back by unstable training and by the lack of a proper evaluation metric.”. Instead the metric suggested in the paper is does not require any specific type of data and was for example shown empirically to generalize to cosmological data.

Hence, the metric we propose is a more generic tool that can serve as a) a monitoring tool to help practitioners throughout training, b) a domain-independent metric that can help spread the use of GANs to non-image domains.

The duality gap (DG) and the minimax value are natural metrics for this, as they are well known to capture exactly that. As rightfully pointed out by the reviewer, the duality gap is a well-known notion in optimization and our contribution is its introduction as a metric for GANs. An important aspect we discuss in the paper is with regard to an efficient way to estimate the duality gap without slowing down training. Note that although the two metrics may seem “too natural” from an optimization point of view, they are simply **not** used in the community, despite the need for them as we discussed earlier.
See for example Salimans et al: “Generative adversarial networks lack an objective function, which makes it difficult to compare performance of different models.” [4] and “GAN optimization challenges: No robust stopping criteria in practice (unlike likelihood based learning)” [5]. In this work, we argue that such a metric does exist and it indeed comes naturally from the objective function. This is also what our experiments demonstrate.

2. “The paper ignores rich literatures in optimization...”
Yes, we do agree, but note that (to the best of our knowledge) almost all the existing literature focuses on solving minimax problems with convex-concave objectives and therefore existing proof guarantees do not apply to GANs. Our contribution does not relate to optimising GANs, but instead in showing that the duality gap can be empirically computed and yields good estimates of the convergence of a GAN. We revised the text to clearly emphasize this and also included the suggested reference. 
</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_HkeCF4Y3a7" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>[Part 2/2] An important open issue in GANs is the lack of a convergence metric: We introduce the duality gap to GANs and show how to compute and use it efficiently in practice</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=Syeben09FQ&amp;noteId=HkeCF4Y3a7"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1049 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">17 Nov 2018</span><span class="item">ICLR 2019 Conference Paper1049 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">3.  “...DG is only able to screen the optimization convergence and the solution quality w.r.t. the same objective…”
Yes, we did discuss this aspect in the conclusion. Note that convergence curves could potentially be normalized but this requires further investigation that we plan on doing as a future work. Given a fixed objective, the DG yields a curve that can be used for: debugging, hyperparameter tuning, understanding whether the model has converged or whether it suffers from stable or unstable collapse, and of course, as mentioned earlier, it serves as a stopping criterion.

Further, a recent interest in the field is to understand which regularizer stabilizes GAN training by keeping the objective fixed and changing the regularizer [1, 6, 7]. This is yet another example where the DG would be meaningful for exactly examining the effect of the regularizer on top of a meaningful curve. Hence, the metric, as is, is useful both in practice and for pushing the research efforts forward. 

4. “how to evaluate such criterion in practice in GAN?”
Please refer to Section 4 “Estimating the DG metric for GANs”, where we explain the details of the practical computation. We also include some subtleties on how to accurately use train/val/test set in order to get an unbiased estimate for the estimation of the DG for GANs.
“Without the optimal solution, what is the meaning of the ``duality gap'' should be explained. (theory/empirical) What will happen if we only obtain the suboptimal solutions which themselves are model collapsed?”. 
Thank you for raising this point. We added a section to the appendix addressing this question. Both theoretically and empirically we analyse how the suboptimality of the solution affects its quality. In particular, we focus on (a) the case where the worst generator used for the computation of the maxmin of DG is itself collapsed, and (b) investigate how the number of optimization steps affects the solution. In summary, we find that this is not an issue, both in terms of theory and practice. Please see Appendix Section C for more details.

5. “the min-max is the variational form of some divergences, which the GANs are directly optimizing”
The estimation of divergences is difficult, whereas we show we can efficiently approximate DG. 

To conclude, based on the review we have updated the manuscript to more clearly emphasize its contribution which we believe was the main concern raised by the reviewer.

References:
[1] Mescheder et al. Which Training Methods for GANs fo actually converge? [ICML 2018] arXiv:1801.04406
[2] Soumith Chintala. How to train a GAN?, NIPS Tutorial, 2016
[3] Chiu et al. GAN Foundations, [CSC254, University of Toronto], &lt;<a href="https://www.cs.toronto.edu/~duvenaud/courses/csc2541/slides/gan-foundations.pdf#page=9&gt;" target="_blank" rel="nofollow">https://www.cs.toronto.edu/~duvenaud/courses/csc2541/slides/gan-foundations.pdf#page=9&gt;</a>
[4] Salimans et al. Improved Techniques for Training GANs [NIPS 2016] arXiv:1606.03498
[5] Ermon et al. Generative Adversarial Networks, [cs236, Stanford], &lt;http://cs236.stanford.edu/assets/slides/cs236_lecture9.pdf#page=19&gt;
[6] Fedus et al. Many Paths to Equilibrium: GANs Do Not Need to Decrease a Divergence At Every Step. [ICLR 2018], arXiv:1710.08446
[7] Kurach and Lucic et al. The GAN Landscape: Losses, Architectures, Regularization, and Normalization. arXiv:1807.04720 </span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div></div></div><div class="note_with_children"><div id="note_B1x8hZ4q27" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>usage of duality in GANs, moderate contribution</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=Syeben09FQ&amp;noteId=B1x8hZ4q27"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1049 AnonReviewer3</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">03 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper1049 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">The focus of the submission is GANs (generative adversarial network), a recent and popular min-max generative modelling approach. Training GANs is considered to be a challenging problem due to the min-max nature of the task. The authors propose two duality-inspired stopping criteria to monitor the efficiency and convergence of GAN learning.  

Though training GAN can have some useful applications, the contribution of the submission is pretty moderate. 
i) Duality-inspired approaches, embedded also in optimization have already been proposed: see for example 'Xu Chen, Jiang Wang, Hao Ge. Training Generative Adversarial Networks via Primal-Dual Subgradient Methods: A Lagrangian Perspective on GAN. ICLR-2018.'.
ii) The notion of generator and discriminator networks with unbounded capacity (which is an assumption in 'Proposition 1') lacks formal definition. I looked up the cited Goodfellow et al. (2014) work; it similarly does not define the concept. Based on the informal definition it is not clear whether they exist or are computationally tractable. 

Minor comments:
-MMD is a specific instance of integral probability metrics when in the latter the function space is chosen to be the unit ball of a reproducing kernel Hilbert space; they are not synonyms.
-mixed Nash equilibrium: E_{v\sim D_1} should be E_{v\sim D_2}.
-It might be better to call Table 1 as Figure 1.
-References: abbreviations and names should be capitalized (e.g., gan, mnist, wasserstein, nash, cifar). Lucic et al. (2017) has been accepted to NIPS-2018.</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">3: Clear rejection</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_BJgjorY2TX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Our usage of duality in GANs is in terms of evaluation, not optimization</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=Syeben09FQ&amp;noteId=BJgjorY2TX"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1049 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">17 Nov 2018</span><span class="item">ICLR 2019 Conference Paper1049 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Thank you for reviewing our paper. Please find our replies inline:

1. “Though training GAN can have some useful applications, the contribution of the submission is pretty moderate.”
First, we would like to stress that the contribution of our paper is not to train GANs. Instead, our contribution is to propose a reliable convergence metric for GANs that can be computed efficiently. The need for such a convergence metric has been pointed out for example in the context of analysing convergence of GANs [1] and understanding when to stop the GAN training [2, 3] (see also Fig. 12 and 13). Indeed, most empirical convergence analyses are for 2-dimensional problems due to the lack of such metric (See for example Mescheder et al. [ICML 2018]: “Measuring convergence for GANs is hard for high dimensional problems, because we lack a metric that can reliably detect non-convergent behavior. We therefore first examine the behavior [...] on simple 2D examples where we can assess convergence using an estimate of the Wasserstein-1-distance.” [1]). Furthermore, since GANs are framed as a 2-player minimax game the stopping criteria is unclear in comparison to the more traditional likelihood training [2]. In this work we argue that there is a convergence metric suitable for the general GAN game.
In particular, our main contributions are:
- Proposing the duality gap as a natural convergence metric and the minimax metric as a performance metric in GANs
- Show how an unbiased estimate of the metrics can be efficiently computed in practice without slowing down training
- Design experiments that target all of the common pitfalls of GANs (stable and unstable mode dropping/invention, intra-mode collapse, non-image domain, distortion of visual quality etc.) and demonstrate empirically that the metrics are able to capture and detect all of those

Thus the two metrics show very desirable properties both in theory and practice. We believe that the DG metric is very helpful as a monitoring tool for any practitioner training a GAN. The benefits are: (i) knowing whether the model has converged; (ii) knowing when to stop training; (iii) have a meaningful curve throughout training that reflects the performance of the model (i.e. whether it’s improving or not); (iv) comparison of different runs and hyperparameter searches and (v) debugging. As computing the metric is very efficient in practice this comes at no significant computational cost, and unlike other metrics requires no labels or a pre-trained classifier and can be applied to any minimax GAN formulation and any domain as demonstrated empirically.
Further, it allows for pushing the research of the non-convergence issue on GANs on problems that are beyond 2-dimensional where they can visually be analysed. We have updated the write-up to make our contribution clearer, both with respect to existing work, as well as the importance of a convergence metric for the community.

2. “Duality-inspired approaches, embedded also in optimization have already been proposed”
Although the reference cited by the reviewer does discuss duality for GANs, it does so in a very different context since it discusses a Lagrangian view to train GANs while we are interested in using the duality GAP as a convergence measure (and not as a training criterion). One problem we focus on in our submission is to demonstrate how to efficiently compute such measure during training, we therefore do not modify the training objective. We added a brief discussion in the related work section.

3. “The notion of generator and discriminator networks with unbounded capacity (which is an assumption in 'Proposition 1') lacks formal definition”
As noted by the reviewer, we re-used the notion originally introduced in the GAN paper. Informally, we consider the capacity as the flexibility of a model to learn a variety of functions. More formally, we regard the capacity as the size of the space that can be approximated with the generator and discriminator. In most cases, neural networks are universal approximators and can therefore approximate any function (i.e. they are dense in the target space), thus leading us to assume they have “unbounded capacity”.

We hope that we have cleared out any confusion and are looking forward to the reviewer’s reply.

References:
[1] Mescheder et al. Which Training Methods for GANs fo actually converge? [ICML 2018] arXiv:1801.04406
[2] Chiu et al. GAN Foundations, [CSC254, University of Toronto], &lt;<a href="https://www.cs.toronto.edu/~duvenaud/courses/csc2541/slides/gan-foundations.pdf#page=9&gt;" target="_blank" rel="nofollow">https://www.cs.toronto.edu/~duvenaud/courses/csc2541/slides/gan-foundations.pdf#page=9&gt;</a>
[3] Ermon et al. Generative Adversarial Networks, [cs236, Stanford], &lt;http://cs236.stanford.edu/assets/slides/cs236_lecture9.pdf#page=19&gt;
</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div><div class="note_with_children"><div id="note_S1xlTDG9nX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>A nicely written work, but concerns on significance</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=Syeben09FQ&amp;noteId=S1xlTDG9nX"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1049 AnonReviewer2</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">03 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper1049 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">This work proposes to use duality gap and minimax loss as measures for monitoring the progress of training GANs. The authors first showed a relationship between duality gap(DG) and Jensen-Shannon divergence and non-negativeness on DG. Then, a comprehensive discussion was presented on how to estimate and efficiently compute DG. A series of experiments were designed on synthetic data and real-world image data to show 1) how duality gap is sensitive to capture non-convergence during training and 2) how minimax loss efficiently reflects the sample quality from generator. 


I was not very familiar with GANs, thus I'm not sure on the significance of paper and would like to see opinions from other reviews on this. For reviewing this paper, I also read the cited works such as Salimans (2016), Heusel (2017). Compared with them, the theoretical contribution of this work seems less significant. Also, I'm not quite impressed by the advantages of proposed metrics. However, this work is nicely written, the ideas are delivered clearly, experiments are nicely designed. I kind of enjoying reading this paper due to its clarity.


Other concerns:

There are two D_1 in Equation Mixed Nash equilibrium.
</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">5: Marginally below acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">3: The reviewer is fairly confident that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_Skgo3KthpX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>[Part 1/2] The metric gives a natural solution to many open challenges in GANs</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=Syeben09FQ&amp;noteId=Skgo3KthpX"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1049 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">17 Nov 2018</span><span class="item">ICLR 2019 Conference Paper1049 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Thank you for the review. We appreciate the comments on the nice flow of the paper and the carefully designed experimental section. Your two concerns are (1) “I was not very familiar with GANs, thus I'm not sure on the significance of paper” and (2) “I'm not quite impressed by the advantages of proposed metrics”, which we address below:

1. Significance
GANs are a 2-player minimax game, which makes their objective function different than the more commonly encountered likelihood optimization problems, thus yielding new challenges in terms of optimization and evaluation. For evaluating likelihood-based models, a common metric to use is the test loss, whereas for minimax problems it is not clear what the equivalent would be [1]. 
In particular, with the absence of such a metric, practitioners are facing several problems, such as (i) determining whether the model has converged, (ii) determining when to stop training (see Fig. 12 and 13), (iii) having a meaningful curve throughout training as the discriminator and generator losses are not intuitive, (iv) comparing different runs and (v) debugging the model in the sense of (un)stable mode collapse, non-convergence etc. See for example [1]: “Generative adversarial networks are not born with a good objection function that can inform us about the training progress. Without a good evaluation metric, it is like working in the dark. No good sign to tell when to stop; No good indicator to compare the performance of multiple models.”. Current methods for stopping criteria rely on visual inspection and/or using some sample-quality metric as a proxy. However this is not principled and it is unclear how to compute the metrics in non-image domains. Thus another open challenge with GANs is (vi) having a useful metric that is domain independent.

In this work, we argue that such a natural metric exists, namely the duality gap and its minimax part. We show how to compute it in practice in an efficient way and demonstrate its desirable properties across different GAN pitfalls, domains and GAN objectives. Thus, in our opinion, this work is of significance for the GAN community, not only for practical purposes as it gives a solution to the previously mentioned open problems (i-vi) both in theory and practice, but also from research perspective as it gives a reliable non-convergence metric to help analyse which methods actually converge, which is one of the central issues of GANs. Note that current practical analyses mainly focus on 2-dimensional problems where the solution can be visually inspected due to the lack of such a metric [2]. 

2. Advantages of the proposed metrics
From a theoretical perspective, the DG is very natural for the detection of non-convergent behaviors, it is always non-negative and is zero if and only if the model has reached a (Nash) equilibrium.

The experimental results presented in the paper provide a thorough evaluation of the metric introduced in our submission. We included various tests that focus on common pitfalls encountered with GANs and demonstrated that the proposed metric can detect these corner cases. In particular:

In experiment 5.1 we demonstrate that the *DG yields a meaningful curve* throughout training and detects convergent and non-convergent behaviours. Please note that the commonly used metrics such as FID and Inception score cannot be applied to these datasets.

In experiment 5.2 we show that the *DG detects stable mode collapse* and can distinguish between stable and unstable collapses.

In experiment 5.3 we empirically demonstrate that the *minimax metric detects visual sample quality (adding noise, Gaussian swirl and blur) and is very sensitive to change of modes* (mode dropping, mode invention and intra-mode collapse). It works better than Inception score, and as well as FID. However, both the Inception score and FID rely on a pre-trained Imagenet classifier, whereas our metrics need no labeled data or a pre-trained classifier.

Finally, in experiment 5.4 we show the *DG metric can be applied on another GAN minimax formulation (WGAN) and on another domain that is not natural images (cosmology data)*. We find that the metric is highly correlated with a domain specific measure of performance used in cosmology. Note that the domain-specific metric requires expert knowledge and its computation is very slow, unlike the DG. Furthermore, the Inception score and FID cannot be applied on this data as they require an imagenet classifier (i.e. trained with labeled natural images).
</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_SJx-uhFn6X" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>[Part 2/2] The metric gives a natural solution to many open challenges in GANs </a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=Syeben09FQ&amp;noteId=SJx-uhFn6X"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1049 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">17 Nov 2018</span><span class="item">ICLR 2019 Conference Paper1049 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">We summarize the properties and advantages of our approach in the table shown below, including a comparison to Inception score (INC) and FID.

+---------------------------------------------------------------------------------------------+----------------+--------+--------------+
| Property\Metric                                                                                      | INC            | FID   | minimax |
+---------------------------------------------------------------------------------------------+----------------+--------+--------------+
| Sensitivity to mode collapse                                                                | moderate | high | high         |
+---------------------------------------------------------------------------------------------+----------------+--------+--------------+
| Sensitivity to mode invention                                                              | low            | high | high         |
+---------------------------------------------------------------------------------------------+----------------+--------+--------------+
| Sensitivity to intra-mode collapse                                                       | low            | high | high        |
+---------------------------------------------------------------------------------------------+----------------+--------+--------------+
| Sensitivity to visual quality and transformations                             | moderate | high | high        |
+---------------------------------------------------------------------------------------------+----------------+--------+--------------+
| Computational: Fast                                                                              | yes             | yes   | yes          |
+---------------------------------------------------------------------------------------------+----------------+--------+--------------+
| Computational: Needs labeled data or a pretrained classifier      | yes             | yes   | no           |
+---------------------------------------------------------------------------------------------+----------------+--------+--------------+
| Computational: Can be applied to any domain without change  | no               | no    | yes          |
+---------------------------------------------------------------------------------------------+----------------+--------+--------------+


We hope to have addressed your concerns and that our reply is detailed and informative enough so that the reviewer can reconsider their judgement. We are looking forward to the reply. 

References:
[1] Ermon et al. Generative Adversarial Networks, [cs236, Stanford], &lt;<a href="http://cs236.stanford.edu/assets/slides/cs236_lecture9.pdf#page=19&gt;" target="_blank" rel="nofollow">http://cs236.stanford.edu/assets/slides/cs236_lecture9.pdf#page=19&gt;</a>
[2] Lil’Log https://lilianweng.github.io/lil-log/2017/08/20/from-GAN-to-WGAN.html#lack-of-a-proper-evaluation-metric
[3] Mescheder et al. Which Training Methods for GANs fo actually converge? [ICML 2018] arXiv:1801.04406
</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div></div></div></div></main></div>
  </div>
</div>


    <!-- Footer -->
    <footer class="sitemap">
      <div class="container">
        <div class="row hidden-xs">
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/venues">All Venues</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="/contact">Contact</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
    
        <div class="row visible-xs-block">
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/contact">Contact</a></li>
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
      </div>
    </footer>
    
    <footer class="sponsor">
      <div class="container">
        <div class="row">
          <div class="col-sm-10 col-sm-offset-1">
            <p class="text-center">
              OpenReview is created by the <a href="http://www.iesl.cs.umass.edu/" target="_blank">Information Extraction and Synthesis Laboratory</a>, College of Information and Computer Science, University of Massachusetts Amherst. We gratefully acknowledge the support of the OpenReview sponsors:  Google,  Facebook, NSF, the University of Massachusetts Amherst Center for Data Science, and Center for Intelligent Information Retrieval, as well as the Google Cloud Platform for donating the computing and networking services on which OpenReview.net runs.
            </p>
          </div>
        </div>
      </div>
    </footer>

  <div id="feedback-modal" class="modal fade" tabindex="-1" role="dialog">
    <div class="modal-dialog">
      <div class="modal-content">
        <div class="modal-header">
          <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button>
          <h3 class="modal-title">Send Feedback</h3>
        </div>
        <div class="modal-body">
          <p>Enter your feedback below and we'll get back to you as soon as possible.</p>
          <form action="/feedback" method="POST">
            <div class="form-group">
              <input type="email" name="from" class="form-control" placeholder="Email" />
            </div>
            <div class="form-group">
              <input type="text" name="subject" class="form-control" placeholder="Subject" />
            </div>
            <div class="form-group">
              <textarea name="message" class="form-control feedback-input" rows="5" placeholder="Message" required=""></textarea>
            </div>
          <ul id="ui-id-2" tabindex="0" class="ui-menu ui-widget ui-widget-content" style="display: none;"></ul></form>
        </div>
        <div class="modal-footer">
          <button type="button" class="btn btn-default" data-dismiss="modal">Cancel</button>
          <button type="button" class="btn btn-primary">Send</button>
        </div>
      </div>
    </div>
  </div>

  <script type="text/javascript" async="" src="https://www.google-analytics.com/analytics.js"></script><script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js"></script>
  <script>window.jQuery || document.write('&lt;script src="/static/js/vendor/jquery-2.2.4.min.js"&gt;&lt;\/script&gt;')</script>

  <script src="/static/dist/vendor.min.js"></script>
  <script src="/static/dist/templates.min.js"></script>
  <script src="/static/dist/openreview.min.js"></script>

    <script>window.legacyScripts = true;</script>


    <script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-108703919-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() { dataLayer.push(arguments); }
      gtag('js', new Date());
      gtag('config', 'UA-108703919-1');
    </script>


<div role="status" aria-live="assertive" aria-relevant="additions" class="ui-helper-hidden-accessible"></div></body></html>
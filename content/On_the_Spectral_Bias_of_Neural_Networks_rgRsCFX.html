<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" class="no-js"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>On the Spectral Bias of Neural Networks | OpenReview</title>
  <meta name="description" content="" />

      <meta name="citation_title" content="On the Spectral Bias of Neural Networks" />
        <meta name="citation_author" content="Anonymous" />
      <meta name="citation_publication_date" content="2018/09/27" />
      <meta name="citation_online_date" content="2018/09/27" />
      <meta name="citation_pdf_url" content="https://openreview.net/pdf?id=r1gR2sC9FX" />
      <meta name="twitter:card" content="summary" />
      <meta name="twitter:site" content="@openreviewnet" />
      <meta name="og:title" content="On the Spectral Bias of Neural Networks" />
      <meta name="og:description" content="Neural networks are known to be a class of highly expressive functions able to fit even random input-output mappings with 100% accuracy. In this work we present properties of neural networks that..." />
      <meta name="og:image" content="https://openreview.net/static/images/openreview_logo_512.png" />

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans:400,400i,700,700i" />

  <link rel="stylesheet" href="/static/css/bootstrap.min.css" />
  <link rel="stylesheet" href="/static/css/jquery-ui.min.css" />
  <link rel="stylesheet" href="/static/css/main.min.css" />
</head>

<body class="forum">
  <nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
  
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand home push-link" href="/"><strong>OpenReview</strong>.net</a>
      </div>
  
      <div id="navbar" class="navbar-collapse collapse">
        <form class="navbar-form navbar-left profile-search" role="search">
          <div class="form-group has-feedback">
            <input id="search_input" type="text" class="form-control ui-autocomplete-input" placeholder="Search ICLR 2019 Conference" autocomplete="off" />
            <span class="glyphicon glyphicon-search form-control-feedback" aria-hidden="true"></span>
          </div>
  
          <input id="search_group" type="hidden" value="ICLR.cc/2019/Conference" />
          <input id="search_content" type="hidden" value="all" />
        <ul id="ui-id-1" tabindex="0" class="ui-menu ui-widget ui-widget-content ui-autocomplete ui-front" style="display: none;"></ul></form>
  
        <ul class="nav navbar-nav navbar-right">
        
            <li id="user-menu"><a href="/login">Login</a></li>
        </ul>
      </div>
  
    </div>
  </nav>

  <div id="or-banner" class="banner" style="">
  <div class="container">
    <div class="row">
      <div class="col-xs-12"><a href="/group?id=ICLR.cc/2019/Conference" title="Venue Homepage"><img class="icon" src="/static/images/arrow_left.svg" /> Go to <strong>ICLR 2019 Conference</strong> homepage</a></div>
    </div>
  </div>
</div>
<div id="flash-message-container" class="alert alert-danger" role="alert" style="display: none;">
  <div class="container">
    <div class="row">
      <div class="col-xs-12">
        <div class="alert-content">
          <button type="button" class="close" aria-label="Close"><span aria-hidden="true">×</span></button>
        </div>
      </div>
    </div>
  </div>
</div>

<div class="container">
  <div class="row">
    <div class="col-xs-12">
      <main id="content" class="clearfix openbanner-visible legacy-styles"><div id="note_r1gR2sC9FX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>On the Spectral Bias of Neural Networks</a> <a class="note_content_pdf" href="/pdf?id=r1gR2sC9FX" title="Download PDF" target="_blank"><img src="/static/images/pdf_icon_blue.svg" /></a> </h2></div><div class="meta_row"><span class="signatures">Anonymous</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">28 Sep 2018 (modified: 16 Nov 2018)</span><span class="item">ICLR 2019 Conference Blind Submission</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span><span class="item"><a class="action-bibtex-modal" data-bibtex="@inproceedings{    &#10;anonymous2019on,    &#10;title={On the Spectral Bias of Neural Networks},    &#10;author={Anonymous},    &#10;booktitle={Submitted to International Conference on Learning Representations},    &#10;year={2019},    &#10;url={https://openreview.net/forum?id=r1gR2sC9FX},    &#10;note={under review}    &#10;}">Show Bibtex</a></span><a class="note_content_pdf item" href="/revisions?id=r1gR2sC9FX" target="_blank">Show Revisions</a></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Abstract: </span><span class="note_content_value">Neural networks are known to be a class of highly expressive functions able to fit even random input-output mappings with 100% accuracy. In this work we present properties of neural networks that complement this aspect of expressivity. By using tools from Fourier analysis, we show that deep ReLU networks are biased towards low frequency functions, meaning that they cannot have local fluctuations without affecting their global behavior. Intuitively, this property is in line with the observation that over-parameterized networks find simple patterns that generalize across data samples. We also investigate how the shape of the data manifold affects expressivity by showing evidence that learning high frequencies gets easier with increasing manifold complexity, and present a theoretical understanding of this behavior. Finally, we study the robustness of the frequency components with respect to parameter perturbation, to develop the intuition that the parameters must be finely tuned to express high frequency functions.</span></div><div class="note_contents"><span class="note_content_field">Keywords: </span><span class="note_content_value">deep learning theory, fourier analysis</span></div><div class="note_contents"><span class="note_content_field">TL;DR: </span><span class="note_content_value">We investigate ReLU networks in the Fourier domain and demonstrate peculiar behaviour.</span></div><div class="reply_row clearfix"><div class="item" id="reply_count">9 Replies</div></div></div><hr class="small" /><div id="note_children"><div class="note_with_children"><div id="note_ByeCM8C8a7" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>theoretical and empirical analysis of implicit bias in neural networks via Fourier coefficients.</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=r1gR2sC9FX&amp;noteId=ByeCM8C8a7"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper757 AnonReviewer4</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">12 Nov 2018</span><span class="item">ICLR 2019 Conference Paper757 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">Summary.

This paper has theoretical and empirical contributions on topic of Fourier coefficients of neural networks.  First is upper bound on Fourier coefficients in terms of number of affine pieces and Lipschitz constant of network.  Second is collection of synthetic data and trained networks whereupon is argued that neural networks focus early effort upon low Fourier coefficients.


Brief evaluation.

Pros:

+ This paper attacks important and timely topic: identifying and analyzing implicit bias of neural networks paired with standard training methods.

Cons:

- "Implicit bias" hypothesis has been put forth by many authors for many years, and this paper does not provide compelling argument that Fourier coefficients provide good characterization of this bias.

- Regarding "many authors for many years", this paper fails to cite and utilize vast body of prior work, as detailed below.

- Main theorem here is loose upper bound primarily derived from prior work, and no lower bounds are given.  Prior work does assess lower bounds.

- Experiments are on synthetic data; prior work on implicit regularization does check real data.


Detailed evaluation.

* "Implicit bias" hypothesis appears in many places, for instance in work of Nati Srebro and colleagues ("The Implicit Bias of Gradient Descent on Separable Data" (and follow-ups), "Exploring generalization in deep learning" (and follow-ups), and others); it can also be found in variety of recent generalization papers, for instance again the work of Srebro et al, but also Bartlett et al, Arora et al.  E.g., Arora et al do detailed analysis of favorable biases in order to obtain refined generalization bound.  Consequently I expect this paper to argue to me, with strong theorems and experiments, that Fourier coefficients are a good way to assess implicit bias.

* Theorem 1 is proved via bounds and tools on the Fourier spectra of indicators of polytopes due to Diaz et al, and linearity of the Fourier transform.  It is only upper bound (indeed one that makes no effort to deal with cancellations and thus become tight).  By contrast, the original proofs of depth separation for neural networks (e.g., Eldan and Shamir, or Telgarsky, both 2015), provide lower bounds and metric space separation.  Indeed, the work of Eldan&amp;Shamir extensively uses Fourier analysis, and the proof develops a refined understanding of why it is hard for a ReLU network to approximate a Fourier transform of even simple functions: it has to approximate exponentially many tubes in Fourier space, which it can only do with exponentially many pieces.  While the present paper aims to cover some material not in Eldan&amp;Shamir --- e.g., the bias with training --- this latter contribution is argued via synthetic data, and overall I feel the present work does not meet the (high) bar set by Eldan&amp;Shamir.

*  I will also point out that prior work of Barron, his "superposition" paper from 1993, is not cited. That paper presents upper bounds on approximation with neural networks which depends on the Fourier transform.  There is also follow-up by Arora et al with "Barron functions".

I feel this paper could be made much stronger by carefully using the results of all this prior work; these are not merely citation omissions, but indeed there is good understanding and progress in these papers.
</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">5: Marginally below acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_H1xuoxUj67" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Response to Reviewer 4 [1/2]</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=r1gR2sC9FX&amp;noteId=H1xuoxUj67"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper757 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">16 Nov 2018 (modified: 20 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper757 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Thank you for your thorough comments and feedback. 

Our response is split in two parts.

Part [1/2]

**Context of the paper and related work**

Thank you for pointing out the importance of the topic! It is also our view that our work should be understood in the context of the very active lines of research on expressivity and implicit bias in neural networks. 

To allow for a fair comparison of our work with the existing literature, we feel it is worth clarifying what is specifically  addressed in our paper - and what is not:

1. What we do (our novelty): 
(i) We describe a computation procedure for the Fourier transform and spectrum of deep ReLU networks. To our knowledge, although the analysis is largely inspired by techniques developed by [Diaz et al. 2016] to evaluate the Fourier shape transform of polytopes, this is a new result. (ii) We build upon this result to show a learning bias of neural network towards low frequency functions. This is motivated by the recent observation made in [Arpit et al. 2017] that neural networks tend to prioritize learning simple patterns that generalize across data samples. (iii) We investigate the subtle interplay between the learnability of large frequencies and the geometry of the data manifold. We believe this a novel and original insight.  

2. What we don't do:
(i) Our work departs from analysis of approximation bounds. This is not our goal. 
(ii) Although we believe this is an important and challenging problem, we do not aim at a full characterization of the implicit bias of gradient descent. This requires to tackle the learning dynamics of non-linear neural networks, which is, to the best of our knowledge, a largely open research topic  -- not (directly) addressed in our paper. 
(iii) Our goal is not to derive generalization bounds.  

**On the related work on Implicit Bias:**

Thank you for the nice references! We have included some of them in our latest revision: both in the introduction,  to make the context of our work more explicit; and in the Related Work section that has been expanded accordingly. We note however that having strong theorems in the context of largely intractable systems such as neural networks often requires making strong assumptions. For instance, the main theorem of the reference Soudry et al,  "The Implicit Bias of Gradient Descent on Separable Data", concerns logistic regression on linearly separable data!

We would also like to point out that the term "implicit bias" is quite generic and can have many interpretations. In our work, we consider learning bias in the ubiquitous class of deep ReLU networks. We believe this is an important first step for future work to build on, given how we expose in a principled manner that a learning  bias in the Fourier domain indeed exists for deep ReLU networks.

**On the related work on expressivity:**

Thank you for pointing out the missing references on architecture-dependent approximation bounds;  we have included them in our new revision. We feel there may have been a confusion about the purpose of Theorem 1: it should not be understood as an approximation bound. The goal in Section 2 is  to compute the Fourier transform; we choose to present the main result of Section 2.2 in the form of an asymptotic bound, which puts the emphasis on the spectral decay. We discuss more the significance of Theorem 1 below. 

On [Eldan &amp; Shamir 2015]: 

Thank you for this nice reference! This paper makes elegant use of specific properties of the Fourier transform of 2-layer networks to show a specific depth-separation result.  Although the motivation for our paper differs from theirs, their proof indeed gives a nice insight on why 2-layer networks do not approximate high frequency functions well. We have included this in the Related Work section. Note however that:
(i) The two papers address entirely different questions: our primary goal is to expose the spectral bias of deep ReLU networks during learning, while their goal is to illustrate the role of depth in expressivity, through a worse-case separation analysis between 2 and 3-layer networks.
(ii) Furthermore, the techniques developed in their paper is of little help for our goal: (a) they do not actually compute the Fourier coefficients and (b) their argument is tailored towards 2-layer networks only (i.e. those having the form $\sum_i f_i(&lt;v_i,x&gt;)$ for some activation function $f$). 

[Continued in Part 2]</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_SJlUNA4i6m" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Response to Reviewer 4 [2/2]</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=r1gR2sC9FX&amp;noteId=SJlUNA4i6m"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper757 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">16 Nov 2018</span><span class="item">ICLR 2019 Conference Paper757 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Part [2/2]

**Regarding Tightness of Bound:**

For some context: the primary motivation behind Section 2 is to develop a formal framework for understanding of the results in Sections 3 and 5 - not to derive approximation error bounds. In a recent revision, we have updated Section 3 in the manuscript to make the link to Theorem 1 more explicit. For example, we now show that the gradient of the MSE loss (w.r.t network parameters) inherits the spectral decay rate of the network function (Eq 11). Consequently, the residual (difference between function and target) at lower frequencies is weighted stronger than at higher frequencies. Folllowing a suggestion of AnonReviewer3, we also included a suite of qualitative ablation experiments demonstrating the effect of width, depth and max-norm in Appendix A.3 of the new revision. As anticipated from Theorem 1, we find that increasing depth indeed helps towards fitting high frequencies, more so than increasing width. Further, increasing the weight clip also has the same effect.

On tightness: The Fourier coefficients take the general form of a rational, typically homogeneous  function $C(W_\epsilon, \hat k) / k^{-d-1}$.

(1) The actual inequality originates from the terms C  depending on linear mappings operating on weights $W_{\epsilon}$ and general unit vectors $\hat{k}$, as can be seen by recursively expanding the FT of the polytope as in Diaz et al. 2016. We think that the requirement of generality leaves little scope for further cancellations and tighter bounds. 

In other words, for a general $k$, the tightness of the bound depends on the weight matrices. Indeed, we provide empirical evidence in Appendix A.3: increasing the weight clip (i.e. by relaxing the upper bound on the parameter max-norm, and by proxy on the Lipschitz constant) has a significant impact towards whether the network can match the target function in the Fourier domain. This implies that in this particular setting, the bound must be tight, given that it is preventing the network from learning higher frequencies. 

(2) Observe that in equation 11, the inequality can only affect all frequencies uniformly. In other words, the scaling behaviour of the fourier coefficients with increasing $k$ remains intact, irrespective of the numerator. Therefore, the down-scaling of the contribution towards the loss gradient of the residual at higher frequencies is not affected by the tightness of the bound. 

**Regarding Synthetic Data**

While we understand and appreciate the need for showing consequences of our analysis on real data (in Appendix), our rationale for exclusively using synthetic data in the main text is that it affords us rich control over experimental parameters (e.g. shape of the manifold, frequency of functions defined on manifold). In a sense, it allows us to study the "raw" behaviour of the network, unconfounded by unknown external factors that might depend on the data in uncontrollable ways. 

**In closing**

We hope our response and the updated revision address your concerns. </span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_SkljfCVj6X" class="note panel trashed"><div class="title_pdf_row clearfix"><h2 class="note_content_title">  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=r1gR2sC9FX&amp;noteId=SkljfCVj6X"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">[Deleted]</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="item">ICLR 2019 Conference Paper757 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div><div class="note_with_children"><div id="note_HygwdiS037" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Intriguing topic and analysis, but its impact on understanding of neural nets seems limited</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=r1gR2sC9FX&amp;noteId=HygwdiS037"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper757 AnonReviewer3</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">06 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper757 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">Synopsis:
This paper analyzes deep Relu neural networks based on the Fourier decomposition of their input-output map. They show theoretically that the decomposition is biased towards low frequencies and give some support that low frequency components of a function are learned earlier under gradient descent training. 

Pros:
--Fourier decomposition is an important and (to the best of my knowledge) mostly original angle from which the authors analyze the input-output map governing neural networks. There is some neat mathematical analysis contained here based off of the piecewise-linearity of deep Relu nets and Fourier decomposition of polytopes in input space.

--The setup in the toy experiments of Sec. 4 seems novel &amp; thoughtful; the authors consider a lower-dimensional manifold embedded in a higher dimensional input space, and the Fourier decomposition of the composition of two functions is related to the decomposition of constituents.

Cons:
--While this paper does a fairly good job establishing that NNs are spectrally biased towards low frequencies, I’m skeptical of its impact on our understanding of deep neural nets. Specifically, at a qualitative level it doesn’t seem very surprising: intuitively (as the authors write in Sec. 5), capturing higher frequencies in a function requires more fine tuning of the parameters.  At initialization, we don’t have such fine tuning (e.g. weights/biases drawn i.i.d Normal), and upon training it takes a certain amount of optimization time before we obtain greater “fine tuning.” At a quantitative level, these results would be more useful if (i) some insight could be gleaned from their dependence on the architectural choices of the network (in particular, depth) or (ii) some insight could be gained from how the spectral bias compares between deep NNs and other models (as is discussed briefly in the appendix -- for instance, kernel machines and K-NN classifiers). The primary dependence in the spectral decay (Theorem 1) seems to be that it (i) decays in a way which depends on the input dimensionality in most directions and (ii) it is highly anisotropic and decays more slowly in specific directions. The depth dependence seems to arise from the constants in the bound in Theorem 1 (see my comment below on the bound). 

--Relying on the growth of the weight norm to justify the network's bias towards learning lower frequencies earlier in training seems a bit tenuous to me. (I think the stronger evidence for learning lower frequencies comes from the experiments.) In particular, I'm not sure I would use the bound in Theorem 1 to conclude what would happen to actual Fourier components during training, since the bound may be far from being met. For instance, (1) the number of linear regions N_f changes during training -- what effect would this have? Also, (2) what if one were to use orthogonal weight matrices for training? Presumably the network would still train and generalize but the conclusions might be different (e.g. the idea that growth of weight norms is the cause of learning low frequency components earlier). 

Miscellaneous:
--Would appreciate a greater discussion on the role of the cost function (MSE vs cross-entropy) in the analysis or experiments. Are the empirical conclusions mostly identical?

</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">6: Marginally above acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">3: The reviewer is fairly confident that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_SyxdkRevp7" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Response to Reviewer 3</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=r1gR2sC9FX&amp;noteId=SyxdkRevp7"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper757 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">12 Nov 2018</span><span class="item">ICLR 2019 Conference Paper757 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Thank you for your thoughtful comments!

**On the dependence on architectural choice**

Following your suggestion, we have included a suite of qualitative ablation experiments demonstrating the effect of width, depth and max-norm in Appendix A.3 of the new revision. As anticipated from Theorem 1, we find that increasing depth indeed helps towards fitting high frequencies, more so than increasing width. Further, increasing the weight clip also has the same effect. 

**On the theoretical evidence of the learning bias**

Thank you for this feedback. We completely agree that relying on the increasing spectral norm to explain the spectral bias (i.e. low frequencies learned first) can be restrictive. In the latest revision, we reinforce the theoretical argument by showing that the gradient of the MSE loss (w.r.t network parameters) inherits the spectral decay rate of the network function itself (Eq 11). Consequently, the residual (difference between function and target) at lower frequencies is weighted stronger than at higher frequencies.

Regarding tightness of the bound:  note that although we choose to present the main result of Section 2.2 in the form of an asymptotic bound in Theorem 1, our analysis (Lemma 1 together with the procedure described in Diaz et al. 2016 and explained in detail Appendix D.2) actually allows us to get the Fourier components in closed form, for a given set of weight matrices. These components typically decay as fast as $k^{-d-1}$ where d is the input data dimension (around 1000 (!) for small-scale real-world problems (e.g. 784 for MNIST)) leading to larger contribution from lower frequencies relative to the higher ones.

On the number $N_f$ of linear regions: During training, i.e. for a given architecture, we note that Raghu et al. 2016 provide tight upper-bounds for $N_f$ which depend on the width and depth of the network, along with the input dimensionality. The effect of $N_f$ is therefore somewhat limited (in contrast with $L_f$, which can become arbitrarily large as training progresses).

**On the role of the cost function**

Thank you for bringing up this interesting point! Note the brief discussion of the role of the MSE loss in Section 3 (Eq 10), showing that it induces no structural bias towards any particular frequency component (there is no weight coefficient $w(k)$ before $|f(k) - \lambda(k)|^2$ in  Eq. 10). This allows us to eliminate the loss function as a potential confounding factor when empirically demonstrating the spectral bias. The same cannot be said of the cross-entropy loss, which could potentially introduce additional biases and thereby make it difficult to isolate the bias due to the network parameterization from that due to the loss function itself. This is precisely why we used MSE in most of our experiments. We make this clearer in the latest revision. 

Note however that we did use cross entropy in Experiment 3, which reproduces Experiment 2 in the context of classification. We obtained similar results. 

We hope you find that our revision and clarifications address your concerns.</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div><div class="note_with_children"><div id="note_SylaVMTh27" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>interesting ideas; message unclear</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=r1gR2sC9FX&amp;noteId=SylaVMTh27"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper757 AnonReviewer2</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">05 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper757 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">The paper considers the Fourier spectrum of functions represented by Deep ReLU networks, as well as the relationship to the training procedure by which the network weights can be learned. 

It is well-known (and somewhat obvious) that deep neural networks with rectifier activations represent piecewise linear continuous function. Thus, the function can be written as a sum of the products of  indicators of various polytopes (which define the partition of R^d) and the linear function on that polytope. This allows the authors to compute the Fourier transform (cf. Thm. 1) and the magnitude of f(k) decays as k^{-i} where the i can depend on the polytope in some intricate fashion. Despite the remarks at the end of Thm 1, I found the result hard to interpret and relate to the rest of the paper. The appearance of N_f in the numerator (which can be exponentially large in the depth) may well make these bounds meaningless for any networks that are relevant in practice.

The main paper only has experiments on some synthetic data. 

Sec 3: Does the MSE actually go to 0 in these experiments? Or are you observing that GD fits lower frequencies, because it has a hard time fitting things that oscillate frequently?

Sec 4: I would have liked to see a clearer explanation for example of why increasing L is better for regression, but not for classification. As it stands I can't read much from these experiments. 

Overall, I feel that there might be some interesting ideas in this paper, but the way it's currently written, I found it very hard to get a good "picture" of what the authors want to convey.

</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">5: Marginally below acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">3: The reviewer is fairly confident that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_ByeFBpev6X" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Response to Reviewer 2</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=r1gR2sC9FX&amp;noteId=ByeFBpev6X"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper757 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">12 Nov 2018 (modified: 15 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper757 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Thank you for your constructive feedback! 

**On clarity of the message**

Thanks for this valuable feedback. We understand your concerns about clarity. To that end, we have reworked parts of our exposition,  including the abstract and introduction, in the new revision, to make the message more clear.

We believe our work follows lines of research on both the expressivity of neural networks and the biases of their learning by gradient descent, which are motivated by a lack of theoretical  understanding of the good generalization performance of these models despite their large capacity [Zhang et al. 2017]. We approach this through the lens of Fourier analysis, which we think is an original and interesting angle. Our main contribution is to show a learning bias of neural networks towards low frequency functions.  We believe this might be an important insight towards explaining why neural networks tend to prioritize learning simple patterns that generalize across data samples [Arpit et al. 2017].  We  also investigate the subtle interplay between the learnability of large frequencies and the geometry of the data manifold, pointing that a low frequency function in input space can fit large frequencies on highly curved manifolds.   

We hope this clarifies the picture we want to convey. 

**On the significance of Theorem 1:**

Despite the analysis of Section 2.2 being of interest in its own right as a result on the  expressivity of ReLU networks,  Theorem 1 plays a central role in developing a formal understanding of the results in Sections 3 and 5. We have revised Section 3 in the manuscript to make the link to Theorem 1 more explicit. 

Although we choose to present the main result of Section 2.2 in the form of an asymptotic bound in Theorem 1, note that our analysis (Lemma 1 together with the procedure described in Diaz et al. 2016 and explained in detail Appendix D.2) actually allows us to get the Fourier components in closed form, for a given set of weight matrices. These components typically decay as fast as $k^{-d-1}$ where d is the input data dimension (around 1000 (!) for small-scale real-world problems (e.g. 784 for MNIST)) leading to larger contribution from lower frequencies relative to the higher ones.

While the number $N_f$ of linear regions can be indeed be large, it affects all frequencies uniformly, i.e. leaves the spectral decay rate intact. Moreover, in most practical settings one usually constrains the Lipschitz constant $L_f$ (which appears together with $N_f$ in the numerator of the bound), e.g. with weight decay, batch norm [cf. Santurkar et al. 2018], gradient penalty, spectral normalization [Miyato et al. 2018], etc.

**On experimenting with synthetic data**: 

While we understand and appreciate the need for showing consequences of our analysis on real data, our rationale for exclusively using synthetic data in the main text is that it affords us rich control over experimental parameters (e.g. shape of the manifold, frequency of functions defined on manifold). In a sense, it allows us to study the "raw" behaviour of the network, unconfounded by unknown external factors that might depend on the data in uncontrollable ways. 

**On the MSE Going to Zero**

In Experiment 1 (Section 3), the mean squared error loss drops reasonably close to zero (typically around 0.05; the revision includes loss curves in the appendix). 

&gt; GD fits lower frequencies, because it has a hard time fitting things that oscillate frequently?

Your intuition is correct: it is indeed true and one of the central themes of the paper that high-frequency components of the target function (i.e. parts of the function that oscillate frequenctly) are harder to fit. If the target function contains extremely large frequencies, the convergence can be extremely slow. 

**On regression v.s classification results:**

Our report of the results might not have been clear enough: increasing L is better for *both* regression and classification. You can observe in Figure 4 that increasing L (going up a column) yields better classification accuracies. 

**In closing:** 

We hope that our answer and revision make the main message of the paper more apparent. 

[Santurkar et al. 2018] <a href="https://arxiv.org/abs/1805.11604" target="_blank" rel="nofollow">https://arxiv.org/abs/1805.11604</a>
[Miyato et al. 2018] https://arxiv.org/abs/1802.05957
[Zhang et al 2017] https://arxiv.org/abs/1611.03530
[Arpit at al 2017] https://arxiv.org/abs/1706.05394</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div><div class="note_with_children"><div id="note_BkgJFfPt37" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Analysis of Spectral Bias of ReLU networks</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=r1gR2sC9FX&amp;noteId=BkgJFfPt37"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper757 AnonReviewer1</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">02 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper757 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">Analysis of Spectral Bias of ReLU networks

The paper uses Fourier analysis to study ReLU network utilizing its continuous piecewise linear structure.

Main finding is that these networks are biased towards learning low frequency which authors denote `spectral bias’.  This provides another theoretical perspective of neural networks preferring more smooth functions while being able to fit complicated function. Also shows that in terms of parameters networks representing lower frequency modes are more robust. 

Pro: 
- Nice introduction to Fourier analysis providing non-trivial insights of ReLU networks.
- Intuitive toy experiments to show spectral bias and its properties 
- Thorough theoretical analysis and empirical support

Con: 
- The analysis is clearly for ReLU networks although the title may provide a false impression that it corresponds to general networks with other non-linearities. It is an interesting question whether the behaviour characterized by the authors are universal. 
- At least for me, Section 4 was not as clearly presented as other section. It takes more effort to parse what experiments were conducted and why such experiments are provided.
- Although some experiments on real dataset are provided in the appendix, I personally could not read much intuition of theoretical findings to the networks used in practice. Does the spectral bias suggest better way of training or designing neural networks for example?

Comments/Questions:
- In Figure 1, two experiments show different layerwise behaviour, i.e. equal amplitude experiment (a) shows spectral norm evolution for all the layers are almost identical whereas in increasing amplitude experiment (b) shows higher layer change spectral norm more than the lower layer. Do you understand why and does Fourier spectrum provide insights into layerwise behaviour?
- Experiment 3 seems to perform binary classification using thresholding to the logits. But how do you find these results also hold for cross-entropy loss?
“The results confirm the behaviour observed in Experiment 2, but in the case of classification tasks with categorical cross-entropy loss.”


Nit: p3 ReLu -&gt; ReLU / p5 k \in {50, 100, … 350, 400} (close bracket) / p5 in Experiment 2 and 3 descriptions the order of Figure appears flipped. Easier to read if the figure appears as the paper reads / p7 Equation 11 [0, 1]^m
</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">7: Good paper, accept</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">3: The reviewer is fairly confident that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_Skx74sew6X" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Response to Reviewer 1</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=r1gR2sC9FX&amp;noteId=Skx74sew6X"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper757 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">12 Nov 2018 (modified: 13 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper757 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Thank you for your insightful comments and thought provoking questions! 

**On the choice of activation**:

&gt; It is an interesting question whether the behaviour characterized by the authors are universal. 

Indeed! We suspect it is fairly common for the usual activation functions. For instance, Xu et al (2018) (in an independent work made available online shortly after ours) show the same behaviour for deep networks with sigmoid/tanh activation. 

**On clarify of Section 4**:

Thanks for this valuable feedback. Section 4 has been streamlined. We hope it's nicer to read now!

**On the practical significance of the results**: 

We believe that the potent toolbox of Fourier analysis has a lot of unharnessed potential for shedding light on fundamental issues like generalization (e.g. from a sampling theory perspective - under what conditions can the target function be reconstructed from samples?) and adversarial examples (e.g. from the perspective of sensitivity analysis under data-distributions supported on low-dimensional manifolds). We view the spectral bias as an important Fourier domain consequence of the prior of neural net parameterization, and as such, expect it to play an important role in future work. 

**About your comments/questions**:

&gt; Do you understand why and does Fourier spectrum provide insights into layerwise behaviour?

We consider it an exciting open question! We tried to look for a pattern in the layer-wise behaviour of the spectral norms, but did not find anything statistical significant over multiple runs (except that they were consistently increasing, see e.g. this plot: <a href="https://imgur.com/a/rCbAW47" target="_blank" rel="nofollow">https://imgur.com/a/rCbAW47</a> ). 

&gt; how do you find these results also hold for cross-entropy loss?

We might not have been clear enough on the set up of Experiment 3: in fact we do use cross-entropy loss there. We threshold a sinusoid at 0.5, and train a network on the resulting binary target signal using binary cross-entropy loss (we use Pytorch's BCEWithLogitsLoss, which takes a sigmoid internally). The "categorical" is indeed a typo, it should be "binary". We have rephrased the corresponding lines in the latest revision and hope it's clearer now. We have also fixed the typos you found (thank you!).

In closing: 

Thank you for the positive feedback. We hope to have adequately addressed your concerns.  

[Xu et al 2018] https://arxiv.org/abs/1807.01251</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div></div></main></div>
  </div>
</div>


    <!-- Footer -->
    <footer class="sitemap">
      <div class="container">
        <div class="row hidden-xs">
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/venues">All Venues</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="/contact">Contact</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
    
        <div class="row visible-xs-block">
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/contact">Contact</a></li>
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
      </div>
    </footer>
    
    <footer class="sponsor">
      <div class="container">
        <div class="row">
          <div class="col-sm-10 col-sm-offset-1">
            <p class="text-center">
              OpenReview is created by the <a href="http://www.iesl.cs.umass.edu/" target="_blank">Information Extraction and Synthesis Laboratory</a>, College of Information and Computer Science, University of Massachusetts Amherst. We gratefully acknowledge the support of the OpenReview sponsors:  Google,  Facebook, NSF, the University of Massachusetts Amherst Center for Data Science, and Center for Intelligent Information Retrieval, as well as the Google Cloud Platform for donating the computing and networking services on which OpenReview.net runs.
            </p>
          </div>
        </div>
      </div>
    </footer>

  <div id="feedback-modal" class="modal fade" tabindex="-1" role="dialog">
    <div class="modal-dialog">
      <div class="modal-content">
        <div class="modal-header">
          <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button>
          <h3 class="modal-title">Send Feedback</h3>
        </div>
        <div class="modal-body">
          <p>Enter your feedback below and we'll get back to you as soon as possible.</p>
          <form action="/feedback" method="POST">
            <div class="form-group">
              <input type="email" name="from" class="form-control" placeholder="Email" />
            </div>
            <div class="form-group">
              <input type="text" name="subject" class="form-control" placeholder="Subject" />
            </div>
            <div class="form-group">
              <textarea name="message" class="form-control feedback-input" rows="5" placeholder="Message" required=""></textarea>
            </div>
          <ul id="ui-id-2" tabindex="0" class="ui-menu ui-widget ui-widget-content" style="display: none;"></ul></form>
        </div>
        <div class="modal-footer">
          <button type="button" class="btn btn-default" data-dismiss="modal">Cancel</button>
          <button type="button" class="btn btn-primary">Send</button>
        </div>
      </div>
    </div>
  </div>

  <script type="text/javascript" async="" src="https://www.google-analytics.com/analytics.js"></script><script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js"></script>
  <script>window.jQuery || document.write('&lt;script src="/static/js/vendor/jquery-2.2.4.min.js"&gt;&lt;\/script&gt;')</script>

  <script src="/static/dist/vendor.min.js"></script>
  <script src="/static/dist/templates.min.js"></script>
  <script src="/static/dist/openreview.min.js"></script>

    <script>window.legacyScripts = true;</script>


    <script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-108703919-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() { dataLayer.push(arguments); }
      gtag('js', new Date());
      gtag('config', 'UA-108703919-1');
    </script>


<div role="status" aria-live="assertive" aria-relevant="additions" class="ui-helper-hidden-accessible"></div></body></html>
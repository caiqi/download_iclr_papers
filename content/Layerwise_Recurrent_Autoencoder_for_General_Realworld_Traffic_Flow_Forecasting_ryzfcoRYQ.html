<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" class="no-js"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>Layerwise Recurrent Autoencoder for General Real-world Traffic Flow Forecasting | OpenReview</title>
  <meta name="description" content="" />

      <meta name="citation_title" content="Layerwise Recurrent Autoencoder for General Real-world Traffic Flow Forecasting" />
        <meta name="citation_author" content="Anonymous" />
      <meta name="citation_publication_date" content="2018/09/27" />
      <meta name="citation_online_date" content="2018/09/27" />
      <meta name="citation_pdf_url" content="https://openreview.net/pdf?id=ryzfcoR5YQ" />
      <meta name="twitter:card" content="summary" />
      <meta name="twitter:site" content="@openreviewnet" />
      <meta name="og:title" content="Layerwise Recurrent Autoencoder for General Real-world Traffic Flow..." />
      <meta name="og:description" content="Accurate spatio-temporal traffic forecasting is a fundamental task that has wide applications in city management, transportation area and financial domain. There are many factors that make this..." />
      <meta name="og:image" content="https://openreview.net/static/images/openreview_logo_512.png" />

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans:400,400i,700,700i" />

  <link rel="stylesheet" href="/static/css/bootstrap.min.css" />
  <link rel="stylesheet" href="/static/css/jquery-ui.min.css" />
  <link rel="stylesheet" href="/static/css/main.min.css" />
</head>

<body class="forum">
  <nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
  
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand home push-link" href="/"><strong>OpenReview</strong>.net</a>
      </div>
  
      <div id="navbar" class="navbar-collapse collapse">
        <form class="navbar-form navbar-left profile-search" role="search">
          <div class="form-group has-feedback">
            <input id="search_input" type="text" class="form-control ui-autocomplete-input" placeholder="Search ICLR 2019 Conference" autocomplete="off" />
            <span class="glyphicon glyphicon-search form-control-feedback" aria-hidden="true"></span>
          </div>
  
          <input id="search_group" type="hidden" value="ICLR.cc/2019/Conference" />
          <input id="search_content" type="hidden" value="all" />
        <ul id="ui-id-1" tabindex="0" class="ui-menu ui-widget ui-widget-content ui-autocomplete ui-front" style="display: none;"></ul></form>
  
        <ul class="nav navbar-nav navbar-right">
        
            <li id="user-menu"><a href="/login">Login</a></li>
        </ul>
      </div>
  
    </div>
  </nav>

  <div id="or-banner" class="banner" style="">
  <div class="container">
    <div class="row">
      <div class="col-xs-12"><a href="/group?id=ICLR.cc/2019/Conference" title="Venue Homepage"><img class="icon" src="/static/images/arrow_left.svg" /> Go to <strong>ICLR 2019 Conference</strong> homepage</a></div>
    </div>
  </div>
</div>
<div id="flash-message-container" class="alert alert-danger" role="alert" style="display: none;">
  <div class="container">
    <div class="row">
      <div class="col-xs-12">
        <div class="alert-content">
          <button type="button" class="close" aria-label="Close"><span aria-hidden="true">Ã—</span></button>
        </div>
      </div>
    </div>
  </div>
</div>

<div class="container">
  <div class="row">
    <div class="col-xs-12">
      <main id="content" class="clearfix openbanner-visible legacy-styles"><div id="note_ryzfcoR5YQ" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Layerwise Recurrent Autoencoder for General Real-world Traffic Flow Forecasting</a> <a class="note_content_pdf" href="/pdf?id=ryzfcoR5YQ" title="Download PDF" target="_blank"><img src="/static/images/pdf_icon_blue.svg" /></a> </h2></div><div class="meta_row"><span class="signatures">Anonymous</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">28 Sep 2018 (modified: 11 Oct 2018)</span><span class="item">ICLR 2019 Conference Blind Submission</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span><span class="item"><a class="action-bibtex-modal" data-bibtex="@inproceedings{    &#10;anonymous2019layerwise,    &#10;title={Layerwise Recurrent Autoencoder for General Real-world Traffic Flow Forecasting},    &#10;author={Anonymous},    &#10;booktitle={Submitted to International Conference on Learning Representations},    &#10;year={2019},    &#10;url={https://openreview.net/forum?id=ryzfcoR5YQ},    &#10;note={under review}    &#10;}">Show Bibtex</a></span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Abstract: </span><span class="note_content_value">Accurate spatio-temporal traffic forecasting is a fundamental task that has wide applications in city management, transportation area and financial domain. There are many factors that make this significant task also challenging, like: (1) maze-like road network makes the spatial dependency complex; (2) the traffic-time relationships bring non-linear temporal complication; (3) with the larger road network, the difficulty of flow forecasting grows. The prevalent and state-of-the-art methods have mainly been discussed on datasets covering relatively small districts and short time span, e.g., the dataset that is collected within a city during months. To forecast the traffic flow across a wide area and overcome the mentioned challenges, we design and propose a promising forecasting model called Layerwise Recurrent Autoencoder (LRA), in which a three-layer stacked autoencoder (SAE) architecture is used to obtain temporal traffic correlations and a recurrent neural networks (RNNs) model for prediction. The convolutional neural networks (CNNs) model is also employed to extract spatial traffic information within the transport topology for more accurate prediction. To the best of our knowledge, there is no general and effective method for traffic flow prediction in large area which covers a group of cities. The experiment is completed on such large scale real-world traffic datasets to show superiority. And a smaller dataset is exploited to prove universality of the proposed model. And evaluations show that our model outperforms the state-of-the-art baselines by 6% - 15%.</span></div><div class="note_contents"><span class="note_content_field">Keywords: </span><span class="note_content_value">traffic flow forecasting, spatiotemporal dependencies, deep learning, intelligent transportation system</span></div><div class="note_contents"><span class="note_content_field">TL;DR: </span><span class="note_content_value">We propose Layerwise Recurrent Autoencoder with effective spatiotemporal dependencies modeling for general traffic flow forecasting.</span></div><div class="reply_row clearfix"><div class="item" id="reply_count">7 Replies</div></div></div><hr class="small" /><div id="note_children"><div class="note_with_children"><div id="note_H1lJ6bITn7" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Confused...</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=ryzfcoR5YQ&amp;noteId=H1lJ6bITn7"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper517 AnonReviewer1</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">05 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper517 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">I am sorry but I am super confused with this paper. There is no clarity and about half of the sentences are written with broken english. 

The model (as far as I can understand from the partial explanations and Figure 2) looks like a kitchen sink -- a combination of pieces from previously explored methods in the context of traffic flow estimation. This might be fine, but there is no motivation provided for this. 

Rather than spending the method section with repeating well known Loss equations, KL-divergence, convolution, etc... Please focus on the architecture provided in the paper and the motivations behind it. More importantly, how it differs from previous approaches and why these choices have been made. 

This paper is not ready for publication. It needs a re-write at least, preferably working out the original motivations behind architectural choices. </span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">4: Ok but not good enough - rejection</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">3: The reviewer is fairly confident that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_rkxDV6Bt6m" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Reply for Reviewer1</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=ryzfcoR5YQ&amp;noteId=rkxDV6Bt6m"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper517 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">14 Nov 2018</span><span class="item">ICLR 2019 Conference Paper517 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Thanks for your review and sorry for the confusions.

In the proposed model, there are three main parts and the motivations behind them are listed here:

SAE: Regardless of the complex traffic trend, the SAE can stably extract implicit high-level features, which have almost the same characteristics as the original input. Besides, the general purpose of using SAE is to reduce the data dimension, this is also a motivation of exploiting SAE. Proved by experiments in Section 4.2, with SAE, the loss value of the model can drop quickly.

RNN: As the commonly used method on time series prediction, RNN was used to process the implicit high-level features extracted by SAE. By the way, we used a layer-wise structured model, which was inspired by Deep Spatio-Temporal Residual Networks for Citywide Crowd Flows Prediction. The structure provided the model a conception of multiple perspectives, that considered three sequence of history data (current time volume, the volume of the time one week ago and the volume of the time four weeks ago). The model can not only learn the peak-valley periods of traffic in days, but learn the peak-valley periods in weeks.

GCN: The motivation of using GCN was because the use of driving distance. Originally, we take driving distance, rather than Euclid distance to build spatial dependency. And based on driving distance, a graph-based matrix was built, which records the correlation between different sensors. As a result, graph convolutional network is used to learn prior knowledge in graph-based matrix, and it is regarded as an important factor in traffic forecasting. In Deep Spatio-Temporal Residual Networks for Citywide Crowd Flows Prediction, the authors used the traffic volume in region blocks to forecast traffic volume, but didn't consider the spatial correlations.

These are our motivation of proposed model, if you have further questions, please let us know.
</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div><div class="note_with_children"><div id="note_BkgiKcMihQ" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>significant clarification needed</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=ryzfcoR5YQ&amp;noteId=BkgiKcMihQ"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper517 AnonReviewer2</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">03 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper517 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">This paper has potential, but I do not think it is ready for publication. I will ask some questions / make some suggestions:

1) Your first sentence makes a claim about there being a large body of research on traffic flow forecasting. I don't doubt this, but you should cite some papers, please.

2) Your contributions raise the following questions for me: 

- Contribution 1 is that you use a very large dataset (for training? you don't say.) and a small dataset (for testing), thus proving that your method works and generalizes. Your method may be effective, but compared to what? Your method may generalize, but how do we know that if you've only tested it on one small dataset?

- Contribution 2 says that you creatively used lagged data in a time series model. This is probably a good idea, but it does not sound all that creative to me, compare with, e.g. an AR model.

- Contribution 3 says that you use driving distance to model spatial correlation. Again, this is probably a good idea, and when we get further we learn that you applied a Graph Convolution Network. Were these the choices that you claim are novel? Are they novel? What other choices might be reasonable and how would they compare?

3) Section 3 immediately jumps into the use of autoencoders. But I think you need to justify why we care about using autoencoders in the first place. If the problem is traffic forecasting, why don't you tackle that problem head on?

4) Section 3 mentions sparsity without justifying why I care about sparsity. This might be an important tool for regularization in a deep neural network. Or it might not be--given enough data and other regularization techniques (weight decay, early stopping, dropout).

5) Is the spatial dependency that you end up learning qualitatively different than the spatial dependency you would get by instead assuming a particular parametric form as is done in kernel methods / Gaussian processes, e.g. the Gaussian kernel or the Matern kernel parameterizes the covariance between observations at two spatial locations?

6) In your experiment I believe you randomly split 15 minute blocks into train/test/validate. I think this evaluation will be over-optimistic insofar as if 10:30-10:45 and 11:00-11:15 are in the train set, but 10:45-11:00 is in the test set, it will be relatively easy to predict 10:45-11:00. I would suggest considering train/test/validate splits based on larger chunks, e.g. leave the data in 15 minute blocks, but randomly select hours (4 blocks) to put in train/test/validate.</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">5: Marginally below acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">3: The reviewer is fairly confident that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_rJlQtpHta7" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Reply for Reviewer2</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=ryzfcoR5YQ&amp;noteId=rJlQtpHta7"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper517 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">14 Nov 2018</span><span class="item">ICLR 2019 Conference Paper517 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Thanks for your review comments. Here's our reply:

1)	You are right, we should cite some publications to support it.

2)	As for our contribution one, the purpose we take experiments on both large and small datasets is to test the generalization of our network. Therefore, we trained our model on both large and small datasets, and tested with these two datasets. We compared our outputs with many baselines in Section 4, on both datasets, please check this in our paper.

As for contribution two, we employed three different time series sequences to provide multi-perspective fusion learning. With the layer-wise structure, the daily and weekly periodic features of traffic volume are captured. In another word, a stack of historical sequence data is used in our experiments, rather than "lagged" time data.

In the contribution three, we used driving distance to determine the spatial dependency, and this contribution was novel. And with the driving distance, we built a graph-based matrix, as a result, we then applied GCN to learn the inner features from the graph-based matrix. The use of GCN was inspired by one of our baselines, DCRNN (Diffusion convolutional recurrent neural network: Data-driven traffic forecasting). In DCRNN, they designed an experiment of comparing their diffusion method with the use of GCN. In their experiment, the result of diffusion method was better than GCN, but their dataset was not so large as ours, and when we compare their method with our datasets, the performance was not so good, even in our smaller dataset. Hence, we think the application of GCN in forecasting task is also novel.

3)	The reason why SAE is the first operator in the network is to extract stable high-level temporal features. We put this part in the beginning of Section 3. And the use of SAE do help the performance of forecasting, please check the content in Section 4.3.

4)	The sparsity of SAE was a proved solution of overfitting in practice. And the key of our paper was to provide a novel method for general forecasting task, therefore, we don't put much words on other choice, but just use sparsity as a common knowledge.

5)	The spatial dependency was determined by driving distance in our paper, and that should be a certain process, rather an assumption. Since the aim of our model was to provide accurate prediction in general situations, and the spatial dependency is crucial, since the spatial dependency is variable in different places. With driving distance and GCN, the model can grasp the most precise priori knowledge of spatial locations.

6)	In fact, we select the time based on a scheme, not randomly. Take the large dataset as example, we have 365 days of traffic data, and the first 80% are randomly divided into training sets and validation sets with a ratio of 7:1, i.e. 255 days for training, and 37 days for evaluation. The remaining 20% (73 days) is used as test sets. We believe this division method is closer to real use.

If you have further questions, we are happy to discuss with you.
</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div><div class="note_with_children"><div id="note_H1xTDOudh7" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Potentially interesting, though large omissions make this difficult to follow</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=ryzfcoR5YQ&amp;noteId=H1xTDOudh7"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper517 AnonReviewer3</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">01 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper517 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">The paper uses a number of deep learning approaches to analyse sets of Traffic data. However, as these sets of traffic data are never explained it is difficult to follow or understand what is going on here.

Some major comments:
1) Many of the key concepts in the paper are not discussed. The primary one would be that of what the two data sets contain. Without knowledge of this it is difficult to ascertain what is going on. 

2) Many of the processes used are not described in enough detail to either understand what is going on or to re-produce the work. Without this it is difficult to make headway wit the work.

3) It is not clearly articulated what the experiments performed are doing. For example, how have you applied the other techniques to this data?

4) Key terms are not defined. Such as Traffic Flow.

5) The English structure of the paper is poor with many mistakes. A thorough proof-reading is essential.

Some more specific points:
- "with the larger road network, the difficulty of flow forecasting grows." - This seems to be a consequence of the other ones not a challenge in it's own right.

- What is "superiority"?

- "Spatiotemporal traffic flow forecasting task is currently under a heated discussion and has attracted a large research population." - evidence to back up this statement.

- Your contributions aren't contributions, but rather a list of what you have done.

- How does your related work relate to what you have done?

- Hard to parse "To extract temporal relationships within the history traffic flows, we model this process as a layering structure with autoencoder as cell"

- Appendices B and C should be in the main paper.

- What is in x^{(1)}?

- "When take the sparsity constrains into consideration" - what are the sparsity constraints?

- How do you obtain the weights?

- Figure 2 should come much sooner as it relates a lot of the concepts together.

- "On both datasets, we slice traffic flow information into 15 minutes windows, where 70% of data is for training, 10% for validation and remaining 20% for testing." - Is that each 15 mins is split 70:10:20?

- Proof by example is not a proof.
</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">3: Clear rejection</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_Syxx2arKa7" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Reply for Reviewer3</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=ryzfcoR5YQ&amp;noteId=Syxx2arKa7"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper517 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">14 Nov 2018</span><span class="item">ICLR 2019 Conference Paper517 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Thanks for your comments. Here's our reply:

For your major comments: 
1)	The two datasets are introduced in the Appendix C, even with a distribution of sensors of the larger one. Please check it in our paper.
2)	We listed some key parameters in Appendix D, we believe with information of our paper, the readers can easily re-produce our work with Tensorflow. Of course, it would be easier if we make our code public, but the intellectual property right was kept by our company, and will be used in business projects. If the time is proper, the code would be released.
3)	The experiments are performed to show the better performance of our method over others, and the efficiency of our design of the network (SAE and GCN in Section 4.3), we think the experiments are clear in Section 4, including the other techniques (AR, ARIMA, ESN, LSTM and DCRNN). Please check our paper, especially in Section 4.
4)	Traffic flow is a common terminology in traffic-related forecasting area, which means the number of moving pedestrians or cars in traffic network.
5)	Yes, we agree that our language skills are poor, and needed to be improved.

Specific points:
1)	It is natural in traffic forecasting that the more complex the road topology is the harder prediction would be. Since the complexity of traffic condition would exponentially grow with the larger traffic network.
2)	The superiority means "better performance", that we originally use driving distance to build spatial dependency, and our model is generalized for traffic forecasting in both large and small datasets.
3)	Yes, this sentence should be supported with citations.
4)	Sorry for giving you this impression, might because of our English skills, but this paper do have some novel contributions. This paper is focused on the design of the model and the originality of our model. We also compared the proposed model with other baselines, to show the efficiency and generalization.
5)	The related works are common forecasting methods and classified in two categories: statistic methods and deep learning methods. We selected some representative methods in both categories as baselines to compare with our model. And we also used some ideas from the related works (Diffusion convolutional recurrent neural network: Data-driven traffic forecasting and Deep Spatio-Temporal Residual Networks for Citywide Crowd Flows Prediction)
6)	To extract temporal relationships within the history traffic flows, we took SAE in the layer-wise structure as a basic unit to extract stable high-level temporal features, which is the preparation of traffic prediction.
7)	We put Appendix B in the end because we think the structures of autoencoder and SAE should be familiar in the forecasting field, and only for reference. The reason Appendix C was put behind the main body is because we want to keep the integrity and fluency in the experiment section.
8)	This is our fault, x^{(1)} is the input sequence of autoencoder, we should make it more clear.
9)	Sparsity constrain is sparsity, but in another presentation. When sparsity constraints are added to the objective function, an autoencoder becomes a sparse autoencoder, which considers the sparse representation of the hidden layer. Sparsity is used to avoid over-fitting.
10)	The weights can be obtained by some API of Tensorflow, and during the training process, they are trained by BP method.
11)	We think it would be better for reading experiment that reader can know the structure of model, before he sees it.
12)	Take the large dataset as example, we have 365 days of traffic data, and the first 80% are randomly divided into training sets and validation sets with a ratio of 7:1, i.e. 255 days for training, and 37 days for evaluation. The remaining 20% (73 days) is used as test sets. We believe this division method is closer to real use.
13)	We don't get your point in your comment, could you please make it clear?

Hope our explanations can help you to understand our paper.
</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div><div class="note_with_children"><div id="note_SJeKCW7scm" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Announcement of a typo</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=ryzfcoR5YQ&amp;noteId=SJeKCW7scm"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper517 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">10 Oct 2018</span><span class="item">ICLR 2019 Conference Paper517 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">We found a typo that may lead misunderstanding in the table 1, the MAE value of DCRNN and our LRA in ST-WB dataset with 15 min window should be 34.24 and 30.56 relatively. 

Sorry for the ambiguousness caused by our fault, if you have any other questions, please feel free to ask us.</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></main></div>
  </div>
</div>


    <!-- Footer -->
    <footer class="sitemap">
      <div class="container">
        <div class="row hidden-xs">
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/venues">All Venues</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="/contact">Contact</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
    
        <div class="row visible-xs-block">
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/contact">Contact</a></li>
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
      </div>
    </footer>
    
    <footer class="sponsor">
      <div class="container">
        <div class="row">
          <div class="col-sm-10 col-sm-offset-1">
            <p class="text-center">
              OpenReview is created by the <a href="http://www.iesl.cs.umass.edu/" target="_blank">Information Extraction and Synthesis Laboratory</a>, College of Information and Computer Science, University of Massachusetts Amherst. We gratefully acknowledge the support of the OpenReview sponsors:  Google,  Facebook, NSF, the University of Massachusetts Amherst Center for Data Science, and Center for Intelligent Information Retrieval, as well as the Google Cloud Platform for donating the computing and networking services on which OpenReview.net runs.
            </p>
          </div>
        </div>
      </div>
    </footer>

  <div id="feedback-modal" class="modal fade" tabindex="-1" role="dialog">
    <div class="modal-dialog">
      <div class="modal-content">
        <div class="modal-header">
          <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">Ã—</span></button>
          <h3 class="modal-title">Send Feedback</h3>
        </div>
        <div class="modal-body">
          <p>Enter your feedback below and we'll get back to you as soon as possible.</p>
          <form action="/feedback" method="POST">
            <div class="form-group">
              <input type="email" name="from" class="form-control" placeholder="Email" />
            </div>
            <div class="form-group">
              <input type="text" name="subject" class="form-control" placeholder="Subject" />
            </div>
            <div class="form-group">
              <textarea name="message" class="form-control feedback-input" rows="5" placeholder="Message" required=""></textarea>
            </div>
          <ul id="ui-id-2" tabindex="0" class="ui-menu ui-widget ui-widget-content" style="display: none;"></ul></form>
        </div>
        <div class="modal-footer">
          <button type="button" class="btn btn-default" data-dismiss="modal">Cancel</button>
          <button type="button" class="btn btn-primary">Send</button>
        </div>
      </div>
    </div>
  </div>

  <script type="text/javascript" async="" src="https://www.google-analytics.com/analytics.js"></script><script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js"></script>
  <script>window.jQuery || document.write('&lt;script src="/static/js/vendor/jquery-2.2.4.min.js"&gt;&lt;\/script&gt;')</script>

  <script src="/static/dist/vendor.min.js"></script>
  <script src="/static/dist/templates.min.js"></script>
  <script src="/static/dist/openreview.min.js"></script>

    <script>window.legacyScripts = true;</script>


    <script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-108703919-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() { dataLayer.push(arguments); }
      gtag('js', new Date());
      gtag('config', 'UA-108703919-1');
    </script>


<div role="status" aria-live="assertive" aria-relevant="additions" class="ui-helper-hidden-accessible"></div></body></html>
<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" class="no-js"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>Combinatorial Attacks on Binarized Neural Networks | OpenReview</title>
  <meta name="description" content="" />

      <meta name="citation_title" content="Combinatorial Attacks on Binarized Neural Networks" />
        <meta name="citation_author" content="Anonymous" />
      <meta name="citation_publication_date" content="2018/09/27" />
      <meta name="citation_online_date" content="2018/09/27" />
      <meta name="citation_pdf_url" content="https://openreview.net/pdf?id=S1lTEh09FQ" />
      <meta name="twitter:card" content="summary" />
      <meta name="twitter:site" content="@openreviewnet" />
      <meta name="og:title" content="Combinatorial Attacks on Binarized Neural Networks" />
      <meta name="og:description" content="Binarized Neural Networks (BNNs) have recently attracted significant interest due to their computational efficiency. Concurrently, it has been shown that neural networks may be overly sensitive to..." />
      <meta name="og:image" content="https://openreview.net/static/images/openreview_logo_512.png" />

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans:400,400i,700,700i" />

  <link rel="stylesheet" href="/static/css/bootstrap.min.css" />
  <link rel="stylesheet" href="/static/css/jquery-ui.min.css" />
  <link rel="stylesheet" href="/static/css/main.min.css" />
</head>

<body class="forum">
  <nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
  
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand home push-link" href="/"><strong>OpenReview</strong>.net</a>
      </div>
  
      <div id="navbar" class="navbar-collapse collapse">
        <form class="navbar-form navbar-left profile-search" role="search">
          <div class="form-group has-feedback">
            <input id="search_input" type="text" class="form-control ui-autocomplete-input" placeholder="Search ICLR 2019 Conference" autocomplete="off" />
            <span class="glyphicon glyphicon-search form-control-feedback" aria-hidden="true"></span>
          </div>
  
          <input id="search_group" type="hidden" value="ICLR.cc/2019/Conference" />
          <input id="search_content" type="hidden" value="all" />
        <ul id="ui-id-1" tabindex="0" class="ui-menu ui-widget ui-widget-content ui-autocomplete ui-front" style="display: none;"></ul></form>
  
        <ul class="nav navbar-nav navbar-right">
        
            <li id="user-menu"><a href="/login">Login</a></li>
        </ul>
      </div>
  
    </div>
  </nav>

  <div id="or-banner" class="banner" style="">
  <div class="container">
    <div class="row">
      <div class="col-xs-12"><a href="/group?id=ICLR.cc/2019/Conference" title="Venue Homepage"><img class="icon" src="/static/images/arrow_left.svg" /> Go to <strong>ICLR 2019 Conference</strong> homepage</a></div>
    </div>
  </div>
</div>
<div id="flash-message-container" class="alert alert-danger" role="alert" style="display: none;">
  <div class="container">
    <div class="row">
      <div class="col-xs-12">
        <div class="alert-content">
          <button type="button" class="close" aria-label="Close"><span aria-hidden="true">×</span></button>
        </div>
      </div>
    </div>
  </div>
</div>

<div class="container">
  <div class="row">
    <div class="col-xs-12">
      <main id="content" class="clearfix openbanner-visible legacy-styles"><div id="note_S1lTEh09FQ" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Combinatorial Attacks on Binarized Neural Networks</a> <a class="note_content_pdf" href="/pdf?id=S1lTEh09FQ" title="Download PDF" target="_blank"><img src="/static/images/pdf_icon_blue.svg" /></a> </h2></div><div class="meta_row"><span class="signatures">Anonymous</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">28 Sep 2018 (modified: 11 Oct 2018)</span><span class="item">ICLR 2019 Conference Blind Submission</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span><span class="item"><a class="action-bibtex-modal" data-bibtex="@inproceedings{    &#10;anonymous2019combinatorial,    &#10;title={Combinatorial Attacks on Binarized Neural Networks},    &#10;author={Anonymous},    &#10;booktitle={Submitted to International Conference on Learning Representations},    &#10;year={2019},    &#10;url={https://openreview.net/forum?id=S1lTEh09FQ},    &#10;note={under review}    &#10;}">Show Bibtex</a></span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Abstract: </span><span class="note_content_value">Binarized Neural Networks (BNNs) have recently attracted significant interest due to their computational efficiency. Concurrently, it has been shown that neural networks may be overly sensitive to "attacks" -- tiny adversarial changes in the input -- which may be detrimental to their use in safety-critical domains. Designing attack algorithms that effectively fool trained models is a key step towards learning robust neural networks.
The discrete, non-differentiable nature of BNNs, which distinguishes them from their full-precision counterparts, poses a challenge to gradient-based attacks. In this work, we study the problem of attacking a BNN through the lens of combinatorial and integer optimization. We propose a Mixed Integer Linear Programming (MILP) formulation of the problem. While exact and flexible, the MILP quickly becomes intractable as the network and perturbation space grow. To address this issue, we propose IProp, a decomposition-based algorithm that solves a sequence of much smaller MILP problems. Experimentally, we evaluate both proposed methods against the standard gradient-based attack (FGSM) on MNIST and Fashion-MNIST, and show that IProp performs favorably compared to FGSM, while scaling beyond the limits of the MILP.</span></div><div class="note_contents"><span class="note_content_field">Keywords: </span><span class="note_content_value">binarized neural networks, combinatorial optimization, integer programming</span></div><div class="note_contents"><span class="note_content_field">TL;DR: </span><span class="note_content_value">Gradient-based attacks on binarized neural networks are not effective due to the non-differentiability of such networks; Our IPROP algorithm solves this problem using integer optimization</span></div><div class="reply_row clearfix"><div class="item" id="reply_count">10 Replies</div></div></div><hr class="small" /><div id="note_children"><div class="note_with_children"><div id="note_r1lwasqC37" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Weak baselines </a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=S1lTEh09FQ&amp;noteId=r1lwasqC37"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">(anonymous)</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">06 Nov 2018</span><span class="item">ICLR 2019 Conference Paper1495 Public Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">While the motivation for studying attacks on binarized is not quite clear to me, I would like to point out that there are much stronger baselines than FGSM for attacking discrete, non-differentiable networks. In particular, several prior works have attempted to suggest binarization as a plausible defense and have evaluated their proposal by coming up with various attacks, all of which were subsequently broken because their attack method was weak compared to PGD [1] (and BPDA) [2]. So it is not sufficient to just compare against FGSM (as some reviewers have also pointed out).

[1] <a href="https://arxiv.org/abs/1706.06083" target="_blank" rel="nofollow">https://arxiv.org/abs/1706.06083</a>
[2] https://arxiv.org/abs/1802.00420</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_S1eiXngK6Q" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Our FGSM is indeed PGD</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=S1lTEh09FQ&amp;noteId=S1eiXngK6Q"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1495 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">14 Nov 2018</span><span class="item">ICLR 2019 Conference Paper1495 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Thank you for taking the time to read our paper!

We just responded to the reviews with the following:
"In our paper, FGSM refers to “iterated FGSM” or “multi-step FGSM” or PGD (these are all referring to the same method, e.g. see page 4 of <a href="https://arxiv.org/abs/1706.06083)." target="_blank" rel="nofollow">https://arxiv.org/abs/1706.06083).</a> We make that clear in section 2: “Soon thereafter, an iterative variant of FGSM was shown to produce much more effective attacks (Kurakin et al., 2016); it is this version of FGSM that we will compare against in this work.”. In fact, we run iterated FGSM/PGD for 3 minutes (same as MIP and IProp) with random restarts every 100 iterations. This provides FGSM with the same computational budget as IProp. We will update the paper to clarify this point in the experiments section."</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_H1l0z6X9a7" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Please use standard terminology</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=S1lTEh09FQ&amp;noteId=H1l0z6X9a7"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures"><a href="/profile?id=~Nicholas_Carlini1" class="profile-link">Nicholas Carlini</a></span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">15 Nov 2018</span><span class="item">ICLR 2019 Conference Paper1495 Public Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">FGSM is a specific attack defined by Goodfellow et al. This attack takes one step in the direction of the gradient.

If you are using a different attack---the "Basic Iterative Method" from Kurakin et al., say---then you should call it by that attack name, and don't call it FGSM. This is misleading.
</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_rJejIzN5Tm" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Will do</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=S1lTEh09FQ&amp;noteId=rJejIzN5Tm"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1495 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">15 Nov 2018</span><span class="item">ICLR 2019 Conference Paper1495 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Thanks for your comment.

We agree: since the name Projected Gradient Descent (PGD) has been widely adopted to refer to the iterative version (as popularized in <a href="https://arxiv.org/abs/1706.06083," target="_blank" rel="nofollow">https://arxiv.org/abs/1706.06083,</a> page 4), we will update the paper to use PGD throughout.</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div></div></div></div></div><div class="note_with_children"><div id="note_HkxFLc32nX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Interesting and novel idea, needs more experimental validation</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=S1lTEh09FQ&amp;noteId=HkxFLc32nX"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1495 AnonReviewer1</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">05 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper1495 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">The authors study the problem of generating strong adversarial attacks on binarized neural networks (networks whose weights are binary valued and have a sign function nonlinearity).  Since these networks are not continuous (due to the sign function nonlinearity), it is possible that standard gradient-based attack algorithms are not effective at producing adversarial examples. While this problem can be encoded as a mixed integer linear program, off-the-shelf MILP solvers are not scalable to larger/deeper networks. Thus, the authors propose a new target propagation style algorithm that attempts to infer desired activations at each layer (from the perspective of maximizing the adversary's objective) starting at the final layer and moving towards the input. The propagation at each layer requires solving another MILP (albeit a much smaller one). Further, in order to prevent the target propagation from discovering assignments at upper layers that are unachievable given the constraints at lower layers, the authors propose two heuristics (making small moves and penalizing deviations from the previous target values) to obtain an effective attack algorithm. The authors validate their approach experimentally on MNIST/Fashion MNIST image classifiers.

Quality: The paper is reasonably well written and the key ideas are communicated well. However, the experimental section needs to be improved significantly.

Clarity: The paper is easy to understand and organized well.

Originality: The application of target propagation in the context of adversarial examples is certainly novel and so are the specific enhancements proposed in the context of adversarial example generation. The 

Significance: The study of adversarial examples for binarized networks is novel and important and effective attack generation algorithms are a significant first step towards training robust models of this type - this could enable deployment of robust and compact binarized classifiers in on-device settings (where model size is important).

Cons
My main concerns with this paper are regarding the experimental evaluation - I do not feel these are sufficient to justify the strength of the attack method proposed. Here are my broad concerns:
1. Even though the datasets used are small (MNIST/Fashion MNIST), the experimental validation of adversarial attacks is only performed on 100 test examples. This is not sufficiently representative (given experimental evidence with adversarial attacks on non-binarized models) and this needs to be addressed for the results to be considered conclusive.

2. The attack method is only compared to FSGM, which is known to be a rather poor attack even on non-binarized networks. The authors should compare to stronger gradient based attacks (like PGD) and gradient free attacks which have been used to break adversarial defenses that are nondifferentiable in prior work - <a href="https://arxiv.org/abs/1802.00420" target="_blank" rel="nofollow">https://arxiv.org/abs/1802.00420</a> and https://arxiv.org/abs/1802.05666). Further, the MILP approach used can be strengthened by doing better bound propagation (like in https://arxiv.org/pdf/1711.00455.pdf)

3. The attack radii used are very small compared to what has been used in non-binarized networks, where networks have been trained to even be verifiably robust to adversarial pertrubations of much larger radii (see for example https://arxiv.org/pdf/1805.12514.pdf). Given the existence of this work, it is important to evaluate the algorithms proposed on larger radii (since it is possible to construct non-binarized networks that are indeed robust to perburbations of eps=.1-.3 on MNIST).

4. Motivation for binarization: I assume that motivation for binarized models arising from faster training/inference times and smaller model sizes. However, to justify this, the authors need to compare their BNNs to comparable non-binarized neural networks (for example,ones that are similar  in terms of number of bits used to represent the model) on training time, inference time and adversarial robustness. Otherwise, it seems hard to see why binarized networks are valuable from a robustness.

</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">5: Marginally below acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_B1lKEYgtaX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Response to Reviewer 1</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=S1lTEh09FQ&amp;noteId=B1lKEYgtaX"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1495 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">14 Nov 2018</span><span class="item">ICLR 2019 Conference Paper1495 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Thanks for the detailed comments - we believe most of your concerns are clarified below. In particular, our FGSM is the same as the PGD you refer to, as we explain below.

1. We are currently running the same experiments reported in the paper on a much larger set of test images, and will report the updated results as soon as they become available.

2. 
- Regarding PGD: Thanks for raising this point - we already use PGD and will clarify this in writing. In our paper, FGSM refers to “iterated FGSM” or “multi-step FGSM” or PGD (these are all referring to the same method, e.g. see page 4 of <a href="https://arxiv.org/abs/1706.06083)." target="_blank" rel="nofollow">https://arxiv.org/abs/1706.06083).</a> We make that clear in section 2: “Soon thereafter, an iterative variant of FGSM was shown to produce much more effective attacks (Kurakin et al., 2016); it is this version of FGSM that we will compare against in this work.”. In fact, we run iterated FGSM/PGD for 3 minutes (same as MIP and IProp) with random restarts every 100 iterations. This provides FGSM with the same computational budget as IProp. We will update the paper to clarify this point in the experiments section.

- Regarding gradient-free attacks: Thanks for bringing those papers to our attention. The first paper (https://arxiv.org/abs/1802.00420) proposes a method that uses the straight-through estimator to approximate gradients of a non-differentiable network; this is indeed the same trick used for FGSM/PGD on BNNs, and so our comparison with PGD already covers the method BPDA proposed in the paper. Regarding the second paper (https://arxiv.org/pdf/1802.05666.pdf), we are now implementing it and will report on results as soon as they become available.

- Regarding bound propagation: indeed, we already do perform bound propagation since the input images are bounded in a small epsilon-box; the reported MIP results already use bound propagation. We will explicitly mention this in the updated paper.

3. Thank you for the reference to this recent paper. We will consider these additional experiments.

4. The point you raise relates to BNNs in general, rather than to our particular work. BNNs are amenable to fast hardware implementations as in the papers [a-c], which are much harder to achieve for non-binarized networks. As such, we believe it is important to study the robustness of BNNs to attacks, regardless of whether there exists robust non-binarized counterparts of similar size.

[a] Liang, Shuang, et al. "FP-BNN: Binarized neural network on FPGA." Neurocomputing 275 (2018): 1072-1086.
[b] McDanel, Bradley, Surat Teerapittayanon, and H. T. Kung. "Embedded binarized neural networks." arXiv preprint arXiv:1709.02260 (2017).
[c] Yang, Li, Zhezhi He, and Deliang Fan. "A Fully Onchip Binarized Convolutional Neural Network FPGA Impelmentation with Accurate Inference." Proceedings of the International Symposium on Low Power Electronics and Design. ACM, 2018.
</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div><div class="note_with_children"><div id="note_H1xCvGx3hX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>an interesting paper </a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=S1lTEh09FQ&amp;noteId=H1xCvGx3hX"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1495 AnonReviewer2</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">04 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper1495 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">This paper proposed a new attack algorithm based on MILP on binary neural networks. In addition to the full MILP formulation, the authors proposed an integer target propagation algorithm (IProp) to find adversarial examples by solving a smaller (instead of the full) MILP.  

The topic is important but the clarity should be improved. It is less clear when describing the Iprop algorithm.  

Questions:
1. Can IProp work for other architectures? It looks like the propagation steps work on only fully connected layers (or conv layers) with activation functions. Does it work for pooling layers?
2. The results in Figure 2 look weird and might be wrong:
since MIP is the exact solution (green bar), how is it possible that the prediction flip rate of IProp larger than MIP? See top row figures where some red bars are larger than green bars. 
3. Also, is the FGSM method comparing in Figure 2 operating on the approximate BNN as described in the related work? How does the performance of PGD (Madry etal) compared to IProp?  
4. How are the big M parameters in equation 4 and 5 computed? Is the formulation eq (1) to (8) the same as that in Tjeng 2018? Since BNN is a special case of general neural networks. Please elaborate. 
5. In Sec 2 related work, why "there's no objective function" for verification method? </span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">6: Marginally above acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_SyxipoxF6m" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Response to Reviewer 2</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=S1lTEh09FQ&amp;noteId=SyxipoxF6m"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1495 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">14 Nov 2018</span><span class="item">ICLR 2019 Conference Paper1495 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Thank you for taking the time to review our paper. Our answers to your questions are numbered in the same order as your review:

1. Yes, IProp does work for pooling layers, as the layer-to-layer satisfaction problem (section 4.1) can be modified to compute a pooling transformation by adding constraints appropriately. For instance, max/mean pooling are easily implemented with linear inequalities and/or binary variables.

2. we discuss this point at length in section 5.2, page 7. The MIP solver fails to scale to the wider/deeper networks, and thus times out at the 3-minute cutoff. The final solution returned by MIP may thus be suboptimal, which results in green bars being smaller than red bars.

3. (same reply as to reviewer 1) Thanks for raising this point - we already use PGD and will clarify this in writing. In our paper, FGSM refers to “iterated FGSM” or “multi-step FGSM” or PGD (these are all referring to the same method, e.g. see page 4 of <a href="https://arxiv.org/abs/1706.06083)." target="_blank" rel="nofollow">https://arxiv.org/abs/1706.06083).</a> We make that clear in section 2: “Soon thereafter, an iterative variant of FGSM was shown to produce much more effective attacks (Kurakin et al., 2016); it is this version of FGSM that we will compare against in this work.”. In fact, we run iterated FGSM/PGD for 3 minutes (same as MIP and IProp) with random restarts every 100 iterations. This provides FGSM with the same computational budget as IProp. We will update the paper to clarify this point in the experiments section.

4. the big-M values are computed by simply bounding the a_{1,j} variables at the first hidden layer, since the input image is in an epsilon-box. Then, those bounds are passed on to the h_{1,j} variables, i.e. if the lower and upper bounds on a given a_{1,j} are negative, then h_{1,j} must be -1. Those bounds on h_{1,j} are then propagated to the a_{2,j} variables, and so on and so forth. This procedure is simple and runs in time linear in the size of the network. We are happy to describe it in the paper, if the reviewer thinks that would be useful.
Our formulation differs from that of Tjeng in that our constraints (4), (5) and (7) encode the discrete sign activation function and the binary weights.

5. in Narodytska et al. (2018), the goal is to prove that an input to a network cannot be fooled with epsilon perturbations, or provide a counter-example to that. As such, they do not care about maximizing the difference between the incorrect class and the true class as we do. In other words, the verification problem in Narodytska et al. (2018) is a feasibility problem rather than an optimization problem, and so it does not have an explicit objective function.
</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div><div class="note_with_children"><div id="note_H1gJQ_S53m" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Reviewer comments</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=S1lTEh09FQ&amp;noteId=H1gJQ_S53m"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1495 AnonReviewer3</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">03 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper1495 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">This paper presents an algorithm to find adversarial attacks to binary neural networks.  Binary neural networks uses sign functions as nonlinearities, making the network essentially discrete.  Previous attempts at finding adversarial attacks for binary neural networks either rely on relaxation which cannot find very good adversarial examples, or calling a mixed integer linear programming (MILP) solver which doesn’t scale.  This paper proposes to decompose the problem and iteratively find desired representations layer by layer from the top to the input.  This so called Integer Propagation (IProp) algorithm is more efficient than solving the full MILP as it solves much smaller MILP problems, one for each layer, thus each step can be solved relatively quickly.  The authors then proposed a few more improvements to the IProp algorithm, including ways to do local adjustments to the solutions, and warming starting from an existing solution.  Experiments on binary neural nets trained for MNIST and Fashion MNIST show the superiority of the proposed method over MILP and relaxation based algorithms.

Overall I found the paper to be very clear and the proposed method is sound.  I think combining ideas from discrete / combinatorial optimization with deep learning is an important research direction and can shed light on training and verifying models with discrete components, like the hard nonlinearities in the binary neural nets studied in this paper.

In terms of the particular proposed approach, it is hard for me to imagine the blind IProp that does not take the input into account until the last layer is ever going to work.  The small step size modifications make a lot more sense.  Regarding the selection of the set S, in the paper the authors simply sampled elements to be in S uniformly, but it seems possible to make use of the information from the forward pass, and choose the hidden units that are the closed to reaching the desired activations.  Would that be any better?

A few minor comments:
- when reporting warm start results, it would be good to also show the performance of the FGSM solution used for warm starting, in addition to the other two results shown in Figure 6 to have a more complete comparison
- the hidden units h_{l,j} were formulated to be in {0, 1} in equation (7), but everywhere else in the paper they are assumed to be in {-1, +1}, which is not consistent and slightly confusing.

Overall I think this is a solid paper and support accepting it for publication.</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">7: Good paper, accept</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_Bklt8KeKpm" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Response to Reviewer 3</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=S1lTEh09FQ&amp;noteId=Bklt8KeKpm"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1495 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">14 Nov 2018</span><span class="item">ICLR 2019 Conference Paper1495 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Thank you for the positive comments and suggestions!
Regarding the set S: indeed, your suggestion is valid and we have tried it early on. We sampled neurons closer to the threshold (zero) with higher probability than others. We did not observe much improvement over uniform sampling at the time, and thus decided to stick with simple uniform sampling.

Regarding warmstart results: that’s a great point; we will do so in the final version of the paper.

Regarding notation: thanks for catching that; we will make the notation consistent throughout.
</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div></div></main></div>
  </div>
</div>


    <!-- Footer -->
    <footer class="sitemap">
      <div class="container">
        <div class="row hidden-xs">
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/venues">All Venues</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="/contact">Contact</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
    
        <div class="row visible-xs-block">
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/contact">Contact</a></li>
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
      </div>
    </footer>
    
    <footer class="sponsor">
      <div class="container">
        <div class="row">
          <div class="col-sm-10 col-sm-offset-1">
            <p class="text-center">
              OpenReview is created by the <a href="http://www.iesl.cs.umass.edu/" target="_blank">Information Extraction and Synthesis Laboratory</a>, College of Information and Computer Science, University of Massachusetts Amherst. We gratefully acknowledge the support of the OpenReview sponsors:  Google,  Facebook, NSF, the University of Massachusetts Amherst Center for Data Science, and Center for Intelligent Information Retrieval, as well as the Google Cloud Platform for donating the computing and networking services on which OpenReview.net runs.
            </p>
          </div>
        </div>
      </div>
    </footer>

  <div id="feedback-modal" class="modal fade" tabindex="-1" role="dialog">
    <div class="modal-dialog">
      <div class="modal-content">
        <div class="modal-header">
          <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button>
          <h3 class="modal-title">Send Feedback</h3>
        </div>
        <div class="modal-body">
          <p>Enter your feedback below and we'll get back to you as soon as possible.</p>
          <form action="/feedback" method="POST">
            <div class="form-group">
              <input type="email" name="from" class="form-control" placeholder="Email" />
            </div>
            <div class="form-group">
              <input type="text" name="subject" class="form-control" placeholder="Subject" />
            </div>
            <div class="form-group">
              <textarea name="message" class="form-control feedback-input" rows="5" placeholder="Message" required=""></textarea>
            </div>
          <ul id="ui-id-2" tabindex="0" class="ui-menu ui-widget ui-widget-content" style="display: none;"></ul></form>
        </div>
        <div class="modal-footer">
          <button type="button" class="btn btn-default" data-dismiss="modal">Cancel</button>
          <button type="button" class="btn btn-primary">Send</button>
        </div>
      </div>
    </div>
  </div>

  <script type="text/javascript" async="" src="https://www.google-analytics.com/analytics.js"></script><script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js"></script>
  <script>window.jQuery || document.write('&lt;script src="/static/js/vendor/jquery-2.2.4.min.js"&gt;&lt;\/script&gt;')</script>

  <script src="/static/dist/vendor.min.js"></script>
  <script src="/static/dist/templates.min.js"></script>
  <script src="/static/dist/openreview.min.js"></script>

    <script>window.legacyScripts = true;</script>


    <script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-108703919-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() { dataLayer.push(arguments); }
      gtag('js', new Date());
      gtag('config', 'UA-108703919-1');
    </script>


<div role="status" aria-live="assertive" aria-relevant="additions" class="ui-helper-hidden-accessible"></div></body></html>
<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" class="no-js"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>Dynamic Channel Pruning: Feature Boosting and Suppression | OpenReview</title>
  <meta name="description" content="" />

      <meta name="citation_title" content="Dynamic Channel Pruning: Feature Boosting and Suppression" />
        <meta name="citation_author" content="Anonymous" />
      <meta name="citation_publication_date" content="2018/09/27" />
      <meta name="citation_online_date" content="2018/09/27" />
      <meta name="citation_pdf_url" content="https://openreview.net/pdf?id=BJxh2j0qYm" />
      <meta name="twitter:card" content="summary" />
      <meta name="twitter:site" content="@openreviewnet" />
      <meta name="og:title" content="Dynamic Channel Pruning: Feature Boosting and Suppression" />
      <meta name="og:description" content="Making deep convolutional neural networks more accurate typically comes at the cost of increased computational and memory resources. In this paper, we exploit the fact that the importance of..." />
      <meta name="og:image" content="https://openreview.net/static/images/openreview_logo_512.png" />

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans:400,400i,700,700i" />

  <link rel="stylesheet" href="/static/css/bootstrap.min.css" />
  <link rel="stylesheet" href="/static/css/jquery-ui.min.css" />
  <link rel="stylesheet" href="/static/css/main.min.css" />
</head>

<body class="forum">
  <nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
  
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand home push-link" href="/"><strong>OpenReview</strong>.net</a>
      </div>
  
      <div id="navbar" class="navbar-collapse collapse">
        <form class="navbar-form navbar-left profile-search" role="search">
          <div class="form-group has-feedback">
            <input id="search_input" type="text" class="form-control ui-autocomplete-input" placeholder="Search ICLR 2019 Conference" autocomplete="off" />
            <span class="glyphicon glyphicon-search form-control-feedback" aria-hidden="true"></span>
          </div>
  
          <input id="search_group" type="hidden" value="ICLR.cc/2019/Conference" />
          <input id="search_content" type="hidden" value="all" />
        <ul id="ui-id-1" tabindex="0" class="ui-menu ui-widget ui-widget-content ui-autocomplete ui-front" style="display: none;"></ul></form>
  
        <ul class="nav navbar-nav navbar-right">
        
            <li id="user-menu"><a href="/login">Login</a></li>
        </ul>
      </div>
  
    </div>
  </nav>

  <div id="or-banner" class="banner" style="">
  <div class="container">
    <div class="row">
      <div class="col-xs-12"><a href="/group?id=ICLR.cc/2019/Conference" title="Venue Homepage"><img class="icon" src="/static/images/arrow_left.svg" /> Go to <strong>ICLR 2019 Conference</strong> homepage</a></div>
    </div>
  </div>
</div>
<div id="flash-message-container" class="alert alert-danger" role="alert" style="display: none;">
  <div class="container">
    <div class="row">
      <div class="col-xs-12">
        <div class="alert-content">
          <button type="button" class="close" aria-label="Close"><span aria-hidden="true">×</span></button>
        </div>
      </div>
    </div>
  </div>
</div>

<div class="container">
  <div class="row">
    <div class="col-xs-12">
      <main id="content" class="clearfix openbanner-visible legacy-styles"><div id="note_BJxh2j0qYm" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Dynamic Channel Pruning: Feature Boosting and Suppression</a> <a class="note_content_pdf" href="/pdf?id=BJxh2j0qYm" title="Download PDF" target="_blank"><img src="/static/images/pdf_icon_blue.svg" /></a> </h2></div><div class="meta_row"><span class="signatures">Anonymous</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">28 Sep 2018 (modified: 11 Oct 2018)</span><span class="item">ICLR 2019 Conference Blind Submission</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span><span class="item"><a class="action-bibtex-modal" data-bibtex="@inproceedings{    &#10;anonymous2019dynamic,    &#10;title={Dynamic Channel Pruning: Feature Boosting and Suppression},    &#10;author={Anonymous},    &#10;booktitle={Submitted to International Conference on Learning Representations},    &#10;year={2019},    &#10;url={https://openreview.net/forum?id=BJxh2j0qYm},    &#10;note={under review}    &#10;}">Show Bibtex</a></span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Abstract: </span><span class="note_content_value">Making deep convolutional neural networks more accurate typically comes at the cost of increased computational and memory resources. In this paper, we exploit the fact that the importance of features computed by convolutional layers is highly input-dependent, and propose feature boosting and suppression (FBS), a new method to predictively amplify salient convolutional channels and skip unimportant ones at run-time. FBS introduces small auxiliary connections to existing convolutional layers. In contrast to channel pruning methods which permanently remove channels, it preserves the full network structures and accelerates convolution by dynamically skipping unimportant input and output channels. FBS-augmented networks are trained with conventional stochastic gradient descent, making it readily available for many state-of-the-art CNNs. We compare FBS to a range of existing channel pruning and dynamic execution schemes and demonstrate large improvements on ImageNet classification. Experiments show that FBS can accelerate VGG-16 by 5x and improve the speed of ResNet-18 by 2x, both with less than 0.6% top-5 accuracy loss.</span></div><div class="note_contents"><span class="note_content_field">Keywords: </span><span class="note_content_value">dynamic network, faster CNNs, channel pruning</span></div><div class="note_contents"><span class="note_content_field">TL;DR: </span><span class="note_content_value">We make convolutional layers run faster by dynamically boosting and suppressing channels in feature computation.</span></div><div class="reply_row clearfix"><div class="item" id="reply_count">5 Replies</div></div></div><hr class="small" /><div id="note_children"><div class="note_with_children"><div id="note_rklHZy28TX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Review for "Dynamic Channel Pruning: Feature Boosting and Suppression"</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=BJxh2j0qYm&amp;noteId=rklHZy28TX"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper748 AnonReviewer4</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">12 Nov 2018</span><span class="item">ICLR 2019 Conference Paper748 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">The authors propose a dynamic inference technique for accelerating neural network prediction with minimal accuracy loss.  The technique prunes channels in an input-dependent way through the addition of auxiliary channel saliency prediction+pruning connections.

Pros:
- The paper is well-written and clearly explains the technique, and Figure 1 nicely summarizes the weakness of static channel pruning
- The technique itself is simple and memory-efficient
- The performance decrease is small

Cons:
- There is no clear motivation for the setting (keeping model accuracy while increasing inference speed by 2x or 5x)
- In contrast to methods that prune weights, the model size is not reduced, decreasing the utility in many settings where faster inference and smaller models are desired (e.g. mobile, real-time)
- The experiments are limited to classification and fairly dated architectures (VGG16, ResNet-18)

Overall, the method is nicely explained but the motivation is not clear.  Provided that speeding up inference without reducing the size of the model is desirable, this paper gives a good technique for preserving accuracy.</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">6: Marginally above acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">3: The reviewer is fairly confident that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_B1eUMSd16X" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>feature suppression to speed up training CNN</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=BJxh2j0qYm&amp;noteId=B1eUMSd16X"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper748 AnonReviewer2</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">07 Nov 2018</span><span class="item">ICLR 2019 Conference Paper748 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">This manuscript presents a nice method that can dynamically prune some channels in a CNN network to speed up the training. The main strength of the proposed method is to determine which channels to be suppressed based upon each data sample without incurring too much computational burden or too much memory consumption.  The good thing is that the proposed pruning strategy does not result in a big performance decrease. Overall, this is a nicely written paper and may be empirically useful for training a very large CNN. Nevertheless, the authors did not present a real-world application in which it is important to speed up by 2 or 3 times at a small cost, so it is hard to judge the real impact of the proposed method.</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">7: Good paper, accept</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_Bkgib72i2X" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Review comments on “Dynamic Channel Pruning: Feature Boosting and Suppression”</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=BJxh2j0qYm&amp;noteId=Bkgib72i2X"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper748 AnonReviewer3</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">04 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper748 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">Summary: 

This paper proposed a feature boosting and suppression method for dynamic channel pruning. To be specific, the proposed method firstly predicts the importance of each channel and then use an affine function to amplify/suppress the importance of different channels. However, the idea of dynamic channel pruning is not novel. Moreover, the comparisons in the experiments are quite limited. 

My detailed comments are as follows.


Strengths:

1. The motivation for this paper is reasonable and very important. 

2. The authors proposed a new method for dynamic channel pruning.

Weaknesses:

1. The idea of dynamic channel pruning is not novel. In my opinion, this paper is only an extension to Network Slimming (Liu et al., 2017). What is the essential difference between the proposed method and Network Slimming?

2. The writing and organization of this paper need to be significantly improved. There are many grammatical errors and this paper should be carefully proof-read.

3. The authors argued that the importance of features is highly input-dependent. This problem is reasonable but the proposed method still cannot handle it. According to Eqn. (7), the prediction of channel saliency relies on a data batch rather than a single data. Given different inputs in a batch, the selected channels should be different for each input rather than a general one for the whole batch. Please comment on this issue.

4. The proposed method does not remove any channels from the original model. As a result, both the memory and the computational cost will not be reduced. It is confusing why the proposed method can yield a significant speed-up in the experiments.

5. The authors only evaluate the proposed method on shallow models, e.g., VGG and ResNet18. What about the deeper model like ResNet50 on ImageNet?

6. It is very confusing why the authors only reported top-5 error of VGG. The results of top-1 error for VGG should be compared in the experiments.

7. Several state-of-the-art channel pruning methods should be considered as the baselines, such as ThiNet (Luo et al., 2017), Channel pruning (He et al., 2017) and DCP (Zhuang et al., 2018)
[1] Channel pruning for accelerating very deep neural networks. CVPR 2017.
[2] Thinet: A filter level pruning method for deep neural network compression. CVPR 2017.
[3] Discrimination-aware Channel Pruning for Deep Neural Networks. NIPS 2018.
</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">4: Ok but not good enough - rejection</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_SJlk4ADkaQ" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Reply to Reviewer 3 (1/2) </a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=BJxh2j0qYm&amp;noteId=SJlk4ADkaQ"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper748 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">07 Nov 2018</span><span class="item">ICLR 2019 Conference Paper748 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Thanks for your review.

We would like to clarify some points to avoid misunderstandings.

Our paper proposes a method called Feature Boosting and Suppression (FBS). FBS adds small auxiliary layers on top of each existing convolution. These auxiliary layers have trainable parameters that are optimized using SGD and control whether individual channels are evaluated at run-time or not. Using this conditional execution, the overall computation required is reduced significantly. Furthermore, the output of the auxiliary layers is used to scale each channel output. Channel saliencies are computed by the auxiliary layers on a per input basis. FBS utilizes sparse input channels (from the previous dynamically pruned convolutional layer) to predict which channels to skip in the output channels, so that we have large reduction in computations, as we exploit both input- and output-side sparsities.

The weaknesses identified by the reviewer (1,3 and 4) do not hold for the approach described above. We will address each of these comments in turn.

Introductory statement:
"firstly predicts the importance of each channel and then use an affine function to amplify/suppress the importance of different channels"

This statement is not true. To clarify, the amplification of channels is dependent on the input (Equation 5), whereas the suppression process effectively performs important channel selection (Equation 6). Both yield strictly non-affine transformations on the batch normalized channel output. 

1. "The idea of dynamic channel pruning is not novel. In my opinion, this paper is only an extension to Network Slimming (Liu et al., 2017).
What is the essential difference between the proposed method and Network Slimming?"

The Network Slimming (NS) procedure is applied statically and only prunes channels away. Our technique is applied at run-time and is input dependent. We prune channels away and boost important channels at run-time.

We consider our method, FBS, to be very different from Network Slimming. For each input image during inference, FBS predicts the relative importance of each channel, and selectively evaluates a subset of output channels that are important for the subsequent layer, given the activation of the previous layer. Different input images would therefore activate drastically different execution paths in the model.

Figure 3b corroborates this observation, as the heat maps show that many channels demonstrate high varying probabilities of being suppressed when being shown images of different categories. Our work is more related to runtime neural pruning [2] and conditional computation [3], where channels are dynamically selected for evaluation in each convolution, yet [2], [3] and FBS use very different methods to achieve this goal. In contrast, NS does not employ dynamic execution, as the pruned channels are *permanently removed* from the model, resulting in a network structure that remains static for all inputs where some capabilities will be permanently lost. 

In addition, FBS preemptively steers feature attention: as FBS not only uses the saliency metrics to predicatively prune unimportant channels at run-time, it further amplifies important channels. The non-linearity added to the network is conceptually similar to Squeeze-and-Excitation (SE) [1], as FBS captures inter-dependencies among input channels and adaptively recalibrates output features in a channel-wise fashion. Even without pruning, FBS can improve the baseline accuracies of CIFAR-10 and ImageNet models (Section 4.2), which is absent from static/dynamic channel pruning methods including NS, RNP, [4] and others.

Because of the above differences, FBS can achieve a much improved accuracy/compute trade-off when compared to other channel pruning methods.

2. "The writing and organization of this paper need to be significantly improved. There are many grammatical errors and this paper should be carefully proof-read."

We will complete another round of polishing to address any shortcomings. Could you suggest how/where the organization of the paper could be improved?
</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_S1euMaPJ67" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Reply to Reviewer 3 (2/2)</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=BJxh2j0qYm&amp;noteId=S1euMaPJ67"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper748 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">07 Nov 2018</span><span class="item">ICLR 2019 Conference Paper748 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">3. "The authors argued that the importance of features is highly input-dependent. This problem is reasonable but the proposed method still cannot handle it.
According to Eqn. (7), the prediction of channel saliency relies on a data batch rather than a single data. Given different inputs in a batch, the selected channels should be different for each input rather than a general one for the whole batch. Please comment on this issue."

The prediction of channel saliency *does not* rely on a batch of data. In equation (7), x_(l-1) is the output of the (l-1)-th layer, which comprises of C_(l-1) features, each feature has the spatial dimensions H_(l-1) * W_(l-1), as defined in Section 3.1. Throughout this paper, x_l for all layers is a single input image, which consists of multiple channels. Equation (7) reduces each channel in an image to a scalar, which is then used to predict the output channel saliencies in equation (8). Although this process is identical for each input image, each evaluation of equation (8) may produce drastically different predicted channel saliencies dependent on the input image.

We would like to update this section to remove any sources of ambiguity, would it be possible for you to describe how our intended meaning was lost?

4. "The proposed method does not remove any channels from the original model. As a result, both the memory and the computational cost will not be reduced. It is confusing why the proposed method can yield a significant speed-up in the experiments.”

It is hopefully clear from previous comments that this is not the case.

Typically, convolutional layers are stacked to form a sequential convolutional network. Prior to computing the costly convolution, FBS uses the input (or the output from the previous layer) to predict the saliencies of output channels of the costly convolution. If an output channel is predicted to have a zero saliency, the evaluation of this output channel can be entirely skipped, as the entire output channel is predicted to contain only zero entries.

In addition, each convolutional layer takes as its input the output of the previous layer. This input can have channel-wise sparsity (channels consisting of only zero entries), if the previous layer is a convolutional layer. It is clear that these inactive input channels can always be skipped when computing the convolution.

The input- and output-side sparsities therefore doubly accelerate the expensive convolution and thus achieve a huge reduction in compute. Such reduction in computation is also seen in [2], as it shares the same goal but uses an entirely different method.

5. "The authors only evaluate the proposed method on shallow models, e.g., VGG and ResNet18. What about the deeper model like ResNet50 on ImageNet?"

The method we propose is a per-layer method, which should not make a difference when targeting deeper models. Unlike NS, we do not rank channel importance globally to produce pruning decisions. We are working on generating results on deeper models, but this might be limited by the amount of time available.

6. "It is very confusing why the authors only reported top-5 error of VGG. The results of top-1 error for VGG should be compared in the experiments."

We will update Table 2 to include top-1 errors. However, some works we compare to, e.g. He et al.'s channel pruning [4], may have missing top-1 errors as they were not reported.

7. "Several state-of-the-art channel pruning methods should be considered as the baselines, such as ThiNet (Luo et al., 2017), Channel pruning (He et al., 2017) and DCP (Zhuang et al., 2018)."

Thank you for pointing out these works. These are all static techniques. We will be including them in our comparisons. In addition, it should be noted that Channel pruning [4] is already in our comparison of Table 2.


We thank the reviewer for providing this review.

We are in the process of updating this paper, and will notify you by comment of the new revision and its changes.

[1]: Squeeze-and-Excitation Networks, CVPR 2018, <a href="https://arxiv.org/abs/1709.01507" target="_blank" rel="nofollow">https://arxiv.org/abs/1709.01507</a>
[2]: Runtime Neural Pruning, NIPS 2017, https://papers.nips.cc/paper/6813-runtime-neural-pruning
[3]: Conditional Computation in Neural Networks for Faster Models, ICLR 2016, https://arxiv.org/abs/1511.06297
[4]: Channel pruning for accelerating very deep neural networks, ICCV 2017, https://arxiv.org/abs/1707.06168</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div></div></main></div>
  </div>
</div>


    <!-- Footer -->
    <footer class="sitemap">
      <div class="container">
        <div class="row hidden-xs">
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/venues">All Venues</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="/contact">Contact</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
    
        <div class="row visible-xs-block">
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/contact">Contact</a></li>
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
      </div>
    </footer>
    
    <footer class="sponsor">
      <div class="container">
        <div class="row">
          <div class="col-sm-10 col-sm-offset-1">
            <p class="text-center">
              OpenReview is created by the <a href="http://www.iesl.cs.umass.edu/" target="_blank">Information Extraction and Synthesis Laboratory</a>, College of Information and Computer Science, University of Massachusetts Amherst. We gratefully acknowledge the support of the OpenReview sponsors:  Google,  Facebook, NSF, the University of Massachusetts Amherst Center for Data Science, and Center for Intelligent Information Retrieval, as well as the Google Cloud Platform for donating the computing and networking services on which OpenReview.net runs.
            </p>
          </div>
        </div>
      </div>
    </footer>

  <div id="feedback-modal" class="modal fade" tabindex="-1" role="dialog">
    <div class="modal-dialog">
      <div class="modal-content">
        <div class="modal-header">
          <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button>
          <h3 class="modal-title">Send Feedback</h3>
        </div>
        <div class="modal-body">
          <p>Enter your feedback below and we'll get back to you as soon as possible.</p>
          <form action="/feedback" method="POST">
            <div class="form-group">
              <input type="email" name="from" class="form-control" placeholder="Email" />
            </div>
            <div class="form-group">
              <input type="text" name="subject" class="form-control" placeholder="Subject" />
            </div>
            <div class="form-group">
              <textarea name="message" class="form-control feedback-input" rows="5" placeholder="Message" required=""></textarea>
            </div>
          <ul id="ui-id-2" tabindex="0" class="ui-menu ui-widget ui-widget-content" style="display: none;"></ul></form>
        </div>
        <div class="modal-footer">
          <button type="button" class="btn btn-default" data-dismiss="modal">Cancel</button>
          <button type="button" class="btn btn-primary">Send</button>
        </div>
      </div>
    </div>
  </div>

  <script type="text/javascript" async="" src="https://www.google-analytics.com/analytics.js"></script><script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js"></script>
  <script>window.jQuery || document.write('&lt;script src="/static/js/vendor/jquery-2.2.4.min.js"&gt;&lt;\/script&gt;')</script>

  <script src="/static/dist/vendor.min.js"></script>
  <script src="/static/dist/templates.min.js"></script>
  <script src="/static/dist/openreview.min.js"></script>

    <script>window.legacyScripts = true;</script>


    <script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-108703919-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() { dataLayer.push(arguments); }
      gtag('js', new Date());
      gtag('config', 'UA-108703919-1');
    </script>


<div role="status" aria-live="assertive" aria-relevant="additions" class="ui-helper-hidden-accessible"></div></body></html>
<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" class="no-js"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>Learning Heuristics for Automated Reasoning through Reinforcement Learning | OpenReview</title>
  <meta name="description" content="" />

      <meta name="citation_title" content="Learning Heuristics for Automated Reasoning through Reinforcement Learning" />
        <meta name="citation_author" content="Anonymous" />
      <meta name="citation_publication_date" content="2018/09/27" />
      <meta name="citation_online_date" content="2018/09/27" />
      <meta name="citation_pdf_url" content="https://openreview.net/pdf?id=HkeyZhC9F7" />
      <meta name="twitter:card" content="summary" />
      <meta name="twitter:site" content="@openreviewnet" />
      <meta name="og:title" content="Learning Heuristics for Automated Reasoning through Reinforcement..." />
      <meta name="og:description" content="We demonstrate how to learn efficient heuristics for automated reasoning algorithms through deep reinforcement learning. We focus on backtracking search algorithms for quantified Boolean logics..." />
      <meta name="og:image" content="https://openreview.net/static/images/openreview_logo_512.png" />

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans:400,400i,700,700i" />

  <link rel="stylesheet" href="/static/css/bootstrap.min.css" />
  <link rel="stylesheet" href="/static/css/jquery-ui.min.css" />
  <link rel="stylesheet" href="/static/css/main.min.css" />
</head>

<body class="forum">
  <nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
  
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand home push-link" href="/"><strong>OpenReview</strong>.net</a>
      </div>
  
      <div id="navbar" class="navbar-collapse collapse">
        <form class="navbar-form navbar-left profile-search" role="search">
          <div class="form-group has-feedback">
            <input id="search_input" type="text" class="form-control ui-autocomplete-input" placeholder="Search ICLR 2019 Conference" autocomplete="off" />
            <span class="glyphicon glyphicon-search form-control-feedback" aria-hidden="true"></span>
          </div>
  
          <input id="search_group" type="hidden" value="ICLR.cc/2019/Conference" />
          <input id="search_content" type="hidden" value="all" />
        <ul id="ui-id-1" tabindex="0" class="ui-menu ui-widget ui-widget-content ui-autocomplete ui-front" style="display: none;"></ul></form>
  
        <ul class="nav navbar-nav navbar-right">
        
            <li id="user-menu"><a href="/login">Login</a></li>
        </ul>
      </div>
  
    </div>
  </nav>

  <div id="or-banner" class="banner" style="">
  <div class="container">
    <div class="row">
      <div class="col-xs-12"><a href="/group?id=ICLR.cc/2019/Conference" title="Venue Homepage"><img class="icon" src="/static/images/arrow_left.svg" /> Go to <strong>ICLR 2019 Conference</strong> homepage</a></div>
    </div>
  </div>
</div>
<div id="flash-message-container" class="alert alert-danger" role="alert" style="display: none;">
  <div class="container">
    <div class="row">
      <div class="col-xs-12">
        <div class="alert-content">
          <button type="button" class="close" aria-label="Close"><span aria-hidden="true">×</span></button>
        </div>
      </div>
    </div>
  </div>
</div>

<div class="container">
  <div class="row">
    <div class="col-xs-12">
      <main id="content" class="clearfix openbanner-visible legacy-styles"><div id="note_HkeyZhC9F7" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Learning Heuristics for Automated Reasoning through Reinforcement Learning</a> <a class="note_content_pdf" href="/pdf?id=HkeyZhC9F7" title="Download PDF" target="_blank"><img src="/static/images/pdf_icon_blue.svg" /></a> </h2></div><div class="meta_row"><span class="signatures">Anonymous</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">28 Sep 2018 (modified: 11 Oct 2018)</span><span class="item">ICLR 2019 Conference Blind Submission</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span><span class="item"><a class="action-bibtex-modal" data-bibtex="@inproceedings{    &#10;anonymous2019learning,    &#10;title={Learning Heuristics for Automated Reasoning through Reinforcement Learning},    &#10;author={Anonymous},    &#10;booktitle={Submitted to International Conference on Learning Representations},    &#10;year={2019},    &#10;url={https://openreview.net/forum?id=HkeyZhC9F7},    &#10;note={under review}    &#10;}">Show Bibtex</a></span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Abstract: </span><span class="note_content_value">We demonstrate how to learn efficient heuristics for automated reasoning algorithms through deep reinforcement learning. We focus on backtracking search algorithms for quantified Boolean logics, which already can solve formulas of impressive size - up to 100s of thousands of variables. The main challenge is to find a representation of these formulas that lends itself to making predictions in a scalable way. For challenging problems, the heuristic learned through our approach reduces execution time by &gt;=90% compared to the existing handwritten heuristics.</span></div><div class="note_contents"><span class="note_content_field">Keywords: </span><span class="note_content_value">reinforcement learning, deep learning, logics, formal methods, automated reasoning, backtracking search, satisfiability, quantified Boolean formulas</span></div><div class="note_contents"><span class="note_content_field">TL;DR: </span><span class="note_content_value">RL finds better heuristics for automated reasoning algorithms.</span></div><div class="reply_row clearfix"><div class="item" id="reply_count">8 Replies</div></div></div><hr class="small" /><div id="note_children"><div class="note_with_children"><div id="note_SklWGYIq2X" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Interesting application of reinforcement learning and GNN over a specific decision problem</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HkeyZhC9F7&amp;noteId=SklWGYIq2X"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1133 AnonReviewer3</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">03 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper1133 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">The paper is proposing to use reinforcement learning as a method for implementing heuristics of a backtracking search algorithm or Boolean Logic. While I'm not familiar with this specific topic, Section 2 is didactic and clear. The challenges of the tackle problem are clearly explained in this section.

The Graph neural network architecture proposed in Section 4 to compute literals of the formula is an original idea. The experimental results look convincing and suggest this approach should be more deeply investigated.

My main concern is that the novelty from a machine learning and reinforcement learning point of view remains limited while the application seems original and promising. So I will not be strongly opposed to the publication if this work in ICLR venue while I remain unsure it is the best one.</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">5: Marginally below acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">3: The reviewer is fairly confident that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_Bye14hEKpQ" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>We believe the work contains insights for the ML community, too.</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HkeyZhC9F7&amp;noteId=Bye14hEKpQ"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1133 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">14 Nov 2018</span><span class="item">ICLR 2019 Conference Paper1133 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">We thank the reviewer for the insightful comments.

&gt;&gt;&gt; [...] the novelty from a ML and RL point of view remains limited [...]

We see contributions to two lines of work published in ICLR and related conferences: The first concerns the representation of formulas to facilitate learning [1, 2, 3], and the second concerns leveraging reinforcement learning in combinatorial search algorithms [5, 6].

Compared to [1, 2, 3], we show how to address the problem of scale. Previous works suggested tree-encoders [2], possible worlds [1], and top-down tree encoders [3]. These approaches seem to be limited to formulas with tens of variables, which would be considered tiny in the verification/formal methods community. To scale up to realistic formulas, orders of magnitude larger of what has been considered before, we suggest to exploit the graph representation of formulas in conjunctive normal form and apply GNNs. While GNNs generally scale well, this is also a conceptual shift: Previous works needed to learn a fixed embedding for variables “a”, “b”, “c”, etc., even though variable “a” has no shared meaning across different formulas. GNNs enable us to embed variables based only on the context of their occurrences in the current formula.

Compared to [5, 6], our work represents a big step towards practicality. While interesting from a learning perspective, their methods do not come even close to the state-of-the-art in specialized algorithms. We demonstrate that the tight integration of deep learning and combinatorial search algorithms can actually improve the performance of complex and (relatively) large-scale applications of combinatorial search. The main challenge here was the significant performance cost of neural networks. Our work shows that this cost can be outweighed by the dramatically better decisions neural networks suggest (1000x fewer steps needed to solve hard formulas).

We acknowledge that we need to state these points more clearly, and will improve the paper accordingly.

[1] "Can Neural Networks Understand Logical Entailment?", in ICLR 2018
[2] "Learning Continuous Semantic Representations of Symbolic Expressions", in ICML 2017
[3] "Top-down neural model for formulae", under submission to ICLR 2019
[4] "Learning a SAT Solver from Single-Bit Supervision", under submission to ICLR 2019
[5] "Learning Combinatorial Optimization Algorithms over Graphs", in NIPS 2017
[6] "Neural Combinatorial Optimization with Reinforcement Learning", in ICLR 2017
</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div><div class="note_with_children"><div id="note_BklL0lZq3X" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>needs some improvement </a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HkeyZhC9F7&amp;noteId=BklL0lZq3X"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1133 AnonReviewer2</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">03 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper1133 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">The aim of this paper is to learn a heuristic for a backtracking search algorithm utilizing Reinforcement learning. The proposed model makes use of Graphical Neural Networks to produce literal and clauses embeddings, and use them to predict the quality of each literal, through a NN, which in turn decides the probability of each action.

Positives
A new approach on how to employ Machine learning techniques to Automated reasoning problems. Works with any 2QBF solver.
The learned heuristic seems to perform better than the state of the art in the presented experiments.

Negatives
No theoretical justification about why this heuristic should work better than the existing ones.
Doesn't solve QBF formulas in general, but only 2QBF.
It is not clear whether the range of formulas that can be solved using this approach is greater than that of existing solvers.
Having a substantial amount of formulas that produce incomplete episodes, as it might be the case in real world scenarios, hinders learning, so the dataset has to be manually adjusted.

Conclusion
The proposed framework is an interesting addition to existing techniques in the field and the idea is suitable for further exploration and refinement. The experimental results are promising, so the direction of the work is worth pursuing. However, some of the foundations and overall nature of the work needs some improvement and maturity. </span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">6: Marginally above acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_r1ggEpNKaX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Some remarks about the concerns raised</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HkeyZhC9F7&amp;noteId=r1ggEpNKaX"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1133 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">14 Nov 2018</span><span class="item">ICLR 2019 Conference Paper1133 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">We thank the reviewer for the detailed feedback.

&gt;&gt;&gt; No theoretical justification about why this heuristic should work better than the existing ones.

This is a very interesting question, but surprisingly hard to answer. Even for the simpler question of why CDCL for SAT solvers is so unreasonably effective for a wide range of applications, there is no concrete theoretical explanation - despite two decades of research! When there is no satisfactory theoretical explanation, we suggest that it is better to learn the heuristics based on the data itself.

&gt;&gt;&gt; Doesn't solve QBF formulas in general, but only 2QBF.

Our approach could be easily applied to general QBF as well. The limitation to 2QBF is also due to the underlying tool. But keep in mind that most applications of QBF, e.g. in verification and program synthesis, can be encoded with just one quantifier alternation, so we believe that we captured the most interesting cases of QBF.

&gt;&gt;&gt; It is not clear whether the range of formulas that can be solved using this approach is 
&gt;&gt;&gt; greater than that of existing solvers.

Our experiments demonstrate that we can solve significantly more formulas when given enough formulas from a single source (=distribution). We do not claim that the learned models generalize to formulas far away from that distribution. The question whether it is possible to learn models that apply to a wide “range of formulas” is indeed an open one.

&gt;&gt;&gt; Having a substantial amount of formulas that produce incomplete episodes, as it might be
&gt;&gt;&gt; the case in real world scenarios, hinders learning, so the dataset has to be manually
&gt;&gt;&gt; adjusted.

We believe that this the inherent challenge of problem solving: how can we learn to solve problems that we have never solved? The assumption underlying this paper is that learning how to solve simpler problems faster, helps us to solve harder problems, too. Our experiments demonstrate that this is indeed possible for problems sets containing many related formulas of different hardness levels.
</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div><div class="note_with_children"><div id="note_ryxJA8gF2Q" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Interesting application of deep learning with interesting results.</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HkeyZhC9F7&amp;noteId=ryxJA8gF2Q"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1133 AnonReviewer1</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">02 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper1133 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">The paper proposes an approach to automatically learning variable selection
heuristics for QBF using deep learning. The evaluation presented by the authors
shows the promise of the method and demonstrates significant performance
improvements over a variable selection heuristic that does not use machine
learning.

In practice, the overhead of the proposed method is likely to be a major
obstacle in its adoption. The authors note the difficulty of finding suitable
benchmarks and restrict the set of instances they use for evaluation to formulae
where the proposed method is likely to achieve improvements. This skews the
evaluation in favor of the proposed method; in particular, the 90% improvement
figure mentioned in the abstract is not representative of the general case.
Indeed, on another set of instances the proposed method falls significantly
short of the performance of a state-of-the-art heuristic that does not employ
learning.

A drawback of the paper is that there is no comparison to related work. I
realize that this is difficult to achieve because other approaches are in
related, but different areas and may be difficult to adapt for this case, but a
general comparison to the improvements other approaches achieve would be
helpful.

Nevertheless, the work is interesting and presents a new angle on using machine
learning to speed up combinatorial problem solving. While several issues hinder
practical adoption, this is likely to lead to interesting follow-up work that
will improve problem solving in practice.

The description of the method (Section 4.1) is short and not detailed enough to
reproduce the approach the authors are proposing. However, the code is
available.

In summary, I feel that the paper can be accepted.</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">7: Good paper, accept</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_Skx240VFpQ" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Clarification about QBFEVAL and additional data sets</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HkeyZhC9F7&amp;noteId=Skx240VFpQ"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1133 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">14 Nov 2018</span><span class="item">ICLR 2019 Conference Paper1133 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Thank you for the detailed comments.

&gt;&gt;&gt; The authors note the difficulty of finding suitable benchmarks and restrict the set of instances
&gt;&gt;&gt; they use for evaluation to formulae where the proposed method is likely to achieve improvements. 
&gt;&gt;&gt; This skews the evaluation in favor of the proposed method; in particular, the 90% improvement
&gt;&gt;&gt; figure mentioned in the abstract is not representative of the general case. Indeed, on 
&gt;&gt;&gt; another set of instances the proposed method falls significantly short of the performance of
&gt;&gt;&gt; a state-of-the-art heuristic that does not employ learning.

Our claim is that training a model on several hundred formulas greatly improves the performance of the logic solver on formulas from the same distribution. In our paper, we only support this claim by experiments on the Reductions benchmark. But, in fact, we have confirmed the same results on several datasets of artificially synthesized formulas (encoding random bit-level and word-level circuits). These additional datasets can be found with the published code, and we will provide more details about them in the appendix.

It is natural to ask how a model trained on one distribution performs on a different dataset. Since QBFEVAL is an important data set in the formal methods community, we used it to test the transferability of the heuristics with only partial success. (Training a model directly on QBFEVAL does not seem to be possible at the moment, because of the small size of the dataset, leading to overfitting.)

Lastly, we want to point out that most other works on ML for formulas only consider sets of random formulas (in particular, formulas synthesized by the authors themselves). In comparison, the Reduction benchmark is a well-known data set from the literature and generated independently from our work. In this way, we believe that we avoid skewing the results in our favor and set a higher bar than related work.

&gt;&gt;&gt; A drawback of the paper is that there is no comparison to related work. I
&gt;&gt;&gt; realize that this is difficult to achieve because other approaches are in
&gt;&gt;&gt; related, but different areas and may be difficult to adapt for this case, but a
&gt;&gt;&gt; general comparison to the improvements other approaches achieve would be
&gt;&gt;&gt; helpful.

We would love to learn about (and compare to) related work, but we are not aware of any we could meaningfully compare to. Could you point us to any works you are aware of?

Compared to the typical improvements through progress in hand-written heuristics, the 1000x improvement in the number of steps needed is enormous.
</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_ryxELVAF6m" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Related Work</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HkeyZhC9F7&amp;noteId=ryxELVAF6m"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1133 AnonReviewer1</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">15 Nov 2018</span><span class="item">ICLR 2019 Conference Paper1133 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">The most relevant paper to the work you're proposing here is probably "Learning to Branch in Mixed Integer Programming", <a href="https://dl.acm.org/citation.cfm?id=3015920." target="_blank" rel="nofollow">https://dl.acm.org/citation.cfm?id=3015920.</a></span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_Hke2JfcoT7" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Thanks for the interesting pointer!</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HkeyZhC9F7&amp;noteId=Hke2JfcoT7"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1133 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">16 Nov 2018</span><span class="item">ICLR 2019 Conference Paper1133 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">We were not aware of this work, and will discuss it in our related work section. There are several key differences compared to our work: Khalil et al. present an approach to learn to predict an existing heuristic called SB using SVMs, while we attempt to learn an entirely new heuristics using deep reinforcement learning. Further, they learn within a single run of the solver, while we learn from executions on a set of formulas. In some sense, the approaches are quite orthogonal, and not necessarily competing against each other. It is unclear to us, if there is a meaningful way to compare the methods experimentally.

</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div></div></div></div></div></div></main></div>
  </div>
</div>


    <!-- Footer -->
    <footer class="sitemap">
      <div class="container">
        <div class="row hidden-xs">
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/venues">All Venues</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="/contact">Contact</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
    
        <div class="row visible-xs-block">
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/contact">Contact</a></li>
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
      </div>
    </footer>
    
    <footer class="sponsor">
      <div class="container">
        <div class="row">
          <div class="col-sm-10 col-sm-offset-1">
            <p class="text-center">
              OpenReview is created by the <a href="http://www.iesl.cs.umass.edu/" target="_blank">Information Extraction and Synthesis Laboratory</a>, College of Information and Computer Science, University of Massachusetts Amherst. We gratefully acknowledge the support of the OpenReview sponsors:  Google,  Facebook, NSF, the University of Massachusetts Amherst Center for Data Science, and Center for Intelligent Information Retrieval, as well as the Google Cloud Platform for donating the computing and networking services on which OpenReview.net runs.
            </p>
          </div>
        </div>
      </div>
    </footer>

  <div id="feedback-modal" class="modal fade" tabindex="-1" role="dialog">
    <div class="modal-dialog">
      <div class="modal-content">
        <div class="modal-header">
          <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button>
          <h3 class="modal-title">Send Feedback</h3>
        </div>
        <div class="modal-body">
          <p>Enter your feedback below and we'll get back to you as soon as possible.</p>
          <form action="/feedback" method="POST">
            <div class="form-group">
              <input type="email" name="from" class="form-control" placeholder="Email" />
            </div>
            <div class="form-group">
              <input type="text" name="subject" class="form-control" placeholder="Subject" />
            </div>
            <div class="form-group">
              <textarea name="message" class="form-control feedback-input" rows="5" placeholder="Message" required=""></textarea>
            </div>
          <ul id="ui-id-2" tabindex="0" class="ui-menu ui-widget ui-widget-content" style="display: none;"></ul></form>
        </div>
        <div class="modal-footer">
          <button type="button" class="btn btn-default" data-dismiss="modal">Cancel</button>
          <button type="button" class="btn btn-primary">Send</button>
        </div>
      </div>
    </div>
  </div>

  <script type="text/javascript" async="" src="https://www.google-analytics.com/analytics.js"></script><script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js"></script>
  <script>window.jQuery || document.write('&lt;script src="/static/js/vendor/jquery-2.2.4.min.js"&gt;&lt;\/script&gt;')</script>

  <script src="/static/dist/vendor.min.js"></script>
  <script src="/static/dist/templates.min.js"></script>
  <script src="/static/dist/openreview.min.js"></script>

    <script>window.legacyScripts = true;</script>


    <script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-108703919-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() { dataLayer.push(arguments); }
      gtag('js', new Date());
      gtag('config', 'UA-108703919-1');
    </script>


<div role="status" aria-live="assertive" aria-relevant="additions" class="ui-helper-hidden-accessible"></div></body></html>
<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" class="no-js"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>Gradient-based learning for F-measure and other performance metrics | OpenReview</title>
  <meta name="description" content="" />

      <meta name="citation_title" content="Gradient-based learning for F-measure and other performance metrics" />
        <meta name="citation_author" content="Anonymous" />
      <meta name="citation_publication_date" content="2018/09/27" />
      <meta name="citation_online_date" content="2018/09/27" />
      <meta name="citation_pdf_url" content="https://openreview.net/pdf?id=H1zxjsCqKQ" />
      <meta name="twitter:card" content="summary" />
      <meta name="twitter:site" content="@openreviewnet" />
      <meta name="og:title" content="Gradient-based learning for F-measure and other performance metrics" />
      <meta name="og:description" content="Many important classification performance metrics, e.g. $F$-measure, are non-differentiable and non-decomposable, and are thus unfriendly to gradient descent algorithm.&#10;  Consequently, despite their..." />
      <meta name="og:image" content="https://openreview.net/static/images/openreview_logo_512.png" />

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans:400,400i,700,700i" />

  <link rel="stylesheet" href="/static/css/bootstrap.min.css" />
  <link rel="stylesheet" href="/static/css/jquery-ui.min.css" />
  <link rel="stylesheet" href="/static/css/main.min.css" />
</head>

<body class="forum">
  <nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
  
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand home push-link" href="/"><strong>OpenReview</strong>.net</a>
      </div>
  
      <div id="navbar" class="navbar-collapse collapse">
        <form class="navbar-form navbar-left profile-search" role="search">
          <div class="form-group has-feedback">
            <input id="search_input" type="text" class="form-control ui-autocomplete-input" placeholder="Search ICLR 2019 Conference" autocomplete="off" />
            <span class="glyphicon glyphicon-search form-control-feedback" aria-hidden="true"></span>
          </div>
  
          <input id="search_group" type="hidden" value="ICLR.cc/2019/Conference" />
          <input id="search_content" type="hidden" value="all" />
        <ul id="ui-id-1" tabindex="0" class="ui-menu ui-widget ui-widget-content ui-autocomplete ui-front" style="display: none;"></ul></form>
  
        <ul class="nav navbar-nav navbar-right">
        
            <li id="user-menu"><a href="/login">Login</a></li>
        </ul>
      </div>
  
    </div>
  </nav>

  <div id="or-banner" class="banner" style="">
  <div class="container">
    <div class="row">
      <div class="col-xs-12"><a href="/group?id=ICLR.cc/2019/Conference" title="Venue Homepage"><img class="icon" src="/static/images/arrow_left.svg" /> Go to <strong>ICLR 2019 Conference</strong> homepage</a></div>
    </div>
  </div>
</div>
<div id="flash-message-container" class="alert alert-danger" role="alert" style="display: none;">
  <div class="container">
    <div class="row">
      <div class="col-xs-12">
        <div class="alert-content">
          <button type="button" class="close" aria-label="Close"><span aria-hidden="true">×</span></button>
        </div>
      </div>
    </div>
  </div>
</div>

<div class="container">
  <div class="row">
    <div class="col-xs-12">
      <main id="content" class="clearfix openbanner-visible legacy-styles"><div id="note_H1zxjsCqKQ" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Gradient-based learning for F-measure and other performance metrics</a> <a class="note_content_pdf" href="/pdf?id=H1zxjsCqKQ" title="Download PDF" target="_blank"><img src="/static/images/pdf_icon_blue.svg" /></a> </h2></div><div class="meta_row"><span class="signatures">Anonymous</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">28 Sep 2018 (modified: 06 Nov 2018)</span><span class="item">ICLR 2019 Conference Blind Submission</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span><span class="item"><a class="action-bibtex-modal" data-bibtex="@inproceedings{    &#10;anonymous2019gradient-based,    &#10;title={Gradient-based learning for F-measure and other performance metrics},    &#10;author={Anonymous},    &#10;booktitle={Submitted to International Conference on Learning Representations},    &#10;year={2019},    &#10;url={https://openreview.net/forum?id=H1zxjsCqKQ},    &#10;note={under review}    &#10;}">Show Bibtex</a></span><a class="note_content_pdf item" href="/revisions?id=H1zxjsCqKQ" target="_blank">Show Revisions</a></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Abstract: </span><span class="note_content_value">Many important classification performance metrics, e.g. $F$-measure, are non-differentiable and non-decomposable, and are thus unfriendly to gradient descent algorithm.
Consequently, despite their popularity as evaluation metrics, these metrics are rarely optimized as training objectives in neural network community.
In this paper, we propose an empirical utility maximization scheme with provable learning guarantees to address the non-differentiability of these metrics. 
We then derive a strongly consistent gradient estimator to handle non-decomposability.
These innovations enable end-to-end optimization of these metrics with the same computational complexity as optimizing a decomposable and differentiable metric, e.g. cross-entropy loss.</span></div><div class="reply_row clearfix"><div class="item" id="reply_count">7 Replies</div></div></div><hr class="small" /><div id="note_children"><div class="note_with_children"><div id="note_HklmIaLChX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Revision</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=H1zxjsCqKQ&amp;noteId=HklmIaLChX"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper592 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">06 Nov 2018</span><span class="item">ICLR 2019 Conference Paper592 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Dear Reviewers and Readers,

We notice that there are typos in our submission. Also, there are places where our presentation are not very clear. We have therefore uploaded a revision of our submission.

We apologize for any confusion caused by the original manuscript.

Best,
Authors</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_r1lueqC63X" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>An interesting paper with some issues </a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=H1zxjsCqKQ&amp;noteId=r1lueqC63X"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper592 AnonReviewer3</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">05 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper592 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">This paper proposes a gradient-based learning for F1 measure under the utility maximization framework. F1 is a widely used evaluation metric in information retrieval and machine learning, and it is hard to optimize as it is non-decomposable and non-differentiable. This research direction is hence extremely interesting. 

The paper is well organized and easy to follow. The general methodology seems sound. Below are some detailed comments.

- Page 1, Section 2.1. The notation of the probabilistic classifier is not typed correctly.  

- Page 7. The result strongly depends on how well Eq. (5) holds. Two critical assumptions regarding the data are made here, (1) D -&gt; ∞ and (2) B -&gt; ∞. The first assumption is implicitly confirmed in the experiments, as in Table 1 the proposed method outperforms when the sample size is big. I am a little bit puzzled about the second assumption though. Eq. (7) holds, (and consequently Eq. (5)) when B -&gt; ∞, but it cannot be the case in practice, since B tends to have moderate sizes. I wonder how this impacts the results. Batch size isn't discussed at all in the experiments. The discussion on noise control is nice, but it doesn't contribute to the validation of Eq. (5) or Eq. (7).

- Algorithm 1 &amp; 2. It may be a good idea to be explicit what the outputs of the algorithms are. The algorithms are referenced by their section numbers instead of their algorithm numbers. 

- The experimental section can be extended. The paper has extensively discussed other well-behaved metrics and tasks beyond binary classification. None of these are tested empirically. 

- If I understand correctly, the GS method, with a much higher computational cost, is near optimal. If so, its results should serve as an empirical upper-bound for F1. Then how come the proposed method outperforms it on 4 over 6 dataset? 

- There are additional references on F1 maximization. To name a few: (1) Chai. Expectation of F-measures. SIGIR 2005. (2) Waegeman et al. On the Bayes-Optimality of F-Measure Maximizers. JMLR.</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">5: Marginally below acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">3: The reviewer is fairly confident that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_rJgelvYYa7" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Responses</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=H1zxjsCqKQ&amp;noteId=rJgelvYYa7"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper592 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">14 Nov 2018</span><span class="item">ICLR 2019 Conference Paper592 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Dear Reviewer,

First, thank you for your helpful review!

Regarding issues you mentioned:

- Page 1, Section 2.1. Could you please specify where the typo is?

- Page 7. Indeed, when analyzing the impact of batch size, we should have given the rate of convergence instead of only considering asymptotic behaviors.

- Algorithm 1 &amp; 2. Fixed.

- We will include an experiment with multi-class F1 score, in which case the GS method is proved optimal as well. For other performance metrics, we are still looking for strong baselines.

- We suspect that the GS method is outperformed because we did not use sufficiently dense grids when grid-searching \lambda. The reason for not using denser grids is that we also have to grid-search other hyper-parameters, e.g. learning rate, and thus using denser grids for the GS method will significantly increase computation time. Using the step size mentioned in our paper, we need almost two days to finish all experiments with the GS method on a 4-GPU workstation. Thus halving the step size in our case will cost almost another two days.

- We did not notice references you mentioned and will include them in our paper.</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div><div class="note_with_children"><div id="note_r1eujgeB37" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Needs more theoretical or experimental support.</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=H1zxjsCqKQ&amp;noteId=r1eujgeB37"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper592 AnonReviewer1</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">30 Oct 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper592 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">The paper proposes a general method to optimize for performance metrics which can be written in terms of the entries of the confusion matrix. The idea is to approximate the entries of the confusion matrix using their expected values for a randomized classifier, plug these estimates into the formula for the desired metric, and optimize that quantity. This is a compelling idea but it needs more support than the theoretical or experimental sections give. 

The simplicity and generality of the method are appealing. Smooth surrogates derived from randomized classifiers have been considered in the context of accuracy [1] and other performance measures [2, 3] and the paper should include some discussion of this prior work, but to my knowledge the broad applicability to non-decomposable and non-differentiable metrics expressible in terms of the confusion matrix is new. 

The theoretical sections could use some improvement. It is worth mentioning that the loss obtained with the proposed method is nonconvex. The first equation in theorem 1 is described with “... where convergence in probability is entry-wise”, when the equation refers to almost sure convergence for a scalar, not convergence in probability for entries of a matrix. 

No convergence rates are given, only asymptotic almost sure convergence as the size of the dataset or the minibatch goes to infinity. For finite datasets these statements are obvious, and while convergence is reassuring for infinite datasets, I imagine the rates will look very different for the loss (a scalar) and the gradient (which may have millions of coordinates). Theorem 3 considers the generalization of a single classifier which is independent of the empirical sample, which makes it irrelevant to cases where the model is learned. Theorem 4, which seeks to give a uniform bound over the model class, only shows that generalization occurs in the limit of infinitely much data (which is not surprising or particularly interesting).

The experimental section compares the algorithm against a well-known and strong baseline, but without any information about the variance of the results and only for a deep network. Several questions remain: Where the proposed method improves over the baseline, is this improvement due to the new method or the interaction between the method and the model? How would the method perform on e.g. a linear model, which is better understood? How do the results depend on batch size, which affects the bias in the gradients? 

[1] Roux, Nicolas Le. "Tighter bounds lead to improved classifiers." arXiv preprint arXiv:1606.09202 (2016).
[2] Mozer, Michael C., et al. "Prodding the ROC curve: Constrained optimization of classifier performance." Advances in Neural Information Processing Systems. 2002.
[3] Goh, Gabriel, et al. "Satisfying real-world goals with dataset constraints." Advances in Neural Information Processing Systems. 2016.
</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">4: Ok but not good enough - rejection</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_ryewV_5KTQ" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Responses</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=H1zxjsCqKQ&amp;noteId=ryewV_5KTQ"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper592 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">14 Nov 2018</span><span class="item">ICLR 2019 Conference Paper592 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Dear Reviewer,

First, thank you for your helpful review!

We agree that we should provide convergence rates. For the convergence of scalars (e.g., in Theorem 4), it would not be hard to derive convergence rates by replacing the law of large number in our analysis with concentration inequalities. The convergence rates of gradients, as you mentioned, is trickier and we will further study this. Also, replacing Theorem 3 with a data-dependent generalization bound may require more efforts and we will further study this.

We believe that the convexity of the proposed surrogate objective depends on the convexity of the performance metric that we are concerned with. With a convex performance metric, the proposed performance metric is convex. For example, in the case where the performance metric is accuracy, the proposed surrogate objective is simply a sum of posterior probabilities inferred by our classifier. Of course, the objective cannot be convex with a non-convex performance metric.

The first equation in Theorem 1 will be fixed.

We will augment the experimental section to provide more information. Works you mentioned are very helpful. We will include them in our updates.</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div><div class="note_with_children"><div id="note_BJguooef3m" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Marginally below acceptance</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=H1zxjsCqKQ&amp;noteId=BJguooef3m"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper592 AnonReviewer2</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">27 Oct 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper592 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">This paper studies the problem of optimizing non-decomposable metric in classification. This topic has been discussed in several recent works mainly under deterministic classifier context, the authors discuss the possibility of training a neural network and learn the model by gradient-based methods, which could result in randomized classifier; and conducted experiments to compare the performance with other existing methodologies. I have the following concerns after reading it.

1.The main idea of the paper has shown in other related works and the authors didn’t convince me why their work solves something that could not be solved in existing work. The related work section missed some relevant recent work including Ref[1], in which the method is also gradient-based and can be applied to neural networks. The well-behaved notion used in Definition 2 seems much weaker than the assumptions shown in Ref[1,2] to guarantee existence or uniqueness of the Bayes classifier, the authors could spend some effort to discuss why they require less assumptions.

2.For the theory part, all the convergence results are proved in an asymptotic way without further discussion in the sample complexity. This becomes problematic for this work because (as shown in eq (7)) mini batch size goes to infinity is an unrealistic assumption in neural network training. Also when the class is unbalanced, empirical mean converging to population also slows down significantly which is required in Eq (4) and other places. I would like to see more discussion on the sample complexity either theoretically or experimentally.

3.The experiments lack details for reproducing the results or generalizing the gain to other problems. For example, batch size, learning rate or how the size of the network influence the performance metrics. This information will be useful for others who want to apply the proposed method.
 
There are some minor formatting issues like the leading space in \citep. Please fix those.

Based on the above reasons, I’ll give this paper a 5.

[Ref 1] Yan, B., Koyejo, S., Zhong, K. &amp; Ravikumar, P.. (2018). Binary Classification with Karmic, Threshold-Quasi-Concave Metrics. Proceedings of the 35th International Conference on Machine Learning, in PMLR 80:5531-5540
[Ref 2] Narasimhan, H., Kar, P., &amp; Jain, P. (2015, June). Optimizing non-decomposable performance measures: a tale of two classes. In International Conference on Machine Learning (pp. 199-208).</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">5: Marginally below acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_SJlQ9lsK6m" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Responses</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=H1zxjsCqKQ&amp;noteId=SJlQ9lsK6m"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper592 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">14 Nov 2018</span><span class="item">ICLR 2019 Conference Paper592 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Dear Reviewer,

First, thank you for your helpful review!

Regarding issues you mentioned:

1. The idea of optimizing non-decomposable objectives by leveraging their mathematical properties is indeed not new. However, we believe that the formulation and analysis of the proposed surrogate objective is novel. [Ref 1] is very interesting and we will consider it as a baseline for our method. We did not consider the existence and uniqueness of the Bayes classifier. We are only interested in whether our surrogate objective can yield best-in-class classifiers given a fixed hypothesis class (Theorem 4), which is why our results only require a weaker condition.

2. Yes, we should discuss sample complexity, especially when discussing the impact of batch size. The convergence of empirical mean to population indeed can become a problem when there are very few samples for a class. However, this issue is less severe for large datasets, where minority classes have numerous samples despite their low frequencies.

3. We will surely include more details about experiments. We will also release our code soon.</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div></div></main></div>
  </div>
</div>


    <!-- Footer -->
    <footer class="sitemap">
      <div class="container">
        <div class="row hidden-xs">
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/venues">All Venues</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="/contact">Contact</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
    
        <div class="row visible-xs-block">
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/contact">Contact</a></li>
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
      </div>
    </footer>
    
    <footer class="sponsor">
      <div class="container">
        <div class="row">
          <div class="col-sm-10 col-sm-offset-1">
            <p class="text-center">
              OpenReview is created by the <a href="http://www.iesl.cs.umass.edu/" target="_blank">Information Extraction and Synthesis Laboratory</a>, College of Information and Computer Science, University of Massachusetts Amherst. We gratefully acknowledge the support of the OpenReview sponsors:  Google,  Facebook, NSF, the University of Massachusetts Amherst Center for Data Science, and Center for Intelligent Information Retrieval, as well as the Google Cloud Platform for donating the computing and networking services on which OpenReview.net runs.
            </p>
          </div>
        </div>
      </div>
    </footer>

  <div id="feedback-modal" class="modal fade" tabindex="-1" role="dialog">
    <div class="modal-dialog">
      <div class="modal-content">
        <div class="modal-header">
          <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button>
          <h3 class="modal-title">Send Feedback</h3>
        </div>
        <div class="modal-body">
          <p>Enter your feedback below and we'll get back to you as soon as possible.</p>
          <form action="/feedback" method="POST">
            <div class="form-group">
              <input type="email" name="from" class="form-control" placeholder="Email" />
            </div>
            <div class="form-group">
              <input type="text" name="subject" class="form-control" placeholder="Subject" />
            </div>
            <div class="form-group">
              <textarea name="message" class="form-control feedback-input" rows="5" placeholder="Message" required=""></textarea>
            </div>
          <ul id="ui-id-2" tabindex="0" class="ui-menu ui-widget ui-widget-content" style="display: none;"></ul></form>
        </div>
        <div class="modal-footer">
          <button type="button" class="btn btn-default" data-dismiss="modal">Cancel</button>
          <button type="button" class="btn btn-primary">Send</button>
        </div>
      </div>
    </div>
  </div>

  <script type="text/javascript" async="" src="https://www.google-analytics.com/analytics.js"></script><script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js"></script>
  <script>window.jQuery || document.write('&lt;script src="/static/js/vendor/jquery-2.2.4.min.js"&gt;&lt;\/script&gt;')</script>

  <script src="/static/dist/vendor.min.js"></script>
  <script src="/static/dist/templates.min.js"></script>
  <script src="/static/dist/openreview.min.js"></script>

    <script>window.legacyScripts = true;</script>


    <script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-108703919-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() { dataLayer.push(arguments); }
      gtag('js', new Date());
      gtag('config', 'UA-108703919-1');
    </script>


<div role="status" aria-live="assertive" aria-relevant="additions" class="ui-helper-hidden-accessible"></div></body></html>
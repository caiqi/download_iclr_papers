<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" class="no-js"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>RotatE: Knowledge Graph Embedding by Relational Rotation in Complex Space | OpenReview</title>
  <meta name="description" content="" />

      <meta name="citation_title" content="RotatE: Knowledge Graph Embedding by Relational Rotation in Complex Space" />
        <meta name="citation_author" content="Anonymous" />
      <meta name="citation_publication_date" content="2018/09/27" />
      <meta name="citation_online_date" content="2018/09/27" />
      <meta name="citation_pdf_url" content="https://openreview.net/pdf?id=HkgEQnRqYQ" />
      <meta name="twitter:card" content="summary" />
      <meta name="twitter:site" content="@openreviewnet" />
      <meta name="og:title" content="RotatE: Knowledge Graph Embedding by Relational Rotation in Complex..." />
      <meta name="og:description" content="We study the problem of learning representations of entities and relations in knowledge graphs for predicting missing links. The success of such a task heavily relies on the ability of modeling and..." />
      <meta name="og:image" content="https://openreview.net/static/images/openreview_logo_512.png" />

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans:400,400i,700,700i" />

  <link rel="stylesheet" href="/static/css/bootstrap.min.css" />
  <link rel="stylesheet" href="/static/css/jquery-ui.min.css" />
  <link rel="stylesheet" href="/static/css/main.min.css" />
</head>

<body class="forum">
  <nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
  
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand home push-link" href="/"><strong>OpenReview</strong>.net</a>
      </div>
  
      <div id="navbar" class="navbar-collapse collapse">
        <form class="navbar-form navbar-left profile-search" role="search">
          <div class="form-group has-feedback">
            <input id="search_input" type="text" class="form-control ui-autocomplete-input" placeholder="Search ICLR 2019 Conference" autocomplete="off" />
            <span class="glyphicon glyphicon-search form-control-feedback" aria-hidden="true"></span>
          </div>
  
          <input id="search_group" type="hidden" value="ICLR.cc/2019/Conference" />
          <input id="search_content" type="hidden" value="all" />
        <ul id="ui-id-1" tabindex="0" class="ui-menu ui-widget ui-widget-content ui-autocomplete ui-front" style="display: none;"></ul></form>
  
        <ul class="nav navbar-nav navbar-right">
        
            <li id="user-menu"><a href="/login">Login</a></li>
        </ul>
      </div>
  
    </div>
  </nav>

  <div id="or-banner" class="banner" style="">
  <div class="container">
    <div class="row">
      <div class="col-xs-12"><a href="/group?id=ICLR.cc/2019/Conference" title="Venue Homepage"><img class="icon" src="/static/images/arrow_left.svg" /> Go to <strong>ICLR 2019 Conference</strong> homepage</a></div>
    </div>
  </div>
</div>
<div id="flash-message-container" class="alert alert-danger" role="alert" style="display: none;">
  <div class="container">
    <div class="row">
      <div class="col-xs-12">
        <div class="alert-content">
          <button type="button" class="close" aria-label="Close"><span aria-hidden="true">×</span></button>
        </div>
      </div>
    </div>
  </div>
</div>

<div class="container">
  <div class="row">
    <div class="col-xs-12">
      <main id="content" class="clearfix openbanner-visible legacy-styles"><div id="note_HkgEQnRqYQ" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>RotatE: Knowledge Graph Embedding by Relational Rotation in Complex Space</a> <a class="note_content_pdf" href="/pdf?id=HkgEQnRqYQ" title="Download PDF" target="_blank"><img src="/static/images/pdf_icon_blue.svg" /></a> </h2></div><div class="meta_row"><span class="signatures">Anonymous</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">28 Sep 2018 (modified: 11 Oct 2018)</span><span class="item">ICLR 2019 Conference Blind Submission</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span><span class="item"><a class="action-bibtex-modal" data-bibtex="@inproceedings{    &#10;anonymous2019rotate:,    &#10;title={RotatE: Knowledge Graph Embedding by Relational Rotation in Complex Space},    &#10;author={Anonymous},    &#10;booktitle={Submitted to International Conference on Learning Representations},    &#10;year={2019},    &#10;url={https://openreview.net/forum?id=HkgEQnRqYQ},    &#10;note={under review}    &#10;}">Show Bibtex</a></span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Abstract: </span><span class="note_content_value">We study the problem of learning representations of entities and relations in knowledge graphs for predicting missing links. The success of such a task heavily relies on the ability of modeling and inferring the patterns of (or between) the relations. In this paper, we present a new approach for knowledge graph embedding called RotatE, which is able to model and infer various relation patterns including: symmetry/antisymmetry, inversion, and composition. Specifically, the RotatE model defines each relation as a rotation from the source entity to the target entity in the complex vector space. Experimental results on multiple benchmark knowledge graphs show that the proposed RotatE model is not only scalable, but also able to infer and model various relation patterns and significantly outperform existing state-of-the-art models for link prediction.</span></div><div class="note_contents"><span class="note_content_field">Keywords: </span><span class="note_content_value">knowledge graph embedding, knowledge graph completion, adversarial sampling</span></div><div class="note_contents"><span class="note_content_field">TL;DR: </span><span class="note_content_value">A new state-of-the-art approach for knowledge graph embedding.</span></div><div class="reply_row clearfix"><div class="item" id="reply_count">10 Replies</div></div></div><hr class="small" /><div id="note_children"><div class="note_with_children"><div id="note_HJlFFR7167" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>What is the difference compared to the ComplEx embedding model?</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HkgEQnRqYQ&amp;noteId=HJlFFR7167"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">(anonymous)</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">06 Nov 2018 (modified: 15 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper1347 Public Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">The reported results are high, which raise my interest. But, it also raises attention to some important issues that need to be addressed.

The proposed model is very similar to the ComplEx embedding model [1]. In fact, in the ComplEx model, the score function is $ real(&lt;r, h, \bar{t}&gt;) $, which includes the element-wise product between $ r \circ h $. Because the ComplEx model uses complex-value embeddings, this product is essentially rotation in the complex plane, thus the same as the idea in this paper.

The authors should clarify and emphasize how their model could provide advantage over the ComplEx model, which is currently one of the SOTA. The authors should provide convincing theoretical arguments because many researches have shown that excessive hyper-parameter tuning and optimization techniques can change benchmark results a lot [2]. The authors also need to provide proof that the ComplEx model cannot model "composition" as in Table 2, given the two models are essentially similar.

Additionally, the comparison with TransE is ambiguous. The authors should make clear that the rotation is in the complex plane of each embedding vector element, thus different from rotation in the embedding space; and check that their arguments and analyses regarding TransE still stand.

About experiments, for fair comparisons, results should be reported on common and standard settings. An example practice could be seen in [3].

Ref:
[1] Trouillon, Theo, et al. Complex Embeddings for Simple Link Prediction. ICML 2016.
[2] Kadlec, Rudolf, Ondrej Bajgar, and Jan Kleindienst. "Knowledge base completion: Baselines strike back." arXiv preprint arXiv:1705.10744 (2017).
[3] Lacroix, Timothée, Nicolas Usunier, and Guillaume Obozinski. "Canonical Tensor Decomposition for Knowledge Base Completion." ICML 2018.</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_rkgeGrg_Tm" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Composition v.s. modelling 1-to-N, N-to-1, N-to-N relations in Table 2</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HkgEQnRqYQ&amp;noteId=rkgeGrg_Tm"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">(anonymous)</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">13 Nov 2018</span><span class="item">ICLR 2019 Conference Paper1347 Public Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">This paper argues that the advantage of the proposed method against ComplEx is its ability to model composition. While this is true, the disadvantage of the TransE-type model (which includes RotatE) is its inability to deal with 1-to-N, N-to-1, N-to-N relations. It seems to me that the composition and modeling of these complicated relations are intrinsically at odds with each other. The author should make this clear, especially in Table 2; ComplEX can handle 1-to-N, N-to-1, N-to-N relations, while RotatE cannot.</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div><div class="note_with_children"><div id="note_HJlYlIhn2X" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>This paper is an important new contribution to the field.   The results should be compared to TorusE.</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HkgEQnRqYQ&amp;noteId=HJlYlIhn2X"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1347 AnonReviewer3</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">05 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper1347 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">The authors propose to model the relations as a rotation in the complex vector space. They show that this way one can model symmetry/antisymmetry, inversion and composition. Another contribution is the so-called self-adversarial negative sampling.

Pros:  The problem that they raise is important and the solution is relevant. The results considering the simplicity of the proposed model are impressive. The experiments, proof of lemmas and general overview are easy to follow, well-written and well-organized.  The improvement given the negative sampling approach is also noteworthy.

Cons: Nevertheless, this approach is very similar to TorusE [1], since the element-wise rotation on the complex plane is somehow related to transformation on high-dimensional Torus. Therefore, it is expected from the authors to investigate the differences between these two approaches.

Suggestions:
Also, it is important to note the result of ablation study on Table 10 in supplementary materials, since part of the improvement does not come only from how the authors model the relation but also from the negative sampling(which could improve the results of other works as well). Maybe it is even better if Table 10 is presented in the main paper. 
Another suggestion is to mention the negative sampling contribution also in the abstract.


[1] Ebisu, Takuma, and Ryutaro Ichise. "Toruse: Knowledge graph embedding on a lie group." arXiv preprint arXiv:1711.05435 (2017)."
</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">7: Good paper, accept</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">3: The reviewer is fairly confident that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_HJlUq8jq3X" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Solid work</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HkgEQnRqYQ&amp;noteId=HJlUq8jq3X"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1347 AnonReviewer1</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">03 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper1347 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">The paper proposes a method for graph embedding to be used for link prediction, in which each entity is represented as a vector in complex space and each relation is modeled as a rotation from the head entity to the tale entity. 
From the modeling perspective, the proposed model is rich as many type of relations can be modeled with it. In particular, symmetric and anti-symmetric relations can be modeled. It is also possible to model the inverse of a relation and the composition of two relations with this setup. Empirical evaluation demonstrates that method is effective and beats a number of well known competitors.

This is a solid work and could be of interest in the community. Modeling is elegant and experimental results are strong.
I have not seen it proposed before.

- The presentation of paper could be improved, in particular the first paragraph of page 2 where the representation in complex domain is introduced is hard to follow and could be improved by inserting formulations instead of merely text.  
It would be nice to explicitly mention the number of real and imaginary dimensions of the complex vectors and provide explicit formulation for the Hadamard product on the complex domain, since the term elementwise could be ambiguous.
- The optimization section does not mention how constraints are imposed. This is an important technicality and should be clarified.
- In experiments, how does the effective number of parameters that are used to express representations compare when the representations are a complex vs a real number? Each complex number is presented with two parameters and each real number with one parameter. How is that taken into account in experiments
- Since the method is reported to beat several number of competitors, it is useful to provide the code.

 
Based on the results above, I vote for the paper to be accepted.
</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">7: Good paper, accept</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_H1e_OITis7" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Is it the RotatE scoring function or the adversarial sampling?</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HkgEQnRqYQ&amp;noteId=H1e_OITis7"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1347 AnonReviewer2</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">23 Oct 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper1347 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value"># Summary
This paper presents a neural link prediction scoring function that can infer symmetry, anti-symmetry, inversion and composition patterns of relations in a knowledge base, whereas previous methods were only able to support a subset. The method achieves state of the art on FB15k-237, WN18RR and Countries benchmark knowledge bases. I think this will be interesting to the ICLR community. I particularly enjoyed the analysis of existing methods regarding the expressiveness of relational patterns mentioned above.

# Strengths
- Improvements over prior neural link prediction methods
- Clearly written paper
- Interesting analysis of existing neural link prediction methods

# Weaknesses
- As the authors not only propose a new scoring function for neural link prediction but also an adversarial sampling mechanism for negative data, I believe a more careful ablation study should have been carried out. There is an ablation study showing the impact of the negative sampling on the baseline TransE, as well as another ablation in the appendix demonstrating the impact of negative sampling on TransE and the proposed method, RotatE, for the FB15k-237. However, from Table 10 in the appendix, one can see that the two competing methods, TransE and RotatE, in fact, perform fairly similarly once both use adversarial sampling it still remains unclear whether the gains observed in table 4 and 5 are due to adversarial sampling or a better scoring function. Particularly, I want to see results of a stronger baseline, ComplEx, equipped with the adversarial sampling approach. Ideally, I would also like to see multiple repeats of the experiments to get a sense of the variance of the results (as it has been done for Countries in Table 6).

# Minor Comments
- Eq 5: Already introduce gamma (the fixed margin) here.
- While I understand that this paper focuses on knowledge graph embeddings, I believe the large body of other relational AI approaches should be mention as some of them can also model symmetry, anti-symmetry, inversion and composition patterns of relations as well (though they might be less scalable and therefore of less practical relevance), e.g. the following come to mind:
  - Lao et al. (2011). Random walk inference and learning in a large scale knowledge base.
  - Neelakantan et al. (2015). Compositional vector space models for knowledge base completion.
  - Das et al. (2016). Chains of Reasoning over Entities, Relations, and Text using Recurrent Neural Networks. 
  - Rocktaschel and Riedel (2017). End-to-end Differentiable Proving.
  - Yang et al. (2017). Differentiable Learning of Logical Rules for Knowledge Base Completion.
- Table 6: How many repeats were used for estimating the standard deviation?
</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">6: Marginally above acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_rkerutP2tQ" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Not mention results of ConvKB and Reciprocal ComplEx-N3</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HkgEQnRqYQ&amp;noteId=rkerutP2tQ"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">(anonymous)</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">29 Sep 2018</span><span class="item">ICLR 2019 Conference Paper1347 Public Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">You should mention the experimental results of ConvKB [1] and Reciprocal ComplEx-N3 [2]. Reciprocal ComplEx-N3 gives higher MRR and Hits@10 scores than yours on both FB15K and FB15k-237. ConvKB produces better scores than yours for MRR on FB15k-237 and MR on WN18RR.

[1] A Novel Embedding Model for Knowledge Base Completion Based on Convolutional Neural Network. NAACL-HLT 2018.
[2] Canonical Tensor Decomposition for Knowledge Base Completion. ICML-2018. Oral presentation.</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_HklyVUAX2m" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Thanks for pointing this out!</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HkgEQnRqYQ&amp;noteId=HklyVUAX2m"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1347 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">29 Oct 2018</span><span class="item">ICLR 2019 Conference Paper1347 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Thanks for pointing this out! We’re aware of the result of ConvKB, which achieves a very high MRR on FB15k (0.396). The reason that we did compare with ConvKB [1] is that there is a bug in ConvKB’s evaluation.

We tried to reproduce their results from their published code [2], but found that the ConvKB tends to assign the same score, i.e., 0,  to many triplets. The reason is that the RELU activation function is used in the convolution layers, which tends to have very sparse output, i.e., the output of many neurons are zero. This brings a big problem in the evaluation.

For evaluation, given a query (h,r, ?), the goals is to identify the rank of the true positive triplets (h, r, t) among all the possible (h, r, t’) triplets. Since the scores of many triplets given by ConvKB equal to 0 (typo, should be "the same score" or "bias"), the true positive triplets and many other false triplets are all ranked the first position at the same time. A reasonable solution would be to randomly pick a triplet among those triplets as the first ranked triplet, and so on. However,  we find that a specific ranking procedure is used by ConvKB, which tends to rank the true positive triplets in a high position. As a result, the performance evaluated in this way is really high, which is not true in reality. We strongly suggest the authors of ConvKB to take a look at this issue and fix their results.

For the results of Reciprocal ComplEx-N3, thanks again for pointing this out, which we are not aware of before the submission. However, note that the focus of the Reciprocal ComplEx-N3 and this paper is different. Our paper proposes a new distance function for learning knowledge graph embedding, and our proposed RotatE is able to infer three relation patterns including composition, symmetry/asymmetry, and inversion, which offers good model interpretability. The focus of Reciprocal ComplEx-N3, however, is on different regularization techniques, which could be potentially applied to our proposed RotatE model. For example, on the FB15k data set, the performance of RotatE increases from 0.797 to 0.815 with the N3-regularizer, which outperforms  the performance of ComplEx-N3 on FB15k (0.80).  We are still in the process of implementing the reciprocal setting for our RotatE model, which seems to be pretty effective according to [3]. 

[1] A Novel Embedding Model for Knowledge Base Completion Based on Convolutional Neural Network
[2] <a href="https://github.com/daiquocnguyen/ConvKB" target="_blank" rel="nofollow">https://github.com/daiquocnguyen/ConvKB</a>
[3] Canonical Tensor Decomposition for Knowledge Base Completion
</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_HJxnXzWVnX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>No bug in our ConvKB evaluation!</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HkgEQnRqYQ&amp;noteId=HJxnXzWVnX"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures"><a href="/profile?id=~Dai_Quoc_Nguyen1" class="profile-link">Dai Quoc Nguyen</a></span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">29 Oct 2018 (modified: 30 Oct 2018)</span><span class="item">ICLR 2019 Conference Paper1347 Public Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Disclose: I am the author of ConvKB. I had re-run my ConvKB implementation. And there is not a single triple having score at 0 on FB15k-237.

It would be nice if you can create an open issue in my ConvKB github before discussing any information made in public.

Update for a clarification:

It is important to note that our implementation can work with other score functions. Last year, I verified my “eval.py” implementation by using the same output vector and matrix embeddings produced by other models (such as TransE, TransR, TransH and STransE) to prove that our "eval.py" implementation is correct and can produce the exact same scores as produced by those models. 

For each correct test triple, I just replicated this correct test triple several times to add to its set of corrupted triples, in order to work with a batch size (as shown in Lines 188-190 in “eval.py”). This is straightforward and does not matter when ranking the correct test triple. I thought that "the same score" you mentioned is actually for the correct test triple because of replicating. You should have a careful look at this point and then edit your comment above to have a reasonable reply.

I just read your paper. This is nice work. Your experimental results are still great even you add negative results from other papers.
</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_HyekBjPinm" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Sorry we meant that many triples have the same score, and an open evaluation code is now available.</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HkgEQnRqYQ&amp;noteId=HyekBjPinm"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1347 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">04 Nov 2018</span><span class="item">ICLR 2019 Conference Paper1347 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Hi Dai, 
     Thanks for the verification. In the above comment, sorry we meant that many triplets have the same score, which equals to the bias of your model, i.e., b = tf.Variable(tf.constant(0.0, shape=[num_classes]), name="b") in your model.py code. The reasons is that in many cases all the nonlinear RELU units are not activated. In addition, we found that this problem would only occur when the nonlinear activation Relu is used in the model. This explains why the evaluation of other models, including TransE, TransR, TransH and STransE, are correct. 

We suggest you to re-evaluate your model without replicating the true triplets. We’ve fixed this debug in your code and put the updated codes in <a href="https://github.com/KnowledgeBaseCompleter/eval-ConvKB" target="_blank" rel="nofollow">https://github.com/KnowledgeBaseCompleter/eval-ConvKB</a> . 

By the way, we appreciate your work, which we find is really interesting.  We did not intend any offence to your work. We hope we can push forward this exciting direction together. We look forward to your feedback.
</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_HkxYw_tn3Q" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>No bug in our ConvKB evaluation! </a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HkgEQnRqYQ&amp;noteId=HkxYw_tn3Q"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures"><a href="/profile?id=~Dai_Quoc_Nguyen1" class="profile-link">Dai Quoc Nguyen</a></span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">04 Nov 2018 (modified: 06 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper1347 Public Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">How many valid test triples and their corrupted triples have the same score. And what are they and their ranks on WN18RR and FB15k237? You had mentioned "equal to 0" (the same score) in your first reply. It seems that you actually did not run my code before. I do not want to discuss our model in details as my code was based on Denny Britz's implementation for employing a CNN to text classification.

There is nothing called "a specific ranking procedure" in my evaluation. I do not know why you must pay much attention to "replicating the valid test triples". Again, this is straightforward and does not matter when ranking, because each valid test triple and its replicated triples have a same score and a same rank.

As I said in my first reply, it would be nice if you created an open issue in my ConvKB github for further discussions. So I could tell you that we also had another version to evaluate the model without replicating the valid test triples, for which the experimental results are still same for with and without replicating the triples. This obviously helps to save time for both of us. 

The "without replicating" version ran slower than the version in the github, thus I did not update it last year. But now, I have just updated it to my ConvKB github. You can check and test it.

Your approach and results are great. And you do not need to beat all scores on all datasets to have an accepted paper. I appreciate if you can also include our published results. </span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div></div></div></div></div></div></div></div></main></div>
  </div>
</div>


    <!-- Footer -->
    <footer class="sitemap">
      <div class="container">
        <div class="row hidden-xs">
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/venues">All Venues</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="/contact">Contact</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
    
        <div class="row visible-xs-block">
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/contact">Contact</a></li>
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
      </div>
    </footer>
    
    <footer class="sponsor">
      <div class="container">
        <div class="row">
          <div class="col-sm-10 col-sm-offset-1">
            <p class="text-center">
              OpenReview is created by the <a href="http://www.iesl.cs.umass.edu/" target="_blank">Information Extraction and Synthesis Laboratory</a>, College of Information and Computer Science, University of Massachusetts Amherst. We gratefully acknowledge the support of the OpenReview sponsors:  Google,  Facebook, NSF, the University of Massachusetts Amherst Center for Data Science, and Center for Intelligent Information Retrieval, as well as the Google Cloud Platform for donating the computing and networking services on which OpenReview.net runs.
            </p>
          </div>
        </div>
      </div>
    </footer>

  <div id="feedback-modal" class="modal fade" tabindex="-1" role="dialog">
    <div class="modal-dialog">
      <div class="modal-content">
        <div class="modal-header">
          <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button>
          <h3 class="modal-title">Send Feedback</h3>
        </div>
        <div class="modal-body">
          <p>Enter your feedback below and we'll get back to you as soon as possible.</p>
          <form action="/feedback" method="POST">
            <div class="form-group">
              <input type="email" name="from" class="form-control" placeholder="Email" />
            </div>
            <div class="form-group">
              <input type="text" name="subject" class="form-control" placeholder="Subject" />
            </div>
            <div class="form-group">
              <textarea name="message" class="form-control feedback-input" rows="5" placeholder="Message" required=""></textarea>
            </div>
          <ul id="ui-id-2" tabindex="0" class="ui-menu ui-widget ui-widget-content" style="display: none;"></ul></form>
        </div>
        <div class="modal-footer">
          <button type="button" class="btn btn-default" data-dismiss="modal">Cancel</button>
          <button type="button" class="btn btn-primary">Send</button>
        </div>
      </div>
    </div>
  </div>

  <script type="text/javascript" async="" src="https://www.google-analytics.com/analytics.js"></script><script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js"></script>
  <script>window.jQuery || document.write('&lt;script src="/static/js/vendor/jquery-2.2.4.min.js"&gt;&lt;\/script&gt;')</script>

  <script src="/static/dist/vendor.min.js"></script>
  <script src="/static/dist/templates.min.js"></script>
  <script src="/static/dist/openreview.min.js"></script>

    <script>window.legacyScripts = true;</script>


    <script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-108703919-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() { dataLayer.push(arguments); }
      gtag('js', new Date());
      gtag('config', 'UA-108703919-1');
    </script>


<div role="status" aria-live="assertive" aria-relevant="additions" class="ui-helper-hidden-accessible"></div></body></html>
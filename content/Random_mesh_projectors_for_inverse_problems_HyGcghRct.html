<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" class="no-js"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>Random mesh projectors for inverse problems | OpenReview</title>
  <meta name="description" content="" />

      <meta name="citation_title" content="Random mesh projectors for inverse problems" />
        <meta name="citation_author" content="Anonymous" />
      <meta name="citation_publication_date" content="2018/09/27" />
      <meta name="citation_online_date" content="2018/09/27" />
      <meta name="citation_pdf_url" content="https://openreview.net/pdf?id=HyGcghRct7" />
      <meta name="twitter:card" content="summary" />
      <meta name="twitter:site" content="@openreviewnet" />
      <meta name="og:title" content="Random mesh projectors for inverse problems" />
      <meta name="og:description" content="We propose a new learning-based approach to solve ill-posed inverse problems in imaging. We address the case where ground truth training samples are rare and the problem is severely..." />
      <meta name="og:image" content="https://openreview.net/static/images/openreview_logo_512.png" />

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans:400,400i,700,700i" />

  <link rel="stylesheet" href="/static/css/bootstrap.min.css" />
  <link rel="stylesheet" href="/static/css/jquery-ui.min.css" />
  <link rel="stylesheet" href="/static/css/main.min.css" />
</head>

<body class="forum">
  <nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
  
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand home push-link" href="/"><strong>OpenReview</strong>.net</a>
      </div>
  
      <div id="navbar" class="navbar-collapse collapse">
        <form class="navbar-form navbar-left profile-search" role="search">
          <div class="form-group has-feedback">
            <input id="search_input" type="text" class="form-control ui-autocomplete-input" placeholder="Search ICLR 2019 Conference" autocomplete="off" />
            <span class="glyphicon glyphicon-search form-control-feedback" aria-hidden="true"></span>
          </div>
  
          <input id="search_group" type="hidden" value="ICLR.cc/2019/Conference" />
          <input id="search_content" type="hidden" value="all" />
        <ul id="ui-id-1" tabindex="0" class="ui-menu ui-widget ui-widget-content ui-autocomplete ui-front" style="display: none;"></ul></form>
  
        <ul class="nav navbar-nav navbar-right">
        
            <li id="user-menu"><a href="/login">Login</a></li>
        </ul>
      </div>
  
    </div>
  </nav>

  <div id="or-banner" class="banner" style="">
  <div class="container">
    <div class="row">
      <div class="col-xs-12"><a href="/group?id=ICLR.cc/2019/Conference" title="Venue Homepage"><img class="icon" src="/static/images/arrow_left.svg" /> Go to <strong>ICLR 2019 Conference</strong> homepage</a></div>
    </div>
  </div>
</div>
<div id="flash-message-container" class="alert alert-danger" role="alert" style="display: none;">
  <div class="container">
    <div class="row">
      <div class="col-xs-12">
        <div class="alert-content">
          <button type="button" class="close" aria-label="Close"><span aria-hidden="true">×</span></button>
        </div>
      </div>
    </div>
  </div>
</div>

<div class="container">
  <div class="row">
    <div class="col-xs-12">
      <main id="content" class="clearfix openbanner-visible legacy-styles"><div id="note_HyGcghRct7" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Random mesh projectors for inverse problems</a> <a class="note_content_pdf" href="/pdf?id=HyGcghRct7" title="Download PDF" target="_blank"><img src="/static/images/pdf_icon_blue.svg" /></a> </h2></div><div class="meta_row"><span class="signatures">Anonymous</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">28 Sep 2018 (modified: 16 Nov 2018)</span><span class="item">ICLR 2019 Conference Blind Submission</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span><span class="item"><a class="action-bibtex-modal" data-bibtex="@inproceedings{    &#10;anonymous2019random,    &#10;title={Random mesh projectors for inverse problems},    &#10;author={Anonymous},    &#10;booktitle={Submitted to International Conference on Learning Representations},    &#10;year={2019},    &#10;url={https://openreview.net/forum?id=HyGcghRct7},    &#10;note={under review}    &#10;}">Show Bibtex</a></span><a class="note_content_pdf item" href="/revisions?id=HyGcghRct7" target="_blank">Show Revisions</a></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Abstract: </span><span class="note_content_value">We propose a new learning-based approach to solve ill-posed inverse problems in imaging. We address the case where ground truth training samples are rare and the problem is severely ill-posed---both because of the underlying physics and because we can only get few measurements. This setting is common in geophysical imaging and remote sensing. We show that in this case the common approach to directly learn the mapping from the measured data to the reconstruction becomes unstable. Instead, we propose to first learn an ensemble of simpler mappings from the data to projections of the unknown image into random piecewise-constant subspaces. We then combine the projections to form a final reconstruction by solving a deconvolution-like problem. We show experimentally that the proposed method is more robust to measurement noise and corruptions not seen during training than a directly learned inverse.</span></div><div class="note_contents"><span class="note_content_field">Keywords: </span><span class="note_content_value">imaging, inverse problems, subspace projections, random Delaunay triangulations, CNN, geophysics, regularization</span></div><div class="note_contents"><span class="note_content_field">TL;DR: </span><span class="note_content_value">We solve ill-posed inverse problems with scarce ground truth examples by estimating an ensemble of random projections of the model instead of the model itself.</span></div><div class="reply_row clearfix"><div class="item" id="reply_count">11 Replies</div></div></div><hr class="small" /><div id="note_children"><div class="note_with_children"><div id="note_SJg0kX0j6m" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Summary of responses to reviewers</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HyGcghRct7&amp;noteId=SJg0kX0j6m"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1103 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">16 Nov 2018 (modified: 20 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper1103 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">We thank the reviewers for taking the time to read the paper and prepare their comments. All are informative and they made us aware of the parts of presentation that might have been confusing; we hope that our updates make the manuscript clearer.

With some of the comments, though, we have to respectfully disagree. We explain this in the responses to individual reviewers. Here we only summarize a few main points, before addressing the individual reviewers’ comments in detail.

-- In our method we solve a linear inverse problem y = Ax + n which is very ill posed, without having access to ground truth training data. To do so, we train a non-linear regressor (a neural net) which maps y to orthogonal projections of x into random subspaces with an arbitrarily chosen training dataset. To simplify network structure, we precompute x0 which can be an application of a pseudoinverse of A to y, a non-negative least squares solution or some other simple estimator. Importantly, because the measurements are few and the problem is very ill posed, x0 is a very bad estimate of x.

-- We do not project x0 into random subspaces as Reviewer 3 suggests—this is achieved by a simple linear operator and would be of limited interest. We rather compute *orthogonal* projections of x from x0. As we elaborate in the updated manuscript (see Appendix A) and in the response to Reviewer 3, this cannot be achieved by a linear operator and it requires training a nonlinear regressor (in our case, a neural network).

-- The term “linear inverse problems” only implies that the forward operators are linear. In most interesting applications, the inverse operators are arbitrarily nonlinear. This is the case already with standard sparsity-based methods. In our case, since we do not know where x lives, the nonlinear modeling is achieved by learning. Many, if not most practical imaging problems have (approximately) linear forward operators: examples are synthetic aperture radar, seismic tomography, radio-interferometric astronomy, MRI, CT, etc. While certainly many are only approximately linear (or fully nonlinear), linearization techniques are at the core of both practical algorithms and theoretical analysis. The latter is true even for questions of uniqueness and stability as discussed beautifully in [1]. In this sense we are looking at a very important and large class of nonlinear operators to be learned, and we do not see our discussion of linear inverse problems as a harsh limitation. That said, our method could be applied to other problems such as depth sensing, as suggested by Reviewer 2, but the justification would require additional work. For example, the Lipschitz stability (which we have per [1]) would not be guaranteed. The fact that an inverse exists for the imaging tasks we consider is given by injectivity on  \mathcal{X}, which is a low-dimensional structure (a manifold) embedded in R^N. In the original manuscript this assumption was in a footnote which is now expanded into a short discussion in Section 3.1. We elaborate this further in the response to Reviewer 2.

-- Our method can be interpreted as a randomization or an ensembling method. But unlike strategies such as randomizing the seed when training many neural networks to directly estimate x, which will be hampered by the instability of the problem and the fact that we do not have ground truth data, we use a particular randomization scheme where we randomize the learning target. That way we a) have a clear model for randomization which tells us exactly how to use the individual projection estimates, and b) make each individual member of the problem ensemble stable.

[1] Stefanov, P. and Uhlmann, G., 2009. Linearizing non-linear inverse problems and an application to inverse backscattering. Journal of Functional Analysis, 256(9), pp.2842-2866.</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_SklYOP5e67" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Interesting method, but limited demonstrations and unclear reason for working</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HyGcghRct7&amp;noteId=SklYOP5e67"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1103 AnonReviewer2</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">08 Nov 2018</span><span class="item">ICLR 2019 Conference Paper1103 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">Summary:
Given an inverse problem, we want to infer (x) s.t. Ax = y, but in situations where the number of observations are very sparse, and do not enable direct inversion. The paper tackles scenarios where 'x' is of the form of an image. The proposed approach is a learning based one which trains CNNs to infer x given y (actually an initial least square solution x_init is used instead of y).

The key insight is that instead of training to directly predict x, the paper proposes to predict different piecewise constant projections of x from x_init , with one CNN trained for each projection, each projection space defined from a random delaunay triangulation, with the hope that learning prediction for each projection is more sample efficient. The desired x is then optimized for given the predicted predicted projections.

Pros:
- The proposed approach is interesting and novel - I've not previously seen the idea of predicting different picewise constant projections instead of directly predicting the desired output (although using random projections has been explored)
- The presented results are quantitatively and qualitatively better compared to a direct prediction baseline
- The paper is generally well written, and interesting to read

Cons:
While the method is interesting, it is apriori unclear why this works, and why this has been only explored in context of linear inverse problems if it really does work.

- Regarding limited demonstration: The central idea presented here is is generally applicable to any per-pixel regression task. Given this, I am not sure why this paper only explores it in the particular case of linear inversion and not other general tasks (e.g. depth prediction from a single image). Is there some limitation which would prevent such applications? If yes, a discussion would help. If not, it would be convincing to see such applications.

- Regarding why it works: While learning a single projection maybe more sample efficient, learning all of them s.t. the obtained x is accurate may not be. Given this, I'm not entirely sure why the proposed approach is supposed to work. One hypothesis is that the different learned CNNs that each predict a piecewise projection are implicitly yielding an ensembling effect, and therefore a more fair baseline to compare would be a 'direct-ensemble' where many different (number = number of projections) direct CNNs (with different seeds etc.) are trained, and their predictions ensembled.


Overall, while the paper is interesting to read and shows some nice results in a particular domain, it is unclear why the proposed approach should work in general and whether it is simply implicitly similar to an ensemble of predictors.</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">5: Marginally below acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_Hke127Csa7" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Explanation for why it works and motivation for "linear" inverse problems (Part 1)</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HyGcghRct7&amp;noteId=Hke127Csa7"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1103 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">16 Nov 2018 (modified: 19 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper1103 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">&gt;&gt; “Pros:
- The proposed approach is interesting and novel - I've not previously seen the idea of predicting different picewise constant projections instead of directly predicting the desired output (although using random projections has been explored)
- The presented results are quantitatively and qualitatively better compared to a direct prediction baseline
- The paper is generally well written, and interesting to read”

Response: We are glad that the reviewer found the paper interesting.

&gt;&gt; “While the method is interesting, it is apriori unclear why this works, and why this has been only explored in context of linear inverse problems if it really does work."

&gt;&gt; "Regarding limited demonstration: The central idea presented here is is generally applicable to any per-pixel regression task. Given this, I am not sure why this paper only explores it in the particular case of linear inversion and not other general tasks (e.g. depth prediction from a single image). Is there some limitation which would prevent such applications? If yes, a discussion would help. If not, it would be convincing to see such applications.”

Response: While we agree with the reviewer that the central idea is more widely applicable, we wish to emphasize that what the reviewer calls a “particular case of linear inversion” covers a very large variety of practically relevant problems. The list includes super-resolution, deconvolution, computed tomography, inverse scattering, synthetic aperture radar, seismic tomography, radio-interferometric astronomy, and many other problems. 

Importantly, the fact that the forward problem is linear (which is why the corresponding inverse problems are unfortunately called linear) does not at all imply that the sought inverse map which we are trying to learn (the solution operator) is linear. The inverse map of interest will not be linear for anything but the simplest Tikhonov regularized solution (and variations thereof). For instance, if x is modeled as sparse in a dictionary, the inverse map is nonlinear even though the vast majority of inverse problems regularized by sparsity are “linear". The entire field of compressive sensing is concerned with linear inverse problems. With general manifold models for x, such as the one assumed in the paper, we depart further from linear inverse maps. We now state this more explicitly in Section 3.1 and a new Appendix A. The ability to adapt to such nonlinear prior models is part of the reason why CNNs perform well on related problems. Additionally, these nonlinear inverses may be arbitrarily ill-posed, which calls for ever more sophisticated regularizers. In this sense, we are looking at a very large class of hard, practically relevant problems, whose solution operators are nonlinear.

While nothing prevents practical application of our proposed method to problems such as single-image depth estimation, one benefit of studying linear inverse problems is that as soon as we are in finite dimensions (e.g., a low-dimensional manifold in R^N and a finite number of measurements), and the forward operator is injective, Lipschitz stability is guaranteed (refer added citation: [1]). Injectivity can be generically achieved with a sufficient number of measurements that depends only on the manifold dimension.

In applications such as depth estimation from a single image it is less straightforward to obtain similar guarantees. Namely, injectivity fails as one can easily construct cases where the same 2D depth map corresponds to multiple 2D images. So, while in practice our method might give good results, the justification would require additional work.</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_rklYC70opQ" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Explanation for why it works and motivation for "linear" inverse problems (Part 2)</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HyGcghRct7&amp;noteId=rklYC70opQ"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1103 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">16 Nov 2018 (modified: 19 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper1103 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">&gt;&gt; “Regarding why it works: While learning a single projection maybe more sample efficient, learning all of them s.t. the obtained x is accurate may not be. Given this, I'm not entirely sure why the proposed approach is supposed to work. One hypothesis is that the different learned CNNs that each predict a piecewise projection are implicitly yielding an ensembling effect, and therefore a more fair baseline to compare would be a 'direct-ensemble' where many different (number = number of projections) direct CNNs (with different seeds etc.) are trained, and their predictions ensembled.”

Response: Recall that we are in a regime where we do not have access to a large ground-truth training dataset and the measurements are very sparse. For this reason, we cannot hope to get a method that reconstructs all the details of x. This is the motivation to split the problem in two stages: in the first stage we only estimate “stable” information, by learning a collection of nonlinear, but stable maps from y (or pinv(A)*y, or its non-negative least squares reconstruction) to projections of x. As shown experimentally, this strategy outperforms the baseline which uses the exact same number of measurements and training samples. In fact, all ProjNets are trained using half the number of samples as the baseline (we now make this more explicit in the manuscript).

In the second stage of computing x from the projections, in order to get a very accurate, detailed estimate, one would need to use more training samples, and those samples should correspond to ground truth images which we do not have. Furthermore, as Reviewer 1 suggests, this might involve new and better regularizers. 

We agree with the reviewer’s hypothesis that the different learned CNNs are implicitly yielding an ensembling effect—that is a nice interpretation of the proposed method. However, because the direct inverse map from y to x is highly unstable, we design a randomization mechanism which is better behaved than just training neural networks with different seeds. The instability of the full inverse map y -&gt; x (or x0 -&gt; x) will result in large systematic errors that will not average out. To illustrate this, per reviewer’s suggestion, we trained ten new direct networks and repeated the erasure experiments (Figures 5b, 10, 11) for the case when p=1/8. If, for example, we consider the image in Figure 5b, we find that 9/10 direct network reconstructions look almost the same as the poor reconstruction shown in the manuscript (see: <a href="https://tinyurl.com/direct-new-seeds" target="_blank" rel="nofollow">https://tinyurl.com/direct-new-seeds</a> ), while one reconstruction looks a bit closer to the true x, but still quite wrong (much more so than the reconstructions from the ProjNets). Our randomization scheme operates by providing random, low-dimensional targets that are stable and have low variance so that the resulting estimates are close to their true values and the subsequent ensembling mechanism is deterministic (in the sense that it does not rely on “noise”). We stress again that the total number of training samples used to train all ProjNets, or the single SubNet is the same or smaller than that used to train the direct baseline.

Moreover, we point out that we train two different architectures—one that requires a different network for each subspace (ProjNet) and one that works for any subspace (SubNet). The success of SubNet and the fact that it outperforms the direct baseline suggests that the important idea is indeed that of estimating low-dimensional projections.

Another important aspect of our choice of randomization is that it leads to interpretable, local measurements. These correspond to a new, equivalent forward operator B with favorable properties (see Section 3.2, 3.3 and Proposition 1). It would be hard to interpret the output of randomly initialized direct networks in a similar way (for example, it is not clear what we should expect the output distribution to be).

[1] Stefanov, P. and Uhlmann, G., 2009. Linearizing non-linear inverse problems and an application to inverse backscattering. Journal of Functional Analysis, 256(9), pp.2842-2866.</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div></div></div><div class="note_with_children"><div id="note_BygsLNF62Q" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>novel method for inverse problems</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HyGcghRct7&amp;noteId=BygsLNF62Q"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1103 AnonReviewer1</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">05 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper1103 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">This paper proposes a novel method of solving ill-posed inverse problems and specifically focuses on geophysical imaging and remote sensing where high-res samples are rare and expensive. 
The motivation is that previous inversion methods are often not stable since the problem is highly under-determined.  To  alleviate these problems, this paper proposes a novel idea: 
instead of fully reconstructing in the original space, the authors create reconstructions in projected spaces. 
The projected spaces they use have very low dimensions so the corresponding Lipschitz constant is small. 
The specific low-dimensional reconstructions they obtain are piecewise constant images on random Delaunay trinagulations. This is theoretically motivated by classical work (Omohundro'89) and has the further advantage that the low-res reconstructions are interpretable. One can visually see how closely they capture the large shapes of the unknown image. 

These low-dimensional reconstructions are subsequently combined in the second stage of the proposed algorithm, to get a high-resolution reconstruction. The important aspect is that the piecewise linear reconstructions are now treated as measurments which however are local in the pixel-space and hence lead to more stable reconstructions. 

The problem of reconstruction from these piecewise constant projections is of independent interest. Improving this second stage of their algorithm, the authors would get a better result overall. For example I would recommend using Deep Image prior as an alternative technique of reconstructing a high-res image from multiple piecewise constant images, but this can be future work. 

Overall I like this paper. It contains a truly novel idea for an architecture in solving inverse problems. The two steps can be individually improved but the idea of separation is quite interesting and novel. 

</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">7: Good paper, accept</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_r1lmQNCjTX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Thank you for your insights on extending our work</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HyGcghRct7&amp;noteId=r1lmQNCjTX"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1103 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">16 Nov 2018</span><span class="item">ICLR 2019 Conference Paper1103 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">We are glad that the reviewer enjoyed the paper. Indeed one of the main ideas put forward is the separation into information that can be stably (but nonlinearly) extracted from the measurements in this very ill-posed, no ground truth regime, and information that requires a stronger regularizing idea which kicks in at stage 2. We find it encouraging that the reviewer’s comments on improving stage 2 are quite similar to our ideas on extending this work (we now mention this in the concluding remarks). Further, we now provide an additional discussion of why the method can work and why nonlinear regressors are necessary in Appendix A and an updated Section 3.1, as an effort to address the comments of other reviewers.</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div><div class="note_with_children"><div id="note_Sygyv3zq3X" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Unclear why this should work</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HyGcghRct7&amp;noteId=Sygyv3zq3X"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1103 AnonReviewer3</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">03 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper1103 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">This paper describes a novel method for solving inverse problems in imaging.

The basic idea of this approach is use the following steps:
1. initialize with nonnegative least squares solution to inverse problem (x0)
2. compute m different projections of x0
3. estimate x from the m different projections by solving "reformuated" inverse problem using TV regularization.

The learning part of this algorithm is in step 2, where m different convolutional neural networks are used to learn m good projections. The projections correspond to computing a random Delaunay triangulation over the image domain and then computing pixel averages within each triangle. It's not clear exactly what the learning part is doing, i.e. what makes a "good" triangulation, why a CNN might accurately represent one, and what the shortcomings of truly random triangulations might be.

More specifically, for each projection the authors start with a random set of points in the image domain and compute a Delaunay triangulation. They average x0 in each of the Delaunay triangles. Then since the projection is constant on each triangle, the projection into the lower-dimensional space is given by the magnitude of the function over each of the triangular regions. Next they train a convolutional neural network to approximate the above projection. The do this m times. It's not clear why the neural network approximation is necessary or helpful. 

Empirically, this method outperforms a straightforward use of a convolutional U-Net to invert the problem.

The core novelty of this paper is the portion that uses a neural network to calculate a projection onto a random Delaunay triangulation. The idea of reconstructing images using random projections is not especially new, and much of the "inverse-ness" of the problem here is removed by first taking the pseudoinverse of the forward operator and applying it to the observations. Then the core idea at the heart of the paper is to speed up this reconstruction using a neural network by viewing the projection onto the mesh space as a set of special filter banks which can be learned.

At the heart of this paper is the idea that for an L-Lipschitz function f : R^k → R the sample complexity
is O(L^k), so the authors want to use the random projections to essentially reduce L. However, the Cooper sample complexity bound scales with k like k^{1+k/2}, so the focus on the Lipschitz constant seems misguided.
This isn't damning, but it seems like the piecewise-constant estimators are a sort of regularizer, and that's where we
really get the benefits.

The authors only compare to another U-Net, and it's not entirely clear how they even trained that U-Net. It'd be nice to see if you get any benefit here from their method relative to other approaches in the literature, or if this is just better than inversion using a U-Net. Even how well a pseudoinverse does would be nice to see or TV-regularized least squares.

Practically I'm quite concerned about their method requiring training 130 separate convolutional neural
nets. The fact that all the different datasets give equal quality triangulations seems a bit odd, too. Is
it possible that any network at all would be okay? Can we just reconstruct the image from regression
on 130 randomly-initialized convolutional networks? 

The proposed method isn't bad, and the idea is interesting. But I can't help but wonder whether it works just because what we're doing is denoising the least squares reconstruction, and regression on many random projections might be pretty good for that. Unfortunately, the experiments don't help with developing a deeper understanding. 
</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">4: Ok but not good enough - rejection</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">3: The reviewer is fairly confident that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_HyxbyBRi6m" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Clarification of our method (Part 1)</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HyGcghRct7&amp;noteId=HyxbyBRi6m"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1103 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">16 Nov 2018 (modified: 19 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper1103 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">The reviewer summarizes our method as

&gt;&gt; “This paper describes a novel method for solving inverse problems in imaging.
 
The basic idea of this approach is use the following steps:
1. initialize with nonnegative least squares solution to inverse problem (x0)
2. compute m different projections of x0
3. estimate x from the m different projections by solving "reformuated" inverse problem using TV regularization.”

Response: We have to respectfully disagree with this summary, especially because it informs the remainder of the reviewer’s comments. There seems to be a misunderstanding about Step 2 and many later comments appear to stem from it. Since this step is the crux of our proposed method, we begin by summarizing it here, with references to the relevant parts of the manuscript.

Instead of computing m different projections of x0 as the reviewer suggests, we regress subspace projections of x, the true image (see Section 3.1.1, Paragraphs 3 and 4). To do so, we must train a nonlinear regressor, in our case a convolutional neural network. (The need for nonlinearity is explained below.) To make this point clearer in the manuscript, we updated Figure 2 to explicitly show that x0 is not fed into linear subspace projectors of itself, but rather used as data from which we estimate projections of x. Indeed, projecting x0 would not be very interesting since it would simply imply various linear ways of looking at x0 and the networks would not be doing any actual inversion or data modeling. 

Again, what we actually do is that we compute *orthogonal* projections P_S x from y = Ax (or x0 = pinv(A)y or something similar) into a collection of subspaces {S_\lambda}_{\lambda=1}^{\Lambda} (see Section 3.1.1, Paragraph 3). While projecting x0 is a simple linear operation, regressing projections of an unknown x from the measurement data y is not. To explain why we need nonlinear regressors, we added a new figure and a short discussion to the manuscript (please see the new Appendix A). For the reviewer’s convenience, we summarize the discussion here (although it might be easier to read in the typeset pdf version):

Suppose that there exists a linear operator F \in R^{N \times M} which maps y (or pinv(A)y) to P_S x. The simplest requirement on such an F is consistency: if x already lives in the subspace S, then we would like to have F A x = x. Another way to write this is that for any x, not necessarily in S, we require FA FA x = FA x, which implies that FA = (FA)^2 is an idempotent operator. However, because range(F) = S \neq range(A^*), it will in general not hold that (FA)^* = FA. This implies that FA is not an orthogonal projection, but rather an oblique one.

As we show in the new Figure 8 (Appendix A), this oblique projection can be an arbitrarily poor approximation of the actual orthogonal projection that we seek. The nullspace of this projection is precisely N(A) = range^\perp(A^*). Similar conclusions can be drawn for any other (ad hoc) linear operator, which would not even be a projection.

There are various assumptions one can make to guarantee that the map from Ax to P_S x exists. We assume that the models live on a low-dimensional manifold (please see updated Section 3.1; this low-dimensional structure assumption has previously been a footnote), and that the measurements are in general position with respect to this manifold. Our future work involves making quantitative statements about this aspect of the method.
</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_S1gHWHAjpm" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Clarification of our method (Part 2) </a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HyGcghRct7&amp;noteId=S1gHWHAjpm"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1103 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">16 Nov 2018 (modified: 19 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper1103 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">&gt;&gt; “The learning part of this algorithm is in step 2, where m different convolutional neural networks are used to learn m good projections. The projections correspond to computing a random Delaunay triangulation over the image domain and then computing pixel averages within each triangle. It's not clear exactly what the learning part is doing, i.e. what makes a "good" triangulation, why a CNN might accurately represent one, and what the shortcomings of truly random triangulations might be.”

Response: Again, we feel that there is a misunderstanding about the role of the networks in our method. In one of the subsequent comments the reviewer posits that 

&gt;&gt; “... the core idea at the heart of the paper is to speed up this reconstruction using a neural network by viewing the projection onto the mesh space as a set of special filter banks which can be learned.”

It seems that the reviewer’s interpretation is that the triangulation is computed by the network, together with the projection. But as we elaborate in Section 3.1.1, and as we explained when commenting on the reviewer’s summary above, the role of the network is to compute an orthogonal projection of x into a given random subspace. This is ensured by an explicit, non-trainable, projector added as the last layer (see Section 4.1.1, Paragraph 2).  As such, we do use *truly random triangulations*. Nothing about these triangulations is being learned from the training data (see Section 3.1.1, Paragraph 3).

As detailed in the discussion above, computing these projections from y (or x0) is a nonlinear problem, and it requires a nonlinear computational structure (please see the new Appendix A). Since the normal operator corresponding to ray transforms is convolutional, we decided to use a CNN (assuming that our rays provide a somewhat constant coverage of the domain). As the reviewer points out, the CNNs are not natural structures to produce images that live exactly on triangulations. That is why we add an explicit, non-trainable projection layer (see Section 4.1.1, Paragraph 2, and Figure 9).

&gt;&gt; “More specifically, for each projection the authors start with a random set of points in the image domain and compute a Delaunay triangulation. They average x0 in each of the Delaunay triangles. Then since the projection is constant on each triangle, the projection into the lower-dimensional space is given by the magnitude of the function over each of the triangular regions. Next they train a convolutional neural network to approximate the above projection. The do this m times. It's not clear why the neural network approximation is necessary or helpful.”

Response: We again wish to emphasize that it is not x0 that we project (this is just a linear operation), but rather we nonlinearly regress orthogonal low-dimensional projections of x which implies that the network models some aspects of the distribution of x. We agree with the reviewer that in the former case, the network would be superfluous. 

&gt;&gt; “The core novelty of this paper is the portion that uses a neural network to calculate a projection onto a random Delaunay triangulation. The idea of reconstructing images using random projections is not especially new, and much of the "inverse-ness" of the problem here is removed by first taking the pseudoinverse of the forward operator and applying it to the observations. Then the core idea at the heart of the paper is to speed up this reconstruction using a neural network by viewing the projection onto the mesh space as a set of special filter banks which can be learned.”

Response: While we agree with the reviewer that random projections are a known idea, as far as we know and as noted by Reviewer 2, this is the first work that attempts to regress the orthogonal projections of the target signal x into random subspaces. We believe that this contribution sets it apart from previous work, especially because computing these projections from measurements is a truly nonlinear problem unlike the more common fixed linear projections. The reason to regress P_S x instead of x is that it is a more stable task, and a “clever” way to achieve randomization while at the same time controlling stability and hardness of learning. The role of the network is to approximate this nonlinear operator that maps y to projections of x, rather than to speed up a simple linear projection of x0.

We also respectfully disagree that much of the inverseness is removed by taking the pseudoinverse. In fact, this is one of our main contributions: we state in several places in the manuscript (for example Paragraph 3 of Introduction), that we work in a highly undersampled regime where the pseudoinverse (or any other simple regularizer for that matter) cannot do a reasonable job and the role of learning cannot be seen as denoising or artifact removal (see for example Figure 1 bottom row). This is also illustrated in  Section 4 with the non-negative least squares reconstructions shown in Figures 6 and 7.
</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_HygKVSRjTX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Clarification of our method (Part 3) </a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HyGcghRct7&amp;noteId=HygKVSRjTX"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1103 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">16 Nov 2018 (modified: 19 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper1103 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">&gt;&gt; “At the heart of this paper is the idea that for an L-Lipschitz function f : R^k → R the sample complexity is O(L^k), so the authors want to use the random projections to essentially reduce L. However, the Cooper sample complexity bound scales with k like k^{1+k/2}, so the focus on the Lipschitz constant seems misguided. This isn't damning, but it seems like the piecewise-constant estimators are a sort of regularizer, and that's where we really get the benefits.”

Response: We apologize for using K in the manuscript while stating this result: this is unfortunate, especially because we later use K for subspace dimension (and in this case the reviewer is absolutely right). We are interested in the stability of the map from measurements y to the targets P_S x, so that the map f(y) operates on objects in R^M. Note that the number of measurements M (or k in the reviewer’s comment) is kept fixed. On the other hand, L changes because we are learning a simpler target.

We agree that the piecewise-constant estimators act as a regularizer in the sense of learning. They restrict the hypothesis class to “regular” or “simple” maps, and one standard way to quantify regularity is via the Lipschitz constant.

&gt;&gt; “The authors only compare to another U-Net, and it's not entirely clear how they even trained that U-Net. It'd be nice to see if you get any benefit here from their method relative to other approaches in the literature, or if this is just better than inversion using a U-Net. Even how well a pseudoinverse does would be nice to see or TV-regularized least squares.”

Response: We describe the training of the U-Net (the direct baseline in the paper) in some detail in Section 4.1.1, which we now expanded to include information about the number of samples for training. We also now explicitly highlight that the training and test sets are entirely different in all experiments and for all networks. The U-Net that we use achieves state of the art results on a very long list of image recovery tasks [1,2,3,4], including tomographic problems that are similar to the one we experiment with. This suggests that it is a hard baseline to beat. Indeed, as the reviewer suggests, we already do show both the pseudoinverse in Figures 1, 6 and 7 and the TV-regularized least squares in bottom row of Figure 1. It can be observed that in all cases the U-Net, our baseline, outperforms them while the proposed method beats the U-Net.

&gt;&gt; “Practically I'm quite concerned about their method requiring training 130 separate convolutional neural nets. The fact that all the different datasets give equal quality triangulations seems a bit odd, too. Is it possible that any network at all would be okay? Can we just reconstruct the image from regression on 130 randomly-initialized convolutional networks?”

Response: We agree that it is favorable to train fewer networks. However, we already do propose the SubNet (motivated exactly by this concern) which requires training only a single network (see Section 4.1.1 Paragraph 5), and which performs on par with the collection of ProjNets and better than the baseline. Note that we are using the same number of samples to train the SubNet and the direct baseline, and only half of those samples to train *all* the ProjNets. We now mention the number of samples explicitly in Section 4 under Robustness to Corruption.

We are not quite certain that we understand the comment about equal quality triangulations. The experiments on different datasets showcase that we can train on arbitrary image datasets and obtain comparable reconstructions. We reiterate that our networks are not computing triangulations, only projections into these triangular subspaces. All triangulations are generated at random, independently of the datasets and the networks. 

The reviewer’s idea of regression on 130 randomly-initialized convolutional networks is interesting and a possible avenue for further research. However, each network would approximate the same unstable, high variance map (see, for example, the response to Reviewer 2, and examples <a href="https://tinyurl.com/direct-new-seeds" target="_blank" rel="nofollow">https://tinyurl.com/direct-new-seeds</a> ). One important aspect of our randomization via random triangulations is that it gives interpretable, local measurements, equivalent to a new forward operator B with favorable properties (see the discussion in Section 3.2 and 3.3). It is not immediately clear how one would interpret the outputs of randomly initialized convolutional networks.
</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_BkeFsHCiam" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Clarification of our method (Part 4)</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=HyGcghRct7&amp;noteId=BkeFsHCiam"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1103 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">16 Nov 2018 (modified: 19 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper1103 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">&gt;&gt; “The proposed method isn't bad, and the idea is interesting. But I can't help but wonder whether it works just because what we're doing is denoising the least squares reconstruction, and regression on many random projections might be pretty good for that. Unfortunately, the experiments don't help with developing a deeper understanding.” 

Response: As we stress in the manuscript (Paragraph 3 of Introduction and Figure 1) we are precisely addressing the regime where the denoising or artifact removal paradigm fails. In Figure 1, we show that standard methods that would indeed correspond to denoising the least squares reconstruction, such as the TV-regularized least squares or non-negative least squares do not give a reasonable solution to our problem.

We feel the reviewer’s impression is based on their interpretation that we project x0 into random subspaces, but as we try to emphasize in our response, we are doing something very different. Estimating *orthogonal* projections of x (as opposed to x0) from few measurements cannot be interpreted as denoising, but rather as discovering different stable pieces of information about the conditional distribution of x which is supported on some a priori unknown low-dimensional structure, $\mathcal{X}$, and the part of learning is to discover this structure (or rather, its projections into a set of random subspaces which is a simpler problem). We updated the manuscript to further emphasize this aspect in Section 3.1 and added Appendix A.

[1] Jin, K.H., McCann, M.T., Froustey, E. and Unser, M., 2017. Deep convolutional neural network for inverse problems in imaging. IEEE Transactions on Image Processing, 26(9), pp.4509-4522.
[2] Rivenson, Y., Zhang, Y., Günaydın, H., Teng, D. and Ozcan, A., 2018. Phase recovery and holographic image reconstruction using deep learning in neural networks. Light: Science &amp; Applications, 7(2), p.17141.
[3] Sinha, A., Lee, J., Li, S. and Barbastathis, G., 2017. Lensless computational imaging through deep learning. Optica, 4(9), pp.1117-1125.
[4] Li, S., Deng, M., Lee, J., Sinha, A. and Barbastathis, G., 2018. Imaging through glass diffusers using densely connected convolutional networks. Optica, 5(7), pp.803-813.</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div></div></div></div></div></div></div></div></main></div>
  </div>
</div>


    <!-- Footer -->
    <footer class="sitemap">
      <div class="container">
        <div class="row hidden-xs">
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/venues">All Venues</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="/contact">Contact</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
    
        <div class="row visible-xs-block">
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/contact">Contact</a></li>
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
      </div>
    </footer>
    
    <footer class="sponsor">
      <div class="container">
        <div class="row">
          <div class="col-sm-10 col-sm-offset-1">
            <p class="text-center">
              OpenReview is created by the <a href="http://www.iesl.cs.umass.edu/" target="_blank">Information Extraction and Synthesis Laboratory</a>, College of Information and Computer Science, University of Massachusetts Amherst. We gratefully acknowledge the support of the OpenReview sponsors:  Google,  Facebook, NSF, the University of Massachusetts Amherst Center for Data Science, and Center for Intelligent Information Retrieval, as well as the Google Cloud Platform for donating the computing and networking services on which OpenReview.net runs.
            </p>
          </div>
        </div>
      </div>
    </footer>

  <div id="feedback-modal" class="modal fade" tabindex="-1" role="dialog">
    <div class="modal-dialog">
      <div class="modal-content">
        <div class="modal-header">
          <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button>
          <h3 class="modal-title">Send Feedback</h3>
        </div>
        <div class="modal-body">
          <p>Enter your feedback below and we'll get back to you as soon as possible.</p>
          <form action="/feedback" method="POST">
            <div class="form-group">
              <input type="email" name="from" class="form-control" placeholder="Email" />
            </div>
            <div class="form-group">
              <input type="text" name="subject" class="form-control" placeholder="Subject" />
            </div>
            <div class="form-group">
              <textarea name="message" class="form-control feedback-input" rows="5" placeholder="Message" required=""></textarea>
            </div>
          <ul id="ui-id-2" tabindex="0" class="ui-menu ui-widget ui-widget-content" style="display: none;"></ul></form>
        </div>
        <div class="modal-footer">
          <button type="button" class="btn btn-default" data-dismiss="modal">Cancel</button>
          <button type="button" class="btn btn-primary">Send</button>
        </div>
      </div>
    </div>
  </div>

  <script type="text/javascript" async="" src="https://www.google-analytics.com/analytics.js"></script><script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js"></script>
  <script>window.jQuery || document.write('&lt;script src="/static/js/vendor/jquery-2.2.4.min.js"&gt;&lt;\/script&gt;')</script>

  <script src="/static/dist/vendor.min.js"></script>
  <script src="/static/dist/templates.min.js"></script>
  <script src="/static/dist/openreview.min.js"></script>

    <script>window.legacyScripts = true;</script>


    <script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-108703919-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() { dataLayer.push(arguments); }
      gtag('js', new Date());
      gtag('config', 'UA-108703919-1');
    </script>


<div role="status" aria-live="assertive" aria-relevant="additions" class="ui-helper-hidden-accessible"></div></body></html>
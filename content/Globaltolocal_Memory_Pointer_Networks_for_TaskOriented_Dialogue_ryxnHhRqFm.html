<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" class="no-js"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>Global-to-local Memory Pointer Networks for Task-Oriented Dialogue | OpenReview</title>
  <meta name="description" content="" />

      <meta name="citation_title" content="Global-to-local Memory Pointer Networks for Task-Oriented Dialogue" />
        <meta name="citation_author" content="Anonymous" />
      <meta name="citation_publication_date" content="2018/09/27" />
      <meta name="citation_online_date" content="2018/09/27" />
      <meta name="citation_pdf_url" content="https://openreview.net/pdf?id=ryxnHhRqFm" />
      <meta name="twitter:card" content="summary" />
      <meta name="twitter:site" content="@openreviewnet" />
      <meta name="og:title" content="Global-to-local Memory Pointer Networks for Task-Oriented Dialogue" />
      <meta name="og:description" content="End-to-end task-oriented dialogue is challenging since knowledge bases are usually large, dynamic and hard to incorporate into a learning framework. We propose the global-to-local memory pointer..." />
      <meta name="og:image" content="https://openreview.net/static/images/openreview_logo_512.png" />

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans:400,400i,700,700i" />

  <link rel="stylesheet" href="/static/css/bootstrap.min.css" />
  <link rel="stylesheet" href="/static/css/jquery-ui.min.css" />
  <link rel="stylesheet" href="/static/css/main.min.css" />
</head>

<body class="forum">
  <nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
  
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand home push-link" href="/"><strong>OpenReview</strong>.net</a>
      </div>
  
      <div id="navbar" class="navbar-collapse collapse">
        <form class="navbar-form navbar-left profile-search" role="search">
          <div class="form-group has-feedback">
            <input id="search_input" type="text" class="form-control ui-autocomplete-input" placeholder="Search ICLR 2019 Conference" autocomplete="off" />
            <span class="glyphicon glyphicon-search form-control-feedback" aria-hidden="true"></span>
          </div>
  
          <input id="search_group" type="hidden" value="ICLR.cc/2019/Conference" />
          <input id="search_content" type="hidden" value="all" />
        <ul id="ui-id-1" tabindex="0" class="ui-menu ui-widget ui-widget-content ui-autocomplete ui-front" style="display: none;"></ul></form>
  
        <ul class="nav navbar-nav navbar-right">
        
            <li id="user-menu"><a href="/login">Login</a></li>
        </ul>
      </div>
  
    </div>
  </nav>

  <div id="or-banner" class="banner" style="">
  <div class="container">
    <div class="row">
      <div class="col-xs-12"><a href="/group?id=ICLR.cc/2019/Conference" title="Venue Homepage"><img class="icon" src="/static/images/arrow_left.svg" /> Go to <strong>ICLR 2019 Conference</strong> homepage</a></div>
    </div>
  </div>
</div>
<div id="flash-message-container" class="alert alert-danger" role="alert" style="display: none;">
  <div class="container">
    <div class="row">
      <div class="col-xs-12">
        <div class="alert-content">
          <button type="button" class="close" aria-label="Close"><span aria-hidden="true">×</span></button>
        </div>
      </div>
    </div>
  </div>
</div>

<div class="container">
  <div class="row">
    <div class="col-xs-12">
      <main id="content" class="clearfix openbanner-visible legacy-styles"><div id="note_ryxnHhRqFm" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Global-to-local Memory Pointer Networks for Task-Oriented Dialogue</a> <a class="note_content_pdf" href="/pdf?id=ryxnHhRqFm" title="Download PDF" target="_blank"><img src="/static/images/pdf_icon_blue.svg" /></a> </h2></div><div class="meta_row"><span class="signatures">Anonymous</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">28 Sep 2018 (modified: 19 Nov 2018)</span><span class="item">ICLR 2019 Conference Blind Submission</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span><span class="item"><a class="action-bibtex-modal" data-bibtex="@inproceedings{    &#10;anonymous2019global-to-local,    &#10;title={Global-to-local Memory Pointer Networks for Task-Oriented Dialogue},    &#10;author={Anonymous},    &#10;booktitle={Submitted to International Conference on Learning Representations},    &#10;year={2019},    &#10;url={https://openreview.net/forum?id=ryxnHhRqFm},    &#10;note={under review}    &#10;}">Show Bibtex</a></span><a class="note_content_pdf item" href="/revisions?id=ryxnHhRqFm" target="_blank">Show Revisions</a></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Abstract: </span><span class="note_content_value">End-to-end task-oriented dialogue is challenging since knowledge bases are usually large, dynamic and hard to incorporate into a learning framework. We propose the global-to-local memory pointer (GLMP) networks to address this issue. In our model, a global memory encoder and a local memory decoder are proposed to share an external knowledge. The encoder encodes dialogue history, modifies global contextual representation that is shared with the decoder, and generates a global memory pointer. The decoder first generates a sketch response with unfilled slots. Next, it passes the global memory pointer to filter the external knowledge for relevant information, then instantiates the slots via the local memory pointers which points to specific entries in the external knowledge. We empirically show that our model can improve copy accuracy and mitigate the common out-of-vocabulary problem. As a result, GLMP is able to improve over the previous state-of-the-art models in both simulated bAbI Dialogue and human-human Stanford Multi-domain Dialogue datasets on automatic and human evaluation.</span></div><div class="note_contents"><span class="note_content_field">Keywords: </span><span class="note_content_value">pointer networks, memory networks, task-oriented dialogue systems, natural language processing</span></div><div class="note_contents"><span class="note_content_field">TL;DR: </span><span class="note_content_value">We propose a global memory encoder and a local memory decoder that share an external knowledge to strengthen task-oriented dialogue generation via sketch responses and pointer networks. </span></div><div class="reply_row clearfix"><div class="item" id="reply_count">8 Replies</div></div></div><hr class="small" /><div id="note_children"><div class="note_with_children"><div id="note_BJetM8J3aX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Interesting Work, Need Clarity on Experiements</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=ryxnHhRqFm&amp;noteId=BJetM8J3aX"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">(anonymous)</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">16 Nov 2018</span><span class="item">ICLR 2019 Conference Paper1581 Public Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">This paper builds upon Mem2Seq (Madotto et al 2018) to incorporate large external KBs for task-oriented dialogs. To the best of my understanding, the innovations over Mem2Seq are: (1) use of context RNN (instead of just last utterance) as the query in MN encoder, (2) addition of the hidden state of context RNN to the dialog memory (equation 3), (3) the use of global memory pointer 4) additional loss components (Loss_g and Loss_l in equation 11) and (5) two step decoding using sketch tags

To me the biggest pro of the paper is its impressive result on SMD corpus. I appreciate the authors performing a human evaluation of the generated response for SMD.  However, I am quite concerned about two main issues. The first issue is in experimental rigor, and second is in dataset preparation, which is also related to experimental rigor but also exposes certain model weaknesses. I elaborate below.

Experimental Rigor
This paper uses "entity type" information in Local Memory Decoder (Section 2.3), but compares against all previous work that does NOT use this information. This makes the comparison not sound. In fact, the original Memory Net paper (Bordes &amp; Weston 2017) and many extensions performed two sets of experiments, one vanilla and one with a "match" feature, which had access to the entity type information. This paper compares against all previous papers in the settings that do NOT use this "match" feature. So, it is not clear, whether the improvement is coming from the specific changes in the model, or just by using additional information at training time. For example, QRN paper (Seo et al 2017) with Match feature reports an average OOV error (across 5 bAbI tasks) of 2.3%, which is fairly close the reported results in Table 2 in this paper. In my opinion, this careful experimental comparison is essential before having a clear assessment of this paper.

Dataset Preparation
This is a comment on this paper and also the Mem2Seq paper. Both these seem to have CHANGED the original training/test datasets to suit their model. In particular, all KB tuples in bAbI follow the format (restaurant_name, relation, value of relation), e.g., (olive_garden, rating, 5), however, Mem2Seq had reversed just the rating-relation tuples (5, rating, olive_garden), because its model allowed it to copy only from the object location, and it needed to copy restaurant name in the dialog. A similar example can be seen in this paper Figure 3 (row 5) where an ARTIFICIAL tuple (chinese_restaurant no_traffic 6_miles, poi, tai_pan) has been added to the SMD KB. Notice that values for different relations (namely poi_type, traffic_info, and distance) for the entity tai_pan have been concatenated in this artificial tuple at subject location and the entity name appears as object. This is just so that it can be copied by the model. Such tuples don't usually exist in normal KBs.

I believe that this changing of datasets makes its comparisons with other models unfair. Even if other models were re-trained with this new modified dataset, it is still a severe limitation, because in practice, such tuples may not be found in the KB, and in such situations this model (and Mem2Seq) will not perform well. 


Questions to authors
1) how does your model compare with "+match" extension of previous models? 
2) Say we are in a more reasonable setting where we are not given entity type information, but say we are given whether it is a KB entity or not. How well will your model perform then?
3) Suppose we remove the reverse relations in bAbI and the concatenated poi relations in SMD. How well will your model perform then?</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_B1xRlvQppm" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Thank you for your feedback and your clear summary of our contribution</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=ryxnHhRqFm&amp;noteId=B1xRlvQppm"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1581 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">17 Nov 2018</span><span class="item">ICLR 2019 Conference Paper1581 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Please let me reply to you below:

First, in our experiment, we did not add the “entity type” information into the word representation, which is same as the previous works such as Mem2Seq, MemNN, QRN, etc. Therefore, the comparison is fair. The step we did related to entity type was the sketch response preprocessing, based on the provided entity table (or the NER if the table is not provided), we can obtain our gold sketch responses for training. The local memory pointer is then learned to copy words to replace the generated sketch tags. Note that all the word-level representations in the external knowledge are not included the “type embedding”.

Second, yes we followed the same preprocessing as in the Mem2Seq paper to represent our KB tuples. If you look into the original KB in the SMD dataset, it is not represented as the triplet format. Therefore, there are many different ways to represent the KB information, some may use flat KB as we did, some may use the hierarchical one, or even the input the table-like KB. Although it might not be the most effective one, we choose this preprocessing strategy, so does the previous works, is because it is simple and fast. There are some related works have tried different ways to represent KB information, but it may need additional attention calculation for entity copying. The comparison between these KB structures are interesting and could be our future works.

Thank you again for your interest in our work. </span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div><div class="note_with_children"><div id="note_rJljYi39nX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>nicely motivated architecture and thorough evaluation, aimed at an interesting and difficult task</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=ryxnHhRqFm&amp;noteId=rJljYi39nX"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1581 AnonReviewer2</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">03 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper1581 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">The paper presents a new model for reading and writing memory in the context of task-oriented dialogue. The model contains three main components: an encoder, a decoder, and an external KB. The external KB is in the format of an SVO triple store. The encoder encodes the dialogue history and, in doing so, writes its hidden states to memory and generates a "global memory pointer" as its last hidden state. The decoder takes as input the global memory pointer, the encoded dialogue state history, and the external KB and then generates a response using a two-step process in which it 1) generates a template response using tags to designate slots that need filling and 2) looks up the correct filler for each slot using the template+global memory pointer as a query. The authors evaluate the model on a simulated dialogue dataset (bAbI) and on a human-human dataset (Stanford Multi-domain Dialogue or SMD) as well as in a human eval. They show substantial improvements over existing models on SMD (the more interesting of the datasets) in terms of entity F1--i.e. the number of correctly-generated entities in the response. They also show improvement on bAbI specifically on cases involving OOVs. On the human evaluation, they show improvements in terms of both "appropriateness" and "human-likeness". 

Overall, I think this is a nice and well-motivated model. I very much appreciate the thoroughness of the evaluation (two different datasets, plus a human evaluation). The level of analysis of the model was also good, although there (inevitably) could have been more. Since it is such a complex model, I would have liked to see more thorough ablations or at least better descriptions of the baselines, in order to better understand which specific pieces of the model yield which types of gains. A few particular questions below:

- You describe the auxiliary loss on the global pointer, and mention an ablation study that show that this improves performance. Maybe I am overlooking something, but I cannot find this ablation in the paper or appendix. It would be nice to see how large the effect is. 
- Following on the above, why no similar auxiliary losses on additional components, e.g. the template generation? Were these tried and deemed unnecessary or vice-versa (i.e. the default was no auxiliary loss and they were only added when needed)? Either way, it would be nice to better communicate the experiments/intuitions that motivated the particular architecture you arrived at.
- I really appreciate that you run a human eval. But why not have humans evaluate objective "correctness" as well? It seems trivial to ask people to say whether or not the answer is correct/communicates the same information as the gold.
</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">8: Top 50% of accepted papers, clear accept</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_BklMNKNLaQ" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Re: Reviewer2</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=ryxnHhRqFm&amp;noteId=BklMNKNLaQ"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1581 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">12 Nov 2018</span><span class="item">ICLR 2019 Conference Paper1581 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Thank you for your review and feedback. The question which you mentioned, the replies are as followed : 

1. You describe the auxiliary loss on the global pointer, and mention an ablation study that show that this improves performance. Maybe I am overlooking something, but I cannot find this ablation in the paper or appendix. It would be nice to see how large the effect is.
Reply: 
The ablation study of our global memory pointer G is in Table 4, the GLMP w/o G. For SMD dataset, without G gave us around 8.3% additional loss.

2. Following on the above, why no similar auxiliary losses on additional components, e.g. the template generation? Were these tried and deemed unnecessary or vice-versa (i.e. the default was no auxiliary loss and they were only added when needed)? 
Reply: 
Our model has three loss functions, Loss_g for global memory pointer, Loss_v for sketch response generation and Loss_l for local memory pointer. The template generation loss you mentioned is included as Loss_v, which is a standard cross-entropy loss. 

3. I really appreciate that you run a human eval. But why not have humans evaluate objective "correctness" as well?
Reply: 
In our evaluation setting, we combine the correctness and the appropriateness, as the criteria we mentioned in the appendix A.3. 
</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div><div class="note_with_children"><div id="note_BJl5tkoN2X" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>End-to-end task oriented system: An encoder-decoder approach with a shared external knowledge base</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=ryxnHhRqFm&amp;noteId=BJl5tkoN2X"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1581 AnonReviewer3</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">29 Oct 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper1581 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">This is, in general, a well-written paper with extensive experimentation. 

The authors tried to describe their architecture both with equations as well as graphically. However, I would like to mention the following: 

In Section 2.1 I am not sure all the symbols are clearly defined. For example, I could not locate the definitions of n, l etc. Even if they are easy to assume, I am fond of appropriate definitions. Also, I suspect that some symbols, like n, are not used consistently across the manuscript.

I am also confused about the loss function. Which loss function is used when?

I am missing one more figure. From Fig 2 it's not so straightforward to see how the encoder/decoder along with the shared KB work at the same time (i.e. not independently)

In Section 2.3, it's not clear to me how the expected output word will be picked up from the local memory pointer. Same goes for the entity table.

How can you guarantee that that position n+l+1 is a null token?

What was the initial query vector and how did you initialise that? Did different initialisations had any effect on performance?

If you can please provide an example of a memory position.

Also, i would like to see a description of how the OOV tasks are handled.

Finally, your method is a NN end-to-end one and I was wondering how do you compare not with other end-to-end approaches, but with a traditional approach, such as pydial?


And some minor suggestions:

Not all the abbreviations are defined. For example QRN, GMN, KVR. It would also be nice to have the references of the respective methods included in the Tables or their captions.

Parts of Figs. 1&amp;2 are pixelised. It would be nice to have everything vectorised.

 I would prefer to see the training details (in fact, I would even be favorable of having more of those) in the main body of the manuscript, rather than in the appendix.

There are some minor typos, such as "our approach that utilizing the recurrent" or "in each datasets"</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">8: Top 50% of accepted papers, clear accept</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_S1g_lF4U6X" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Re: Reviewer3</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=ryxnHhRqFm&amp;noteId=S1g_lF4U6X"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1581 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">12 Nov 2018</span><span class="item">ICLR 2019 Conference Paper1581 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Thank you for your review and feedback. The question which you mentioned, the replies are as followed : 

1. In Section 2.1 I am not sure all the symbols are clearly defined.
Reply: 
We will make the definitions more appropriate and consistent. 

2. I am also confused about the loss function. Which loss function is used when?
Reply: 
Our model has three loss functions: Loss_g for global memory pointer, Loss_v for sketch response generation and Loss_l for local memory pointer. During training, they are summed and optimized simultaneously.

3. I am missing one more figure. From Fig 2 it's not so straightforward to see how the encoder/decoder along with the shared KB work at the same time (i.e. not independently)
Reply: 
As shown in the block diagram Fig 1(a), first, the global memory encoder encodes dialogue history and writes its hidden states into the external knowledge. Then the last hidden state is used to read the external knowledge and generate the global memory pointer at the same time. Later during the decoding stage, the local memory decoder generates sketch responses. Then the global memory pointer and the sketch RNN hidden state are passed to the external knowledge, which returns the local memory pointer that can copy plain text to replace the sketch tags and obtain the final system response.

4. In Section 2.3, it's not clear to me how the expected output word will be picked up from the local memory pointer. Same goes for the entity table.
Reply: 
Sorry that we did not make it clear. As the visualization in Fig 3, the right column is the local memory pointers for time step 0 to 3. For example, in step 3, when our sketch RNN generated tags such as“@address”, the word will be picked out from the learned local memory pointer, which points to the memory node “[783_arcadia_pl] address chevron”. Therefore, we took the Object word “783_arcadia_pl” out as the real address. Otherwise, the output word is generated from the vocabulary

5. How can you guarantee that that position n+l+1 is a null token?
Reply: 
We manually assign token of “n+l+1” position to be “NULL” during preprocessing.

6. What was the initial query vector and how did you initialise that? Did different initialisations had any effect on performance?
Reply: 
The query vector is the vector to query the external knowledge. In the encoder, the query vector is the last hidden state of context RNN. In the decoder, the query vectors are the hidden states of the sketch RNN. 

7. If you can please provide an example of a memory position.
Reply: 
The example of memory position is shown in the left part of Fig 3, as you can see, our external knowledge includes the kB and the dialogue history.

8. Also, i would like to see a description of how the OOV tasks are handled.
Reply:
Sorry that we did not make it clear. In Sec 2.2, we explain that our model can mitigate the OOV problem is because we use the context RNN hidden states as the global contextual representation, and feed into the external knowledge. Therefore, the embedding of each token includes its RNN hidden state, including embeddings of OOV tokens. 

9. Finally, your method is a NN end-to-end one and I was wondering how do you compare not with other end-to-end approaches, but with a traditional approach, such as pydial?
Reply: 
We mainly followed previous works to compare end-to-end models without human feature engineer efforts. In Table 3, results of the rule-based system from the Eric et al., 2017 are reported, we can observe the improvement over the traditional pipeline solution on the SMD human-human dialogue dataset.
</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div><div class="note_with_children"><div id="note_ryeDCdQ-jQ" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Expect more experiments</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=ryxnHhRqFm&amp;noteId=ryeDCdQ-jQ"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1581 AnonReviewer1</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">15 Oct 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper1581 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">This paper puts forward a new global+local memory pointer network to tackle task-oriented dialogue problem.

The idea of introducing global memory is novel and experimental results show its effectiveness to encode external knowledge in most cases.

Here're some comments:
1. In global memory pointer, the users employ non-normalized probability (non-softmax). What is the difference in performance if one uses softmax?

2. In (11), there's no linear weights. Will higher weights in global/local help?

3. As pointed out in ablation study, it's weird that in task5 global memory pointer does not help.

4. The main competitor of this algorithm is mem2seq. While mem2seq includes DSTC2 and In-car Assistant, and especially in-car assistant provides the first example dialogue, why does the paper not include expeirments on these two datasets?</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">5: Marginally below acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">3: The reviewer is fairly confident that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_BkeK5uELpm" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Re: Reviewer1</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=ryxnHhRqFm&amp;noteId=BkeK5uELpm"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper1581 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">12 Nov 2018</span><span class="item">ICLR 2019 Conference Paper1581 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Thank you for your review and feedback.  The question which you mentioned, the replies are as followed : 

1. In global memory pointer, the users employ non-normalized probability (non-softmax). What is the difference in performance if one uses softmax?
Reply: 
Sorry that we did not make it clear. We treat the training of global memory pointer as a multi-label learning problem, instead of a multi-class classification problem. For example, if the system generates a response like “Starbucks is 4_miles away”, both “Starbucks” and “4_miles” are model’s outputs. 

2. In (11), there's no linear weights. Will higher weights in global/local help?
Reply: 
In our experiments, we tried to add the linear weights in (11) as hyper-parameters, the results are similar. 

3. As pointed out in ablation study, it's weird that in task5 global memory pointer does not help.
Reply: 
Note that our ablation study on bAbI dialogue is on its OOV setting, which could be considered as a zero-shot scenario. Therefore, we observe a performance tradeoff between the normal setting and the OOV setting, that is, if we increase the dropout ratio, the accuracy in normal setting may decrease and the accuracy in OOV setting may increase. Therefore, after we rerun the ablation study on task5 OOV with the same dropout rate, the performance difference between with and without global memory pointer is very little. We will include this explanation in the paper. 

4. The main competitor of this algorithm is mem2seq. While mem2seq includes DSTC2 and In-car Assistant, and especially in-car assistant provides the first example dialogue, why does the paper not include expeirments on these two datasets?
Reply: 
Sorry that we did not make it clear. The “SMD” dataset in our experiment is exactly the same as the “In-Car Assistant” dataset in the Mem2Seq paper (different naming), both came from the paper Eric et al, 2017. Therefore, the results are comparable. Second, We did not include the DSTC2 in our paper is because it is a “human-machine” dataset which is originally designed as a DST task, not a response generation task. That dataset has many noisy system responses as well. We take one of the dialogues as an example, one can observe that the system responses are not properly collected.
...
User: &lt;SILENCE&gt;	
System: the_lucky_star is a nice place in the south of town and the prices are cheap
User: what else is there	
System: the_lucky_star is a great restaurant
User: anything else	
System: The post code of the_lucky_star is the_lucky_star_post_code
...
</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div></div></main></div>
  </div>
</div>


    <!-- Footer -->
    <footer class="sitemap">
      <div class="container">
        <div class="row hidden-xs">
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/venues">All Venues</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="/contact">Contact</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
    
        <div class="row visible-xs-block">
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/contact">Contact</a></li>
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
      </div>
    </footer>
    
    <footer class="sponsor">
      <div class="container">
        <div class="row">
          <div class="col-sm-10 col-sm-offset-1">
            <p class="text-center">
              OpenReview is created by the <a href="http://www.iesl.cs.umass.edu/" target="_blank">Information Extraction and Synthesis Laboratory</a>, College of Information and Computer Science, University of Massachusetts Amherst. We gratefully acknowledge the support of the OpenReview sponsors:  Google,  Facebook, NSF, the University of Massachusetts Amherst Center for Data Science, and Center for Intelligent Information Retrieval, as well as the Google Cloud Platform for donating the computing and networking services on which OpenReview.net runs.
            </p>
          </div>
        </div>
      </div>
    </footer>

  <div id="feedback-modal" class="modal fade" tabindex="-1" role="dialog">
    <div class="modal-dialog">
      <div class="modal-content">
        <div class="modal-header">
          <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button>
          <h3 class="modal-title">Send Feedback</h3>
        </div>
        <div class="modal-body">
          <p>Enter your feedback below and we'll get back to you as soon as possible.</p>
          <form action="/feedback" method="POST">
            <div class="form-group">
              <input type="email" name="from" class="form-control" placeholder="Email" />
            </div>
            <div class="form-group">
              <input type="text" name="subject" class="form-control" placeholder="Subject" />
            </div>
            <div class="form-group">
              <textarea name="message" class="form-control feedback-input" rows="5" placeholder="Message" required=""></textarea>
            </div>
          <ul id="ui-id-2" tabindex="0" class="ui-menu ui-widget ui-widget-content" style="display: none;"></ul></form>
        </div>
        <div class="modal-footer">
          <button type="button" class="btn btn-default" data-dismiss="modal">Cancel</button>
          <button type="button" class="btn btn-primary">Send</button>
        </div>
      </div>
    </div>
  </div>

  <script type="text/javascript" async="" src="https://www.google-analytics.com/analytics.js"></script><script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js"></script>
  <script>window.jQuery || document.write('&lt;script src="/static/js/vendor/jquery-2.2.4.min.js"&gt;&lt;\/script&gt;')</script>

  <script src="/static/dist/vendor.min.js"></script>
  <script src="/static/dist/templates.min.js"></script>
  <script src="/static/dist/openreview.min.js"></script>

    <script>window.legacyScripts = true;</script>


    <script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-108703919-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() { dataLayer.push(arguments); }
      gtag('js', new Date());
      gtag('config', 'UA-108703919-1');
    </script>


<div role="status" aria-live="assertive" aria-relevant="additions" class="ui-helper-hidden-accessible"></div></body></html>
<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" class="no-js"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>Cosine similarity-based Adversarial process | OpenReview</title>
  <meta name="description" content="" />

      <meta name="citation_title" content="Cosine similarity-based Adversarial process" />
        <meta name="citation_author" content="Hee-Soo Heo" />
        <meta name="citation_author" content="Hye-Jin Shim" />
        <meta name="citation_author" content="Jee-Weon Jung" />
        <meta name="citation_author" content="IL-Ho Yang" />
        <meta name="citation_author" content="Sung-Hyun Yoon" />
        <meta name="citation_author" content="Ha-Jin Yu" />
      <meta name="citation_publication_date" content="2018/09/27" />
      <meta name="citation_online_date" content="2018/09/27" />
      <meta name="citation_pdf_url" content="https://openreview.net/pdf?id=S1eL8i0cFm" />
      <meta name="twitter:card" content="summary" />
      <meta name="twitter:site" content="@openreviewnet" />
      <meta name="og:title" content="Cosine similarity-based Adversarial process" />
      <meta name="og:description" content="An adversarial process between two deep neural networks is a promising approach to train robust networks. In this study, we propose a framework for training networks that eliminates subsidiary..." />
      <meta name="og:image" content="https://openreview.net/static/images/openreview_logo_512.png" />

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans:400,400i,700,700i" />

  <link rel="stylesheet" href="/static/css/bootstrap.min.css" />
  <link rel="stylesheet" href="/static/css/jquery-ui.min.css" />
  <link rel="stylesheet" href="/static/css/main.min.css" />
</head>

<body class="forum">
  <nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
  
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand home push-link" href="/"><strong>OpenReview</strong>.net</a>
      </div>
  
      <div id="navbar" class="navbar-collapse collapse">
        <form class="navbar-form navbar-left profile-search" role="search">
          <div class="form-group has-feedback">
            <input id="search_input" type="text" class="form-control ui-autocomplete-input" placeholder="Search ICLR 2019 Conference" autocomplete="off" />
            <span class="glyphicon glyphicon-search form-control-feedback" aria-hidden="true"></span>
          </div>
  
          <input id="search_group" type="hidden" value="ICLR.cc/2019/Conference" />
          <input id="search_content" type="hidden" value="all" />
        <ul id="ui-id-1" tabindex="0" class="ui-menu ui-widget ui-widget-content ui-autocomplete ui-front" style="display: none;"></ul></form>
  
        <ul class="nav navbar-nav navbar-right">
        
            <li id="user-menu"><a href="/login">Login</a></li>
        </ul>
      </div>
  
    </div>
  </nav>

  <div id="or-banner" class="banner" style="">
  <div class="container">
    <div class="row">
      <div class="col-xs-12"><a href="/group?id=ICLR.cc/2019/Conference" title="Venue Homepage"><img class="icon" src="/static/images/arrow_left.svg" /> Go to <strong>ICLR 2019 Conference</strong> homepage</a></div>
    </div>
  </div>
</div>
<div id="flash-message-container" class="alert alert-danger" role="alert" style="display: none;">
  <div class="container">
    <div class="row">
      <div class="col-xs-12">
        <div class="alert-content">
          <button type="button" class="close" aria-label="Close"><span aria-hidden="true">Ã—</span></button>
        </div>
      </div>
    </div>
  </div>
</div>

<div class="container">
  <div class="row">
    <div class="col-xs-12">
      <main id="content" class="clearfix openbanner-visible legacy-styles"><div id="note_S1eL8i0cFm" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Cosine similarity-based Adversarial process</a> <a class="note_content_pdf" href="/pdf?id=S1eL8i0cFm" title="Download PDF" target="_blank"><img src="/static/images/pdf_icon_blue.svg" /></a> </h2></div><div class="meta_row"><span class="signatures"><a href="/profile?email=zhasgone%40naver.com" class="profile-link" data-toggle="tooltip" data-placement="bottom" title="" data-original-title="zhasgone@naver.com">Hee-Soo Heo</a>, <a href="/profile?email=shimhyejin930615%40gmail.com" class="profile-link" data-toggle="tooltip" data-placement="bottom" title="" data-original-title="shimhyejin930615@gmail.com">Hye-Jin Shim</a>, <a href="/profile?email=aberforth19%40naver.com" class="profile-link" data-toggle="tooltip" data-placement="bottom" title="" data-original-title="aberforth19@naver.com">Jee-Weon Jung</a>, <a href="/profile?email=heisco%40hanmail.net" class="profile-link" data-toggle="tooltip" data-placement="bottom" title="" data-original-title="heisco@hanmail.net">IL-Ho Yang</a>, <a href="/profile?email=ysh901108%40naver.com" class="profile-link" data-toggle="tooltip" data-placement="bottom" title="" data-original-title="ysh901108@naver.com">Sung-Hyun Yoon</a>, <a href="/profile?email=hjyu%40uos.ac.kr" class="profile-link" data-toggle="tooltip" data-placement="bottom" title="" data-original-title="hjyu@uos.ac.kr">Ha-Jin Yu</a></span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">28 Sep 2018 (modified: 20 Nov 2018)</span><span class="item">ICLR 2019 Conference Withdrawn Submission</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Abstract: </span><span class="note_content_value">An adversarial process between two deep neural networks is a promising approach to train robust networks. In this study, we propose a framework for training networks that eliminates subsidiary information via the adversarial process. The objective of the proposed framework is to train a primary model that is robust to existing subsidiary information. This primary model can be used for various recognition tasks, such as digit recognition and speaker identification. Subsidiary information refers to the factors that might decrease the performance of the primary model such as channel information in speaker recognition and noise information in digit recognition.
Our proposed framework comprises two discriminative models for the primary and subsidiary task, as well as an encoder network for feature representation. A subsidiary task is an operation associated with subsidiary information such as identifying the noise type. The discriminative model for the subsidiary task is trained for modeling the dependency of subsidiary class labels on codes from the encoder. Therefore, we expect that subsidiary information could be eliminated by training the encoder to reduce the dependency between the class labels and codes. In order to do so, we train the weight parameters of the subsidiary model; then, we develop the codes and the parameters of subsidiary model to make them orthogonal. For this purpose, we design a loss function to train the encoder based on cosine similarity between the weight parameters of the subsidiary model and codes. Finally, the proposed framework involves repeatedly performing the adversarial process of modeling the subsidiary information and eliminating it. Furthermore, we discuss possible applications of the proposed framework: reducing channel information for speaker identification and domain information for unsupervised domain adaptation.  </span></div><div class="note_contents"><span class="note_content_field">Keywords: </span><span class="note_content_value">adversarial process, cosine similarity, speaker identification, domain adaptation</span></div><div class="reply_row clearfix"><div class="item" id="reply_count">4 Replies</div></div></div><hr class="small" /><div id="note_children"><div class="note_with_children"><div id="note_SJxB67GxRX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Submission Withdrawn by the Authors</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=S1eL8i0cFm&amp;noteId=SJxB67GxRX"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper176 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">19 Nov 2018</span><span class="item">ICLR 2019 Conference Paper176 Withdraw Submission</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Withdrawal confirmation: </span><span class="note_content_value">I have read and agree with the withdrawal statement on behalf of myself and my co-authors.</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_S1l0Ivcq3m" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>The paper proposes a new way to utilize the discriminator in adversarial learning. The method seems reasonable and effective, but the paper writing needs significant improvement.</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=S1eL8i0cFm&amp;noteId=S1l0Ivcq3m"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper176 AnonReviewer3</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">03 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper176 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">Pros:
1) The paper utilizes the concept of adversarial learning for eliminating unwanted information from the original input and treats domain adaptation and noise removal as two cases. Such a viewpoint is appreciated.

2) A new way of utilizing the discriminator S to update the encoder---by forcing the features to be orthogonal to the classifier weights---is proposed. The method seems more stable.

Cons:
1) The paper needs significant rewriting. First of all, the motivations are not clear. The introduction simply ignores the problem to be resolved. The abstract (as well as Section 2) looks like a plain description of the technical details instead of highlighting the motivations and contributions. The related work should include discussions on both noisy removal and domain adaptation.

2) The main difference between the proposed method to existing adversarial learning methods is in how to use the information form the discriminator S. To give a more meaningful comparison, I would suggest the authors having a section detailedly comparing the math formulations to support the claim. I would also suggest the authors looking into other models/problems where adversarial learning is being used and see if the proposed idea can be applied---this will make the proposed method widely applicable and have more impact. 

3) Section 4 needs improvement.
3-1) From Fig 3, it seems all the compared methods already perform pretty good. Data from each speaker are already clustered very well.
3-2) It would be great to have tables summarizing the essential statistics of datasets being used.
3-3) For Table 2, more compared baselines are needed.

Other comments:
1) The authors mentioned that Yu's 2017 method is not applicable to the experiments. Then how do they still implement it in Table 1?
 </span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">4: Ok but not good enough - rejection</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">3: The reviewer is fairly confident that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_ryg44h-v3X" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Confusing writing and limited novelty</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=S1eL8i0cFm&amp;noteId=ryg44h-v3X"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper176 AnonReviewer2</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">31 Oct 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper176 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">The authors propose a training procedure to avoid models relying on "subsidiary information" while being optimized for a certain task, through a cosine similarity based adversarial process. The authors propose to use this measure to force orthogonality between the features extracted and the weights associated with a subsidiary task.

While the idea of removing information not related to the main task of a learning system in order to better generalize is an interesting direction, the novelty of this paper is limited, and the current version contains several flaws. 

First of all, the paper is very confusingly written. A proper problem formulation, with a more formal definition of what "subsidiary information" is, is necessary to walk the reader through the paper. For instance, the introduction is extremely scarce of details (paradoxically, the abstract has more), and there is a logic gap between the description of Generative Adversarial Networks (GANs) and the introduction of the cosine similarity method. The authors write that it "differs from existing GANs in that it trains the discriminative model by using the cosine similarity-based adversarial process"; this is a confusing statement, as the method proposed by the authors is not a generative model. At most, this is what makes the proposed method differ from Ganin et al. (ICML2015).

A proper description of the training procedure is missing. How subsidiary information is eliminated is clarified by Figure 2, but it is not clear how and when E and M are trained to perform the primary task. Does this happen only before the iterative procedure? Observing Figure 2, it seems that E and M are never trained to perform the primary task of interest while running the iterative procedure. This seems wrong, because in the described in Figure 2.b the weights of the encoder E are updated and thus also the feature space on which M was trained is changed. Also, what is the stop condition of the iterative procedure? How can one determine if the subsidiary information has been eliminated or not from the codes? Summarizing, the overall training procedure needs to be better detailed. Perhaps with the aid of an Algorithm box to detail the procedure step-by-step? 

This statement of related works confused this reviewer: "in particular, our proposed CAN framework is designed to work without target samples". Do the authors mean that in the speaker recognition experiment the target is not used? Because it certainly is in the unsupervised domain adaptation experiments, by definition of the problem formulation. If the target is not used in the speaker recognition experiment, a suggestion to the authors is to read something from the literature about "domain generalization".

Concerning unsupervised domain adaptation, the related work section is not complete, the authors only cite Ganin et al. (ICML2015) and Tzeng et al. (CVPR2017), but the literature is not limited to these two works. The authors should include all the relevant works and provide the connections between the proposed method and the related method to let the reader fully understand the contributions. This also makes Table 2 incomplete, as the authors only compare their method against ADDA. It should include at least more recent, effective approaches, which perform substantially better on the faced tasks.

Furthermore, since the proposed approach in unsupervised domain adaptation is very related to Ganin et al. (ICML2015), where the domain information is eliminated from the features through adversarial training, the two methods should be compared in a fairer fashion. In particular, they should be compared using the same network architectures and possibly with the same settings (Leaky ReLU, L2 normalization). This experiment would make the reader better understand and appreciate the pros (and, eventually, cons) of using cosine similarity instead of vanilla adversarial training. At present, the effectiveness of using cosine similarity is not clear.

Due to the aforementioned issues with the current version, this reviewer does not recommend this work for acceptance to ICLR 2019.</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">3: Clear rejection</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div><div class="note_with_children"><div id="note_B1evr18Asm" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>A borderline paper. </a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=S1eL8i0cFm&amp;noteId=B1evr18Asm"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper176 AnonReviewer1</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">25 Oct 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper176 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">The authors proposed a deep framework that incorporating adversarial training process for eliminating the subsidiary information from the input data. In particular, to remove the subsidiary context, a main task neural network M and a subsidiary task neural networks are trained in an alternative way. With that, the authors present intuitive results on some real-world tasks, such as domain adaptations, and reducing channel information. In general, the paper is well-organized and clearly represented. Despite this, there lacks some insightful analysis of the proposed approach, and the empirical studies should be enriched. In particular:
(1) the authors claimed that "the performance of S degrades, and the performance of M increases, consequently. ", which is arbitrary and not well motivated. As the subsidiary information is removed from E, why the performance of S will degrade? 
(2) for the proposed objective function, more discussion should be provided regarding the intuition. The loss function is minimized over the cosine similarity between the E and W_i^{sub} for each class i. It is unclear whether useful information is also eliminated from the embedding E, especially some subsidiary is either relevant or correlated with the main task space.
(3) why L2 normalization can increase the efficiency of the proposed framework?
(4) I would expect the authors could provide more empirical studies over more benchmark datasets and comparing with more baselines. It will largely convince the readers with such experimental results. </span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">5: Marginally below acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></main></div>
  </div>
</div>


    <!-- Footer -->
    <footer class="sitemap">
      <div class="container">
        <div class="row hidden-xs">
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/venues">All Venues</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="/contact">Contact</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
    
        <div class="row visible-xs-block">
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/contact">Contact</a></li>
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
      </div>
    </footer>
    
    <footer class="sponsor">
      <div class="container">
        <div class="row">
          <div class="col-sm-10 col-sm-offset-1">
            <p class="text-center">
              OpenReview is created by the <a href="http://www.iesl.cs.umass.edu/" target="_blank">Information Extraction and Synthesis Laboratory</a>, College of Information and Computer Science, University of Massachusetts Amherst. We gratefully acknowledge the support of the OpenReview sponsors:  Google,  Facebook, NSF, the University of Massachusetts Amherst Center for Data Science, and Center for Intelligent Information Retrieval, as well as the Google Cloud Platform for donating the computing and networking services on which OpenReview.net runs.
            </p>
          </div>
        </div>
      </div>
    </footer>

  <div id="feedback-modal" class="modal fade" tabindex="-1" role="dialog">
    <div class="modal-dialog">
      <div class="modal-content">
        <div class="modal-header">
          <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">Ã—</span></button>
          <h3 class="modal-title">Send Feedback</h3>
        </div>
        <div class="modal-body">
          <p>Enter your feedback below and we'll get back to you as soon as possible.</p>
          <form action="/feedback" method="POST">
            <div class="form-group">
              <input type="email" name="from" class="form-control" placeholder="Email" />
            </div>
            <div class="form-group">
              <input type="text" name="subject" class="form-control" placeholder="Subject" />
            </div>
            <div class="form-group">
              <textarea name="message" class="form-control feedback-input" rows="5" placeholder="Message" required=""></textarea>
            </div>
          <ul id="ui-id-2" tabindex="0" class="ui-menu ui-widget ui-widget-content" style="display: none;"></ul></form>
        </div>
        <div class="modal-footer">
          <button type="button" class="btn btn-default" data-dismiss="modal">Cancel</button>
          <button type="button" class="btn btn-primary">Send</button>
        </div>
      </div>
    </div>
  </div>

  <script type="text/javascript" async="" src="https://www.google-analytics.com/analytics.js"></script><script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js"></script>
  <script>window.jQuery || document.write('&lt;script src="/static/js/vendor/jquery-2.2.4.min.js"&gt;&lt;\/script&gt;')</script>

  <script src="/static/dist/vendor.min.js"></script>
  <script src="/static/dist/templates.min.js"></script>
  <script src="/static/dist/openreview.min.js"></script>

    <script>window.legacyScripts = true;</script>


    <script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-108703919-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() { dataLayer.push(arguments); }
      gtag('js', new Date());
      gtag('config', 'UA-108703919-1');
    </script>


<div role="status" aria-live="assertive" aria-relevant="additions" class="ui-helper-hidden-accessible"></div></body></html>
<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" class="no-js"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>Learning to Make Analogies by Contrasting Abstract Relational Structure | OpenReview</title>
  <meta name="description" content="" />

      <meta name="citation_title" content="Learning to Make Analogies by Contrasting Abstract Relational Structure" />
        <meta name="citation_author" content="Anonymous" />
      <meta name="citation_publication_date" content="2018/09/27" />
      <meta name="citation_online_date" content="2018/09/27" />
      <meta name="citation_pdf_url" content="https://openreview.net/pdf?id=SylLYsCcFm" />
      <meta name="twitter:card" content="summary" />
      <meta name="twitter:site" content="@openreviewnet" />
      <meta name="og:title" content="Learning to Make Analogies by Contrasting Abstract Relational..." />
      <meta name="og:description" content="Analogical reasoning has been a principal focus of various waves of AI research. Analogy is particularly challenging for machines because it requires relational structures to be represented such..." />
      <meta name="og:image" content="https://openreview.net/static/images/openreview_logo_512.png" />

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans:400,400i,700,700i" />

  <link rel="stylesheet" href="/static/css/bootstrap.min.css" />
  <link rel="stylesheet" href="/static/css/jquery-ui.min.css" />
  <link rel="stylesheet" href="/static/css/main.min.css" />
</head>

<body class="forum">
  <nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
  
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand home push-link" href="/"><strong>OpenReview</strong>.net</a>
      </div>
  
      <div id="navbar" class="navbar-collapse collapse">
        <form class="navbar-form navbar-left profile-search" role="search">
          <div class="form-group has-feedback">
            <input id="search_input" type="text" class="form-control ui-autocomplete-input" placeholder="Search ICLR 2019 Conference" autocomplete="off" />
            <span class="glyphicon glyphicon-search form-control-feedback" aria-hidden="true"></span>
          </div>
  
          <input id="search_group" type="hidden" value="ICLR.cc/2019/Conference" />
          <input id="search_content" type="hidden" value="all" />
        <ul id="ui-id-1" tabindex="0" class="ui-menu ui-widget ui-widget-content ui-autocomplete ui-front" style="display: none;"></ul></form>
  
        <ul class="nav navbar-nav navbar-right">
        
            <li id="user-menu"><a href="/login">Login</a></li>
        </ul>
      </div>
  
    </div>
  </nav>

  <div id="or-banner" class="banner" style="">
  <div class="container">
    <div class="row">
      <div class="col-xs-12"><a href="/group?id=ICLR.cc/2019/Conference" title="Venue Homepage"><img class="icon" src="/static/images/arrow_left.svg" /> Go to <strong>ICLR 2019 Conference</strong> homepage</a></div>
    </div>
  </div>
</div>
<div id="flash-message-container" class="alert alert-danger" role="alert" style="display: none;">
  <div class="container">
    <div class="row">
      <div class="col-xs-12">
        <div class="alert-content">
          <button type="button" class="close" aria-label="Close"><span aria-hidden="true">×</span></button>
        </div>
      </div>
    </div>
  </div>
</div>

<div class="container">
  <div class="row">
    <div class="col-xs-12">
      <main id="content" class="clearfix openbanner-visible legacy-styles"><div id="note_SylLYsCcFm" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Learning to Make Analogies by Contrasting Abstract Relational Structure</a> <a class="note_content_pdf" href="/pdf?id=SylLYsCcFm" title="Download PDF" target="_blank"><img src="/static/images/pdf_icon_blue.svg" /></a> </h2></div><div class="meta_row"><span class="signatures">Anonymous</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">28 Sep 2018 (modified: 11 Oct 2018)</span><span class="item">ICLR 2019 Conference Blind Submission</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span><span class="item"><a class="action-bibtex-modal" data-bibtex="@inproceedings{    &#10;anonymous2019learning,    &#10;title={Learning to Make Analogies by Contrasting Abstract Relational Structure},    &#10;author={Anonymous},    &#10;booktitle={Submitted to International Conference on Learning Representations},    &#10;year={2019},    &#10;url={https://openreview.net/forum?id=SylLYsCcFm},    &#10;note={under review}    &#10;}">Show Bibtex</a></span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Abstract: </span><span class="note_content_value">Analogical reasoning has been a principal focus of various waves of AI research. Analogy is particularly challenging for machines because it requires relational structures to be represented such that they can be flexibly applied across diverse domains of experience. Here, we study how analogical reasoning can be induced in neural networks that learn to perceive and reason about raw visual data. We find that the critical factor for inducing such a capacity is not an elaborate architecture, but rather, careful attention to the choice of data and the manner in which it is presented to the model. The most robust capacity for analogical reasoning is induced when networks learn analogies by contrasting abstract relational structures in their input domains, a training method that uses only the input data to force models to learn about important abstract features. Using this technique we demonstrate capacities for complex, visual and symbolic analogy making and generalisation in even the simplest neural network architectures.</span></div><div class="note_contents"><span class="note_content_field">Keywords: </span><span class="note_content_value">cognitive science, analogy, psychology, cognitive theory, cognition, abstraction, generalization</span></div><div class="note_contents"><span class="note_content_field">TL;DR: </span><span class="note_content_value">The most robust capacity for analogical reasoning is induced when networks learn analogies by contrasting abstract relational structures in their input domains.</span></div><div class="reply_row clearfix"><div class="item" id="reply_count">9 Replies</div></div></div><hr class="small" /><div id="note_children"><div class="note_with_children"><div id="note_SJx77lip2Q" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Interesting direction and nice discussions, but evaluation and analysis are not strong enough </a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=SylLYsCcFm&amp;noteId=SJx77lip2Q"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper446 AnonReviewer1</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">05 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper446 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">This work investigates the ability of a neural network to learn analogy. They showed that a simple neural network is able to solve analogy problems with image or abstract input, given that the training data is selected to contrast abstract relational structures. 

The paper is relatively well-written with rich discussions. Some details about the experiments are missing like how many examples are used for training and testing. It is also important to show how much variations are in the dataset, and there should be some external baselines like those proposed in (Barrett et al, 2018). 

Although the performance is relatively high, some error analysis will provide more insights into what the neural network is missing and if it makes mistakes similar to human. 

Section 4 claims that “For a model trained via LABC, we found that these activities clustered according to relation type (e.g. progression ) more-so than domain”. However, it is unclear whether Figure 4 can support this. Some quantitive measure should help, for example, the average distance within the clusters between clustering based on relation type and domain. 

The novelty of the proposed approach is limited. The difference between the proposed method and baseline in performance seems to be a result of whether there is a difference between train and test setting. For example, if trained in “contrasting” will have better test performance on “contrasting” but worse on “normal” and vice versa. 

The problem is very interesting and the discussion is extensive. However, the proposed approach isn’t very novel and the evaluation and analysis should be improved to provide a stronger support. 

Barrett, David GT, et al. "Measuring abstract reasoning in neural networks." arXiv preprint arXiv:1807.04225 (2018).</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">5: Marginally below acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">3: The reviewer is fairly confident that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_SyenWffTX" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>response to reviewer 1</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=SylLYsCcFm&amp;noteId=SyenWffTX"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper446 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">09 Nov 2018</span><span class="item">ICLR 2019 Conference Paper446 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Thanks for the review -- we’re glad you find the problem interesting! 

You are right that we could have included more details of the visual analogy dataset to give a sense of its variety and scope. The training set contained 600,000 samples, 10,000 for validation, and 100,000 for testing. Regarding the variation in the dataset: are you referring to the number of possible questions? While the number of domains and relations is small, the combinatorics of the puzzles (born out through the choices for source and target domains, the relations, the values of the attributes, etc.) ensures that the dataset is highly variable. For example, a quick back-of-the-envelope calculation shows that there are nearly 8 billion possible analogy questions (source domain + target domain) that the generator could produce. Moreover, variability in the possible incorrect choices further increases the number of possible questions to an astronomical amount. I hope this gives some sense of the scope of the dataset: we will add a table detailing these statistics to the appendix.

We agree that it would be interesting to see how the model fails and whether the ways are similar to the ways in which humans fail. We’re performing this analysis now, and will be able to share specific failure cases with you soon. Additionally, we are testing a wider range of existing models models. We’d like to note, though, that the appropriate baselines are comparisons *within* model-type; that is, using normal or LABC training on the same model. Our choice of model (an RNN -- not even an LSTM!) was deliberately as simple as possible so as to emphasize the effect of the training method; we agree, however, that it would be useful to corroborate the effect we observed using other well-known (and closer to state-of-the-art) architectures. 

Regarding quantitative measures for the clustering analysis. We performed this analysis and found that the inter-class cluster means are greater in LABC compared to normal training (5.2 vs. 4.4), confirming the intuition that can be gleaned from the figure. We will soon compile further analyses with results of new experiments into a new comment addressed to all reviewers. 

Would you mind clarifying your opinion that the method is not novel? As far as we are aware, there is no prior work that has analyzed the effects of negative examples on out-of-distribution generalization. Indeed, there is very little work at all addressing out-of-distribution generalization in abstract relational spaces. The closest work that we are aware is the triplet loss in computer vision, and some recent work in generative adversarial training. However, this work did not study the effects of the training method on out-of-distribution generalization, as we have. If you can provide specific examples of similar work, we'll try to explain where this study differs.
</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div><div class="note_with_children"><div id="note_S1gWz6NqhQ" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>The paper describes an approach to train neural networks for analogical reasoning tasks by selecting training instances that force the network to learn relational structure</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=SylLYsCcFm&amp;noteId=S1gWz6NqhQ"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper446 AnonReviewer2</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">03 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper446 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">The paper describes an approach to train neural networks for analogical reasoning tasks.

General analogical reasoning is quite a significant milestone in Machine learning. Therefore, the paper tackles an extremely challenging problem.  The paper does a good job of constructing various tasks to show that analogies can be learned in different scenarios which are complex analogy tasks. Specifically, visual analogy and symbolic analogies are considered. The main idea is to choose training examples such that the model is forced to learn the relational structure rather than simply learn superficial features. One weakness is that we need to hand code the training examples to force it to have contrasting relational structure for different tasks. Is this realistic in different problems? That is maybe a limiting factor of this work. An automated method for generating such examples is given, but there is not too much detail on this (5.3). Maybe this needs to be expanded.

Also, is the idea of LABC different from SMT. The novelty may be a bit weak in this aspect. If LABC  can be described in a more general manner, it would help a reader not familiar with the other related work.  Since the baseline comparison is with a very weak method (randomly chosen examples), it is hard to judge the impact of the proposed approach. In summary, I think the paper has nice ideas, particularly, if we can automatically generate examples using LABC. but maybe there is a need to work on better organizing the ideas, more general formulation of LABC and a more convincing experimental evaluation that includes a state-of-the-art method if available</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">5: Marginally below acceptance threshold</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">3: The reviewer is fairly confident that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_H1xPezMMTm" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>response to reviewer 2</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=SylLYsCcFm&amp;noteId=H1xPezMMTm"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper446 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">09 Nov 2018</span><span class="item">ICLR 2019 Conference Paper446 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Thank you for your review! 

You mention that one weakness is the need to hand code the training examples such that they have contrasting relational structure. We believe that there may be some deep, important links between LABC, generative adversarial training, and even self-play dynamics. Indeed, the latter two approaches may be seen as automated methods that can approximate LABC. For example, in self-play, agents continuously challenge their opponents by proposing maximally challenging data. In the context of our work, maximally challenging data are analogous to answer choices that are congruent at the level of abstract relational structure, as opposed to simply perceptual structure. 

Although we believe there are links to these other methods that may naturally automate candidate generation, no work, to our knowledge, has explored the effects of generative adversarial training or self-play on out-of-distribution generalization, especially in a training setup as we have demonstrated. And so, since this link is as of now just intuitive, we did not want to overclaim in the paper and propose these as natural methods of automating an LABC-like procedure to induce out-of-distribution generalization. We had hoped that our experiment on generative candidate proposals in the symbolic analogy task could point in this direction without overclaiming. Do you think it is appropriate to expand on these points in the paper?

There is a very important point that we’d like to clarify. You note that “[s]ince the baseline comparison is with a very weak method (randomly chosen examples), it is hard to judge the impact of the proposed approach”. We believe this may be a misunderstanding. The baseline comparison is actually quite strong, as we do not choose *truly random* candidates in this condition. Rather, the candidates in this baseline condition are *perceptually plausible* given the visuals of the context panels (i.e. they are always taken from the target domain). For example, if the context panels contain 1 circle, then 2 circles, then a possible answer choice would have 4 circles. A possible answer choice would *not* contain something as truly random as various colored lines; if the training questions had such truly random candidates we think it is obvious that the model would learn very little of interest at all - it would learn the most superficial ability to match the visuals of the question and the answer, and yield no generalisation whatsoever. If you would like, we can run an experiment to demonstrate this, and will update the text to reflect our procedure for generating baseline candidates.

Finally, regarding LABC and SMT, there are indeed some crucial differences. First, SMT is a psychological description of a human phenomena. It describes how humans tend to make analogies by mapping relational structures from one domain to another. LABC, on the other hand, is a *training* method. LABC contends that if a model is coaxed into *learning* to map relational structure, then it will be better at making analogies, as evidenced by out-of-distribution generalization. And indeed, our results show that this may be the case. Thank you for pointing out that these ideas are not clear -- we will try to update the description of LABC to better situate it in the previous literature. 
</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_rkgGYJ4Z0X" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Reading author response</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=SylLYsCcFm&amp;noteId=rkgGYJ4Z0X"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper446 AnonReviewer2</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">20 Nov 2018</span><span class="item">ICLR 2019 Conference Paper446 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">I am happy with the author response. Thanks for the clarification regarding experiments..I think the experiments section is a little more clear to me in terms of the baselines used. Also I think "applying" the idea of SMT into a concrete learning algorithm seems to be a good contribution.</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div></div></div><div class="note_with_children"><div id="note_BygdZ9AvnQ" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Intuitive idea for improved training demonstrated powerful in the analogy domain</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=SylLYsCcFm&amp;noteId=BygdZ9AvnQ"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper446 AnonReviewer3</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">01 Nov 2018 (modified: 07 Nov 2018)</span><span class="item">ICLR 2019 Conference Paper446 Official Review</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Review: </span><span class="note_content_value">Cons

1.	It’s unclear why LABC produces lower scores than ‘normal’ training on ‘normal’ testing.
2.	The text says nothing I can find to explain why in Fig 5 the ‘entity’ vectors have all 0s except in one dimension, which seems to make the problem considerably easier.
3.	In a sense, there is no cross-domain adaptation required in the symbolic task: min is min, whether it operates on dimension k of the source vectors or dimension j of the target vectors. On the other hand, dimensions are processed independently in the model, as far as I can tell, so there’s no free transfer of learning min on dimension k to knowing min on dimension j. It would be good to comment on this issue.
4.	There seem to be obvious analogies (so to speak) to GANs, and it is very curious that this is not mentioned anywhere that I can see. This is particularly glaring in Sec. 5.3.
5.	The quantitative results are scattered throughout the prose; it would be challenging, but worthwhile, to gather them into an actual table.

Pros

6.	The basic idea (“We should aspire to select as negative examples those examples that are plausible considering the most abstract principles that describe the data”, p. 14) is very intuitive, common-sensical, bordering on obvious. But it is not at all obvious that the idea has as much power as is demonstrated in the experiments. The transfer to novel domain combinations, novel domains, and novel values of dimensions is impressive and surprising.
7.	The result that the proposed training, designed to promote generalization on analogy tasks, also seems to promote improved sensory processing is interesting. Whether it really instantiates the parallel connection argued for by the High-Level Perception view from psychology/philosophy is debatable, but that is itself an interesting connection that the authors should be praised for identifying.
8.	In general, the connection to the cognitive literature is creative and tantalizing and provides good scientific grounding for the work.
9.	The linking to the flexibility of word meanings in the final paragraph pushes the limit of the plausibility of connection to broader cognitive issues, but I’m inclined to indulge the authors for at least bringing up this important and relevant issue.  
</span></div><div class="note_contents"><span class="note_content_field">Rating: </span><span class="note_content_value">7: Good paper, accept</span></div><div class="note_contents"><span class="note_content_field">Confidence: </span><span class="note_content_value">4: The reviewer is confident but not absolutely certain that the evaluation is correct</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_HJgeOMGM6m" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>response to reviewer 3</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=SylLYsCcFm&amp;noteId=HJgeOMGM6m"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper446 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">09 Nov 2018</span><span class="item">ICLR 2019 Conference Paper446 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">Thanks for your review, we're grateful you like the work!

We have given a lot of thought to your point 1. We're running experiments now to mix clever (semantically-plausible) and random (perceptually-plausible) candidates in a more refined way, hoping to train a model that does not degrade at all on test questions involving perceptually-plausible candidates while retaining the strong ability to generalise in the case of semantically-plausible candidates. Would such a result satisfy your reservations here? Having said all this, we don't believe this uncertainty detracts from the fact that a model trained to contrast abstract relational structure generalises more accurately and in a wider-range of out-of-distribution cases than one trained otherwise.  

Regarding the entity vectors having all 0’s in the unused dimensions, we agree that this makes the problem easier. This experiment was designed to explicitly test domain-transfer generalization moreso than an ability to discern the domains that need to be considered. The idea was to strip away any difficulties in perception (i.e., in identifying the relevant domains) to see if the effect of LABC persisted. As you note, “dimensions are processed independently in the model...so there’s no free transfer of learning min on dimension k to knowing min on dimension j.” This is indeed the case, and we will clarify this. At test time the model should have an easy time identifying the relevant dimensions, but it will never have seen the particular transfer from dimension i to dimension j. So, even though it may have an easy time identifying and processing each dimension, it may be incapable (without LABC) of integrating the information processed from each of these dimensions, which we demonstrate.

Regarding the link to GANs -- we believe there is a very interesting, potentially deep connection to GAN training, as well as self-play. Please see our reply to R2 for more thoughts here. We think that drawing connections between these methods is a very promising line of future work. We erred on the side of not overclaiming, and not drawing links that we have not rigorously proved, but our minds are definitely oriented in this direction, and we can add some text alluding to these ideas if you believe it necessary.
</span></div><div class="reply_row clearfix"></div></div><div class="children"><div class="note_with_children"><div id="note_H1l7cB-sa7" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>reply to response to Rev 3</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=SylLYsCcFm&amp;noteId=H1l7cB-sa7"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper446 AnonReviewer3</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">15 Nov 2018</span><span class="item">ICLR 2019 Conference Paper446 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">I agree with all the points in the authors' response to my Review (3).
I would indeed be satisfied by "a model that does not degrade at all on test questions involving perceptually-plausible candidates while retaining the strong ability to generalise in the case of semantically-plausible candidates" if you can manage it.
About the 0s, the text should state that the vectors have this property, and explain the rationale, i.e., what aspect of the problem the model is addressing. 
My comment about there being "no free transfer" was actually in reference to the potential criticism that "the cross-domain mapping is trivial, there's nothing to learn there: min maps to min" which as my "no free transfer" comment pointed out, is not actually valid.
A mention of GAN is recommended, even as entirely future work, as the omission is GLARING.</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></div></div></div><div class="note_with_children"><div id="note_HJeoWFkec7" class="note panel"><div class="title_pdf_row clearfix"><h2 class="note_content_title"><a>Error in caption of figure 1</a>  <button class="btn btn-xs btn-default permalink-button" title="Link to this comment" data-permalink-url="https://openreview.net/forum?id=SylLYsCcFm&amp;noteId=HJeoWFkec7"><span class="glyphicon glyphicon-link" aria-hidden="true"></span></button></h2></div><div class="meta_row"><span class="signatures">ICLR 2019 Conference Paper446 Authors</span></div><div class="clearfix"><div class="meta_row pull-left"><span class="date item">02 Oct 2018</span><span class="item">ICLR 2019 Conference Paper446 Official Comment</span><span class="item">Readers: <span class="readers-icon glyphicon glyphicon-globe"></span> Everyone</span></div><div class="meta_row meta_actions"></div></div><div class="note_contents"><span class="note_content_field">Comment: </span><span class="note_content_value">The caption to Figure 1 refers to an old caption. It should read: In this analogy puzzle, the model must identify a relation
(Progression ) on a particular domain ( shape quantity ) in the source sequence (top), and apply it to a different domain ( line color) in order to find the candidate answer panel that correctly completes target sequence (bottom). Apologies - we will fix up asap.</span></div><div class="reply_row clearfix"></div></div><div class="children"></div></div></div></main></div>
  </div>
</div>


    <!-- Footer -->
    <footer class="sitemap">
      <div class="container">
        <div class="row hidden-xs">
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/venues">All Venues</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="/contact">Contact</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-sm-4">
            <ul class="list-unstyled">
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
    
        <div class="row visible-xs-block">
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/" class="home">Home</a></li>
              <li><a href="/about">About OpenReview</a></li>
              <li><a href="#" data-toggle="modal" data-target="#feedback-modal">Feedback</a></li>
            </ul>
          </div>
    
          <div class="col-xs-6">
            <ul class="list-unstyled">
              <li><a href="/contact">Contact</a></li>
              <li><a href="/terms">Terms of Service</a></li>
              <li><a href="/privacy">Privacy Policy</a></li>
            </ul>
          </div>
        </div>
      </div>
    </footer>
    
    <footer class="sponsor">
      <div class="container">
        <div class="row">
          <div class="col-sm-10 col-sm-offset-1">
            <p class="text-center">
              OpenReview is created by the <a href="http://www.iesl.cs.umass.edu/" target="_blank">Information Extraction and Synthesis Laboratory</a>, College of Information and Computer Science, University of Massachusetts Amherst. We gratefully acknowledge the support of the OpenReview sponsors:  Google,  Facebook, NSF, the University of Massachusetts Amherst Center for Data Science, and Center for Intelligent Information Retrieval, as well as the Google Cloud Platform for donating the computing and networking services on which OpenReview.net runs.
            </p>
          </div>
        </div>
      </div>
    </footer>

  <div id="feedback-modal" class="modal fade" tabindex="-1" role="dialog">
    <div class="modal-dialog">
      <div class="modal-content">
        <div class="modal-header">
          <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button>
          <h3 class="modal-title">Send Feedback</h3>
        </div>
        <div class="modal-body">
          <p>Enter your feedback below and we'll get back to you as soon as possible.</p>
          <form action="/feedback" method="POST">
            <div class="form-group">
              <input type="email" name="from" class="form-control" placeholder="Email" />
            </div>
            <div class="form-group">
              <input type="text" name="subject" class="form-control" placeholder="Subject" />
            </div>
            <div class="form-group">
              <textarea name="message" class="form-control feedback-input" rows="5" placeholder="Message" required=""></textarea>
            </div>
          <ul id="ui-id-2" tabindex="0" class="ui-menu ui-widget ui-widget-content" style="display: none;"></ul></form>
        </div>
        <div class="modal-footer">
          <button type="button" class="btn btn-default" data-dismiss="modal">Cancel</button>
          <button type="button" class="btn btn-primary">Send</button>
        </div>
      </div>
    </div>
  </div>

  <script type="text/javascript" async="" src="https://www.google-analytics.com/analytics.js"></script><script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js"></script>
  <script>window.jQuery || document.write('&lt;script src="/static/js/vendor/jquery-2.2.4.min.js"&gt;&lt;\/script&gt;')</script>

  <script src="/static/dist/vendor.min.js"></script>
  <script src="/static/dist/templates.min.js"></script>
  <script src="/static/dist/openreview.min.js"></script>

    <script>window.legacyScripts = true;</script>


    <script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-108703919-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() { dataLayer.push(arguments); }
      gtag('js', new Date());
      gtag('config', 'UA-108703919-1');
    </script>


<div role="status" aria-live="assertive" aria-relevant="additions" class="ui-helper-hidden-accessible"></div></body></html>